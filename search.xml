<?xml version="1.0" encoding="utf-8"?>
<search> 
  
    
    <entry>
      <title>获取github解析地址方法,connect to github.com port 443 无法访问</title>
      <link href="/get-github-ip/"/>
      <url>/get-github-ip/</url>
      <content type="html"><![CDATA[<p>获取github解析地址方法，GitHub Connection refused 无法访问</p><p>国内经常出现访问不了github情况， github给了一个获取ip地址的接口。 &#x20;</p><p>我们可以手动获取， 配置本机hosts解析，就可以访问了。 &#x20;</p><p>拉取代码时候 &#x20;</p><p>Failed to connect to github.com port 443 : Timed out</p><p>或</p><p>fatal: unable to access ‘<a href="https://github.com/xxx.git/&#39;" target="_blank" rel="noopener">https://github.com/xxx.git/&#39;</a>: Failed to connect to github.com port 443: Connection refused</p><p>也可以解决这个问题。 或者是配置代理， （需要自己有代理地址。）</p><h2 id="配置hosts方法"><a href="#配置hosts方法" class="headerlink" title="配置hosts方法"></a>配置hosts方法</h2><p>可以访问：</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://api.github.com/meta</span><br></pre></td></tr></table></figure><p>返回内容是json格式，我们可以在里面找到 git 值，里面的IP地址我们可以配置到 /etc/hosts 中。</p><p>如：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">20.199.39.232 github.com</span><br></pre></td></tr></table></figure><a id="more"></a><h3 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h3><p>测试命令，看看是否能连接</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ssh -vT git@github.com</span><br><span class="line">或</span><br><span class="line">ssh -vT -p 443 git@github.com</span><br></pre></td></tr></table></figure><h2 id="另外配置代理方法"><a href="#另外配置代理方法" class="headerlink" title="另外配置代理方法"></a>另外配置代理方法</h2><p>git 配置代理，需要自己有代理可以访问出去。</p><h3 id="全局代理"><a href="#全局代理" class="headerlink" title="全局代理"></a>全局代理</h3><p>通过 <code>git config --global</code> 可以设置全局代理，命令及示例如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 设置代理，http 和 https 都加上代理，代理到 http://127.0.0.1:1087 这个 vpn 本地 IP</span></span><br><span class="line">git config --global http.proxy http://127.0.0.1:1087</span><br><span class="line">git config --global https.proxy http://127.0.0.1:1087</span><br><span class="line"></span><br><span class="line"><span class="comment"># 取消代理</span></span><br><span class="line">git config --global --<span class="built_in">unset</span> http.proxy</span><br><span class="line">git config --global --<span class="built_in">unset</span> https.proxy</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看代理</span></span><br><span class="line">git config --global --get http.proxy</span><br><span class="line">git config --global --get https.proxy</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看全局所有配置</span></span><br><span class="line">git config --global --list</span><br></pre></td></tr></table></figure><h3 id="本地代理"><a href="#本地代理" class="headerlink" title="本地代理"></a>本地代理</h3><p>全局代理会将所有的 git 请求都使用这个代理，对于国内的或者公司内部的仓库，实际上是不需要的，加了反而拖慢速度。</p><p>故可以指定是 GitHub 的项目才走代理，其他的项目不走代理。</p><p>通过 <code>git config --local</code> 设置本项目代理，命令及示例如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 设置代理</span></span><br><span class="line">git config --<span class="built_in">local</span> http.proxy http://127.0.0.1:1087</span><br><span class="line">git config --<span class="built_in">local</span> https.proxy http://127.0.0.1:1087</span><br><span class="line"></span><br><span class="line"><span class="comment"># 取消代理</span></span><br><span class="line">git config --<span class="built_in">local</span> --<span class="built_in">unset</span> http.proxy</span><br><span class="line">git config --<span class="built_in">local</span> --<span class="built_in">unset</span> https.proxy</span><br></pre></td></tr></table></figure><h3 id="按源代理"><a href="#按源代理" class="headerlink" title="按源代理"></a>按源代理</h3><p>本地代理的不方便之处是，每个需要代理的 GitHub 项目都需要手工配置一次，实在麻烦。</p><p>所以可以通过直接修改 git 全局配置文件的方式，指定哪些请求源走代理，不指定的就不走代理。</p><p>修改全局 <code>.gitconfig</code> 配置文件（一般在 <code>~/.gitconfig</code>），增加如下代理配置即可。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 配置 http 代理</span></span><br><span class="line">[http <span class="string">"https://github.com"</span>]</span><br><span class="line">  proxy = http://127.0.0.1:1087</span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置 https 代理</span></span><br><span class="line">[https <span class="string">"https://github.com"</span>]</span><br><span class="line">  proxy = http://127.0.0.1:1087</span><br></pre></td></tr></table></figure>]]></content>
      
      <categories>
          
          <category> github </category>
          
      </categories>
      
      
        <tags>
            
            <tag> shell </tag>
            
            <tag> github </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>MacOS安装brew, 并更换国内源</title>
      <link href="/macos-install-brew/"/>
      <url>/macos-install-brew/</url>
      <content type="html"><![CDATA[<h2 id="MacOS-安装-brew，并更换国内源"><a href="#MacOS-安装-brew，并更换国内源" class="headerlink" title="MacOS 安装 brew，并更换国内源"></a>MacOS 安装 brew，并更换国内源</h2><p>brew 官网地址是: <a href="https://brew.sh/" target="_blank" rel="noopener">https://brew.sh/</a>  </p><p>上面有安装方法， 也是中文语言，但是国内经常访问不到。 我们可以用国内的地址。</p><p>国内，我们可以用gitee 上的代码：  </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/zsh -c <span class="string">"<span class="variable">$(curl -fsSL https://gitee.com/cunkai/HomebrewCN/raw/master/Homebrew.sh)</span>"</span></span><br></pre></td></tr></table></figure><p>按照步骤一步一步往下运行即可， &#x20;</p><p>这个脚本可以判断你的系统是否已经安装了brew， 是否需要重新安装。 &#x20;</p><p>并且可以设置国内的源，这样安装软件也可以了。  </p><a id="more"></a><h3 id="手动设置国内源的方法"><a href="#手动设置国内源的方法" class="headerlink" title="手动设置国内源的方法"></a>手动设置国内源的方法</h3><p>如果想手动设置源的方法，</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> HOMEBREW_INSTALL_FROM_API=1</span><br><span class="line"><span class="built_in">export</span> HOMEBREW_API_DOMAIN=<span class="string">"https://mirrors.tuna.tsinghua.edu.cn/homebrew-bottles/api"</span></span><br><span class="line"><span class="built_in">export</span> HOMEBREW_BOTTLE_DOMAIN=<span class="string">"https://mirrors.tuna.tsinghua.edu.cn/homebrew-bottles"</span></span><br><span class="line"><span class="built_in">export</span> HOMEBREW_BREW_GIT_REMOTE=<span class="string">"https://mirrors.tuna.tsinghua.edu.cn/git/homebrew/brew.git"</span></span><br><span class="line"><span class="built_in">export</span> HOMEBREW_CORE_GIT_REMOTE=<span class="string">"https://mirrors.tuna.tsinghua.edu.cn/git/homebrew/homebrew-core.git"</span></span><br></pre></td></tr></table></figure><h3 id="查看安装版本"><a href="#查看安装版本" class="headerlink" title="查看安装版本"></a>查看安装版本</h3><p>安装脚本执行完成后，重启终端。（重启后才生效） &#x20;</p><p>虽然叫做’Homebrew’，但实际使用时，命令是’brew’。 &#x20;</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">brew -v</span><br></pre></td></tr></table></figure><p>在M1芯片上，homebrew的安装路径为：”/opt/Homebrew/“ &#x20;</p><h3 id="卸载方法"><a href="#卸载方法" class="headerlink" title="卸载方法"></a>卸载方法</h3><p>如需卸载，使用指令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/bin/zsh -c <span class="string">"<span class="variable">$(curl -fsSL https://gitee.com/cunkai/HomebrewCN/raw/master/HomebrewUninstall.sh)</span>"</span></span><br></pre></td></tr></table></figure>]]></content>
      
      <categories>
          
          <category> mac </category>
          
      </categories>
      
      
        <tags>
            
            <tag> shell </tag>
            
            <tag> mac </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>setfacl 命令详解</title>
      <link href="/setfacl-command/"/>
      <url>/setfacl-command/</url>
      <content type="html"><![CDATA[<p>setfacl命令详解</p><p><code>setfacl</code>命令提供了强大的工具来管理文件和目录的权限，允许比传统UNIX权限模型更细粒度的控制。通过掌握这些选项和语法，可以灵活地配置系统中的访问控制策略。</p><p><code>setfacl</code> 命令用于设置或修改文件和目录的访问控制列表（ACL），ACL允许为文件或目录分配更精细的权限，超越传统的所有者、组、和其他用户权限模型。</p><h3 id="常用选项"><a href="#常用选项" class="headerlink" title="常用选项"></a>常用选项</h3><ul><li>-m：修改ACL。用于添加或修改文件或目录的ACL条目。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">setfacl -m u:username:rwx file</span><br></pre></td></tr></table></figure><p>解释：为用户username设置文件file的权限为rwx。</p><ul><li>-x：移除ACL。用于从文件或目录中移除指定的ACL条目。</li></ul><a id="more"></a><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">setfacl -x u:username file</span><br></pre></td></tr></table></figure><p>解释：移除用户username对文件file的ACL条目。</p><ul><li>-b：删除所有ACL。用于移除文件或目录的所有ACL条目。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">setfacl -b file</span><br></pre></td></tr></table></figure><p>解释：删除文件file的所有ACL条目，使其恢复为仅使用传统的rwx权限。</p><ul><li>-k：删除默认ACL。用于删除目录的默认ACL条目，但保留其他ACL条目。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">setfacl -k directory</span><br></pre></td></tr></table></figure><p>解释：删除目录directory的默认ACL条目。</p><ul><li>-d：默认ACL。用于设置目录的默认ACL条目，这些条目会被自动继承到新创建的文件和子目录。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">setfacl -d -m d:u:username:rwx directory</span><br></pre></td></tr></table></figure><p>解释：为目录directory设置用户username的默认ACL条目rwx。</p><ul><li>-R：递归应用ACL。用于递归设置指定目录及其子目录和文件的ACL。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">setfacl -R -m u:username:rwx directory</span><br></pre></td></tr></table></figure><p>解释：递归地为目录directory及其所有子目录和文件设置用户username的权限为rwx。</p><ul><li>-n：不重写掩码。在修改ACL时，保留现有的掩码值。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">setfacl -n -m u:username:rwx file</span><br></pre></td></tr></table></figure><p>解释：在不更改现有掩码的情况下，为用户username设置文件file的权限为rwx。</p><ul><li>--set：设置ACL。完全覆盖现有ACL，用新的ACL条目集替换现有的ACL。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">setfacl --<span class="built_in">set</span> u:username:rwx file</span><br></pre></td></tr></table></figure><p>解释：将文件file的ACL设置为仅用户username拥有rwx权限，删除所有其他ACL条目。</p><ul><li>-M：从文件读取ACL。用于从指定文件中读取ACL条目，并将其应用于目标文件或目录。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">setfacl -M aclfile file</span><br></pre></td></tr></table></figure><p>解释：从文件aclfile中读取ACL条目，并将其应用于文件file。</p><ul><li>-X：从文件中删除ACL。用于从指定文件中读取要删除的ACL条目。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">setfacl -X aclfile file</span><br></pre></td></tr></table></figure><p>解释：从文件aclfile中读取要删除的ACL条目，并将其从文件file的ACL中删除。</p><h3 id="ACL-条目格式"><a href="#ACL-条目格式" class="headerlink" title="ACL 条目格式"></a>ACL 条目格式</h3><p>ACL条目格式为<code>[d[efault]:][u[ser]:uid|g[roup]:gid|m[ask]|o[ther]]:perms</code>，其中：</p><ul><li><code>default</code>：指定为默认ACL，仅适用于目录。</li><li><code>user:uid</code>：用户权限条目。</li><li><code>group:gid</code>：组权限条目。</li><li><code>mask</code>：限制对文件的最大允许权限。</li><li><code>other</code>：其他用户的权限条目。</li><li><code>perms</code>：权限，<code>r</code>表示读取，<code>w</code>表示写入，<code>x</code>表示执行。</li></ul><h3 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h3><ol><li><p><strong>为文件设置特定用户的读写执行权限：</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">setfacl -m u:john:rwx myfile</span><br></pre></td></tr></table></figure><p>为用户<code>john</code>设置文件<code>myfile</code>的<code>rwx</code>权限。</p></li></ol><ol start="2"><li><p><strong>为目录及其子目录和文件递归设置权限：</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">setfacl -R -m g:developers:rwx /mydir</span><br></pre></td></tr></table></figure><p>为组<code>developers</code>递归地设置目录<code>/mydir</code>及其内容的<code>rwx</code>权限。</p></li></ol><ol start="3"><li><p><strong>删除某个用户的ACL条目：</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">setfacl -x u:john myfile</span><br></pre></td></tr></table></figure><p>移除用户<code>john</code>在文件<code>myfile</code>上的ACL条目。</p></li></ol><ol start="4"><li><p><strong>查看文件的ACL：</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">getfacl myfile</span><br></pre></td></tr></table></figure><p>使用<code>getfacl</code>查看文件或目录的ACL条目。</p></li></ol><h4 id="设置目录下所有新创建的子目录和文件的默认权限为775"><a href="#设置目录下所有新创建的子目录和文件的默认权限为775" class="headerlink" title="设置目录下所有新创建的子目录和文件的默认权限为775"></a>设置目录下所有新创建的子目录和文件的默认权限为775</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">setfacl -m d:u::rwx,d:g::rwx,d:o::r-x /path/to/directory</span><br></pre></td></tr></table></figure><p>解释：</p><p>d:u::rwx - 设置默认的用户权限为775 (rwx表示7)。<br>d:g::rwx - 设置默认的组权限为775 (rwx表示7)。<br>d:o::r-x - 设置默认的其他用户权限为775 (r-x表示5)。</p>]]></content>
      
      <categories>
          
          <category> shell </category>
          
      </categories>
      
      
        <tags>
            
            <tag> command </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>github-hosts</title>
      <link href="/github-hosts/"/>
      <url>/github-hosts/</url>
      <content type="html"><![CDATA[<p>  访问github的话，可以不用梯子，用配置hosts的方式来访问，hosts是变化的，可以用过gitlab地址来获取。</p><p>获取地址：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://gitlab.com/ineo6/hosts/-/raw/master/next-hosts</span><br></pre></td></tr></table></figure><p>内容如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"># New！欢迎使用基于DNS的新方案</span><br><span class="line"># https://gitlab.com/ineo6/hosts/-/raw/master/next-hosts</span><br><span class="line"># 地址可能会变动，请务必关注GitHub、Gitlab获取最新消息</span><br><span class="line"># 也可以关注公众号：湖中剑，保证不迷路</span><br><span class="line"># GitHub Host Start</span><br><span class="line"></span><br><span class="line">185.199.109.154              github.githubassets.com</span><br><span class="line">140.82.113.22                central.github.com</span><br><span class="line">185.199.110.133              desktop.githubusercontent.com</span><br><span class="line">185.199.111.153              assets-cdn.github.com</span><br><span class="line">185.199.108.133              camo.githubusercontent.com</span><br><span class="line">185.199.109.133              github.map.fastly.net</span><br><span class="line">151.101.193.194              github.global.ssl.fastly.net</span><br><span class="line">140.82.114.3                 gist.github.com</span><br><span class="line">185.199.109.153              github.io</span><br><span class="line">140.82.114.3                 github.com</span><br><span class="line">140.82.113.5                 api.github.com</span><br><span class="line">185.199.108.133              raw.githubusercontent.com</span><br><span class="line">185.199.109.133              user-images.githubusercontent.com</span><br><span class="line">185.199.111.133              favicons.githubusercontent.com</span><br><span class="line">185.199.108.133              avatars5.githubusercontent.com</span><br><span class="line">185.199.110.133              avatars4.githubusercontent.com</span><br><span class="line">185.199.110.133              avatars3.githubusercontent.com</span><br><span class="line">185.199.110.133              avatars2.githubusercontent.com</span><br><span class="line">185.199.111.133              avatars1.githubusercontent.com</span><br><span class="line">185.199.109.133              avatars0.githubusercontent.com</span><br><span class="line">185.199.109.133              avatars.githubusercontent.com</span><br><span class="line">140.82.112.9                 codeload.github.com</span><br><span class="line">52.217.229.241               github-cloud.s3.amazonaws.com</span><br><span class="line">52.217.133.73                github-com.s3.amazonaws.com</span><br><span class="line">52.217.130.81                github-production-release-asset-2e65be.s3.amazonaws.com</span><br><span class="line">52.217.138.161               github-production-user-asset-6210df.s3.amazonaws.com</span><br><span class="line">52.217.132.241               github-production-repository-file-5c1aeb.s3.amazonaws.com</span><br><span class="line">185.199.111.153              githubstatus.com</span><br><span class="line">140.82.112.17                github.community</span><br><span class="line">185.199.108.133              media.githubusercontent.com</span><br><span class="line">185.199.111.133              objects.githubusercontent.com</span><br><span class="line">185.199.109.133              raw.github.com</span><br><span class="line">20.221.80.166                copilot-proxy.githubusercontent.com</span><br><span class="line"></span><br><span class="line"># Please Star : https://github.com/ineo6/hosts</span><br><span class="line"># Mirror Repo : https://gitlab.com/ineo6/hosts</span><br><span class="line"></span><br><span class="line"># Update at: 2023-06-25 16:14:11</span><br><span class="line"></span><br><span class="line"># GitHub Host End</span><br></pre></td></tr></table></figure><p>将内容配置到hosts中即可。</p>]]></content>
      
      <categories>
          
          <category> doc </category>
          
      </categories>
      
      
        <tags>
            
            <tag> github </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>alluxio-install</title>
      <link href="/alluxio-install/"/>
      <url>/alluxio-install/</url>
      <content type="html"><![CDATA[<h1 id="Alluxio-安装文档"><a href="#Alluxio-安装文档" class="headerlink" title="Alluxio 安装文档"></a>Alluxio 安装文档</h1><p>  Alluxio是一个基于内存的分布式文件系统，它是架构在底层分布式文件系统和上层分布式计算框架之间的一个中间件，主要职责是以文件形式在内存或其它存储设施中提供数据的存取服务。<br><br>  <br></p><h3 id="架构图"><a href="#架构图" class="headerlink" title="架构图"></a>架构图</h3><!-- ![架构图.jpg](https://file.moetu.org/images/2022/12/27/1122e07b6ea41cc259ac.jpg)<br> --><p><img src="https://i.niupic.com/images/2023/12/26/ekIf.png" alt="架构图.jpg"><br></p><a id="more"></a><p>  在大数据生态系统中，Alluxio 位于数据驱动框架或应用（如 Apache Spark、Presto、Tensorflow、Apache HBase、Apache Hive 或 Apache Flink）和各种持久化存储系统（如 Amazon S3、Google Cloud Storage、OpenStack Swift、HDFS、GlusterFS、IBM Cleversafe、EMC ECS、Ceph、NFS 、Minio和 Alibaba OSS）之间。 Alluxio 统一了存储在这些不同存储系统中的数据，为其上层数据驱动型应用提供统一的客户端 API 和全局命名空间。<br><br><br></p><h3 id="安装："><a href="#安装：" class="headerlink" title="安装："></a>安装：</h3><p>下载地址：<br><br><a href="https://www.alluxio.io/download/releases/" target="_blank" rel="noopener">https://www.alluxio.io/download/releases/</a><br><br>wget <a href="https://downloads.alluxio.io/downloads/files/2.8.1/alluxio-2.8.1-bin.tar.gz" target="_blank" rel="noopener">https://downloads.alluxio.io/downloads/files/2.8.1/alluxio-2.8.1-bin.tar.gz</a> <br></p><p>Alluxio 集群安装分为两种，zookeeper 和 raft 两种方式。<br></p><p>Zookeeper 方式，集群master通过zk来选择主节点。<br></p><p>安装说明：<br><br>两个master节点，两个work节点。<br><br>用hadoop用户启动，每个节点之间ssh免密<br></p><p>####修改配置文件：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">su – hadoop </span><br><span class="line">cd apache-hadoop </span><br><span class="line">tar -zxvf alluxio-2.8.1-bin.tar.gz</span><br><span class="line">cd alluxio-2.8.1/conf/</span><br></pre></td></tr></table></figure><p>软连hdfs配置文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ln -s $HADOOP_CONF_DIR/hdfs-site.xml hdfs-site.xml</span><br><span class="line">ln -s $HADOOP_CONF_DIR/core-site.xml core-site.xml</span><br></pre></td></tr></table></figure><p>vim master       #  写上master 节点的主机名</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">shining-bigdata00.host.com</span><br><span class="line">shining-bigdata01.host.com</span><br></pre></td></tr></table></figure><p>vim workers       # 写上 worker 节点的主机名</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">shining-bigdata02.host.com</span><br><span class="line">shining-bigdata04.host.com</span><br></pre></td></tr></table></figure><p>vim alluxio-site.properties    #  alluxio主配置文件  zookeeper HA 配置文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">#########&lt;--  zookeeper ha #######</span><br><span class="line"># Common properties</span><br><span class="line">alluxio.master.hostname=shining-bigdata00.host.com      #  每个master 设置自己的主机名，每个worker 节点不用配置，  需要注意！！！</span><br><span class="line">#配置日志文件目录</span><br><span class="line">alluxio.master.mount.table.root.ufs=hdfs://shininghadoop/underFSStorage</span><br><span class="line">alluxio.underfs.hdfs.configuration=/home/hadoop/apache-hadoop/hadoop/etc/hadoop/core-site.xml:/home/hadoop/pache-hadoop/hadoop/etc/hadoop/hdfs-site.xml</span><br><span class="line">alluxio.debug=true</span><br><span class="line"></span><br><span class="line">##下面是高可用的配置</span><br><span class="line">alluxio.master.hostname=shining-bigdata00.host.com</span><br><span class="line">alluxio.zookeeper.enabled=true</span><br><span class="line">alluxio.zookeeper.address=shining-bigdata00.host.com:2181,shining-bigdata01.host.com:2181,shining-bigdata03.host.com2181,shining-bigdata04.host.com:2181,shining-bigdata02.host.com:2181</span><br><span class="line">alluxio.master.journal.type=UFS</span><br><span class="line">alluxio.master.journal.folder=hdfs://shininghadoop/alluxio/journal</span><br><span class="line"></span><br><span class="line"># Security properties</span><br><span class="line">alluxio.security.authorization.permission.enabled=false</span><br><span class="line">alluxio.security.authentication.type=NOSASL</span><br><span class="line">##配置用户模拟，允许yarn用户模拟任意用户</span><br><span class="line">alluxio.master.security.impersonation.yarn.users=*</span><br><span class="line"></span><br><span class="line"># Worker properties</span><br><span class="line">alluxio.worker.ramdisk.size=5GB</span><br><span class="line">alluxio.worker.tieredstore.levels=1</span><br><span class="line">alluxio.worker.tieredstore.level0.alias=MEM</span><br><span class="line">alluxio.worker.tieredstore.level0.dirs.path=/home/hadoop/alluxio_ramdisk</span><br><span class="line"></span><br><span class="line"># User properties</span><br><span class="line">#alluxio.user.file.readtype.default=CACHE</span><br><span class="line">#alluxio.user.file.writetype.default=ASYNC_THROUGH</span><br><span class="line">#########   zookeeper  ha  --&gt; ######</span><br></pre></td></tr></table></figure><p>vim alluxio-site.properties    #  alluxio主配置文件  RAFT HA 配置文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">######### &lt;-- raft ha #####</span><br><span class="line"># raft ha</span><br><span class="line">alluxio.master.hostname=shining-bigdata00.host.com</span><br><span class="line">alluxio.master.mount.table.root.ufs=hdfs://shininghadoop/underFSStorage</span><br><span class="line">alluxio.master.embedded.journal.addresses=shining-bigdata00.host.com:19200,shining-bigdata01.host.com:19200</span><br><span class="line">alluxio.underfs.hdfs.configuration=/home/hadoop/apache-hadoop/hadoop/etc/hadoop/core-site.xml:/home/hadoop/apache-hadoop/hadoop/etc/hadoop/hdfs-site.xml</span><br><span class="line">alluxio.debug=true</span><br><span class="line">alluxio.master.journal.type=UFS</span><br><span class="line">alluxio.master.journal.folder=hdfs://shininghadoop/alluxio/journal</span><br><span class="line"></span><br><span class="line"># Security properties</span><br><span class="line">alluxio.security.authorization.permission.enabled=false</span><br><span class="line">alluxio.security.authentication.type=NOSASL</span><br><span class="line">##配置用户模拟，允许yarn用户模拟任意用户</span><br><span class="line">alluxio.master.security.impersonation.yarn.users=*</span><br><span class="line"></span><br><span class="line"># Worker properties</span><br><span class="line">alluxio.worker.ramdisk.size=5GB</span><br><span class="line">alluxio.worker.tieredstore.levels=1</span><br><span class="line">alluxio.worker.tieredstore.level0.alias=MEM</span><br><span class="line">alluxio.worker.tieredstore.level0.dirs.path=/home/hadoop/alluxio_ramdisk</span><br><span class="line">######### raft ha --&gt; #####</span><br></pre></td></tr></table></figure><p>根据上面的配置，需要准备的配置：<br><br>HDFS 上创建目录：<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs -mkdir /alluxio/journal</span><br><span class="line">hdfs dfs -mkdir /underFSStorage</span><br><span class="line">hdfs dfs -chmod  777 /underFSStorage  /alluxio/journal</span><br><span class="line">worker 节点上执行：</span><br><span class="line">su – Hadoop</span><br><span class="line">mkdir -p /home/hadoop/alluxio_ramdisk</span><br><span class="line">chmod 777 /home/hadoop/alluxio_ramdisk</span><br></pre></td></tr></table></figure><p>同步配置文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd /home/hadoop/alluxio-2.8.1</span><br><span class="line">alluxio copyDir conf/   # 会将此节点的conf目录下的所有配置同步到master和worker节点上，（前提需要ssh免密）</span><br><span class="line">workers 上 修改visudo  让hadoop用户有sudo权限</span><br></pre></td></tr></table></figure><p>启动和停止Alluxio集群：<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">启动：</span><br><span class="line">cd /home/hadoop /alluxio-2.8.1</span><br><span class="line">./bin/alluxio formatMaster</span><br><span class="line">./bin/alluxio-start.sh all SudoMount</span><br><span class="line">./bin/alluxio fs leader     #  查看当前leader节点</span><br><span class="line">./bin/alluxio runTests     # 运行一个测试</span><br><span class="line">停止：</span><br><span class="line">./bin/alluxio-stop.sh all</span><br><span class="line">下次再启动的时候就用用</span><br><span class="line">./bin/alluxio-start.sh all</span><br><span class="line">其他启动命令：</span><br><span class="line">Master：</span><br><span class="line">alluxio-start.sh master</span><br><span class="line">alluxio-start.sh job_master</span><br><span class="line">alluxio-start.sh proxy</span><br></pre></td></tr></table></figure><p>worker：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">alluxio-start.sh worker</span><br><span class="line">alluxio-start.sh job_worker</span><br><span class="line">alluxio-start.sh proxy</span><br><span class="line">停止用 alluxio-stop.sh 后面跟相同服务即可</span><br></pre></td></tr></table></figure><p>Web UI 访问地址：<br><br><a href="http://shining-bigdata00.host.com:19999/overview" target="_blank" rel="noopener">http://shining-bigdata00.host.com:19999/overview</a> <br></p><h3 id="HDFS支持Alluxio"><a href="#HDFS支持Alluxio" class="headerlink" title="HDFS支持Alluxio"></a>HDFS支持Alluxio</h3><p>修改hdfs配置文件<br></p><p>cd $HADOOP_CONF_DIR<br><br>vim core-site.xml<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;fs.alluxio.impl&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;alluxio.hadoop.FileSystem&lt;/value&gt;</span><br><span class="line">  &lt;description&gt;The Alluxio FileSystem (Hadoop 1.x and 2.x)&lt;/description&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;fs.AbstractFileSystem.alluxio.impl&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;alluxio.hadoop.AlluxioFileSystem&lt;/value&gt;</span><br><span class="line">  &lt;description&gt;The Alluxio AbstractFileSystem (Hadoop 2.x)&lt;/description&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;!-- alluxio zookeeper 集群时，配置</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;alluxio.zookeeper.enabled&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;true&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;alluxio.zookeeper.address&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;shining-bigdata00.host.com:2181&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">--&gt;</span><br><span class="line">&lt;!—alluxio raft 集群时配置</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;alluxio.master.rpc.addresses&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;shining-bigdata00.host.com:19998,shining-bigdata01.host.com:19998&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">--&gt;</span><br></pre></td></tr></table></figure><p>添加jar包，将alluxio-client 的jar包放到hdfs的lib加载目录下。<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cp /home/hadoop/alluxio-2.8.1/client/alluxio-2.8.1-client.jar /home/hadoop/apache-hadoop/hadoop/share/hadoop/common/lib/</span><br><span class="line">分发到每台datanode上</span><br></pre></td></tr></table></figure><p>重启 hadoop 集群<br><br>之后，可以用hdfs命令查看alluxio上文件<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -ls alluxio:///ys</span><br></pre></td></tr></table></figure><h3 id="hive-配置alluxio"><a href="#hive-配置alluxio" class="headerlink" title="hive 配置alluxio"></a>hive 配置alluxio</h3><p>copy alluxio client jar 包</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cp /home/hadoop/alluxio-2.8.1/client/alluxio-2.8.1-client.jar $HIVE_HOME/lib/</span><br></pre></td></tr></table></figure><p>hive 配置文件中 hive-site.xml 中添加</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&lt;!--</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;alluxio.zookeeper.enabled&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;true&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;alluxio.zookeeper.address&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;shining-bigdata00.host.com:2181&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">--&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;alluxio.master.rpc.addresse&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;shining-bigdata00.host.com:19998,shining-bigdata01.host.com:19998&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure><p>Hive 客户端和hive meta 都需要添加。<br><br><br><br>Hive中创建 alluxio 文件系统的表。<br><br>Alluxio 官网提供一个测试的hive数据，<br><br>可以在 <a href="http://grouplens.org/datasets/movielens/" target="_blank" rel="noopener">http://grouplens.org/datasets/movielens/</a> <br><br>下载数据文件（如：ml-100k.zip）。然后接下该文件，并且将文件u.user上传到Alluxio的ml-100k/下：<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">./bin/alluxio fs mkdir /ml-100k</span><br><span class="line">./bin/alluxio fs copyFromLocal /path/to/ml-100k/u.user  /ml-100k/</span><br></pre></td></tr></table></figure><p>创建表：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; CREATE TABLE u_user (</span><br><span class="line">userid INT,</span><br><span class="line">age INT,</span><br><span class="line">gender CHAR(1),</span><br><span class="line">occupation STRING,</span><br><span class="line">zipcode STRING)</span><br><span class="line">ROW FORMAT DELIMITED</span><br><span class="line">FIELDS TERMINATED BY &apos;|&apos;</span><br><span class="line">STORED AS TEXTFILE</span><br><span class="line">LOCATION &apos;alluxio://shining-bigdata00.host.com:19998,shining-bigdata01.host.com:19998/ml-100k&apos;;</span><br></pre></td></tr></table></figure><p>执行查询：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Select * from u_user limit 5;</span><br></pre></td></tr></table></figure><p>常用命令</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">./bin/alluxio copyDir conf/</span><br><span class="line"></span><br><span class="line">./bin/alluxio formatMaster</span><br><span class="line">./bin/alluxio-start.sh all SudoMount</span><br><span class="line">./bin/alluxio runTests</span><br><span class="line">./bin/alluxio fs leader</span><br><span class="line">alluxio fs masterInfo</span><br><span class="line">alluxio fsadmin report</span><br><span class="line">./bin/alluxio fs ls /</span><br><span class="line">alluxio fs loadMetadata -R /ys/</span><br><span class="line">alluxio fs copyToLocal /ml-100k/u.user 123</span><br><span class="line"></span><br><span class="line">alluxio fs stat /ys/hdfs_file_num/000000_0</span><br><span class="line">alluxio fs setTtl /ys/hdfs_file_num/000000_0 60000</span><br><span class="line">alluxio fs setTtl --action /ys/hdfs_file_num/000000_0 60000</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">hadoop fs -ls alluxio:///ys</span><br></pre></td></tr></table></figure>]]></content>
      
      <categories>
          
          <category> alluxio </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hadoop </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>素书-原文及译文</title>
      <link href="/sushu/"/>
      <url>/sushu/</url>
      <content type="html"><![CDATA[<h2 id="《素书》"><a href="#《素书》" class="headerlink" title="《素书》"></a>《素书》</h2><p>《素书》以道家思想为宗旨，集儒、法、兵的思想发挥道的作用及功能，同时以道、德、仁、义、礼为立身治国的根本、揆度宇宙万物自然运化的理数，以此认识事物，对应事物、处理事物的智能之作。</p><p>有一个典故大概大家都知道，黄石公故意把鞋子弄到桥下，张良毕恭毕敬的为老人拾鞋穿鞋，后来老人又几次考验张良，张良终于通过了考验，于是黄石公就把自己的一本书传授给了张良，这部书的名字有传说叫做《太公兵法》，其实是以讹传讹，这部书的名字应该叫做《素书》。张良却没有把这部书传给后人，而是将书埋进了自己的坟墓。张良死后大约五百年，盗墓人从张良墓里偷了这本书，才在民间流传开来。这段故事记载于宋朝人张商英为《素书》写的序里。张良虽然用这部书里的知识帮助刘邦取得了天下，但是张良也没有完全领悟书中的奥义。此典故正式名曰“圯桥授书”。</p><p>《素书》全书一百三十二句，共六章：原始、正道、求人之志、本德宗道、遵义和安礼。但这本书的内容可非同寻常，不仅包含治国安邦大谋略，更有修身处世、为人之道的智慧，每一句箴言都是切中要害，一针见血，读来如醍醐灌顶、豁然顿悟，其对人生的指导意义不言而喻，值得我们每个人读上一读。</p><a id="more"></a><h3 id="第一章-原始"><a href="#第一章-原始" class="headerlink" title="第一章 原始"></a>第一章 原始</h3><p>【原文】</p><p>夫道、德、仁、义、礼五者，一体也。道者，人之所蹈，使万物不知其所由。德者，人之所使，使万物各得其所欲。仁者，人之所亲，有慈慧恻隐之心，以遂其生成。义者，人之所宜，赏善罚恶，以立功立事。礼者，人之所履，夙兴夜寐，以成人伦之序。夫欲为人之本，不可无一焉。贤人君子，明于盛衰之道，通乎成败之数，审乎治乱之势，达乎去就之理。故潜居抱道，以待其时。若时至而行，则能极人臣之位；得机而动，则能成绝代之功。如其不遇，没身而已。是以其道足高，而名重于后代。</p><p>【译文】</p><p>道、德、仁、义、礼五者，本为一体，不可分离。</p><p>道，是一种自然规律，人人都在遵循著自然规律，自己却意识不到这一点，自然界万事万物亦是如此。德、即是获得，依德而行，可使一己的欲求得到满足，自然界万事万物也是如此。仁、是人所独具的仁慈、爱人的心理，人能关心、同情人，各种善良的愿望和行动就会产生。义、是人所认为符合某种道德观念的行为，人们根据义的原则奖善惩恶，以建立功业。礼、是规定社会行为的法则，规范仪式的总称。人人必须遵循礼的规范，兢兢业业，夙兴夜寐，按照君臣、父子、夫妻、兄弟等人伦关系所排列的顺序行事。这五个条目是做人的根本，缺一不可的。贤明能干的人物，品德高尚的君子，都能看清国家兴盛、衰弱、存亡的道理，通晓事业成败的规律，明白社会政治修明与纷乱的形势，懂得隐退仕进的原则。因此，当条件不适宜之时，都能默守正道，甘于隐伏，等待时机的到来。一旦时机到来而有所行动，常能建功立业位极人臣。如果所遇非时，也不过是淡泊以终而已。也就因此，像这样的人物常能树立极为崇高的典范，名重于后世呵！</p><h3 id="第二章-正道"><a href="#第二章-正道" class="headerlink" title="第二章 正道"></a>第二章 正道</h3><p>【原文】</p><p>德足以怀远，信足以一异，义足以得众，才足以鉴古，明足以照下，此人之俊也；</p><p>行足以为仪表，智足以决嫌疑，信可以使守约，廉可以使分财，此人之豪也；</p><p>守职而不废，处义而不回，见嫌而不茍免，见利而不茍得，此人之杰也。</p><p>【译文】</p><p>品德高尚，则可使远方之人前来归顺。诚实不欺，可以统一不同的意见。道理充分可以得到部下群众的拥戴。才识杰出，可以借鉴历史。聪明睿智可以知众而容众。这样的人，可以称他为人中之俊。行为端正，可以为人表率。足智多谋，可以解决疑难问题。天无信，四时失序，人无信，行止不立。如果能忠诚守信，这是立身成名之本。君子寡言，言而有信，一言议定，再不肯改议、失约。是故讲究信用，可以守约而无悔。廉洁公正，且疏财仗义。这样的人，可以称他为人中之豪。见嫌而不苟免，克尽职守，而无所废弛；恪守信义，而不稍加改变；受到嫌疑，而能居义而不反顾；利字当头，懂得不悖理苟得。这样的人，可以称为人中之杰。</p><h3 id="第三章-求人之志"><a href="#第三章-求人之志" class="headerlink" title="第三章 求人之志"></a>第三章 求人之志</h3><p>【原文】</p><p>绝嗜禁欲，所以除累。抑非损恶，所以让过。贬酒阙色，所以无污。</p><p>避嫌远疑，所以不误。博学切问，所以广知。高行微言，所以修身。</p><p>恭俭谦约，所以自守。深计远虑，所以不穷。亲仁友直，所以扶颠。</p><p>近恕笃行，所以接人。任材使能，所以济物。殚恶斥谗，所以止乱。</p><p>推古验今，所以不惑。先揆后度，所以应卒。设变致权，所以解结。</p><p>括囊顺会，所以无咎。橛橛梗梗，所以立功。孜孜淑淑，所以保终。</p><p>【译文】</p><p>杜绝不良的嗜好，禁止非分的欲望，这样可以免除各种牵累；抑制不合理的行为，减少邪恶的行径，这样可以避免过失；谢绝酒色侵扰，这样可以不受玷污；回避嫌疑，远离惑乱，这样可以不出错误。广泛地学习，仔细地提出各种问题，这样可以丰富自己的知识；行为高尚，辞锋不露，这样可以修养身心、陶冶性情；肃敬、节俭、谦逊、简约，这样可以守身不辱；深谋远虑，这样可以不至于困危；亲近仁义之士，结交正直之人，这样可以在逆境中得到帮助。为人尽量宽容，行为敦厚，这是待人处世之道。任才使能，使人人能尽其才，这是用人成事之要领；抑制邪恶，斥退谗佞之徒，这样可以防止动乱；推求往古，验证当今，这样可以不受迷惑；了解事态，心中有数，这样可以应付仓卒事变；采用灵活手法，施展权变之术，这样可以解开纠结；心中有数，闭口不言，凡事能顺从时机，这样可以远怨无咎；坚定不移，正直刚强，这样才能建功立业；勤勉惕励；心地善良，这样才能善始善终。</p><h3 id="第四章-本德宗道"><a href="#第四章-本德宗道" class="headerlink" title="第四章 本德宗道"></a>第四章 本德宗道</h3><p>【原文】</p><p>夫志心笃行之术。长莫长于博谋，安莫安于忍辱，先莫先于修德，乐莫乐于好善，神莫神于至诚，明莫明于体物，吉莫吉于知足，苦莫苦于多愿，悲莫悲于精散，病莫病于无常，短莫短于苟得，幽莫幽于贪鄙，孤莫孤于自恃，危莫危于任疑，败莫败于多私。</p><p>【译文】</p><p>欲始志向坚定，笃实力行：最好的方法，莫过于深思多谋；最安全的方式，莫过于安于忍辱；最优先的要务，莫过于进德修业；最快乐的态度，莫过于乐于好善；最神奇的效验，莫过于用心至诚；最高明的做法，莫过于明察秋毫；最吉祥的想法，莫过于安分知足；最痛苦的缺点，莫过于欲求太多；最悲哀的情形，莫过于心神离散；最麻烦的病态，莫过于反覆无常；最无聊的妄念，莫过于不劳而获；最愚昧的观念，莫过于贪婪卑鄙；最孤独的念头，莫过于目空一切；最危险的举措，莫过于任人而疑；最失败的行径；莫过于自私自利；</p><h3 id="第五章-道义"><a href="#第五章-道义" class="headerlink" title="第五章 道义"></a>第五章 道义</h3><p>【原文】</p><p>以明示下者暗，有过不知者蔽，迷而不返者惑，以言取怨者祸，令与心乖者废，后令缪前者毁，怒而无威者犯，好众辱人者殃，戮辱所任者危，慢其所敬者凶，貌合心离者孤，亲谗远忠者亡，近色远贤者昏，女谒公行者乱，私人以官者浮，凌下取胜者侵，名不胜实者耗。略己而责人者不治，自厚而薄人者弃废。以过弃功者损，群下外异者沦，既用不任者疏，行赏吝色者沮，多许少与者怨，既迎而拒者乖。薄施厚望者不报，贵而忘贱者不久。念旧而弃新功者凶，用人不得正者殆，强用人者不畜，为人择官者乱，失其所强者弱，决策于不仁者险，阴计外泄者败，厚敛薄施者凋。战士贫，游士富者衰；货赂公行者昧；闻善忽略，记过不忘者暴；所任不可信，所信不可任者浊。牧人以德者集，绳人以刑者散。小功不赏，则大功不立；小怨不赦，则大怨必生。赏不服人，罚不甘心者叛。赏及无功，罚及无罪者酷。听谗而美，闻谏而仇者亡。能有其有者安，贪人之有者残。</p><p>【译文】</p><p>在部下面前显示高明，一定会遭到愚弄。有过错而不能自知，一定会受到蒙蔽。走入迷途而不知返回正道，一定是神志惑乱。因为语言招致怨恨，一定会有祸患。思想与政令矛盾，一定会坏事。政令前后不一，一定会失败。发怒却无人畏惧，一定会受到侵犯。喜欢当众侮辱别人，一定会有灾难。对手下的大将罚之过当，一定会有危险。怠慢应受尊重的人，一定会招致不幸。表面上关系密切，实际上心怀异志的，一定会陷于孤独。亲近谗慝，远离忠良，一定会灭亡。亲近女色，疏远贤人，必是昏瞆目盲。女子干涉大政，一定会有动乱。随便将官职到处乱送，政治就会出现乱相。欺凌下属而获得胜利的，自己也一定会受到下属的侵犯。所享受的名声超过自己的实际才能，即使耗尽精力也治理不好事务。对自己马虎，对别人求全责备的，无法处理事务。对自己宽厚，对别人刻薄的，一定被众人遗弃。因为小过失便取消别人的功劳的，一定会大失人心。部下纷纷有离异之心，必定沦亡。既然用了人却不给予信任，必定导致关系疏远。论功行赏时吝啬小气，形于颜色，必定使人感到沮丧。承诺多，兑现少，必招致怨恨。起初竭诚欢迎，末了又拒于门外，一定会恩断义绝。给予别人很少，却希望得到厚报的，一定会大失所望。富贵之后就忘却贫贱时候的情状，一定不会长久。念及别人旧恶，忘记其所立新功的，一定遭来大凶。任用邪恶之徒，一定会有危险。勉强用人，一定留不住人。用人无法摆脱人情纠结，政事必越理越乱。失去自己的优势，力量必然削弱。处理问题、制定决策时向不仁之人问计，必有危险。秘密的计划泄露出去，一定会失败。横征暴敛、薄施寡恩，一定会衰落。奋勇征战的将士生活贫穷，鼓舌摇唇的游士安享富贵，国势一定会衰落。贿赂政府官员的事到处可见，政治必定十分昏暗。知道别人的优点长处却不重视，对别人的缺点错误反而耿耿于怀的，则是作风粗暴。使用的人不堪信任，信任的人又不能胜任其职，这样的政治一定很混浊。依靠道德的力量来治理人民，人民就会团结；若一味地依靠刑法来维持统治，则人民将离散而去。小的功劳不奖赏，便不会建立大功劳；小的怨恨不宽赦，大的怨恨便会产生。奖赏不能服人，处罚不能让人甘心，必定引起叛乱；赏及无功之人，罚及无罪之人，就是所谓的残酷。听到谗佞之言就十分高兴，听到忠谏之言便心生怨恨，一定灭亡。藏富于民，以百姓的富有作为本身的富有，这样才会安定；欲壑难填，总是贪求别人所有的，必然残民以逞。</p><h3 id="第六章-安礼"><a href="#第六章-安礼" class="headerlink" title="第六章 安礼"></a>第六章 安礼</h3><p>【原文】</p><p>怨在不舍小过，患在不预定谋。福在积善，祸在积恶。饥在贱农，寒在堕织。安在得人，危在失事。富在迎来，贫在弃时。上无常操，下多疑心。轻上生罪，侮下无亲。近臣不重，远臣轻之。自疑不信人，自信不疑人。枉士无正友，曲上无直下。危国无贤人，乱政无善人。爱人深者求贤急，乐得贤者养人厚。国将霸者士皆归，邦将亡者贤先避。地薄者大物不产，水浅者大鱼不游，树秃者大禽不栖，林疏者大兽不居。山峭者崩，泽满者溢。弃玉取石者盲，羊质虎皮者柔。衣不举领者倒，走不视地者颠。柱弱者屋坏，辅弱者国倾。足寒伤心，人怨伤国。山将崩者下先隳，国将衰者人先弊。根枯枝朽，人困国残。与覆车同轨者倾，与亡国同事者灭。见已生者慎将生，恶其迹者须避之。畏危者安，畏亡者存。夫人之所行，有道则吉，无道则凶。吉者，百福所归；凶者，百祸所攻。非其神圣，自然所钟。务善策者无恶事，无远虑者有近忧。同志相得，同仁相忧，同恶相党，同爱相求，同美相妒，同智相谋，同贵相害，同利相忌，同声相应，同气相感，同类相依，同义相亲，同难相济，同道相成，同艺相规，同巧相胜：此乃数之所得，不可与理违。释己而教人者逆，正己而化人者顺。逆者难从，顺者易行，难从则乱，易行则理。如此理身、理国、理家，可也！</p><p>【译文】</p><p>怨恨产生于不肯赦免小的过失；祸患产生于事前未作仔细的谋画；幸福在于积善累德；灾难在于多行不义。轻视农业，必招致饥馑；惰于蚕桑，必挨冷受冻。得人必安，失士则危。招来远客即富，荒废农时则贫。上位者反覆无常，言行不一，部属必生猜疑之心，以求自保。对上官轻视怠慢，必定获罪；对下属侮辱傲慢，必定失去亲附。近幸左右之臣不受尊重，关系疏远之臣必不安其位。自己怀疑自己，则不会信任别人；自己相信自己，则不会怀疑别人。邪恶之士决无正直的朋友；邪僻的上司必没有公正刚直的部下。行将灭亡的国家，决不会有贤人辅政；陷于混乱的政治，决不会有善人参与。爱人深者，一定急于求贤才，乐得于贤才者，待人一定丰厚。国家即将称霸，人才都会聚集来归；邦国即将败亡，贤者先行隐避。土地贫瘠，大物不产；水浅之处，大鱼不游；秃树之上，大禽不栖；疏林之中，大兽不居。山势过于陡峭，则容易崩塌；沼泽蓄水过满，则会漫溢出来。弃玉抱石者目光如盲，羊质虎皮者虚于矫饰。拿衣服时不提领子，势必把衣服拿倒。走路不看地面的一定会跌倒。</p><p>房屋梁柱软弱，屋子会倒塌；才力不足的人掌政，国家会倾覆。脚下受寒，心肺受损；人心怀恨，国家受伤。大山将要崩塌，土质会先毁坏；国家将要衰亡，人民先受损害。树根干枯，枝条就会腐朽；人民困窘，国家将受伤害。与倾覆的车子走同一轨道的车，也会倾覆；与灭亡的国家做相同的事，也会灭亡。见到已发生的事情，应警惕还将发生类似的事情；预见险恶的人事，应事先回避。害怕危险，常能得安全；害怕灭亡，反而能生存。人的所作所为，符合行事之道则吉，不符合行事之道则凶。吉祥的人，各种各样的好处都到他那里；不吉祥的人，各种各样的恶运灾祸都向他袭来。这并不是什么奥妙的事，而是自然之理。务善策者无恶事，无远虑者有近忧。同志相得，同仁同忧，同恶相党，同爱同求，同美相妒，同智相谋，同贵相害，同利相忌。同声相应，同气相感，同类相似，同义相亲，同难相济。同道相成，同艺相窥，同巧相胜。以上这些都是自然而然的道理，凡人类有所举措，均应遵守这些规律，不可与理相抗。把自己放在一边，单纯去教育别人，别人就不接受他的大道理；如果严格要求自己，进而去感化别人，别人就会顺服。违反常理，部属则难以顺从；合乎常理，则办事容易。部属难以顺从，则容易产生动乱；办事容易，则能得到畅通的治理。</p><blockquote><p>以上所述的各项事理，用在修身、持家、治国，均会获得丰硕的效果。</p></blockquote><blockquote><p>传播国学文化，分享智慧人生！</p></blockquote><blockquote><p>以上内容均来之互联网，如有侵权请联系我。 </p></blockquote>]]></content>
      
      <categories>
          
          <category> doc </category>
          
      </categories>
      
      
        <tags>
            
            <tag> doc </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>制作rsyslog服务将日志输入到kafka</title>
      <link href="/rsyslog-to-kafka/"/>
      <url>/rsyslog-to-kafka/</url>
      <content type="html"><![CDATA[<p>有一些服务，需要将日志打到UDP端口， 其实也可以打到本机的rsyslog服务，但是我的服务已经上容器了， 还不想没个容器都封装rsyslog服务，也不像挂载， 就想着把rsyslog封装成为一个服务发布。谁都可以调用。</p><p>那么问题来了， rsyslog将日志怎么处理，怎么区分？</p><ul><li>我这是比较固定的日志格式， 不用做过多处理，</li><li>rsyslog 将收到的日志，直接抓发到kafka上。本地不留数据。</li><li>rsyslog启多个端口，通过端口来区别放到哪个kafka topic上。</li><li>也可以通过local级别来区分，我这里没做。</li></ul><a id="more"></a><p>简单的是有 Dcokerfile</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">FROM centos:7</span><br><span class="line">MAINTAINER Shining-YS</span><br><span class="line">RUN yum install -y rsyslog rsyslog-kafka lz4 libfastjson libestr</span><br><span class="line"></span><br><span class="line">COPY rsyslog.conf /etc/rsyslog.conf</span><br><span class="line">COPY tokafka.conf /etc/rsyslog.d/tokafka.conf</span><br><span class="line">COPY rsyslog  /etc/sysconfig/rsyslog</span><br><span class="line"></span><br><span class="line">EXPOSE 514</span><br><span class="line"></span><br><span class="line">#CMD [&quot;/usr/sbin/rsyslogd&quot;,&quot;-dn&quot;]</span><br><span class="line">CMD [&quot;/usr/sbin/rsyslogd&quot;,&quot;-n&quot;]</span><br></pre></td></tr></table></figure><p>这其中包括及个文件， 我就直接列出来了</p><p>rsyslog.conf   主要是开启514端口，TCP和UDP</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br></pre></td><td class="code"><pre><span class="line"># rsyslog configuration file</span><br><span class="line"></span><br><span class="line"># For more information see /usr/share/doc/rsyslog-*/rsyslog_conf.html</span><br><span class="line"># If you experience problems, see http://www.rsyslog.com/doc/troubleshoot.html</span><br><span class="line"></span><br><span class="line">#### MODULES ####</span><br><span class="line"></span><br><span class="line"># The imjournal module bellow is now used as a message source instead of imuxsock.</span><br><span class="line">$ModLoad imuxsock # provides support for local system logging (e.g. via logger command)</span><br><span class="line">$ModLoad imjournal # provides access to the systemd journal</span><br><span class="line">#$ModLoad imklog # reads kernel messages (the same are read from journald)</span><br><span class="line">#$ModLoad immark  # provides --MARK-- message capability</span><br><span class="line"></span><br><span class="line"># Provides UDP syslog reception</span><br><span class="line">$ModLoad imudp</span><br><span class="line">$UDPServerRun 514</span><br><span class="line"></span><br><span class="line"># Provides TCP syslog reception</span><br><span class="line">$ModLoad imtcp</span><br><span class="line">$InputTCPServerRun 514</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#### GLOBAL DIRECTIVES ####</span><br><span class="line"></span><br><span class="line"># Where to place auxiliary files</span><br><span class="line">$WorkDirectory /var/lib/rsyslog</span><br><span class="line"></span><br><span class="line"># Use default timestamp format</span><br><span class="line">$ActionFileDefaultTemplate RSYSLOG_TraditionalFileFormat</span><br><span class="line"></span><br><span class="line"># File syncing capability is disabled by default. This feature is usually not required,</span><br><span class="line"># not useful and an extreme performance hit</span><br><span class="line">#$ActionFileEnableSync on</span><br><span class="line"></span><br><span class="line"># Include all config files in /etc/rsyslog.d/</span><br><span class="line">$IncludeConfig /etc/rsyslog.d/*.conf</span><br><span class="line"></span><br><span class="line"># Turn off message reception via local log socket;</span><br><span class="line"># local messages are retrieved through imjournal now.</span><br><span class="line">$OmitLocalLogging on</span><br><span class="line"></span><br><span class="line"># File to store the position in the journal</span><br><span class="line">$IMJournalStateFile imjournal.state</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#### RULES ####</span><br><span class="line"></span><br><span class="line"># Log all kernel messages to the console.</span><br><span class="line"># Logging much else clutters up the screen.</span><br><span class="line">#kern.*                                                 /dev/console</span><br><span class="line"></span><br><span class="line"># Log anything (except mail) of level info or higher.</span><br><span class="line"># Don&apos;t log private authentication messages!</span><br><span class="line">*.info;mail.none;authpriv.none;cron.none                /var/log/messages</span><br><span class="line"></span><br><span class="line"># The authpriv file has restricted access.</span><br><span class="line">authpriv.*                                              /var/log/secure</span><br><span class="line"></span><br><span class="line"># Log all the mail messages in one place.</span><br><span class="line">mail.*                                                  -/var/log/maillog</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># Log cron stuff</span><br><span class="line">cron.*                                                  /var/log/cron</span><br><span class="line"></span><br><span class="line"># Everybody gets emergency messages</span><br><span class="line">*.emerg                                                 :omusrmsg:*</span><br><span class="line"></span><br><span class="line"># Save news errors of level crit and higher in a special file.</span><br><span class="line">uucp,news.crit                                          /var/log/spooler</span><br><span class="line"></span><br><span class="line"># Save boot messages also to boot.log</span><br><span class="line">local7.*                                                /var/log/boot.log</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># ### begin forwarding rule ###</span><br><span class="line"># The statement between the begin ... end define a SINGLE forwarding</span><br><span class="line"># rule. They belong together, do NOT split them. If you create multiple</span><br><span class="line"># forwarding rules, duplicate the whole block!</span><br><span class="line"># Remote Logging (we use TCP for reliable delivery)</span><br><span class="line">#</span><br><span class="line"># An on-disk queue is created for this action. If the remote host is</span><br><span class="line"># down, messages are spooled to disk and sent when it is up again.</span><br><span class="line">#$ActionQueueFileName fwdRule1 # unique name prefix for spool files</span><br><span class="line">#$ActionQueueMaxDiskSpace 1g   # 1gb space limit (use as much as possible)</span><br><span class="line">#$ActionQueueSaveOnShutdown on # save messages to disk on shutdown</span><br><span class="line">#$ActionQueueType LinkedList   # run asynchronously</span><br><span class="line">#$ActionResumeRetryCount -1    # infinite retries if host is down</span><br><span class="line"># remote host is: name/ip:port, e.g. 192.168.0.1:514, port optional</span><br><span class="line">#*.* @@remote-host:514</span><br><span class="line"># ### end of the forwarding rule ###</span><br></pre></td></tr></table></figure><p>rsyslog 文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># Options for rsyslogd</span><br><span class="line"># Syslogd options are deprecated since rsyslog v3.</span><br><span class="line"># If you want to use them, switch to compatibility mode 2 by &quot;-c 2&quot;</span><br><span class="line"># See rsyslogd(8) for more details</span><br><span class="line">SYSLOGD_OPTIONS=&quot;-r -m 0&quot;</span><br></pre></td></tr></table></figure><p>tokafka.conf  通过端口将日志写入到kakfa不同topic</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">module(load=&quot;omkafka&quot;)</span><br><span class="line">module(load=&quot;imudp&quot;)</span><br><span class="line">module(load=&quot;imtcp&quot;)</span><br><span class="line">input(type=&quot;imudp&quot; port=&quot;514&quot; ruleset=&quot;tokafka&quot;)</span><br><span class="line">input(type=&quot;imtcp&quot; port=&quot;514&quot; ruleset=&quot;tokafka&quot;)</span><br><span class="line"></span><br><span class="line">ruleset(name=&quot;tokafka&quot;) &#123;</span><br><span class="line">      #输出到kafka</span><br><span class="line">      action(type=&quot;omkafka&quot; topic=&quot;shining_test1&quot; broker=&quot;kafka1:9092,kafka2:9092,hkafka3:9092&quot; partitions.number=&quot;5&quot;)</span><br><span class="line">      #输出到文件</span><br><span class="line">      #action(type=&quot;omfile&quot; file=&quot;/tmp/shining_test1.log&quot;)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">ruleset(name=&quot;shining_test2&quot;) &#123;</span><br><span class="line">      action(type=&quot;omkafka&quot; topic=&quot;shining_test2&quot; broker=&quot;kafka1:9092,kafka2:9092,hkafka3:9092&quot; partitions.number=&quot;5&quot;)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">ruleset(name=&quot;shining_test3&quot;) &#123;</span><br><span class="line">      action(type=&quot;omkafka&quot; topic=&quot;shining_test2&quot; broker=&quot;kafka1:9092,kafka2:9092,hkafka3:9092&quot; partitions.number=&quot;5&quot;)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">ruleset(name=&quot;shining_test4&quot;) &#123;</span><br><span class="line">      action(type=&quot;omkafka&quot; topic=&quot;shining_test3&quot; broker=&quot;kafka1:9092,kafka2:9092,hkafka3:9092&quot; partitions.number=&quot;5&quot;)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">input(type=&quot;imudp&quot; port=&quot;7510&quot; ruleset=&quot;shining_test4&quot;)</span><br><span class="line">input(type=&quot;imtcp&quot; port=&quot;7510&quot; ruleset=&quot;shining_test4&quot;)</span><br><span class="line">input(type=&quot;imudp&quot; port=&quot;7511&quot; ruleset=&quot;shining_test2&quot;)</span><br><span class="line">input(type=&quot;imtcp&quot; port=&quot;7511&quot; ruleset=&quot;shining_test2&quot;)</span><br><span class="line">input(type=&quot;imudp&quot; port=&quot;7512&quot; ruleset=&quot;shining_test3&quot;)</span><br><span class="line">input(type=&quot;imtcp&quot; port=&quot;7512&quot; ruleset=&quot;shining_test3&quot;)</span><br></pre></td></tr></table></figure><p>其中 omkafka 模块参数说明，可以参考：<br><a href="https://rsyslog.readthedocs.io/en/latest/configuration/modules/omkafka.html" target="_blank" rel="noopener">https://rsyslog.readthedocs.io/en/latest/configuration/modules/omkafka.html</a></p><p>For Example</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">#加载omkafka和imfile模块</span><br><span class="line">module(load=&quot;omkafka&quot;)</span><br><span class="line">module(load=&quot;imfile&quot;)</span><br><span class="line"></span><br><span class="line"># nginx template</span><br><span class="line">template(name=&quot;nginxAccessTemplate&quot; type=&quot;string&quot; string=&quot;%hostname%&lt;-+&gt;%syslogtag%&lt;-+&gt;%msg%\n&quot;)</span><br><span class="line"></span><br><span class="line"># ruleset</span><br><span class="line">ruleset(name=&quot;nginx-kafka&quot;) &#123;</span><br><span class="line">    #日志转发kafka</span><br><span class="line">    action (</span><br><span class="line">        type=&quot;omkafka&quot;</span><br><span class="line">        template=&quot;nginxAccessTemplate&quot;</span><br><span class="line">        confParam=[&quot;compression.codec=snappy&quot;, &quot;queue.buffering.max.messages=400000&quot;]</span><br><span class="line">        partitions.number=&quot;4&quot;</span><br><span class="line">        topic=&quot;test_nginx&quot;</span><br><span class="line">        broker=&quot;localhost:9092&quot;</span><br><span class="line">        queue.spoolDirectory=&quot;/tmp&quot;</span><br><span class="line">        queue.filename=&quot;test_nginx_kafka&quot;</span><br><span class="line">        queue.size=&quot;360000&quot;</span><br><span class="line">        queue.maxdiskspace=&quot;2G&quot;</span><br><span class="line">        queue.highwatermark=&quot;216000&quot;</span><br><span class="line">        queue.discardmark=&quot;350000&quot;</span><br><span class="line">        queue.type=&quot;LinkedList&quot; </span><br><span class="line">        queue.dequeuebatchsize=&quot;4096&quot;</span><br><span class="line">        queue.timeoutenqueue=&quot;0&quot;</span><br><span class="line">        queue.maxfilesize=&quot;10M&quot; </span><br><span class="line">        queue.saveonshutdown=&quot;on&quot;</span><br><span class="line">        queue.workerThreads=&quot;4&quot;</span><br><span class="line">    )</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"># 定义消息来源及设置相关的action</span><br><span class="line">input(type=&quot;imfile&quot; Tag=&quot;nginx,aws&quot; File=&quot;/usr/local/nginx/logs/access.log&quot; Ruleset=&quot;nginx-kafka&quot;)</span><br></pre></td></tr></table></figure><p>docker 镜像编译</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker build -t rsyslog-to-kafka:latest .</span><br></pre></td></tr></table></figure><p>启动容器，还需要映射UDP端口</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run --name rsyslog-to -kafka -p 514:514 -p 514:514/udp  -p 7510: 7510 -p 7510: 7510/udp -p 7511: 7511 -p 7511: 7511/udp -p 7512: 7512 -p 7512: 7512/udp rsyslog-to-kafka:latest</span><br></pre></td></tr></table></figure>]]></content>
      
      <categories>
          
          <category> docker </category>
          
      </categories>
      
      
        <tags>
            
            <tag> docker </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>marathon通过api更新update app id</title>
      <link href="/marathon-api-update/"/>
      <url>/marathon-api-update/</url>
      <content type="html"><![CDATA[<h3 id="marathon-api-方法"><a href="#marathon-api-方法" class="headerlink" title="marathon api 方法"></a>marathon api 方法</h3><p>发布程序：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">例如： json文件名为  nginx-test.json</span><br><span class="line">curl -X POST http://10.0.0.25:8080/v2/apps -d @nginx-test.json -H &quot;Content-type: application/json”</span><br></pre></td></tr></table></figure><p>更新程序：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">例如： nginx-test 这个app</span><br><span class="line">更新 nginx-test.json </span><br><span class="line">id 为 ：  /nginx/nginx-test</span><br><span class="line">curl -X PUT http://10.0.0.25:8080/v2/apps/nginx/nginx-test -d @nginx-test.json -H &quot;Content-type: application/json”</span><br></pre></td></tr></table></figure><p>强制杀掉 deployment:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">marathonAddr=&quot;http://ip:8080&quot;;</span><br><span class="line">deployment_id=&quot;1463-672-414-839-cb32&quot;;</span><br><span class="line">apiPath=&quot;/v2/deployments/$&#123;deployment_id&#125;&quot;</span><br><span class="line">curl -X DELETE $&#123;marathonAddr&#125;$&#123;apiPath&#125;?force=true</span><br><span class="line">或</span><br><span class="line">curl -X DELETE http://localhost:8080/v2/apps/io-test?force=true  -H &quot;Content-type: application/json&quot;</span><br></pre></td></tr></table></figure><a id="more"></a><p>更新某个变量：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"># 更新实例数</span><br><span class="line">curl -XPUT localhost:8080/v2/apps/path/to/app/app123 -d &apos;&#123;&quot;instances&quot;:20&#125;&apos;</span><br><span class="line"></span><br><span class="line"># 更新节点亲和性</span><br><span class="line">ID=/test/abc123</span><br><span class="line">curl -u user1:passwd -H &quot;Content-type: application/json&quot; -X PUT http://localhost:8080/v2/apps$&#123;ID&#125; -d &apos;&#123;&quot;constraints&quot;: [[&quot;node1&quot;, &quot;LIKE&quot;, &quot;true&quot;]]&#125;&apos;</span><br><span class="line"></span><br><span class="line"># 更新j镜像</span><br><span class="line">ID=/test/abc123</span><br><span class="line">curl -u user1:passwd -H &quot;Content-type: application/json&quot; -X PUT http://localhost:8080/v2/apps$&#123;ID&#125; -d &apos;&#123;&quot;container&quot;: &#123;&quot;docker&quot;: &#123;&quot;image&quot;:&quot;nginx:1.13&quot;&#125;&#125;&#125;&apos;</span><br></pre></td></tr></table></figure><p>获取 app 信息</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 获取到所有的id</span><br><span class="line">curl -s http://cmc-marathon.inc-mtime.com/v2/apps | jq .apps[].id</span><br></pre></td></tr></table></figure><p>restart</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ID=/test/test-mysql</span><br><span class="line">curl -u user:passwd123 -X POST -H &quot;Content-type: application/json&quot; http://localhost:8080/v2/apps/$&#123;ID&#125;/restart</span><br></pre></td></tr></table></figure>]]></content>
      
      <categories>
          
          <category> marathon </category>
          
      </categories>
      
      
        <tags>
            
            <tag> marathoin </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>mac iterm2 login shell</title>
      <link href="/mac-iterm-shell/"/>
      <url>/mac-iterm-shell/</url>
      <content type="html"><![CDATA[<p>Mac OS自带的终端，用起来虽然有些不太方便，界面也不够友好,iTerm2是一款相对比较好用的终端工具.iTerm2常用操作包括主题选择、声明高亮、自动填充建议、隐藏用户名和主机名、分屏效果等.  </p><p>Mac 暗转 itrem2 的文章很多， 我就不写太多了。  </p><p>itrem2 官网下载： <a href="https://iterm2.com/downloads.html" target="_blank" rel="noopener">https://iterm2.com/downloads.html</a></p><p>可以用命令直接安装：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">brew cask install iterm2</span><br></pre></td></tr></table></figure><p>创建登入脚本，密码设置好，通过传入参数，登入不同机器。</p><p>vim  allssh</p><a id="more"></a><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">#!/usr/bin/expect</span><br><span class="line">set timeout 2</span><br><span class="line">set password loginpasswd</span><br><span class="line">set port [lindex $argv 0]</span><br><span class="line">set user [lindex $argv 1]</span><br><span class="line">set host [lindex $argv 2]</span><br><span class="line">spawn ssh -p  $port -l $user $host</span><br><span class="line">expect &#123;</span><br><span class="line">&quot;*continue connecting*&quot;</span><br><span class="line">&#123;send &quot;yes\r&quot;;exp_continue;&#125;</span><br><span class="line">        &quot;*password*&quot;</span><br><span class="line">        &#123;send &quot;$password\n&quot;&#125;</span><br><span class="line">&#125;</span><br><span class="line">interact</span><br></pre></td></tr></table></figure><p>保存脚本，执行的时候需要传入  端口、用户、主机地址</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./allssh 22 root 192.168.1.243</span><br></pre></td></tr></table></figure><p>在来一个例子：</p><p>密码也会传输。</p><p>vim  autossh</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">#!/usr/bin/expect</span><br><span class="line">set timeout 2</span><br><span class="line">set PORT 22</span><br><span class="line">set USER root</span><br><span class="line">set IP [lindex $argv 0]</span><br><span class="line">set PASS [lindex $argv 1]</span><br><span class="line">if ![string compare $PASS &quot;&quot;] &#123;   # //此处花括号前必须有一个空格，具体请参考TCL语言规范</span><br><span class="line">#    //如果PASS变量为空字符串</span><br><span class="line">    set PASS loginpasswd</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">spawn ssh -p $PORT -l $USER $IP</span><br><span class="line">expect &#123;</span><br><span class="line">&quot;*continue connecting*&quot;</span><br><span class="line">&#123;send &quot;yes\r&quot;;exp_continue;&#125;</span><br><span class="line">        &quot;*password*&quot;</span><br><span class="line">        &#123;send &quot;$PASS\n&quot;&#125;</span><br><span class="line">&#125;</span><br><span class="line">interact</span><br></pre></td></tr></table></figure><p>执行：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">./autossh 192.168.1.243 </span><br><span class="line">或</span><br><span class="line">./autossh 192.168.1.243 newloginpasswd</span><br></pre></td></tr></table></figure><p>在来一个三级登入的例子，先登入堡垒机，在登入跳板机， 在登入内网的机器。</p><p>vim ssh-gate</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">#!/usr/bin/expect</span><br><span class="line">set host [lindex $argv 0]</span><br><span class="line">set TERMSERV 192.168.2.2</span><br><span class="line">set USER baoleiji</span><br><span class="line">set PASSWORD baoleijipasswd</span><br><span class="line">set TBIP 192.168.2.3</span><br><span class="line">set UATUN tiaobanji</span><br><span class="line">set UATPWD tiaobanjipasswd</span><br><span class="line"></span><br><span class="line"># 登录堡垒机</span><br><span class="line">spawn ssh -p 22 -l $USER $TERMSERV</span><br><span class="line">expect &#123;</span><br><span class="line">        &quot;yes/no&quot; &#123;send &quot;yes\r&quot;;exp_continue;&#125;</span><br><span class="line">         &quot;*password:*&quot; &#123; send &quot;$PASSWORD\r&quot; &#125;</span><br><span class="line">        &#125;</span><br><span class="line"># 登录跳板机</span><br><span class="line">expect &quot;*baoleiji@shining-gate00*&quot; &#123;send &quot;ssh -l $UATUN $TBIP\r&quot;&#125;</span><br><span class="line">expect &#123;</span><br><span class="line">        &quot;yes/no&quot; &#123;send &quot;yes\r&quot;;exp_continue;&#125;</span><br><span class="line">        &quot;*password:*&quot; &#123; send &quot;$UATPWD\r&quot; &#125;</span><br><span class="line">        &#125;</span><br><span class="line"># 登入内网</span><br><span class="line">expect &quot;tiaobanji$*&quot; &#123;send &quot;ssh -l root $host\r&quot;&#125;</span><br><span class="line">interact</span><br></pre></td></tr></table></figure><p>执行</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./ssh-gate  192.168.2.243</span><br></pre></td></tr></table></figure><p>另外，iterm2 的快捷键还是很好用的。 </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">登入可以在 Preferences -&gt; Profile -&gt; shortcut key  </span><br><span class="line">Command 里选择 Login Shell  </span><br><span class="line">Send text at start 填写你的脚本路径和命令： /home/autossh 192.168.1.243</span><br></pre></td></tr></table></figure><p>输入的快捷键也是很好用的。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">可以在 Preferences -&gt; keys -&gt; 选择加号 ”+ “</span><br><span class="line">Keyboard Shortcut  设置快捷键，键盘输入</span><br><span class="line">Action 选择 Send Text</span><br><span class="line">下面输入你要输入的内容,  &quot;\n&quot;  代表回车，如：</span><br><span class="line">loginpasswd\n</span><br><span class="line">代表输入我呢密码之后回车。</span><br></pre></td></tr></table></figure>]]></content>
      
      <categories>
          
          <category> mac </category>
          
      </categories>
      
      
        <tags>
            
            <tag> shell </tag>
            
            <tag> mac </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>nginx qat on docker</title>
      <link href="/qat-on-docker/"/>
      <url>/qat-on-docker/</url>
      <content type="html"><![CDATA[<p>Intel QAT 加速卡可以对HTTPS的请求进行异步请求， 加快证书处理， 降低系统性能消耗。<br>nginx 作为代理， 可以代理HTTPS请求， 需要重新编译，支持QAT加速卡，这样才能将请求给QAT加速卡。<br>Intel QAT 加速卡安装在上一遍文章已经提到， 这里就不在说了， 可以查看之前文章。<br>这回我们说说如何把QAT卡封装到docker容器中。<br>我测试过了， 就算在docker容器中安装驱动， 也需要在宿主机上安装驱动。是值代理服务可以不用在宿主机上安装。  </p><p>intel qat 加速卡安装配置 ： <a href="https://sukbeta.github.io/intel-qat/">https://sukbeta.github.io/intel-qat/</a><br>宿主机上nginx配置qat：<a href="https://sukbeta.github.io/nginx-qat/">https://sukbeta.github.io/nginx-qat/</a></p><h5 id="相关URL"><a href="#相关URL" class="headerlink" title="相关URL"></a>相关URL</h5><a id="more"></a><p>nginx qat  docker container install ： <a href="https://01.org/sites/default/files/downloads//337020-003-qatwcontaineranddocker.pdf" target="_blank" rel="noopener">https://01.org/sites/default/files/downloads//337020-003-qatwcontaineranddocker.pdf</a></p><h5 id="安装docker"><a href="#安装docker" class="headerlink" title="安装docker"></a>安装docker</h5><p>简单安装一个docker服务</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">yum install -y yum-utils</span><br><span class="line">yum-config-manager --add-repo  https://download.docker.com/linux/centos/docker-ce.repo</span><br><span class="line">yum install docker-ce</span><br><span class="line">systemctl start docker</span><br></pre></td></tr></table></figure><p>修改docker limit</p><p>vim /usr/lib/systemd/system/docker.service</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[Service]</span><br><span class="line">LimitNOFILE=infinity</span><br><span class="line">LimitNPROC=infinity</span><br><span class="line">LimitCORE=infinity</span><br><span class="line">添加</span><br><span class="line">LimitMEMLOCK=infinity</span><br></pre></td></tr></table></figure><p>重启服务</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl restart docker.service</span><br></pre></td></tr></table></figure><h5 id="Dockerfile-qat-nginx-on-docker"><a href="#Dockerfile-qat-nginx-on-docker" class="headerlink" title="Dockerfile  qat nginx on docker"></a>Dockerfile  qat nginx on docker</h5><p>首先宿主上是安装qat驱动的。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line">FROM centos:7 AS build</span><br><span class="line">RUN yum install -y -q epel-release centos-release-scl</span><br><span class="line">RUN yum -y groupinstall &quot;Development Tools&quot;</span><br><span class="line">RUN yum install -y wget tar gcc-c++ make bzip2 make gcc zlib-devel libtool autoconf cmake make python gcc gawk autoconf automake libtool pkg-config patch pcre-devel libxslt-devel openssl openssl-devel zlib pcre libxslt perl perl-devel pciutils libudev-devel gzip unzip net-tools lsof bzip2 bzip2-devel kernel kernel-devel &amp;&amp; \</span><br><span class="line">rm -rf /var/yum/cache/*</span><br><span class="line">#ADD QAT.tar.gz /home/</span><br><span class="line">ARG ICP_ROOT=/home/QAT</span><br><span class="line">RUN mkdir $ICP_ROOT</span><br><span class="line">ADD QAT1.7.L.4.13.0-00009.tar.gz $ICP_ROOT</span><br><span class="line">RUN cd $ICP_ROOT &amp;&amp; ./configure &amp;&amp; make &amp;&amp; make install &amp;&amp; make samples-install</span><br><span class="line"></span><br><span class="line">ENV OPENSSL_LIB /usr/local/ssl</span><br><span class="line">ENV OPENSSL_ENGINES /usr/local/ssl/lib/engines-1.1</span><br><span class="line">ENV PERL5LIB $PERL5LIB:/home/openssl</span><br><span class="line">ENV PATH $PATH:/usr/local/sbin</span><br><span class="line">ENV SSL_INC /usr/local/ssl/include</span><br><span class="line">ENV SSL_LIB /usr/local/ssl/lib</span><br><span class="line">ENV QZ_ROOT /home/QATzip</span><br><span class="line">ENV OPENSSL_LIB /usr/local/ssl</span><br><span class="line">ENV ICP_ROOT /home/QAT</span><br><span class="line">ENV LD_LIBRARY_PATH $LD_LIBRARY_PATH:$QZ_ROOT/utils:/usr/lib64:/usr/local/lib64:/usr/local/ssl/lib:/usr/local/ssl/lib/engines-1.1:/usr/lib64/openssl/engines:$ICP_ROOT/build:/usr/local/lib</span><br><span class="line"></span><br><span class="line">#RUN cd /home &amp;&amp; git clone https://github.com/openssl/openssl.git</span><br><span class="line">#ADD openssl_github.tar.gz /home/</span><br><span class="line">ADD OpenSSL_1_1_1j.tar.gz /home/</span><br><span class="line">RUN cd /home/ &amp;&amp; mv openssl-OpenSSL_1_1_1j openssl</span><br><span class="line">RUN yum -y install yum-utils perl* judy</span><br><span class="line">RUNcd /home/openssl &amp;&amp; \</span><br><span class="line">./config --prefix=/usr/local/ssl -Wl,-rpath,/usr/local/ssl/lib &amp;&amp;\</span><br><span class="line">make depend &amp;&amp; \</span><br><span class="line">make &amp;&amp; \</span><br><span class="line">make install</span><br><span class="line"></span><br><span class="line">##RUN cd /home &amp;&amp; git clone https://github.com/intel/QAT_Engine.git</span><br><span class="line">ADD QAT_Engine_github.tar.gz /home/</span><br><span class="line">RUN cd /home/QAT_Engine &amp;&amp; \</span><br><span class="line">./autogen.sh &amp;&amp; \</span><br><span class="line">./configure \</span><br><span class="line">--with-qat_hw_dir=/home/QAT \</span><br><span class="line">--enable-qat_sw \</span><br><span class="line">--with-openssl_install_dir=/usr/local/ssl &amp;&amp; \</span><br><span class="line">make &amp;&amp; \</span><br><span class="line">make install</span><br><span class="line"></span><br><span class="line">RUN cd /home/QAT_Engine/qat_contig_mem &amp;&amp; \</span><br><span class="line">make</span><br><span class="line"></span><br><span class="line">RUN cd /home &amp;&amp; git clone https://github.com/intel/asynch_mode_nginx.git</span><br><span class="line">RUN cd /home &amp;&amp; wget http://nginx.org/download/nginx-1.18.0.tar.gz &amp;&amp; tar -zxf nginx-1.18.0.tar.gz</span><br><span class="line">#RUN cd /home &amp;&amp; diff -Naru -x .git nginx-1.18.0 asynch_mode_nginx &gt; async_mode_nginx_1.18.0.patch</span><br><span class="line">ADD patch.sh /home/</span><br><span class="line">RUN chmod +x /home/patch.sh &amp;&amp; bash /home/patch.sh</span><br><span class="line">RUN cd /home/nginx-1.18.0 &amp;&amp; patch -p1 &lt; ../async_mode_nginx_1.18.0.patch</span><br><span class="line"></span><br><span class="line">#RUN cd /home &amp;&amp; git clone https://github.com/intel/QATzip.git</span><br><span class="line">ADD ./QATzip-master.zip /home/</span><br><span class="line">RUN cd /home &amp;&amp; unzip QATzip-master.zip &amp;&amp; mv QATzip-master QATzip</span><br><span class="line">RUN cd /home/QATzip &amp;&amp; \</span><br><span class="line">./configure --with-ICP_ROOT=$ICP_ROOT &amp;&amp; \</span><br><span class="line">make clean &amp;&amp; \</span><br><span class="line">make all install</span><br><span class="line">#RUN cd /home/QATzip &amp;&amp; ./setenv.sh</span><br><span class="line"></span><br><span class="line">ARG NGINX_INSTALL_DIR=/home/nginx</span><br><span class="line">RUN cd /home/nginx-1.18.0 &amp;&amp; \</span><br><span class="line">./configure \</span><br><span class="line">        --prefix=$NGINX_INSTALL_DIR \</span><br><span class="line">        --with-http_ssl_module \</span><br><span class="line">        --add-dynamic-module=modules/nginx_qatzip_module \</span><br><span class="line">        --add-dynamic-module=modules/nginx_qat_module/ \</span><br><span class="line">        --with-cc-opt=&quot;-DNGX_SECURE_MEM -I$OPENSSL_LIB/include -I$ICP_ROOT/quickassist/include -I$ICP_ROOT/quickassist/include/dc -I$QZ_ROOT/include -Wno-error=deprecated-declarations&quot; \</span><br><span class="line">        --with-ld-opt=&quot;-Wl,-rpath=$OPENSSL_LIB/lib -L$OPENSSL_LIB/lib -L$QZ_ROOT/src -lqatzip -lz&quot; &amp;&amp; \</span><br><span class="line">make &amp;&amp; \</span><br><span class="line">make install</span><br><span class="line">ADD ./nginx-conf.tar.gz /home/nginx/conf/</span><br><span class="line">RUN ls /home</span><br><span class="line"></span><br><span class="line">EXPOSE 80 443</span><br><span class="line">CMD [&quot;/home/nginx/sbin/nginx&quot;, &quot;-g&quot;, &quot;daemon off;&quot;]</span><br></pre></td></tr></table></figure><p>build  </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker build -t qat-centos .</span><br></pre></td></tr></table></figure><p>docker run</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">docker run -it --rm --ulimit memlock=-1:-1  $devpara -p 80:80 -p 443:443 qat-centos:latest /bin/bash</span><br><span class="line"># /home/nginx/sbin/nginx</span><br></pre></td></tr></table></figure><h5 id="挂载方式运行"><a href="#挂载方式运行" class="headerlink" title="挂载方式运行"></a>挂载方式运行</h5><p>用挂载方式运行， 将宿主安装的目录挂载到容器中运行， 这样可以运行多个容器。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">docker run -it --rm --ulimit memlock=-1:-1  -v /home:/home -v /usr/local/ssl:/usr/local/ssl -v /usr/local/lib64:/usr/local/lib64 -v /dev/hugepages:/dev/hugepages $devpara -p 80:80 -p 443:443  centos:7 /bin/bash</span><br><span class="line"></span><br><span class="line">#  容器中设置黄精变量</span><br><span class="line">export OPENSSL_LIB=/usr/local/ssl</span><br><span class="line">export OPENSSL_ENGINES=/usr/local/ssl/lib/engines-1.1</span><br><span class="line">export PERL5LIB=$PERL5LIB:/home/openssl</span><br><span class="line">export PATH=$PATH:/usr/local/sbin</span><br><span class="line">export SSL_INC=/usr/local/ssl/include</span><br><span class="line">export SSL_LIB=/usr/local/ssl/lib</span><br><span class="line">export QZ_ROOT=/home/QATzip</span><br><span class="line">export OPENSSL_LIB=/usr/local/ssl</span><br><span class="line">export ICP_ROOT=/home/QAT</span><br><span class="line">export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$QZ_ROOT/utils:/usr/lib64:/usr/local/lib64:/usr/local/ssl/lib:/usr/local/ssl/lib/engines-1.1:/usr/lib64/openssl/engines:$ICP_ROOT/build:/usr/local/lib</span><br><span class="line"></span><br><span class="line"># 容器中验证 qat 卡</span><br><span class="line">/usr/local/ssl/bin/openssl  engine -t -c -vvvv qatengine</span><br><span class="line"></span><br><span class="line"># 容器中启动nginx</span><br><span class="line">/home/nginx/sbin/nginx</span><br></pre></td></tr></table></figure><h5 id="验证加速卡处理数据"><a href="#验证加速卡处理数据" class="headerlink" title="验证加速卡处理数据"></a>验证加速卡处理数据</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat /sys/kernel/debug/qat_dh895xcc_0000\:07\:00.0/fw_counters</span><br></pre></td></tr></table></figure>]]></content>
      
      <categories>
          
          <category> qat </category>
          
      </categories>
      
      
        <tags>
            
            <tag> qat </tag>
            
            <tag> nginx </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>nginx 配置 Intel QAT 加速卡</title>
      <link href="/nginx-qat/"/>
      <url>/nginx-qat/</url>
      <content type="html"><![CDATA[<h4 id="nginx-配置-Intel-QAT-加速卡"><a href="#nginx-配置-Intel-QAT-加速卡" class="headerlink" title="nginx 配置 Intel QAT 加速卡"></a>nginx 配置 Intel QAT 加速卡</h4><p>Intel QAT 加速卡可以对HTTPS的请求进行异步请求， 加快证书处理， 降低系统性能消耗。<br>nginx 作为代理， 可以代理HTTPS请求， 需要重新编译，支持QAT加速卡，这样才能将请求给QAT加速卡。<br> Intel QAT 加速卡安装在上一遍文章已经提到， 这里就不在说了， 可以查看之前文章。<br>intel qat 加速卡安装配置 ： <a href="https://sukbeta.github.io/intel-qat/">https://sukbeta.github.io/intel-qat/</a>  </p><h5 id="相关URL"><a href="#相关URL" class="headerlink" title="相关URL"></a>相关URL</h5><p>Nginx QAT Instasll： <a href="https://01.org/sites/default/files/downloads//337020-003-qatwcontaineranddocker.pdf" target="_blank" rel="noopener">https://01.org/sites/default/files/downloads//337020-003-qatwcontaineranddocker.pdf</a></p><h5 id="下载所需要的安装包"><a href="#下载所需要的安装包" class="headerlink" title="下载所需要的安装包"></a>下载所需要的安装包</h5><p>nginx package</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd /home</span><br><span class="line">wget http://nginx.org/download/nginx-1.18.0.tar.gz</span><br></pre></td></tr></table></figure><a id="more"></a><p>nginx path  ,， nginx 需要打的path文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd /home </span><br><span class="line">git clone https://github.com/intel/asynch_mode_nginx.git</span><br></pre></td></tr></table></figure><p>QATzip ， nginx 上的压缩</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd /home </span><br><span class="line">git clone https://github.com/intel/QATzip.git</span><br></pre></td></tr></table></figure><p>开始干活</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cd /home</span><br><span class="line">tar -zxf nginx-1.18.0.tar.gz</span><br><span class="line">diff -Naru -x .git nginx-1.18.0 asynch_mode_nginx &gt; async_mode_nginx_1.18.0.patch</span><br><span class="line">cd /home/nginx-1.18.0 </span><br><span class="line">patch -p1 &lt; ../async_mode_nginx_1.18.0.patch</span><br></pre></td></tr></table></figure><h5 id="编译-QATzip"><a href="#编译-QATzip" class="headerlink" title="编译 QATzip"></a>编译 QATzip</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">cd /home </span><br><span class="line">git clone https://github.com/intel/QATzip.git</span><br><span class="line">export QZ_ROOT=/home/QATzip</span><br><span class="line">echo 1024 &gt; /sys/kernel/mm/hugepages/hugepages-2048kB/nr_hugepages</span><br><span class="line">rmmod usdm_drv</span><br><span class="line">insmod $ICP_ROOT/build/usdm_drv.ko max_huge_pages=1024 max_huge_pages_per_process=16</span><br><span class="line">cd $QZ_ROOT</span><br><span class="line">./configure --with-ICP_ROOT=$ICP_ROOT</span><br><span class="line">make clean</span><br><span class="line">make all install</span><br><span class="line"> ./setenv.sh</span><br><span class="line"> </span><br><span class="line"> /etc/init.d/qat_service restart</span><br><span class="line">systemctl restart qat_service</span><br></pre></td></tr></table></figure><p>QATzip run test</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd $QZ_ROOT/test/performance_tests</span><br><span class="line">./run_perf_test.sh</span><br></pre></td></tr></table></figure><h5 id="nginx-编译"><a href="#nginx-编译" class="headerlink" title="nginx 编译"></a>nginx 编译</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">cd /home/nginx-1.18.0</span><br><span class="line"> export NGINX_INSTALL_DIR=/home/nginx</span><br><span class="line">./configure \</span><br><span class="line">    --prefix=$NGINX_INSTALL_DIR \</span><br><span class="line">    --with-http_ssl_module \</span><br><span class="line">    --add-dynamic-module=modules/nginx_qatzip_module \</span><br><span class="line">    --add-dynamic-module=modules/nginx_qat_module/ \</span><br><span class="line">    --with-cc-opt=&quot;-DNGX_SECURE_MEM -I$OPENSSL_LIB/include -I$ICP_ROOT/quickassist/include -I$ICP_ROOT/quickassist/include/dc -I$QZ_ROOT/include -Wno-error=deprecated-declarations&quot; \</span><br><span class="line">    --with-ld-opt=&quot;-Wl,-rpath=$OPENSSL_LIB/lib -L$OPENSSL_LIB/lib -L$QZ_ROOT/src -lqatzip -lz&quot; </span><br><span class="line">make </span><br><span class="line">make install</span><br></pre></td></tr></table></figure><h5 id="nginx-配置文件"><a href="#nginx-配置文件" class="headerlink" title="nginx 配置文件"></a>nginx 配置文件</h5><p>vim conf/nginx.conf</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><span class="line">worker_processes  10;</span><br><span class="line">user root;</span><br><span class="line">error_log logs/error.log;</span><br><span class="line"></span><br><span class="line">load_module modules/ngx_http_qatzip_filter_module.so;</span><br><span class="line">load_module modules/ngx_ssl_engine_qat_module.so;</span><br><span class="line"></span><br><span class="line">events &#123;</span><br><span class="line">    use epoll;</span><br><span class="line">    worker_connections 102400;</span><br><span class="line">    accept_mutex off;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"># Enable QAT engine in heretic mode.</span><br><span class="line">ssl_engine &#123;</span><br><span class="line">    use_engine qatengine;</span><br><span class="line">    default_algorithms RSA,EC,DH,DSA;</span><br><span class="line">    qat_engine &#123;</span><br><span class="line">        qat_offload_mode async;</span><br><span class="line">        qat_notify_mode poll;</span><br><span class="line">        qat_poll_mode heuristic;</span><br><span class="line">        qat_sw_fallback on;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">http &#123;</span><br><span class="line">    gzip on;</span><br><span class="line">    gzip_min_length     128;</span><br><span class="line">    gzip_comp_level     1;</span><br><span class="line">    gzip_types  text/css text/javascript text/xml text/plain text/x-component application/javascript application/json application/xml application/rss+xml font/truetype font/opentype application/vnd.ms-fontobject image/svg+xml;</span><br><span class="line">    gzip_vary            on;</span><br><span class="line">    gzip_disable        &quot;msie6&quot;;</span><br><span class="line">    gzip_http_version   1.0;</span><br><span class="line"></span><br><span class="line">    qatzip_sw failover;</span><br><span class="line">    qatzip_min_length 128;</span><br><span class="line">    qatzip_comp_level 1;</span><br><span class="line">    qatzip_buffers 16 8k;</span><br><span class="line">    qatzip_types text/css text/javascript text/xml text/plain text/x-component application/javascript application/json application/xml application/rss+xml font/truetype font/opentype application/vnd.ms-fontobject image/svg+xml application/octet-stream image/jpeg;</span><br><span class="line">    qatzip_chunk_size   64k;</span><br><span class="line">    qatzip_stream_size  256k;</span><br><span class="line">    qatzip_sw_threshold 256;</span><br><span class="line"></span><br><span class="line">    log_format  main  &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos;</span><br><span class="line">                      &apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos;</span><br><span class="line">                      &apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&apos;;</span><br><span class="line"></span><br><span class="line">    access_log  logs/access.log  main;</span><br><span class="line"></span><br><span class="line">    include server/*.conf;</span><br><span class="line"></span><br><span class="line">    # HTTP server with QATZip enabled.</span><br><span class="line">    server &#123;</span><br><span class="line">        listen       80;</span><br><span class="line">        server_name  localhost;</span><br><span class="line">        location / &#123;</span><br><span class="line">            root   html;</span><br><span class="line">            index  index.html index.htm;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    # HTTPS server with async mode.</span><br><span class="line">    server &#123;</span><br><span class="line">        #If QAT Engine enabled,  `asynch` need to add to `listen` directive or just add `ssl_asynch  on;` to the context.</span><br><span class="line">        listen       443 ssl asynch;</span><br><span class="line">access_log  logs/access.log  main;</span><br><span class="line">        server_name  localhost;</span><br><span class="line"></span><br><span class="line">        ssl_protocols       TLSv1.2;</span><br><span class="line">        ssl_certificate crt/ca.com.crt;</span><br><span class="line">        ssl_certificate_key crt/ca.com.key;</span><br><span class="line"></span><br><span class="line">        location / &#123;</span><br><span class="line">            root   html;</span><br><span class="line">            index  index.html index.htm;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>配置文件需要添加的很明确， 就不多说了。   </p><p>run nginx server</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/home/nginx/sbin/nginx</span><br></pre></td></tr></table></figure><h5 id="验证QAT卡是否工作"><a href="#验证QAT卡是否工作" class="headerlink" title="验证QAT卡是否工作"></a>验证QAT卡是否工作</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat /sys/kernel/debug/qat_dh895xcc_0000\:07\:00.0/fw_counters</span><br></pre></td></tr></table></figure><p>这个是QAT卡计数的， 当QAT卡处理请求时， 这里会变化的。 </p>]]></content>
      
      <categories>
          
          <category> qat </category>
          
      </categories>
      
      
        <tags>
            
            <tag> qat </tag>
            
            <tag> nginx </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Haproxy 配置 Intel QAT 加速卡</title>
      <link href="/haproxy-qat/"/>
      <url>/haproxy-qat/</url>
      <content type="html"><![CDATA[<h4 id="Haproxy-配置-Intel-QAT-加速卡"><a href="#Haproxy-配置-Intel-QAT-加速卡" class="headerlink" title="Haproxy 配置 Intel QAT 加速卡"></a>Haproxy 配置 Intel QAT 加速卡</h4><p>Intel QAT 加速卡可以对HTTPS的请求进行异步请求， 加快证书处理， 降低系统性能消耗。<br>Haproxy 作为代理， 可以代理HTTPS请求， 需要重新编译，支持QAT加速卡，这样才能将请求给QAT加速卡。<br> Intel QAT 加速卡安装在上一遍文章已经提到， 这里就不在说了， 可以查看之前文章。<br>intel qat 加速卡安装配置 ： <a href="https://sukbeta.github.io/intel-qat/">https://sukbeta.github.io/intel-qat/</a>  </p><h5 id="相关URL"><a href="#相关URL" class="headerlink" title="相关URL"></a>相关URL</h5><p>haproxy QAT Install： <a href="https://01.org/sites/default/files/downloads/621658-1.1-qat-debugging-guide.pdf" target="_blank" rel="noopener">https://01.org/sites/default/files/downloads/621658-1.1-qat-debugging-guide.pdf </a><br> haproxy intel 测试配置:  <a href="https://software.intel.com/content/www/cn/zh/develop/articles/accelerating-ssl-load-balancers-with-intel-xeon-v3-processors.html" target="_blank" rel="noopener">https://software.intel.com/content/www/cn/zh/develop/articles/accelerating-ssl-load-balancers-with-intel-xeon-v3-processors.html</a></p><h5 id="Hadproxy-下载"><a href="#Hadproxy-下载" class="headerlink" title="Hadproxy 下载"></a>Hadproxy 下载</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd /home</span><br><span class="line">wget https://www.haproxy.org/download/1.9/src/haproxy-1.9.16.tar.gz</span><br></pre></td></tr></table></figure><a id="more"></a><h5 id="编译"><a href="#编译" class="headerlink" title="编译"></a>编译</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd haproxy-1.9.16</span><br><span class="line">make TARGET=linux2628 ARCH=x86_64 USE_PCRE=1 USE_OPENSSL=1 USE_ZLIB=1 USE_CRYPT_H=1 USE_LIBCRYPT=1 SSL_INC=/usr/local/ssl/include SSL_LIB=/usr/local/ssl/lib ADDLIB=-ldl</span><br><span class="line">make install PREFIX=/usr/local/haproxy</span><br></pre></td></tr></table></figure><h5 id="Hadproxy-配置文件"><a href="#Hadproxy-配置文件" class="headerlink" title="Hadproxy 配置文件"></a>Hadproxy 配置文件</h5><p>需要再配置文件中添加：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ssl-engine qatengine algo ALL</span><br><span class="line">ssl-mode-async</span><br></pre></td></tr></table></figure><p>具体内容：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">global</span><br><span class="line">  daemon</span><br><span class="line">  log 127.0.0.1 local1 debug</span><br><span class="line">  maxconn 65535</span><br><span class="line">  ssl-engine qatengine algo ALL</span><br><span class="line">  ssl-mode-async</span><br><span class="line">  tune.ssl.default-dh-param 2048</span><br><span class="line">  ssl-default-bind-ciphers AES128-SHA</span><br><span class="line">  ssl-default-bind-options no-tls-tickets no-sslv3 no-tlsv10 no-tlsv11</span><br><span class="line">  nbproc 10</span><br><span class="line">defaults</span><br><span class="line">  log               global</span><br><span class="line">  modehttp</span><br><span class="line">  optionhttplog</span><br><span class="line">  optiondontlognull</span><br><span class="line">  retries                   3</span><br><span class="line">  backlog               10000</span><br><span class="line">  maxconn               65535</span><br><span class="line">  timeout connect          10s</span><br><span class="line">  timeout client          300s</span><br><span class="line">  timeout server          300s</span><br><span class="line">  timeout tunnel        3600s</span><br><span class="line">  timeout http-keep-alive  1s</span><br><span class="line">  timeout http-request    15s</span><br><span class="line">  timeout queue           300s</span><br><span class="line">  timeout tarpit          60s</span><br><span class="line">  option            dontlognull</span><br><span class="line">  option            http-server-close</span><br><span class="line">  option            redispatch</span><br><span class="line"></span><br><span class="line">frontend myfrontend</span><br><span class="line">        bind :443 ssl crt /usr/local/haproxy/crt/cacom.pem</span><br><span class="line">mode http</span><br><span class="line"></span><br><span class="line">frontend myfrontend_80</span><br><span class="line">        bind :80</span><br><span class="line">mode http</span><br><span class="line"></span><br><span class="line">backend mybackend</span><br><span class="line">        server s3 192.168.1.246:80</span><br></pre></td></tr></table></figure><h5 id="启动-Haproxy"><a href="#启动-Haproxy" class="headerlink" title="启动 Haproxy"></a>启动 Haproxy</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd /usr/local/haproxy/sbin</span><br><span class="line">./haproxy -f qat.conf</span><br></pre></td></tr></table></figure><h5 id="验证QAT卡是否工作"><a href="#验证QAT卡是否工作" class="headerlink" title="验证QAT卡是否工作"></a>验证QAT卡是否工作</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat /sys/kernel/debug/qat_dh895xcc_0000\:07\:00.0/fw_counters</span><br></pre></td></tr></table></figure><p>这个是QAT卡计数的， 当QAT卡处理请求时， 这里会变化的。 </p>]]></content>
      
      <categories>
          
          <category> qat </category>
          
      </categories>
      
      
        <tags>
            
            <tag> qat </tag>
            
            <tag> haproxy </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>intel qat 加速卡安装配置</title>
      <link href="/intel-qat/"/>
      <url>/intel-qat/</url>
      <content type="html"><![CDATA[<h3 id="intel-qat-加速卡安装配置"><a href="#intel-qat-加速卡安装配置" class="headerlink" title="intel qat 加速卡安装配置"></a>intel qat 加速卡安装配置</h3><p>  英特尔 Quick Assist Technology （以下简称 QAT ）是 英特尔 针对网络安全和数据存储 推出 的一个硬件 加速 技术。 QAT 支持对称数据加密算法（如AES）中的密码操作和验证操作运算和公钥非对称数据加密算法。<br>  Intel QAT加速卡结合Intel其QAT_Engine测试性能的提升，其支持的异步模式对性能的提升很大</p><h3 id="相关URL"><a href="#相关URL" class="headerlink" title="相关URL"></a>相关URL</h3><p>QAT 官网 ： <a href="https://www.intel.cn/content/www/cn/zh/architecture-and-technology/intel-quick-assist-technology-overview.html" target="_blank" rel="noopener">https://www.intel.cn/content/www/cn/zh/architecture-and-technology/intel-quick-assist-technology-overview.html</a><br>QAT卡说明：<a href="https://01.org/sites/default/files/downloads/intelr-quickassist-technology/intelquickassisttechnologyopensslperformance.pdf" target="_blank" rel="noopener">https://01.org/sites/default/files/downloads/intelr-quickassist-technology/intelquickassisttechnologyopensslperformance.pdf</a><br><a id="more"></a><br>QAT卡相关驱动、资料：<a href="https://01.org/intel-quickassist-technology" target="_blank" rel="noopener">https://01.org/intel-quickassist-technology</a><br>QAT驱动安装文档：<a href="https://01.org/sites/default/files/downloads//336212-intelrquickassisttechnology-gsg-revision008.pdf" target="_blank" rel="noopener">https://01.org/sites/default/files/downloads//336212-intelrquickassisttechnology-gsg-revision008.pdf</a><br>QAT安装视频：<a href="https://software.intel.com/content/www/us/en/develop/videos/intel-quickassist-technology-openssl-1-1-x-qat-engine.html" target="_blank" rel="noopener">https://software.intel.com/content/www/us/en/develop/videos/intel-quickassist-technology-openssl-1-1-x-qat-engine.html</a><br>性能对比：<a href="https://software.intel.com/content/www/cn/zh/develop/articles/improving-openssl-performance.html" target="_blank" rel="noopener">https://software.intel.com/content/www/cn/zh/develop/articles/improving-openssl-performance.html</a>  </p><h3 id="centos7-5-系统环境"><a href="#centos7-5-系统环境" class="headerlink" title="centos7.5  系统环境"></a>centos7.5  系统环境</h3><h5 id="yum-package"><a href="#yum-package" class="headerlink" title="yum package"></a>yum package</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">yum install epel-release.noarch</span><br><span class="line">yum -y install  wget gcc gcc-c++ gcc-g77 autoconf automake zlib* fiex* libxml* ncurses-devel libmcrypt* libtool-ltdl-devel* make cmake bind-utils ntp ntpdate lrzsz rsync gzip unzip vim telnet openssl-devel nscd g++ sysstat ncurses-libs bzip2-devel git lsof sqlite-devel ftp net-tools</span><br><span class="line"></span><br><span class="line">yum install -y openssl-devel pciutils zlib-devel gcc libudev-devel boost-devel</span><br><span class="line"></span><br><span class="line">yum -y groupinstall &quot;Development Tools&quot;</span><br><span class="line">yum -y install pciutils</span><br><span class="line">yum -y install openssl-devel  zlib-devel  gcc   libudev-devel boost-devel  pciutils</span><br><span class="line"></span><br><span class="line">yum install perl perl-devel</span><br><span class="line">yum groupinstall perl*</span><br><span class="line">yum install -y kernel kernel-devel kernel-devel-$(uname -r)</span><br></pre></td></tr></table></figure><h5 id="关闭服务"><a href="#关闭服务" class="headerlink" title="关闭服务"></a>关闭服务</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">systemctl stop firewalld</span><br><span class="line">systemctl disable firewalld</span><br><span class="line">systemctl stop NetworkManager</span><br><span class="line">systemctl disable NetworkManager</span><br><span class="line"></span><br><span class="line">sed -i &quot;/^SELINUX=/s/enforcing/disabled/g&quot; /etc/selinux/config</span><br><span class="line"></span><br><span class="line">vim  /etc/security/limits.conf</span><br><span class="line">*       soft nofile 655350</span><br><span class="line">*       hard nofile 655350</span><br><span class="line">*       soft nproc 655350</span><br><span class="line">*       hard nproc 655350</span><br><span class="line">*       soft core 655350</span><br><span class="line">*       hard core 655350</span><br><span class="line">*       soft memlock 655350</span><br><span class="line">*       hard memlock 655350</span><br></pre></td></tr></table></figure><p>###安装驱动：<br>驱动下载地址： <a href="https://01.org/packet-processing/intel%C2%AE-quickassist-technology-drivers-and-patches" target="_blank" rel="noopener">https://01.org/packet-processing/intel%C2%AE-quickassist-technology-drivers-and-patches</a></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">cd /home</span><br><span class="line">wget https://downloadmirror.intel.com/30178/eng/QAT1.7.L.4.13.0-00009.tar.gz</span><br><span class="line">mkdir  /home/QAT</span><br><span class="line">tar -zxvf QAT1.7.L.4.13.0-00009.tar.gz -C /home/QAT</span><br><span class="line">cd /home/QAT</span><br><span class="line">./configure    开启api  ./configure --enable-kapi</span><br><span class="line">我的</span><br><span class="line">./configure --enable-qat-lkcf --enable-icp-dc-sym-only --enable-kapi</span><br><span class="line">make</span><br><span class="line">make install</span><br><span class="line">make samples-install  </span><br><span class="line"></span><br><span class="line">在build下， 会出 cpa_sample_code.ko 模块， 可以用  </span><br><span class="line">insmod ./build/cpa_sample_code.ko 加载</span><br><span class="line">cpa_sample_code   执行测试</span><br></pre></td></tr></table></figure><p>查看服务</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">/etc/init.d/qat_service status</span><br><span class="line">/etc/init.d/qat_service restart</span><br><span class="line">systemctl restart qat_service</span><br></pre></td></tr></table></figure><h3 id="升级-openssl"><a href="#升级-openssl" class="headerlink" title="升级 openssl"></a>升级 openssl</h3><p>qat 用到的 openssl 的版本需要 1.1.0 之上的。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">wget https://www.openssl.org/source/openssl-1.1.1g.tar.gz</span><br><span class="line">tar -zxvf openssl-1.1.1g.tar.gz</span><br><span class="line">ln -s openssl-1.1.1g openssl</span><br><span class="line">cd openssl</span><br><span class="line">./config --prefix=/usr/local/ssl</span><br><span class="line">make depend</span><br><span class="line">make</span><br><span class="line">make install</span><br><span class="line"></span><br><span class="line">添加环境变量</span><br><span class="line">export OPENSSL_ENGINES=/usr/local/ssl/lib/engines-1.1   并添加到   vim /etc/profile   source /etc/profile</span><br><span class="line"></span><br><span class="line">添加动态库</span><br><span class="line">echo /usr/local/ssl/lib/ &gt; /etc/ld.so.conf.d/qat.conf</span><br><span class="line">ldconfig</span><br><span class="line"></span><br><span class="line">验证</span><br><span class="line">/usr/local/ssl/bin/openssl version</span><br></pre></td></tr></table></figure><h3 id="设置环境变量"><a href="#设置环境变量" class="headerlink" title="设置环境变量"></a>设置环境变量</h3><p>统一在这里整理一份</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/profile</span><br><span class="line"></span><br><span class="line">export OPENSSL_LIB=/usr/local/ssl</span><br><span class="line">export OPENSSL_ENGINES=/usr/local/ssl/lib/engines-1.1</span><br><span class="line">export PERL5LIB=$PERL5LIB:/home/openssl</span><br><span class="line">export PATH=$PATH:/usr/local/sbin</span><br><span class="line">export SSL_INC=/usr/local/ssl/include</span><br><span class="line">export SSL_LIB=/usr/local/ssl/lib</span><br><span class="line">export QZ_ROOT=/home/QATzip</span><br><span class="line">export OPENSSL_LIB=/usr/local/ssl</span><br><span class="line">export ICP_ROOT=/home/QAT</span><br><span class="line">export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$QZ_ROOT/utils:/usr/lib64:/usr/local/lib64:/usr/local/ssl/lib:/usr/local/ssl/lib/engines-1.1:/usr/lib64/openssl/engines:/$ICP_ROOT/build</span><br><span class="line"></span><br><span class="line">source /etc/profile</span><br></pre></td></tr></table></figure><h3 id="QAT引擎编译"><a href="#QAT引擎编译" class="headerlink" title="QAT引擎编译"></a>QAT引擎编译</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">cd /home</span><br><span class="line">git clone https://github.com/01org/QAT_Engine.git</span><br><span class="line">cd QAT_Engine</span><br><span class="line">./autogen.sh</span><br><span class="line">./configure --with-qat_dir=/root/qat --with-openssl_dir=/root/openssl-1.1.1g --with-openssl_install_dir=/usr/local/ssl --with-qat_hw_dir=/root/qat --enable-upstream_driver --enable-usdm</span><br><span class="line">或</span><br><span class="line">./configure --with-qat_dir=$ICP_ROOT --with-openssl_dir=/home/openssl --with-openssl_install_dir=/usr/local/ssl --with-qat_hw_dir=$ICP_ROOT --enable-qat_sw --enable-upstream_driver  --enable-usdm</span><br><span class="line">export PERL5LIB=$PERL5LIB:/home/openssl   不配置这个 make 会报错</span><br><span class="line">make</span><br><span class="line">make install</span><br><span class="line"></span><br><span class="line">cd /home/QAT_Engine/qat_contig_mem</span><br><span class="line">make</span><br><span class="line"></span><br><span class="line">cp /etc/dh895xcc_dev0.conf /etc/dh895xcc_dev0.conf_backup1</span><br><span class="line">cp qat/config/dh895xcc/multi_process_optimized/dh895xcc_dev0.conf /etc/   后续需要整合配置文件</span><br><span class="line">/etc/init.d/qat_service restart</span><br><span class="line">systemctl restart qat_service</span><br></pre></td></tr></table></figure><h3 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h3><h5 id="测试验证："><a href="#测试验证：" class="headerlink" title="测试验证："></a>测试验证：</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">/usr/local/ssl/bin/openssl  engine -t -c -vvvv qatengine</span><br><span class="line">或  (看生成的是名字， 是qat 还是 qatengine)</span><br><span class="line">/usr/local/ssl/bin/openssl  engine -t -c -vvvv qat</span><br><span class="line">`</span><br></pre></td></tr></table></figure><p>系统正常跑</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/usr/local/ssl/bin/openssl speed -elapsed rsa2048</span><br></pre></td></tr></table></figure><p>加速卡跑</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/usr/local/ssl/bin/openssl speed -engine qat_dev0 -elapsed rsa2048</span><br></pre></td></tr></table></figure><h5 id="openssl-speed测试命令"><a href="#openssl-speed测试命令" class="headerlink" title="openssl speed测试命令"></a>openssl speed测试命令</h5><ul><li>RSA2048</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">  # Software 纯软</span><br><span class="line">/usr/local/ssl/bin/opensslspeed -elapsed rsa2048</span><br><span class="line">  # Synchronous 同步</span><br><span class="line">/usr/local/ssl/bin/opensslspeed -engine qatengine -elapsed rsa2048</span><br><span class="line">  # Asynchronous1 异步</span><br><span class="line">/usr/local/ssl/bin/openssl speed -engine qatengine -elapsed -async_jobs 36 rsa2048</span><br><span class="line">    # Asynchronous2 异步</span><br><span class="line">/usr/local/ssl/bin/openssl speed -engine qatengine -elapsed -async_jobs 72 rsa2048</span><br></pre></td></tr></table></figure><ul><li>ECDSA-P256</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">  # Software 纯软</span><br><span class="line">/usr/local/ssl/bin/openssl speed -elapsed ecdsap256</span><br><span class="line">  # Synchronous 同步</span><br><span class="line">/usr/local/ssl/bin/openssl speed -engine qatengine -elapsed ecdsap256</span><br><span class="line">  # Asynchronous1 异步1</span><br><span class="line">/usr/local/ssl/bin/openssl speed -engine qatengine -elapsed -async_jobs 36 ecdsap256</span><br><span class="line">    # Asynchronous2 异步2</span><br><span class="line">/usr/local/ssl/bin/opensslspeed -engine qatengine -elapsed -async_jobs 72 ecdsap256</span><br></pre></td></tr></table></figure><h3 id="查看-qat-卡-接受处理数据"><a href="#查看-qat-卡-接受处理数据" class="headerlink" title="查看 qat 卡 接受处理数据"></a>查看 qat 卡 接受处理数据</h3><p>QAT卡在工作的时候，计数会一直变化</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat /sys/kernel/debug/qat_dh895xcc_0000\:07\:00.0/fw_counters</span><br></pre></td></tr></table></figure><h3 id="配置文件："><a href="#配置文件：" class="headerlink" title="配置文件："></a>配置文件：</h3><p>QAT 默认配置文件   /etc/dh895xcc_dev0.conf</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br></pre></td><td class="code"><pre><span class="line">#########################################################################</span><br><span class="line">#</span><br><span class="line"># @par</span><br><span class="line"># This file is provided under a dual BSD/GPLv2 license.  When using or</span><br><span class="line">#   redistributing this file, you may do so under either license.</span><br><span class="line">#</span><br><span class="line">#   GPL LICENSE SUMMARY</span><br><span class="line">#</span><br><span class="line">#   Copyright(c) 2007-2021 Intel Corporation. All rights reserved.</span><br><span class="line">#</span><br><span class="line">#   This program is free software; you can redistribute it and/or modify</span><br><span class="line">#   it under the terms of version 2 of the GNU General Public License as</span><br><span class="line">#   published by the Free Software Foundation.</span><br><span class="line">#</span><br><span class="line">#   This program is distributed in the hope that it will be useful, but</span><br><span class="line">#   WITHOUT ANY WARRANTY; without even the implied warranty of</span><br><span class="line">#   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU</span><br><span class="line">#   General Public License for more details.</span><br><span class="line">#</span><br><span class="line">#   You should have received a copy of the GNU General Public License</span><br><span class="line">#   along with this program; if not, write to the Free Software</span><br><span class="line">#   Foundation, Inc., 51 Franklin St - Fifth Floor, Boston, MA 02110-1301 USA.</span><br><span class="line">#   The full GNU General Public License is included in this distribution</span><br><span class="line">#   in the file called LICENSE.GPL.</span><br><span class="line">#</span><br><span class="line">#   Contact Information:</span><br><span class="line">#   Intel Corporation</span><br><span class="line">#</span><br><span class="line">#   BSD LICENSE</span><br><span class="line">#</span><br><span class="line">#   Copyright(c) 2007-2021 Intel Corporation. All rights reserved.</span><br><span class="line">#</span><br><span class="line">#   Redistribution and use in source and binary forms, with or without</span><br><span class="line">#   modification, are permitted provided that the following conditions</span><br><span class="line">#   are met:</span><br><span class="line">#</span><br><span class="line">#     * Redistributions of source code must retain the above copyright</span><br><span class="line">#       notice, this list of conditions and the following disclaimer.</span><br><span class="line">#     * Redistributions in binary form must reproduce the above copyright</span><br><span class="line">#       notice, this list of conditions and the following disclaimer in</span><br><span class="line">#       the documentation and/or other materials provided with the</span><br><span class="line">#       distribution.</span><br><span class="line">#     * Neither the name of Intel Corporation nor the names of its</span><br><span class="line">#       contributors may be used to endorse or promote products derived</span><br><span class="line">#       from this software without specific prior written permission.</span><br><span class="line">#</span><br><span class="line">#   THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS</span><br><span class="line">#   &quot;AS IS&quot; AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT</span><br><span class="line">#   LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR</span><br><span class="line">#   A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT</span><br><span class="line">#   OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,</span><br><span class="line">#   SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT</span><br><span class="line">#   LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,</span><br><span class="line">#   DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY</span><br><span class="line">#   THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT</span><br><span class="line">#   (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE</span><br><span class="line">#   OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.</span><br><span class="line">#</span><br><span class="line">#</span><br><span class="line">#########################################################################</span><br><span class="line">[GENERAL]</span><br><span class="line">ServicesEnabled = dc;cy</span><br><span class="line"></span><br><span class="line"># Set the service profile to determine available features</span><br><span class="line"># =====================================================================</span><br><span class="line">#                               DEFAULT    CRYPTO  COMPRESSION  CUSTOM1</span><br><span class="line"># Asymmetric Crypto                *         *                     *</span><br><span class="line"># Symmetric Crypto                 *         *                     *</span><br><span class="line"># MGF KeyGen                       *         *</span><br><span class="line"># SSL/TLS KeyGen                   *         *                     *</span><br><span class="line"># HKDF                                       *                     *</span><br><span class="line"># Compression                      *                    *          *</span><br><span class="line"># Decompression (stateless)        *                    *          *</span><br><span class="line"># Decompression (stateful)         *                    *</span><br><span class="line"># Service Chaining                                      *</span><br><span class="line"># Device Utilization                         *                     *</span><br><span class="line"># Rate Limiting                              *                     *</span><br><span class="line"># =====================================================================</span><br><span class="line">ServicesProfile = DEFAULT</span><br><span class="line"></span><br><span class="line">ConfigVersion = 2</span><br><span class="line"></span><br><span class="line">#Default values for number of concurrent requests*/</span><br><span class="line">CyNumConcurrentSymRequests = 512</span><br><span class="line">CyNumConcurrentAsymRequests = 64</span><br><span class="line"></span><br><span class="line">#Statistics, valid values: 1,0</span><br><span class="line">statsGeneral = 1</span><br><span class="line">statsDh = 1</span><br><span class="line">statsDrbg = 1</span><br><span class="line">statsDsa = 1</span><br><span class="line">statsEcc = 1</span><br><span class="line">statsKeyGen = 1</span><br><span class="line">statsDc = 1</span><br><span class="line">statsLn = 1</span><br><span class="line">statsPrime = 1</span><br><span class="line">statsRsa = 1</span><br><span class="line">statsSym = 1</span><br><span class="line"></span><br><span class="line"># Debug feature, if set to 1 it enables additional entries in /proc filesystem</span><br><span class="line">ProcDebug = 1</span><br><span class="line"></span><br><span class="line"># This flag is to enable device auto reset on heartbeat error</span><br><span class="line">AutoResetOnError = 0</span><br><span class="line"></span><br><span class="line">##############################################</span><br><span class="line"># Kernel Instances Section</span><br><span class="line">##############################################</span><br><span class="line">[KERNEL]</span><br><span class="line">NumberCyInstances = 0</span><br><span class="line">NumberDcInstances = 0</span><br><span class="line"></span><br><span class="line">##############################################</span><br><span class="line"># User Process Instance Section</span><br><span class="line">##############################################</span><br><span class="line">[SHIM]</span><br><span class="line">NumberCyInstances = 1</span><br><span class="line">NumberDcInstances = 0</span><br><span class="line">NumProcesses = 32</span><br><span class="line">LimitDevAccess = 1</span><br><span class="line"></span><br><span class="line"># Crypto - User space</span><br><span class="line">Cy0Name = &quot;UserCY0&quot;</span><br><span class="line">Cy0IsPolled = 1</span><br><span class="line">Cy0CoreAffinity = 0-31</span><br><span class="line"></span><br><span class="line">##############################################</span><br><span class="line"># User Process Instance Section</span><br><span class="line">##############################################</span><br><span class="line">[SSL]</span><br><span class="line">NumberCyInstances = 2</span><br><span class="line">NumberDcInstances = 2</span><br><span class="line">NumProcesses = 1</span><br><span class="line">LimitDevAccess = 0</span><br><span class="line"></span><br><span class="line"># Crypto - User instance #0</span><br><span class="line">Cy0Name = &quot;SSL0&quot;</span><br><span class="line">Cy0IsPolled = 1</span><br><span class="line"># List of core affinities</span><br><span class="line">Cy0CoreAffinity = 0</span><br><span class="line"></span><br><span class="line"># Crypto - User instance #1</span><br><span class="line">Cy1Name = &quot;SSL1&quot;</span><br><span class="line">Cy1IsPolled = 1</span><br><span class="line"># List of core affinities</span><br><span class="line">Cy1CoreAffinity = 1</span><br><span class="line"></span><br><span class="line"># Data Compression - User instance #0</span><br><span class="line">Dc0Name = &quot;Dc0&quot;</span><br><span class="line">Dc0IsPolled = 1</span><br><span class="line"># List of core affinities</span><br><span class="line">Dc0CoreAffinity = 0</span><br><span class="line"></span><br><span class="line"># Data Compression - User instance #1</span><br><span class="line">Dc1Name = &quot;Dc1&quot;</span><br><span class="line">Dc1IsPolled = 1</span><br><span class="line"># List of core affinities</span><br><span class="line">Dc1CoreAffinity = 1</span><br><span class="line"></span><br><span class="line">[KERNEL_QAT]</span><br><span class="line">NumberCyInstances = 2</span><br><span class="line">NumberDcInstances = 2</span><br><span class="line"></span><br><span class="line"># Crypto - Kernel instance #0</span><br><span class="line">Cy0Name = &quot;IPSec0&quot;</span><br><span class="line">Cy0IsPolled = 0</span><br><span class="line">Cy0CoreAffinity = 1</span><br><span class="line"></span><br><span class="line"># Crypto - Kernel instance #1</span><br><span class="line">Cy1Name = &quot;IPSec1&quot;</span><br><span class="line">Cy1IsPolled = 0</span><br><span class="line">Cy1CoreAffinity = 2</span><br><span class="line"></span><br><span class="line"># Data Compression - Kernel instance #0</span><br><span class="line">Dc0Name = &quot;IPComp0&quot;</span><br><span class="line">Dc0IsPolled = 0</span><br><span class="line">Dc0CoreAffinity = 3</span><br><span class="line"></span><br><span class="line"># Data Compression - Kernel instance #1</span><br><span class="line">Dc1Name = &quot;IPComp1&quot;</span><br><span class="line">Dc1IsPolled = 0</span><br><span class="line">Dc1CoreAffinity = 4</span><br></pre></td></tr></table></figure><h5 id="重启服务"><a href="#重启服务" class="headerlink" title="重启服务"></a>重启服务</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">/etc/init.d/qat_service restart</span><br><span class="line">systemctl restart qat_service</span><br><span class="line"></span><br><span class="line">验证</span><br><span class="line">/usr/local/ssl/bin/openssl  engine -t -c -vvvv qatengine</span><br><span class="line">和</span><br><span class="line">cpa_sample_code</span><br><span class="line">都可以跑了</span><br></pre></td></tr></table></figure>]]></content>
      
      <categories>
          
          <category> qat </category>
          
      </categories>
      
      
        <tags>
            
            <tag> qat </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>RKE 安装 rancher server HA</title>
      <link href="/rke-rancher-ha/"/>
      <url>/rke-rancher-ha/</url>
      <content type="html"><![CDATA[<p>RKE 安装 rancher HA server 一般要有4台机器， 一台是lvs、nginx代理机器，3台为K8S机器，做etc、rancher server。</p><p>版本：  </p><ul><li>docker: 19.03.5  </li><li>rancher server： 2.4.5  </li><li>kubrctl: 1.18.5  </li><li>rke: 1.0.10  </li><li>helm：2.16.6  </li></ul><a id="more"></a><h3 id="机器列表"><a href="#机器列表" class="headerlink" title="机器列表"></a>机器列表</h3><table><thead><tr><th>IP</th><th>主机名</th><th>备注</th></tr></thead><tbody><tr><td>192.168.5.100</td><td>bigdata00.shining.com</td><td>k8s、etcd、rancher server</td></tr><tr><td>192.168.5.101</td><td>bigdata01.shining.com</td><td>k8s、etcd、rancher server</td></tr><tr><td>192.168.5.103</td><td>bigdata03.shining.com</td><td>k8s、etcd、rancher server</td></tr><tr><td>192.168.5.237</td><td>rancher.shining.com</td><td>nginx</td></tr></tbody></table><p>centos7 永久修改主机名，使用命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hostnamectl set-hostname xxx</span><br></pre></td></tr></table></figure><h3 id="安装-RKE"><a href="#安装-RKE" class="headerlink" title="安装 RKE"></a>安装 RKE</h3><p>Rancher Kubernetes Engine(RKE)是一款轻量级Kubernetes安装程序，支持在裸机和虚拟化服务器上安装Kubernetes。 RKE解决了Kubernettes社区中的一个常见问题，比如:安装复杂性。RKE支持多种平台运行，比如MacOS,linux,windows。  </p><p>50.100 机器上安装  </p><p>1、下载二进制文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://github.com/rancher/rke/releases/latest</span><br></pre></td></tr></table></figure><p> 现在稳定版本是 1.0.10<br>下载</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">wget https://github.com/rancher/rke/releases/download/v1.0.10/rke_linux-amd64</span><br><span class="line">chmod +x rke_linux-amd64</span><br><span class="line">mv rke_linux-amd64 /usr/bin/rke</span><br><span class="line">rke --version</span><br></pre></td></tr></table></figure><h3 id="安装kubectl"><a href="#安装kubectl" class="headerlink" title="安装kubectl"></a>安装kubectl</h3><p>kubectl是一个CLI命令行工具，用于运行Kubernetes集群的命令。Rancher 2.x中的许多维护和管理都需要它。  </p><p>这里在5.100上安装kubectl:  </p><p>kubectl 安装方式：  </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">wget https://storage.googleapis.com/kubernetes-release/release/v1.18.5/kubernetes-client-linux-amd64.tar.gz</span><br><span class="line">(需要翻墙，正常下载不了)</span><br><span class="line"></span><br><span class="line">官方下载说明：</span><br><span class="line">curl -LO https://storage.googleapis.com/kubernetes-release/release/$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt)/bin/linux/amd64/kubectl</span><br><span class="line">若需要下载特定版本的 kubectl，请将上述命令中的 $(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt) 部分替换成为需要下载的 kubectl 的具体版本即可。</span><br><span class="line">curl -LO https://storage.googleapis.com/kubernetes-release/release/v1.18.5/bin/linux/amd64/kubectl</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">curl -LO https://storage.googleapis.com/kubernetes-release/release/$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt)/bin/linux/amd64/kubectl</span><br><span class="line">有时候可以连接</span><br><span class="line"></span><br><span class="line">chmpd +x kubectl</span><br><span class="line">mv kubectl /usr/bin/</span><br><span class="line">kubectl version</span><br></pre></td></tr></table></figure><p>配置kubectl的shell补全<br>CentOS Linux上，您可能需要安装默认情况下未安装的bash-completion软件包。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install bash-completion -y</span><br></pre></td></tr></table></figure><p>运行source &lt;(kubectl completion bash)可将kubectl自动补全添加到当前shell，要使kubectl自动补全命令自动加载:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">echo &quot;source &lt;(kubectl completion bash)&quot; &gt;&gt; ~/.bashrc</span><br></pre></td></tr></table></figure><p>退出，重新登录一下即可。</p><h3 id="使用-RKE-安装-kubernetes"><a href="#使用-RKE-安装-kubernetes" class="headerlink" title="使用 RKE 安装 kubernetes"></a>使用 RKE 安装 kubernetes</h3><p>下面使用 RKE(Kubernetes Engine) 安装高可用的 Kubernetes。<br>rancher server 之间建立 ssh 信任<br>我们目前有三台服务器用作 local 集群，首先要确保我们主机能够通过 ssh 访问到另外两台主机并执行相关操作。  </p><h4 id="创建用户rancher"><a href="#创建用户rancher" class="headerlink" title="创建用户rancher"></a>创建用户rancher</h4><p>注意：使用rke安装kubernetes时，不能以root用户执行。必须是一个普通用户才行！！！<br>在5.100、5.101、5.103执行以下命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">useradd rancher</span><br><span class="line">passwd rancher</span><br></pre></td></tr></table></figure><h4 id="授权docker权限"><a href="#授权docker权限" class="headerlink" title="授权docker权限"></a>授权docker权限</h4><p>在5.100、5.101、5.103执行以下命令：<br>使用root账号登录  </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">#将登陆用户rancher加入到docker用户组中</span><br><span class="line">gpasswd -a rancher docker</span><br><span class="line">#更新用户组</span><br><span class="line">newgrp docker</span><br><span class="line">切换到rancher用户进行测试</span><br><span class="line">su - rancher</span><br><span class="line">docker ps</span><br></pre></td></tr></table></figure><h4 id="ssh信任"><a href="#ssh信任" class="headerlink" title="ssh信任"></a>ssh信任</h4><p>在5.100、5.101、5.103执行以下命令：  </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">每台机器上的rancher用户都执行  </span><br><span class="line"># su rancher</span><br><span class="line">$ ssh-keygen -t rsa -P &quot;&quot; -f ~/.ssh/id_rsa</span><br><span class="line">#$ cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys</span><br><span class="line">$$ chmod 600 ~/.ssh/authorized_keys</span><br><span class="line"></span><br><span class="line">$ ssh-copy-id 192.168.5.100</span><br><span class="line">$ ssh-copy-id 192.168.5.101</span><br><span class="line">$ ssh-copy-id 192.168.5.103</span><br></pre></td></tr></table></figure><p>编写 rancher-cluster.yml 文件  </p><p>在5.100上执行<br>注意：以rancher用户执行。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">$ vi rancher-cluster.yml</span><br><span class="line">nodes:</span><br><span class="line">  - address: 192.168.5.100</span><br><span class="line">    internal_address: 192.168.5.100</span><br><span class="line">    user: rancher</span><br><span class="line">    role: [controlplane,worker,etcd]</span><br><span class="line">    hostname_override: bigdata00.shining.com</span><br><span class="line">  - address: 192.168.5.101</span><br><span class="line">    internal_address: 192.168.5.101</span><br><span class="line">    user: rancher</span><br><span class="line">    role: [controlplane,worker,etcd]</span><br><span class="line">    hostname_override: bigdata01.shining.com</span><br><span class="line">  - address: 192.168.5.103</span><br><span class="line">    internal_address: 192.168.5.103</span><br><span class="line">    user: rancher</span><br><span class="line">    role: [controlplane,worker,etcd]</span><br><span class="line">    hostname_override: bigdata03.shining.com</span><br><span class="line"></span><br><span class="line">services:</span><br><span class="line">  etcd:</span><br><span class="line">    backup_config:</span><br><span class="line">        enabled: true</span><br><span class="line">        interval_hours: 6</span><br><span class="line">        retention: 60</span><br></pre></td></tr></table></figure><p>备注：</p><ul><li>address 公共域名或IP地址</li><li>user 可以运行docker命令的用户</li><li>role 分配给节点的Kubernetes角色列表</li><li>internal_address 内部集群通信的私有域名或IP地址</li><li>开启了etcd的备份机制，每隔6小时备份一次，保存60天数据</li></ul><h3 id="运行-RKE-构建-kubernetes-集群"><a href="#运行-RKE-构建-kubernetes-集群" class="headerlink" title="运行 RKE 构建 kubernetes 集群"></a>运行 RKE 构建 kubernetes 集群</h3><p>在5.100上执行<br>注意：以rancher用户执行。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">$ rke up --config ./rancher-cluster.yml</span><br><span class="line">INFO[0000] Running RKE version: v1.0.8                  </span><br><span class="line">INFO[0000] Initiating Kubernetes cluster                </span><br><span class="line">INFO[0000] [dialer] Setup tunnel for host [192.168.5.100] </span><br><span class="line">INFO[0000] [dialer] Setup tunnel for host [192.168.5.101] </span><br><span class="line">INFO[0000] [dialer] Setup tunnel for host [192.168.5.103] </span><br><span class="line">INFO[0000] Checking if container [cluster-state-deployer] is running on host [192.168.5.100], try #1 </span><br><span class="line">INFO[0000] Image [rancher/rke-tools:v0.1.56] exists on host [192.168.5.100] </span><br><span class="line">...</span><br><span class="line">INFO[0128] [ingress] ingress controller nginx deployed successfully </span><br><span class="line">INFO[0128] [addons] Setting up user addons              </span><br><span class="line">INFO[0128] [addons] no user addons defined              </span><br><span class="line">INFO[0128] Finished building Kubernetes cluster successfully</span><br></pre></td></tr></table></figure><p>以上输出，表示安装成功了。<br>执行成功会在当前目录生成2个文件，分别是rancher-cluster.rkestate和kube_config_rancher-cluster.yml  </p><p>文件说明</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">rancher-cluster.yml：RKE集群配置文件。</span><br><span class="line">kube_config_rancher-cluster.yml：群集的Kubeconfig文件，此文件包含完全访问群集的凭据。</span><br><span class="line">rancher-cluster.rkestate：Kubernetes群集状态文件，此文件包含完全访问群集的凭据。</span><br></pre></td></tr></table></figure><h4 id="错误集锦"><a href="#错误集锦" class="headerlink" title="错误集锦"></a>错误集锦</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">WARN[0000] Failed to set up SSH tunneling for host [192.168.5.103]: Can&apos;t retrieve Docker Info: error during connect: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.24/info: Unable to access node with address [10.212.20.97:22] using SSH. Please check if you are able to SSH to the node using the specified SSH Private Key and if you have configured the correct SSH username. Error: ssh: handshake failed: ssh: unable to authenticate, attempted methods [none publickey], no supported methods remain</span><br></pre></td></tr></table></figure><p>ssh信任没有做好，请确保是普通用户执行rke。不能是root用户</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Failed to get job complete status for job rke-network-plugin-deploy-job in namespace kube-system</span><br></pre></td></tr></table></figure><p>重新执行一遍 rke_linux-amd64 up –config ./rancher-cluster.yml即可。<br>docker 和系统代理 （如果需要代理上网的话， docker需要拉取镜像，本机也需要出去下载yaml文件）  </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/systemd/system/docker.service.d//http-proxy.conf</span><br><span class="line">[Service]</span><br><span class="line">Environment=&quot;HTTP_PROXY=//user:password@192.168.1.1:78/&quot;</span><br><span class="line">Environment=&quot;HTTPS_PROXY=http://user:password@192.168.1.1:79/&quot;</span><br><span class="line">Environment=&quot;NO_PROXY=localhost,127.0.0.1,0.0.0.0,10.0.0.0/8,192.168.0.0/16,shining.com,shining.com&quot;</span><br><span class="line"></span><br><span class="line">systemctl daemon-reload &amp;&amp; systemctl restart docker</span><br><span class="line"></span><br><span class="line">vim /etc/profile</span><br><span class="line">use_proxy=yes</span><br><span class="line">export https_proxy=http://user:password@192.168.1.1:78</span><br><span class="line">export http_proxy=http://user:password@192.168.1.1:78</span><br><span class="line">export NO_PROXY=&quot;localhost,127.0.0.1,0.0.0.0,10.0.0.0/8,192.168.0.0/16,shining.com,shining.com&quot;</span><br><span class="line"></span><br><span class="line">source /etc/profile</span><br><span class="line"></span><br><span class="line">NO_PROXY  根据自己的ip、域名、主机配置</span><br></pre></td></tr></table></figure><h3 id="设置环境变量"><a href="#设置环境变量" class="headerlink" title="设置环境变量"></a>设置环境变量</h3><p>在5.100上执行<br>注意：以rancher用户执行。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mkdir ~/.kube</span><br><span class="line">cp kube_config_rancher-cluster.yml ~/.kube/config</span><br><span class="line">export KUBECONFIG=$(pwd)/kube_config_rancher-cluster.yml</span><br></pre></td></tr></table></figure><p>查看node</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get node</span><br><span class="line">NAME                 STATUS   ROLES                      AGE   VERSION</span><br><span class="line">bigdata00.shining.com   Ready    controlplane,etcd,worker   42h   v1.17.6</span><br><span class="line">bigdata01.shining.com   Ready    controlplane,etcd,worker   42h   v1.17.6</span><br><span class="line">bigdata03.shining.com   Ready    controlplane,etcd,worker   42h   v1.17.6</span><br></pre></td></tr></table></figure><p>如果需要root用户执行kubectl，切换到root用户，执行以下命令</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mkdir ~/.kube</span><br><span class="line">cp /home/rancher/kube_config_rancher-cluster.yml ~/.kube/config</span><br><span class="line">export KUBECONFIG=~/.kube/config</span><br></pre></td></tr></table></figure><p>查看 k8s pod</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get pods -A</span><br><span class="line">ingress-nginx   default-http-backend-67cf578fc4-kqwlc     1/1     Running            1          42h</span><br><span class="line">ingress-nginx   nginx-ingress-controller-hwgxq            1/1     Running            2          42h</span><br><span class="line">ingress-nginx   nginx-ingress-controller-jqc6g            1/1     Running            3          42h</span><br><span class="line">ingress-nginx   nginx-ingress-controller-wttkx            1/1     Running            2          42h</span><br><span class="line">kube-system     canal-j28c2                               2/2     Running            4          42h</span><br><span class="line">kube-system     canal-k244c                               2/2     Running            6          42h</span><br><span class="line">kube-system     canal-pt74w                               2/2     Running            5          42h</span><br><span class="line">kube-system     coredns-7c5566588d-d6742                  1/1     Running            2          42h</span><br><span class="line">kube-system     coredns-7c5566588d-wclvc                  1/1     Running            2          42h</span><br><span class="line">kube-system     coredns-autoscaler-65bfc8d47d-8phv4       1/1     Running            2          42h</span><br><span class="line">kube-system     metrics-server-6b55c64f86-pc8qk           1/1     Running            2          42h</span><br><span class="line">kube-system     rke-coredns-addon-deploy-job-zg68c        0/1     Completed          0          42h</span><br><span class="line">kube-system     rke-ingress-controller-deploy-job-fw5fn   0/1     Completed          0          42h</span><br><span class="line">kube-system     rke-metrics-addon-deploy-job-j9tgw        0/1     Completed          0          42h</span><br><span class="line">kube-system     rke-network-plugin-deploy-job-85z6d       0/1     Completed          0          42h</span><br></pre></td></tr></table></figure><h3 id="安装和配置Helm"><a href="#安装和配置Helm" class="headerlink" title="安装和配置Helm"></a>安装和配置Helm</h3><p>Helm是Kubernetes首选的包管理工具。Helmcharts为Kubernetes YAML清单文档提供模板语法。使用Helm，可以创建可配置的部署，而不仅仅是使用静态文件。Helm有两个部分：Helm客户端(helm)和Helm服务端(Tiller)。  </p><h4 id="配置Helm客户端访问权限"><a href="#配置Helm客户端访问权限" class="headerlink" title="配置Helm客户端访问权限"></a>配置Helm客户端访问权限</h4><p>在5.100上执行，下面提到的所有命令，都可以在root用户执行了。  </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kubectl -n kube-system create serviceaccount tiller</span><br><span class="line">kubectl create clusterrolebinding tiller \</span><br><span class="line">--clusterrole cluster-admin --serviceaccount=kube-system:tiller</span><br></pre></td></tr></table></figure><p>备注：在kube-system命名空间中创建ServiceAccount；创建ClusterRoleBinding以授予tiller帐户对集群的访问权限；helm初始化tiller服务</p><h4 id="安装Helm客户端"><a href="#安装Helm客户端" class="headerlink" title="安装Helm客户端"></a>安装Helm客户端</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">wget https://get.helm.sh/helm-v2.16.6-linux-amd64.tar.gz</span><br><span class="line">tar zxvf helm-v2.16.6-linux-amd64.tar.gz -C /usr/src/</span><br><span class="line">cp /usr/src/linux-amd64/helm /usr/local/bin/</span><br><span class="line">cp /usr/src/linux-amd64/tiller /usr/local/bin/</span><br></pre></td></tr></table></figure><p>安装Helm服务端（Tiller）  </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">helm_version=`helm version |grep Client | awk -F&quot;&quot;\&quot; &apos;&#123;print $2&#125;&apos;`</span><br><span class="line">helm init  \</span><br><span class="line">--service-account tiller --skip-refresh \</span><br><span class="line">--tiller-image registry.cn-shanghai.aliyuncs.com/rancher/tiller:$helm_version</span><br></pre></td></tr></table></figure><p>备注：</p><p>1、RKE默认启用RBAC,所以在安装tiller时需要指定ServiceAccount。<br>2、helm init在缺省配置下，会去谷歌镜像仓库拉取gcr.io/kubernetes-helm/tiller镜像，在Kubernetes集群上安装配置Tiller；由于在国内可能无法访问gcr.io、storage.googleapis.com等域名，可以通过–tiller-image指定私有镜像仓库镜像。<br>3、helm init在缺省配置下，会利用<a href="https://kubernetes-charts.storage.googleapis.com作为缺省的stable" target="_blank" rel="noopener">https://kubernetes-charts.storage.googleapis.com作为缺省的stable</a> repository地址,并去更新相关索引文件。在国内可能无法访问storage.googleapis.com地址, 可以通过–stable-repo-url指定chart国内加速镜像地址。<br>4、如果您是离线安装Tiller, 假如没有内部的chart仓库, 可通过添加–skip-refresh参数禁止Tiller更新索引。  </p><h4 id="遇到问题："><a href="#遇到问题：" class="headerlink" title="遇到问题："></a>遇到问题：</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">helm status</span><br><span class="line">Error: could not find a ready tiller pod</span><br><span class="line"></span><br><span class="line">查看一下 tiller 有没有运行起来</span><br><span class="line">kubectl -n kube-system get po</span><br><span class="line">.....</span><br><span class="line">tiller-deploy-86dfb4886-4544p             0/1     ERRORIMAGE    0          25h</span><br></pre></td></tr></table></figure><p>image 没有下来的话， 可以改为其他镜像地址</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">helm init --service-account tiller --skip-refresh --tiller-image jessestuart/tiller:$helm_version --upgrade</span><br><span class="line">helm init --service-account tiller</span><br></pre></td></tr></table></figure><p>如果没起来。可以</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">helm init --upgrade</span><br></pre></td></tr></table></figure><p>如果报错信息：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">This command needs 1 argument: chart name</span><br></pre></td></tr></table></figure><p>那么需要添加 –name 参数  ：  如</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">helm init --service-account --name tiller</span><br></pre></td></tr></table></figure><h3 id="Helm安装Rancher"><a href="#Helm安装Rancher" class="headerlink" title="Helm安装Rancher"></a>Helm安装Rancher</h3><p>添加Chart仓库地址</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">helm repo add rancher-stable \</span><br><span class="line">https://releases.rancher.com/server-charts/stable</span><br><span class="line"></span><br><span class="line">helm repo update</span><br></pre></td></tr></table></figure><font color="#FF0000"> 如果自己有证书：可以用下面方法：</font> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">配置SSL</span><br><span class="line">注意：rancher默认使用https访问，因此，需要有一个公网的SSL才行。我在阿里云上面买了一个通配符的SSL证书。</span><br><span class="line">将证书上传到5.100</span><br><span class="line">在5.100上执行</span><br><span class="line">创建secret</span><br><span class="line">kubectl create ns cattle-system</span><br><span class="line">kubectl -n cattle-system create secret tls tls-rancher-ingress --cert=./123pem --key=./123key</span><br><span class="line">通过helm安装rancher</span><br><span class="line">helm install rancher-stable/rancher   --name rancher   --namespace cattle-system   --set hostname=rancher.shining.com   --set ingress.tls.source=secret</span><br><span class="line">注意：这里指定了hostname=rancher.shining.com，必须使用域名访问才行。</span><br></pre></td></tr></table></figure><font color="#FF0000"> 没有证书， 需要rancher自己创建证书，需要配置：</font> <p>仅在使用 Rancher 生成的证书 ingress.tls.source=rancher 或 Let’s Encrypt 颁发的证书 ingress.tls.source=letsEncrypt时才需要 cert-manager。<br>这些说明来自官方的 cert-manager 文档。  </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"># 安装 CustomResourceDefinition 资源</span><br><span class="line">kubectl apply --validate=false -f https://github.com/jetstack/cert-manager/releases/download/v0.15.0/cert-manager.crds.yaml</span><br><span class="line"></span><br><span class="line"># **重要：**</span><br><span class="line"># 如果您正在运行 Kubernetes v1.15 或更低版本，</span><br><span class="line"># 则需要在上方的 kubectl apply 命令中添加`--validate=false`标志，</span><br><span class="line"># 否则您将在 cert-manager 的 CustomResourceDefinition 资源中收到与</span><br><span class="line"># x-kubernetes-preserve-unknown-fields 字段有关的验证错误。</span><br><span class="line"># 这是一个良性错误，是由于 kubectl 执行资源验证的方式造成的。</span><br><span class="line"></span><br><span class="line"># 为 cert-manager 创建命名空间</span><br><span class="line">kubectl create namespace cert-manager</span><br><span class="line"># 添加 Jetstack Helm 仓库</span><br><span class="line">helm repo add jetstack https://charts.jetstack.io</span><br><span class="line"># 更新本地 Helm chart 仓库缓存</span><br><span class="line">helm repo update</span><br><span class="line"># 安装 cert-manager Helm chart</span><br><span class="line">helm install \</span><br><span class="line"> --name cert-manager jetstack/cert-manager \</span><br><span class="line"> --namespace cert-manager \</span><br><span class="line"> --version v0.15.0</span><br></pre></td></tr></table></figure><p>安装完 cert-manager 后，您可以通过检查 cert-manager 命名空间中正在运行的 Pod 来验证它是否已正确部署：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get pods --namespace cert-manager</span><br><span class="line">NAME                                      READY   STATUS    RESTARTS   AGE</span><br><span class="line">cert-manager-6557d7bd98-dqjxh             1/1     Running   0          25h</span><br><span class="line">cert-manager-cainjector-6749f5b67-p46rd   1/1     Running   0          25h</span><br><span class="line">cert-manager-webhook-d886869c4-x6r7f      1/1     Running   0          25h</span><br></pre></td></tr></table></figure><h3 id="通过helm安装rancher"><a href="#通过helm安装rancher" class="headerlink" title="通过helm安装rancher"></a>通过helm安装rancher</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">helm install rancher-stable/rancher   --name rancher   --namespace cattle-system  --set hostname=rancher.shining.com  --set ingress.tls.source=rancher</span><br></pre></td></tr></table></figure><p>注意：这里指定了hostname=rancher.shining.com，必须使用域名访问才行。<br>查看rancher 运行状况：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"> kubectl get pods --namespace cattle-system</span><br><span class="line">NAME                                    READY   STATUS             RESTARTS   AGE</span><br><span class="line">cattle-cluster-agent-85695669b4-fh27p   0/1     CrashLoopBackOff   297        25h</span><br><span class="line">cattle-node-agent-7js5j                 1/1     Running            0          25h</span><br><span class="line">cattle-node-agent-p9ft2                 1/1     Running            0          25h</span><br><span class="line">cattle-node-agent-zdrb7                 1/1     Running            0          25h</span><br><span class="line">rancher-7d578c767b-5f2fv                1/1     Running            0          25h</span><br><span class="line">rancher-7d578c767b-9b72j                1/1     Running            0          25h</span><br><span class="line">rancher-7d578c767b-khrv6                1/1     Running            0          25h</span><br></pre></td></tr></table></figure><p>可以临时配置域名解析，或hosts方式访问，后期可以配置到DNS中 ， agent添加到server中都需要这个域名。</p><p>编辑主机 hosts</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">192.168.5.100  rancher.shining.com</span><br></pre></td></tr></table></figure><p>注释，5.100、5.101、5.103 指向任何一台机器都可以访问。</p><p>访问页面：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://rancher.shining.com</span><br></pre></td></tr></table></figure><p>页面提示设置密码，rangcher就配置好了。</p><h3 id="nginx-代理配置："><a href="#nginx-代理配置：" class="headerlink" title="nginx 代理配置："></a>nginx 代理配置：</h3><p>nginx是作为前端访问的代理地址， 祈祷负载作用。agent 也会通过这么域名访问到server的   </p><p>5.237 机器上配置 nginx。<br>添加repo 源  </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/yum.repos.d/nginx.repo</span><br><span class="line">[nginx]</span><br><span class="line">name=nginx repo</span><br><span class="line">baseurl=http://nginx.org/packages/centos/$releasever/$basearch/</span><br><span class="line">gpgcheck=0</span><br><span class="line">enabled=1</span><br></pre></td></tr></table></figure><p>安装</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install -y nginx</span><br></pre></td></tr></table></figure><p>修改配置文件：  vim /etc/nginx/nginx.conf  </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">user nginx;</span><br><span class="line">worker_processes auto;</span><br><span class="line">error_log /var/log/nginx/error.log;</span><br><span class="line">pid /run/nginx.pid;</span><br><span class="line">include /usr/share/nginx/modules/*.conf;</span><br><span class="line">events &#123;</span><br><span class="line">    worker_connections 8192;</span><br><span class="line">&#125;</span><br><span class="line">http &#123;</span><br><span class="line">    log_format  main  &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos;</span><br><span class="line">                      &apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos;</span><br><span class="line">                      &apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&apos;;</span><br><span class="line">    access_log  /var/log/nginx/access.log  main;</span><br><span class="line">    sendfile            on;</span><br><span class="line">    tcp_nopush          on;</span><br><span class="line">    tcp_nodelay         on;</span><br><span class="line">    keepalive_timeout   65;</span><br><span class="line">    types_hash_max_size 2048;</span><br><span class="line">    include             /etc/nginx/mime.types;</span><br><span class="line">    default_type        application/octet-stream;</span><br><span class="line">    # Load modular configuration files from the /etc/nginx/conf.d directory.</span><br><span class="line">    # See http://nginx.org/en/docs/ngx_core_module.html#include</span><br><span class="line">    # for more information.</span><br><span class="line">    include /etc/nginx/conf.d/*.conf;</span><br><span class="line">    server &#123;</span><br><span class="line">        listen         80;</span><br><span class="line">        return 301 https://$host$request_uri;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">stream &#123;</span><br><span class="line">    upstream rancher_servers &#123;</span><br><span class="line">        least_conn;</span><br><span class="line">        server 192.168.5.100:443 max_fails=3 fail_timeout=5s;</span><br><span class="line">        server 192.168.5.101:443 max_fails=3 fail_timeout=5s;</span><br><span class="line">        server 192.168.5.103:443 max_fails=3 fail_timeout=5s;</span><br><span class="line">    &#125;</span><br><span class="line">    server &#123;</span><br><span class="line">        listen     443;</span><br><span class="line">        proxy_pass rancher_servers;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>启动nginx  </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">systemctl start nginx</span><br><span class="line">或</span><br><span class="line">systemctl reload nginx</span><br></pre></td></tr></table></figure><p>以后域名地址解析到 5.237 机器上就可以访问了。当然nginx也可以安装到集群中，或其他负载方式。</p><h3 id="Q-amp-A"><a href="#Q-amp-A" class="headerlink" title="Q&amp;A"></a>Q&amp;A</h3><p>1、执行以下命令为Rancher Server容器配置hosts:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">[rancher@5.100 ~]$ kubectl -n cattle-system patch deployments rancher --patch &apos;&#123;</span><br><span class="line">    &quot;spec&quot;: &#123;</span><br><span class="line">        &quot;template&quot;: &#123;</span><br><span class="line">            &quot;spec&quot;: &#123;</span><br><span class="line">                &quot;hostAliases&quot;: [</span><br><span class="line">                    &#123;</span><br><span class="line">                        &quot;hostnames&quot;:</span><br><span class="line">                        [</span><br><span class="line">                            &quot;rancher.shining.com&quot;</span><br><span class="line">                        ],</span><br><span class="line">                            &quot;ip&quot;: &quot;192.168.100.237&quot;</span><br><span class="line">                    &#125;</span><br><span class="line">                ]</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;&apos;</span><br></pre></td></tr></table></figure><p>2、在Rancher Web UI中依次进入local集群/system项目，在cattle-system命名空间中查看是否有cattle-cluster-agent Pod和cattle-node-agent pod被创建。如果有创建则进行下面的步骤，没有创建则等待；<br>cattle-cluster-agent pod  </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">[rancher@5.100 ~]$ kubectl -n cattle-system \</span><br><span class="line">patch deployments cattle-cluster-agent --patch &apos;&#123;</span><br><span class="line">    &quot;spec&quot;: &#123;</span><br><span class="line">        &quot;template&quot;: &#123;</span><br><span class="line">            &quot;spec&quot;: &#123;</span><br><span class="line">                &quot;dnsPolicy&quot;: &quot;ClusterFirstWithHostNet&quot;,</span><br><span class="line">                &quot;hostNetwork&quot;: true,</span><br><span class="line">                &quot;hostAliases&quot;: [</span><br><span class="line">                    &#123;</span><br><span class="line">                        &quot;hostnames&quot;:</span><br><span class="line">                        [</span><br><span class="line">                            &quot;rancher.shining.com&quot;</span><br><span class="line">                        ],</span><br><span class="line">                            &quot;ip&quot;: &quot;192.168.5.237&quot;</span><br><span class="line">                    &#125;</span><br><span class="line">                ]</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;&apos;</span><br></pre></td></tr></table></figure><p>cattle-node-agent pod</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">[rancher@node1 ~]$ kubectl -n cattle-system \</span><br><span class="line">patch  daemonsets cattle-node-agent --patch &apos;&#123;</span><br><span class="line">    &quot;spec&quot;: &#123;</span><br><span class="line">        &quot;template&quot;: &#123;</span><br><span class="line">            &quot;spec&quot;: &#123;</span><br><span class="line">                &quot;hostAliases&quot;: [</span><br><span class="line">                    &#123;</span><br><span class="line">                        &quot;hostnames&quot;:</span><br><span class="line">                        [</span><br><span class="line">                            &quot;rancher.shining.com&quot;</span><br><span class="line">                        ],</span><br><span class="line">                            &quot;ip&quot;: &quot;192.168.5.237&quot;</span><br><span class="line">                    &#125;</span><br><span class="line">                ]</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;&apos;</span><br></pre></td></tr></table></figure><h3 id="相关文章："><a href="#相关文章：" class="headerlink" title="相关文章："></a>相关文章：</h3><p>rancher 官网:  <a href="https://rancher2.docs.rancher.cn/docs/installation/k8s-install/helm-rancher/_index" target="_blank" rel="noopener">https://rancher2.docs.rancher.cn/docs/installation/k8s-install/helm-rancher/_index</a><br>腾讯云文档 :  <a href="https://cloud.tencent.com/developer/article/1638170" target="_blank" rel="noopener">https://cloud.tencent.com/developer/article/1638170</a>  </p>]]></content>
      
      <categories>
          
          <category> rancher </category>
          
      </categories>
      
      
        <tags>
            
            <tag> docker </tag>
            
            <tag> rancher </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>docker容器里排错小方法</title>
      <link href="/docker-share-troubleshooting/"/>
      <url>/docker-share-troubleshooting/</url>
      <content type="html"><![CDATA[<p>docker 容器在封装的时候一般只会安装程序需要的软件包。一些工具类的软件包不会安装的，这样容器会很大。也不常用，无意义。</p><p>但是这样如果容器有问题，或想查看一些信息，如网络信息、文件内容、抓包等。这样就没办法做到了。</p><p>下面说一种方法，容器共享进程、网络资源，可以用用 –pid、–ipc、–net 等参数</p><p>这样就可以查看容器的进程信息、网络、文件等事情了。</p><p>首先，运行一个容器：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -d -p 7080:80 nginx:latest</span><br></pre></td></tr></table></figure><p>运行一个nginx容器，</p><p>直接用 docker exec 进到容器里的时候， 是不能用iptables、ps、vim等命令的。</p><a id="more"></a><p>获取容器ID</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">docker ps</span><br><span class="line">CONTAINER ID        IMAGE                                        COMMAND                  CREATED             STATUS              PORTS                                          NAMES</span><br><span class="line">b99f5509819c        nginx:latest   &quot;nginx -g &apos;daemon of…&quot;   2 hours ago         Up 2 hours           0.0.0.0:7080-&gt;80/tcp   musing_kepler</span><br></pre></td></tr></table></figure><h4 id="我们开始进入到容器"><a href="#我们开始进入到容器" class="headerlink" title="我们开始进入到容器"></a>我们开始进入到容器</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">CID=b99f5509819c</span><br><span class="line">docker run -it --net=container:$CID --ipc=container:$CID --pid=container:$CID alpine-tools:latest</span><br></pre></td></tr></table></figure><p>CID 是容器 ID， 后面都用 $CID  来代替</p><ul><li>alpine-tools:latest 是自己做的镜像， 可以把常用的命令放在里面，如（iptables、tcpdump、vim等）</li></ul><p>这样，容器的网络、磁盘、进程都和你启动这个容器共享了，所以就可以实时查看nginx容器里的信息。</p><p>运行ps 就可以看到nginx的进程了  </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">/ # ps</span><br><span class="line">PID   USER     TIME  COMMAND</span><br><span class="line">    1 root      0:00 nginx: master process nginx -g daemon off;</span><br><span class="line">    6 101       0:00 nginx: worker process</span><br><span class="line">   77 root      0:00 /bin/sh</span><br><span class="line">   82 root      0:00 ps</span><br><span class="line">/ #</span><br></pre></td></tr></table></figure><p>运行tcpdump 就可以实时抓包了</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">/ # tcpdump -XX -A</span><br><span class="line">tcpdump: verbose output suppressed, use -v or -vv for full protocol decode</span><br><span class="line">listening on eth0, link-type EN10MB (Ethernet), capture size 262144 bytes</span><br><span class="line">09:35:44.971181 IP 10.1.1.1.5045 &gt; b99f5509819c.80: Flags [S], seq 1170821353, win 65535, options [mss 1280,nop,wscale 6,nop,nop,TS val 53306312 ecr 0,sackOK,eol], length 0</span><br><span class="line">0x0000:  0242 ac11 0002 0242 bf93 7039 0800 45b8  .B.....B..p9..E.</span><br><span class="line">0x0010:  0040 0000 0000 2a06 1951 0a76 c026 ac11  .@....*..Q.v.&amp;..</span><br><span class="line">0x0020:  0002 13b5 0050 45c9 50e9 0000 0000 b002  .....PE.P.......</span><br><span class="line">0x0030:  ffff af53 0000 0204 0500 0103 0306 0101  ...S............</span><br><span class="line">0x0040:  080a 032d 63c8 0000 0000 0402 0000       ...-c.........</span><br><span class="line">09:35:44.971227 IP b99f5509819c.80 &gt; 10.1.11.5045: Flags [S.], seq 3301963106, ack 1170821354, win 28960, options [mss 1460,sackOK,TS val 237381948 ecr 53306312,nop,wscale 9], length 0</span><br><span class="line">0x0000:  0242 bf93 7039 0242 ac11 0002 0800 4500  .B..p9.B......E.</span><br><span class="line">0x0010:  003c 0000 4000 4006 c40c ac11 0002 0a76  .&lt;..@.@........v</span><br><span class="line">......</span><br></pre></td></tr></table></figure><p>但是这个时候运行 iptables 还是不行的， 提示没有权限</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">/ # iptables -n -L</span><br><span class="line">iptables v1.8.3 (legacy): can&apos;t initialize iptables table `filter&apos;: Permission denied (you must be root)</span><br><span class="line">Perhaps iptables or your kernel needs to be upgraded.</span><br><span class="line">/ #</span><br></pre></td></tr></table></figure><h4 id="需要运行工具容器的时候提权才能行，添加-privileged-参数。-如："><a href="#需要运行工具容器的时候提权才能行，添加-privileged-参数。-如：" class="headerlink" title="需要运行工具容器的时候提权才能行，添加 privileged  参数。 如："></a>需要运行工具容器的时候提权才能行，添加 privileged  参数。 如：</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -it --privileged --net=container:$CID --ipc=container:$CID --pid=container:$CID alpine-tools:latest</span><br></pre></td></tr></table></figure><p>运行 iptables 命令  (返回结果类似于这样)</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"> # iptables -t nat -nL</span><br><span class="line">Chain PREROUTING (policy ACCEPT)</span><br><span class="line">target     prot opt source               destination</span><br><span class="line"></span><br><span class="line">Chain INPUT (policy ACCEPT)</span><br><span class="line">target     prot opt source               destination</span><br><span class="line"></span><br><span class="line">Chain OUTPUT (policy ACCEPT)</span><br><span class="line">target     prot opt source               destination</span><br><span class="line">DOCKER_OUTPUT  all  --  0.0.0.0/0            127.0.0.11</span><br><span class="line"></span><br><span class="line">Chain POSTROUTING (policy ACCEPT)</span><br><span class="line">target     prot opt source               destination</span><br><span class="line">DOCKER_POSTROUTING  all  --  0.0.0.0/0            127.0.0.11</span><br><span class="line"></span><br><span class="line">Chain DOCKER_OUTPUT (1 references)</span><br><span class="line">target     prot opt source               destination</span><br><span class="line">DNAT       tcp  --  0.0.0.0/0            127.0.0.11           tcp dpt:53 to:127.0.0.11:36820</span><br><span class="line">DNAT       udp  --  0.0.0.0/0            127.0.0.11           udp dpt:53 to:127.0.0.11:37685</span><br><span class="line"></span><br><span class="line">Chain DOCKER_POSTROUTING (1 references)</span><br><span class="line">target     prot opt source               destination</span><br><span class="line">SNAT       tcp  --  127.0.0.11           0.0.0.0/0            tcp spt:36820 to::53</span><br><span class="line">SNAT       udp  --  127.0.0.11           0.0.0.0/0            udp spt:37685 to::53</span><br></pre></td></tr></table></figure><p>如果你的容器是 -v 挂载volume 启动的话</p><p>容器启动：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -d -p 7080:80 nginx:latest</span><br></pre></td></tr></table></figure><h4 id="可以用下面的方式查看-volume-里数据。"><a href="#可以用下面的方式查看-volume-里数据。" class="headerlink" title="可以用下面的方式查看 volume 里数据。"></a>可以用下面的方式查看 volume 里数据。</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -it --privileged --net=container:$CID --ipc=container:$CID --pid=container:$CID --volumes-from $CID:ro alpine-tools:latest</span><br></pre></td></tr></table></figure><p>这样就可以查看 volume 里的数据了， </p><ul><li>如果你的volume是NFS、ceph等网络存储，你可以这样做来吧数据备份到本地。</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">docker run --volumes-from $CID -v $(pwd):/backup alpine-tools:latest tar cvf /backup/backup.tar /home</span><br><span class="line"></span><br><span class="line"> # 将 $CID 容器上volume挂在到本容器上， 在讲当前目录挂在到容器的 /backup 目录， 进入容器执行 tar 备份目录</span><br></pre></td></tr></table></figure><p>另外 还有其他方式可以查看容器的方式，简单介绍一下。</p><h4 id="nsenter-方式"><a href="#nsenter-方式" class="headerlink" title="nsenter 方式"></a>nsenter 方式</h4><p>nsenter 需要做的容器里的进程 PID 的， </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">PID=$(docker inspect --format &apos;&#123;&#123;.State.Pid&#125;&#125;&apos; $CID)</span><br><span class="line">nsenter --target $PID --mount --uts --ipc --net --pid</span><br></pre></td></tr></table></figure><p>这样就可以进图到容器里了。</p><p>这样的你程序镜像就不用安装一下系统工具的软件包了。 有问题可以用这一种容器共享的方式来排查了。</p>]]></content>
      
      <categories>
          
          <category> docker </category>
          
      </categories>
      
      
        <tags>
            
            <tag> docker </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>docker配置proxy代理用户名和密码</title>
      <link href="/docker-proxy/"/>
      <url>/docker-proxy/</url>
      <content type="html"><![CDATA[<p>当Docker的服务器无法直接访问Internet时，需要使用代理。将Docker守护程序配置为使用代理服务器来访问Docker Hub等镜像仓库。有两种方法可以为docker配置代理。</p><ul><li>在 /etc/sysconfig/docker 文件中配置代理变量</li><li>配置环境变量</li></ul><h4 id="方法一：-在-etc-sysconfig-docker-文件中配置代理变量"><a href="#方法一：-在-etc-sysconfig-docker-文件中配置代理变量" class="headerlink" title="方法一： 在 /etc/sysconfig/docker 文件中配置代理变量"></a>方法一： 在 /etc/sysconfig/docker 文件中配置代理变量</h4><p>1、在 /etc/sysconfig/docker 文件中添加以下配置：</p><a id="more"></a><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">export HTTP_PROXY=&quot;http://USERNAME:PASSWORD@[your.proxy.server]:[port]&quot;</span><br><span class="line">export HTTPS_PROXY=&quot;https://USERNAME:PASSWORD@[your.proxy.server]:[port]&quot;</span><br></pre></td></tr></table></figure><p>For example :</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># cat /etc/sysconfig/docker</span><br><span class="line">HTTP_PROXY=&quot;http://username:password@192.168.1.1:8080&quot;</span><br><span class="line">HTTPS_PROXY=&quot;https://username:password@192.168.1.1:8080&quot;</span><br></pre></td></tr></table></figure><p>2、设置代理后，重新启动Docker守护程序。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># service docker restart</span><br></pre></td></tr></table></figure><h4 id="方法二：-配置环境变量方式"><a href="#方法二：-配置环境变量方式" class="headerlink" title="方法二： 配置环境变量方式"></a>方法二： 配置环境变量方式</h4><p>1、创建目录（如果没有）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># mkdir /etc/systemd/system/docker.service.d</span><br></pre></td></tr></table></figure><p>2、编辑一个peoxy的配置文件   /etc/systemd/system/docker.service.d/http-proxy.conf  ，添加内容为</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># vim /etc/systemd/system/docker.service.d/http-proxy.conf</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">Environment=&quot;HTTP_PROXY=http://username:password@192.168.1.1:8080/&quot;</span><br><span class="line">Environment=&quot;HTTPS_PROXY=https://username:password@192.168.1.1:8080/&quot;</span><br><span class="line">Environment=&quot;NO_PROXY= hostname.example.com,172.16.0.12&quot;</span><br></pre></td></tr></table></figure><p>3、重新加载systemd守护程序</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># systemctl daemon-reload</span><br></pre></td></tr></table></figure><p>4、重启docker</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># systemctl restart docker</span><br></pre></td></tr></table></figure><p>5、验证配置是否已加载：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># systemctl show docker --property Environment</span><br><span class="line">Environment=HTTP_PROXY=http://username:password@192.168.1.1:8080/ HTTPS_PROXY=https://username:password@192.168.1.1:8080/ NO_PROXY= hostname.example.com,172.16.0.12</span><br></pre></td></tr></table></figure><p>这样配置完成之后在 docker pull 镜像就可以了  </p><ul><li>验证第二种配置生效</li></ul>]]></content>
      
      <categories>
          
          <category> docker </category>
          
      </categories>
      
      
        <tags>
            
            <tag> docker </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>hbase在线平滑迁移region数据</title>
      <link href="/region-data-migration/"/>
      <url>/region-data-migration/</url>
      <content type="html"><![CDATA[<p>hbase regionserver 下线，做数据迁移。 这个方法可以在线上平滑迁移。   </p><p>hbase 版本： 1.2.4</p><p>####n首先 关闭 hbase 的 balance </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hbase(main)&gt; balance_switch false</span><br></pre></td></tr></table></figure><h4 id="将新的regionserver节点上线"><a href="#将新的regionserver节点上线" class="headerlink" title="将新的regionserver节点上线"></a>将新的regionserver节点上线</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hbase-daemon.sh start regionserver</span><br></pre></td></tr></table></figure><h4 id="之后就可以迁移数据了。"><a href="#之后就可以迁移数据了。" class="headerlink" title="之后就可以迁移数据了。"></a>之后就可以迁移数据了。</h4><p>到新的region server上执行 下面命令。<br>使用hbase自带的rb脚本，在hbase bin目录下面<br>unload：转移rs上的region；load：将所有region转移到此rs<br><a id="more"></a><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hbase org.jruby.Main $&#123;HBASE_HOME&#125;/bin/region_mover.rb unload  regionserver00.hostname.com</span><br></pre></td></tr></table></figure></p><ul><li>在需要迁移到的机器上执行， 如要将regionserver00.hostname.com上的数据迁移到regionserver03.hostname.com机器上， 那么就在regionserver03.hostname.com机器上执行命令，hostname写regionserver00.hostname.com  </li></ul><p>等待任务完成。</p><h4 id="之后就可以把数据迁移走的节点下线了"><a href="#之后就可以把数据迁移走的节点下线了" class="headerlink" title="之后就可以把数据迁移走的节点下线了"></a>之后就可以把数据迁移走的节点下线了</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hbase-daemon.sh stop regionserver</span><br></pre></td></tr></table></figure><h4 id="最后在开启hbase的balance"><a href="#最后在开启hbase的balance" class="headerlink" title="最后在开启hbase的balance"></a>最后在开启hbase的balance</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hbase(main)&gt; balance_switch true</span><br></pre></td></tr></table></figure><p>这样就完成了数据迁移。 之后需要的就是更新同步hbase 配置文件中的regionservers 文件。</p>]]></content>
      
      <categories>
          
          <category> hadoop </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hbase </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>docker启动容器的时候携带&quot;--restart=always&quot;参数后如何删除容器</title>
      <link href="/docker-restart-always/"/>
      <url>/docker-restart-always/</url>
      <content type="html"><![CDATA[<p>当容器启动的时候添加了 “–restart=always” 参数，那样容器有问题会一直重启， docker服务重启之后，这个容器也会自动起来。</p><p>这样的启动方式适合与一些监控程序，跟着机器一起启动，出问题也会自动重启。</p><p>例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -d --restart=always nginx:latest</span><br></pre></td></tr></table></figure><a id="more"></a> <p>如果这个时候我们不要这个容器了， 应该怎么停止呢？</p><p>我们需要更新 restart 的状态。</p><p>例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker update --restart=no nginx:latest</span><br></pre></td></tr></table></figure><p>这样之后， 这个容器就不会在自动启动了。 </p>]]></content>
      
      <categories>
          
          <category> docker </category>
          
      </categories>
      
      
        <tags>
            
            <tag> docker </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>tls Cipher 算法和名字对应表</title>
      <link href="/tls-ciphers-list/"/>
      <url>/tls-ciphers-list/</url>
      <content type="html"><![CDATA[<p>tls Cipher 算法和名字对应表  </p><p>可以用opensll命令得到加密套件，如</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">openssl ciphers [-v] [-ssl2] [-ssl3] [-tls1] [cipherlist]</span><br></pre></td></tr></table></figure><h4 id="选项说明："><a href="#选项说明：" class="headerlink" title="选项说明："></a>选项说明：</h4><p>-v：详细列出所有加密套件。包括ssl版本（SSLv2 、SSLv3以及 TLS）、密钥交换算法、身份验证算法、对称算法、摘要算法以及该算法是否可以出口。</p><p>-ssl2：只列出SSLv2使用的加密套件。</p><p>-ssl3：只列出SSLv3使用的加密套件。<br><a id="more"></a>  </p><p>-tls1：只列出tls使用的加密套件。</p><p>cipherlist：列出一个cipher list的详细内容。用此项能列出所有符合规则的加密套件，如果不加-v选项，它只显示各个套件名字；</p><h4 id="示例："><a href="#示例：" class="headerlink" title="示例："></a>示例：</h4><p>列举OpenSSL算法套件包括NULL算法：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">openssl ciphers -v &apos;ALL:eNULL&apos;</span><br></pre></td></tr></table></figure><p>包括所有的算法除空的以及匿名的DH算法：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">openssl ciphers -v &apos;ALL:!ADH:@STRENGTH&apos;</span><br></pre></td></tr></table></figure><p>包含3DES算法和RSA算法：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">openssl ciphers -v &apos;3DES:+RSA&apos;</span><br></pre></td></tr></table></figure><p>包含所有的RC4算法但是不包含验证算法：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">openssl ciphers -v &apos;RC4:!COMPLEMENTOFDEFAUL</span><br></pre></td></tr></table></figure><p>相关链接 <a href="https://blog.csdn.net/as3luyuan123/article/details/13609819" target="_blank" rel="noopener">https://blog.csdn.net/as3luyuan123/article/details/13609819</a></p><h4 id="Mapping-OpenSSL-cipher-suite-names-to-IANA-names"><a href="#Mapping-OpenSSL-cipher-suite-names-to-IANA-names" class="headerlink" title="Mapping OpenSSL cipher suite names to IANA names"></a>Mapping OpenSSL cipher suite names to IANA names</h4><p>List</p><p>相关链接 ： <a href="https://testssl.sh/openssl-iana.mapping.html" target="_blank" rel="noopener">https://testssl.sh/openssl-iana.mapping.html</a></p><table><thead><tr><th>Cipher Suite</th><th>Name (OpenSSL)</th><th>KeyExch.</th><th>Encryption</th><th>Bits</th><th>Cipher Suite Name (IANA)</th></tr></thead><tbody><tr><td>[0x00]</td><td></td><td>None</td><td>Null</td><td>0</td><td>TLS_NULL_WITH_NULL_NULL</td></tr><tr><td>[0x01]</td><td>NULL-MD5</td><td>RSA</td><td>Null</td><td>0</td><td>TLS_RSA_WITH_NULL_MD5</td></tr><tr><td>[0x02]</td><td>NULL-SHA</td><td>RSA</td><td>Null</td><td>0</td><td>TLS_RSA_WITH_NULL_SHA</td></tr><tr><td>[0x03]</td><td>EXP-RC4-MD5</td><td>RSA(512)</td><td>RC4</td><td>40, export</td><td>TLS_RSA_EXPORT_WITH_RC4_40_MD5</td></tr><tr><td>[0x04]</td><td>RC4-MD5</td><td>RSA</td><td>RC4</td><td>128</td><td>TLS_RSA_WITH_RC4_128_MD5</td></tr><tr><td>[0x05]</td><td>RC4-SHA</td><td>RSA</td><td>RC4</td><td>128</td><td>TLS_RSA_WITH_RC4_128_SHA</td></tr><tr><td>[0x06]</td><td>EXP-RC2-CBC-MD5</td><td>RSA(512)</td><td>RC2</td><td>40, export</td><td>TLS_RSA_EXPORT_WITH_RC2_CBC_40_MD5</td></tr><tr><td>[0x07]</td><td>IDEA-CBC-SHA</td><td>RSA</td><td>IDEA</td><td>128</td><td>TLS_RSA_WITH_IDEA_CBC_SHA</td></tr><tr><td>[0x08]</td><td>EXP-DES-CBC-SHA</td><td>RSA(512)</td><td>DES</td><td>40, export</td><td>TLS_RSA_EXPORT_WITH_DES40_CBC_SHA</td></tr><tr><td>[0x09]</td><td>DES-CBC-SHA</td><td>RSA</td><td>DES</td><td>56</td><td>TLS_RSA_WITH_DES_CBC_SHA</td></tr><tr><td>[0x0a]</td><td>DES-CBC3-SHA</td><td>RSA</td><td>3DES</td><td>168</td><td>TLS_RSA_WITH_3DES_EDE_CBC_SHA</td></tr><tr><td>[0x0b]</td><td>EXP-DH-DSS-DES-CBC-SHA</td><td>DH/DSS</td><td>DES</td><td>40, export</td><td>TLS_DH_DSS_EXPORT_WITH_DES40_CBC_SHA</td></tr><tr><td>[0x0c]</td><td>DH-DSS-DES-CBC-SHA</td><td>DH/DSS</td><td>DES</td><td>56</td><td>TLS_DH_DSS_WITH_DES_CBC_SHA</td></tr><tr><td>[0x0d]</td><td>DH-DSS-DES-CBC3-SHA</td><td>DH/DSS</td><td>3DES</td><td>168</td><td>TLS_DH_DSS_WITH_3DES_EDE_CBC_SHA</td></tr><tr><td>[0x0e]</td><td>EXP-DH-RSA-DES-CBC-SHA</td><td>DH/RSA</td><td>DES</td><td>40, export</td><td>TLS_DH_RSA_EXPORT_WITH_DES40_CBC_SHA</td></tr><tr><td>[0x0f]</td><td>DH-RSA-DES-CBC-SHA</td><td>DH/RSA</td><td>DES</td><td>56</td><td>TLS_DH_RSA_WITH_DES_CBC_SHA</td></tr><tr><td>[0x10]</td><td>DH-RSA-DES-CBC3-SHA</td><td>DH/RSA</td><td>3DES</td><td>168</td><td>TLS_DH_RSA_WITH_3DES_EDE_CBC_SHA</td></tr><tr><td>[0x11]</td><td>EXP-EDH-DSS-DES-CBC-SHA</td><td>DH(512)</td><td>DES</td><td>40, export</td><td>TLS_DHE_DSS_EXPORT_WITH_DES40_CBC_SHA</td></tr><tr><td>[0x12]</td><td>EDH-DSS-DES-CBC-SHA</td><td>DH</td><td>DES</td><td>56</td><td>TLS_DHE_DSS_WITH_DES_CBC_SHA</td></tr><tr><td>[0x13]</td><td>EDH-DSS-DES-CBC3-SHA</td><td>DH</td><td>3DES</td><td>168</td><td>TLS_DHE_DSS_WITH_3DES_EDE_CBC_SHA</td></tr><tr><td>[0x14]</td><td>EXP-EDH-RSA-DES-CBC-SHA</td><td>DH(512)</td><td>DES</td><td>40, export</td><td>TLS_DHE_RSA_EXPORT_WITH_DES40_CBC_SHA</td></tr><tr><td>[0x15]</td><td>EDH-RSA-DES-CBC-SHA</td><td>DH</td><td>DES</td><td>56</td><td>TLS_DHE_RSA_WITH_DES_CBC_SHA</td></tr><tr><td>[0x16]</td><td>EDH-RSA-DES-CBC3-SHA</td><td>DH</td><td>3DES</td><td>168</td><td>TLS_DHE_RSA_WITH_3DES_EDE_CBC_SHA</td></tr><tr><td>[0x17]</td><td>EXP-ADH-RC4-MD5</td><td>DH(512)</td><td>RC4</td><td>40, export</td><td>TLS_DH_anon_EXPORT_WITH_RC4_40_MD5</td></tr><tr><td>[0x18]</td><td>ADH-RC4-MD5</td><td>DH</td><td>RC4</td><td>128</td><td>TLS_DH_anon_WITH_RC4_128_MD5</td></tr><tr><td>[0x19]</td><td>EXP-ADH-DES-CBC-SHA</td><td>DH(512)</td><td>DES</td><td>40, export</td><td>TLS_DH_anon_EXPORT_WITH_DES40_CBC_SHA</td></tr><tr><td>[0x1a]</td><td>ADH-DES-CBC-SHA</td><td>DH</td><td>DES</td><td>56</td><td>TLS_DH_anon_WITH_DES_CBC_SHA</td></tr><tr><td>[0x1b]</td><td>ADH-DES-CBC3-SHA</td><td>DH</td><td>3DES</td><td>168</td><td>TLS_DH_anon_WITH_3DES_EDE_CBC_SHA</td></tr><tr><td>[0x1c]</td><td></td><td>FORTEZZA</td><td>Null</td><td>0</td><td>SSL_FORTEZZA_KEA_WITH_NULL_SHA</td></tr><tr><td>[0x1d]</td><td></td><td>FORTEZZA</td><td>FORTEZZA_CBC</td><td>80</td><td>SSL_FORTEZZA_KEA_WITH_FORTEZZA_CBC_SHA</td></tr><tr><td>[0x1e]</td><td></td><td>FORTEZZA</td><td>FORTEZZA_RC4</td><td>128</td><td>SSL_FORTEZZA_KEA_WITH_RC4_128_SHA</td></tr><tr><td>[0x1e]</td><td>KRB5-DES-CBC-SHA</td><td>KRB5</td><td>DES</td><td>56</td><td>TLS_KRB5_WITH_DES_CBC_SHA</td></tr><tr><td>[0x1f]</td><td>KRB5-DES-CBC3-SHA</td><td>KRB5</td><td>3DES</td><td>168</td><td>TLS_KRB5_WITH_3DES_EDE_CBC_SHA</td></tr><tr><td>[0x20]</td><td>KRB5-RC4-SHA</td><td>KRB5</td><td>RC4</td><td>128</td><td>TLS_KRB5_WITH_RC4_128_SHA</td></tr><tr><td>[0x21]</td><td>KRB5-IDEA-CBC-SHA</td><td>KRB5</td><td>IDEA</td><td>128</td><td>TLS_KRB5_WITH_IDEA_CBC_SHA</td></tr><tr><td>[0x22]</td><td>KRB5-DES-CBC-MD5</td><td>KRB5</td><td>DES</td><td>56</td><td>TLS_KRB5_WITH_DES_CBC_MD5</td></tr><tr><td>[0x23]</td><td>KRB5-DES-CBC3-MD5</td><td>KRB5</td><td>3DES</td><td>168</td><td>TLS_KRB5_WITH_3DES_EDE_CBC_MD5</td></tr><tr><td>[0x24]</td><td>KRB5-RC4-MD5</td><td>KRB5</td><td>RC4</td><td>128</td><td>TLS_KRB5_WITH_RC4_128_MD5</td></tr><tr><td>[0x25]</td><td>KRB5-IDEA-CBC-MD5</td><td>KRB5</td><td>IDEA</td><td>128</td><td>TLS_KRB5_WITH_IDEA_CBC_MD5</td></tr><tr><td>[0x26]</td><td>EXP-KRB5-DES-CBC-SHA</td><td>KRB5</td><td>DES</td><td>40, export</td><td>TLS_KRB5_EXPORT_WITH_DES_CBC_40_SHA</td></tr><tr><td>[0x27]</td><td>EXP-KRB5-RC2-CBC-SHA</td><td>KRB5</td><td>RC2</td><td>40, export</td><td>TLS_KRB5_EXPORT_WITH_RC2_CBC_40_SHA</td></tr><tr><td>[0x28]</td><td>EXP-KRB5-RC4-SHA</td><td>KRB5</td><td>RC4</td><td>40, export</td><td>TLS_KRB5_EXPORT_WITH_RC4_40_SHA</td></tr><tr><td>[0x29]</td><td>EXP-KRB5-DES-CBC-MD5</td><td>KRB5</td><td>DES</td><td>40, export</td><td>TLS_KRB5_EXPORT_WITH_DES_CBC_40_MD5</td></tr><tr><td>[0x2a]</td><td>EXP-KRB5-RC2-CBC-MD5</td><td>KRB5</td><td>RC2</td><td>40, export</td><td>TLS_KRB5_EXPORT_WITH_RC2_CBC_40_MD5</td></tr><tr><td>[0x2b]</td><td>EXP-KRB5-RC4-MD5</td><td>KRB5</td><td>RC4</td><td>40, export</td><td>TLS_KRB5_EXPORT_WITH_RC4_40_MD5</td></tr><tr><td>[0x2c]</td><td>PSK-NULL-SHA</td><td>PSK</td><td>Null</td><td>0</td><td>TLS_PSK_WITH_NULL_SHA</td></tr><tr><td>[0x2d]</td><td>DHE-PSK-NULL-SHA</td><td>DH/PSK</td><td>Null</td><td>0</td><td>TLS_DHE_PSK_WITH_NULL_SHA</td></tr><tr><td>[0x2e]</td><td>RSA-PSK-NULL-SHA</td><td>RSA/PSK</td><td>Null</td><td>0</td><td>TLS_RSA_PSK_WITH_NULL_SHA</td></tr><tr><td>[0x2f]</td><td>AES128-SHA</td><td>RSA</td><td>AES</td><td>128</td><td>TLS_RSA_WITH_AES_128_CBC_SHA</td></tr><tr><td>[0x30]</td><td>DH-DSS-AES128-SHA</td><td>DH/DSS</td><td>AES</td><td>128</td><td>TLS_DH_DSS_WITH_AES_128_CBC_SHA</td></tr><tr><td>[0x31]</td><td>DH-RSA-AES128-SHA</td><td>DH/RSA</td><td>AES</td><td>128</td><td>TLS_DH_RSA_WITH_AES_128_CBC_SHA</td></tr><tr><td>[0x32]</td><td>DHE-DSS-AES128-SHA</td><td>DH</td><td>AES</td><td>128</td><td>TLS_DHE_DSS_WITH_AES_128_CBC_SHA</td></tr><tr><td>[0x33]</td><td>DHE-RSA-AES128-SHA</td><td>DH</td><td>AES</td><td>128</td><td>TLS_DHE_RSA_WITH_AES_128_CBC_SHA</td></tr><tr><td>[0x34]</td><td>ADH-AES128-SHA</td><td>DH</td><td>AES</td><td>128</td><td>TLS_DH_anon_WITH_AES_128_CBC_SHA</td></tr><tr><td>[0x35]</td><td>AES256-SHA</td><td>RSA</td><td>AES</td><td>256</td><td>TLS_RSA_WITH_AES_256_CBC_SHA</td></tr><tr><td>[0x36]</td><td>DH-DSS-AES256-SHA</td><td>DH/DSS</td><td>AES</td><td>256</td><td>TLS_DH_DSS_WITH_AES_256_CBC_SHA</td></tr><tr><td>[0x37]</td><td>DH-RSA-AES256-SHA</td><td>DH/RSA</td><td>AES</td><td>256</td><td>TLS_DH_RSA_WITH_AES_256_CBC_SHA</td></tr><tr><td>[0x38]</td><td>DHE-DSS-AES256-SHA</td><td>DH</td><td>AES</td><td>256</td><td>TLS_DHE_DSS_WITH_AES_256_CBC_SHA</td></tr><tr><td>[0x39]</td><td>DHE-RSA-AES256-SHA</td><td>DH</td><td>AES</td><td>256</td><td>TLS_DHE_RSA_WITH_AES_256_CBC_SHA</td></tr><tr><td>[0x3a]</td><td>ADH-AES256-SHA</td><td>DH</td><td>AES</td><td>256</td><td>TLS_DH_anon_WITH_AES_256_CBC_SHA</td></tr><tr><td>[0x3b]</td><td>NULL-SHA256</td><td>RSA</td><td>Null</td><td>0</td><td>TLS_RSA_WITH_NULL_SHA256</td></tr><tr><td>[0x3c]</td><td>AES128-SHA256</td><td>RSA</td><td>AES</td><td>128</td><td>TLS_RSA_WITH_AES_128_CBC_SHA256</td></tr><tr><td>[0x3d]</td><td>AES256-SHA256</td><td>RSA</td><td>AES</td><td>256</td><td>TLS_RSA_WITH_AES_256_CBC_SHA256</td></tr><tr><td>[0x3e]</td><td>DH-DSS-AES128-SHA256</td><td>DH/DSS</td><td>AES</td><td>128</td><td>TLS_DH_DSS_WITH_AES_128_CBC_SHA256</td></tr><tr><td>[0x3f]</td><td>DH-RSA-AES128-SHA256</td><td>DH/RSA</td><td>AES</td><td>128</td><td>TLS_DH_RSA_WITH_AES_128_CBC_SHA256</td></tr><tr><td>[0x40]</td><td>DHE-DSS-AES128-SHA256</td><td>DH</td><td>AES</td><td>128</td><td>TLS_DHE_DSS_WITH_AES_128_CBC_SHA256</td></tr><tr><td>[0x41]</td><td>CAMELLIA128-SHA</td><td>RSA</td><td>Camellia</td><td>128</td><td>TLS_RSA_WITH_CAMELLIA_128_CBC_SHA</td></tr><tr><td>[0x42]</td><td>DH-DSS-CAMELLIA128-SHA</td><td>DH/DSS</td><td>Camellia</td><td>128</td><td>TLS_DH_DSS_WITH_CAMELLIA_128_CBC_SHA</td></tr><tr><td>[0x43]</td><td>DH-RSA-CAMELLIA128-SHA</td><td>DH/RSA</td><td>Camellia</td><td>128</td><td>TLS_DH_RSA_WITH_CAMELLIA_128_CBC_SHA</td></tr><tr><td>[0x44]</td><td>DHE-DSS-CAMELLIA128-SHA</td><td>DH</td><td>Camellia</td><td>128</td><td>TLS_DHE_DSS_WITH_CAMELLIA_128_CBC_SHA</td></tr><tr><td>[0x45]</td><td>DHE-RSA-CAMELLIA128-SHA</td><td>DH</td><td>Camellia</td><td>128</td><td>TLS_DHE_RSA_WITH_CAMELLIA_128_CBC_SHA</td></tr><tr><td>[0x46]</td><td>ADH-CAMELLIA128-SHA</td><td>DH</td><td>Camellia</td><td>128</td><td>TLS_DH_anon_WITH_CAMELLIA_128_CBC_SHA</td></tr><tr><td>[0x60]</td><td>EXP1024-RC4-MD5</td><td>RSA(1024)</td><td>RC4</td><td>56, export</td><td>TLS_RSA_EXPORT1024_WITH_RC4_56_MD5</td></tr><tr><td>[0x61]</td><td>EXP1024-RC2-CBC-MD5</td><td>RSA(1024)</td><td>RC2</td><td>56, export</td><td>TLS_RSA_EXPORT1024_WITH_RC2_CBC_56_MD5</td></tr><tr><td>[0x62]</td><td>EXP1024-DES-CBC-SHA</td><td>RSA(1024)</td><td>DES</td><td>56, export</td><td>TLS_RSA_EXPORT1024_WITH_DES_CBC_SHA</td></tr><tr><td>[0x63]</td><td>EXP1024-DHE-DSS-DES-CBC-SHA</td><td>DH(1024)</td><td>DES</td><td>56, export</td><td>TLS_DHE_DSS_EXPORT1024_WITH_DES_CBC_SHA</td></tr><tr><td>[0x64]</td><td>EXP1024-RC4-SHA</td><td>RSA(1024)</td><td>RC4</td><td>56, export</td><td>TLS_RSA_EXPORT1024_WITH_RC4_56_SHA</td></tr><tr><td>[0x65]</td><td>EXP1024-DHE-DSS-RC4-SHA</td><td>DH(1024)</td><td>RC4</td><td>56, export</td><td>TLS_DHE_DSS_EXPORT1024_WITH_RC4_56_SHA</td></tr><tr><td>[0x66]</td><td>DHE-DSS-RC4-SHA</td><td>DH</td><td>RC4</td><td>128</td><td>TLS_DHE_DSS_WITH_RC4_128_SHA</td></tr><tr><td>[0x67]</td><td>DHE-RSA-AES128-SHA256</td><td>DH</td><td>AES</td><td>128</td><td>TLS_DHE_RSA_WITH_AES_128_CBC_SHA256</td></tr><tr><td>[0x68]</td><td>DH-DSS-AES256-SHA256</td><td>DH/DSS</td><td>AES</td><td>256</td><td>TLS_DH_DSS_WITH_AES_256_CBC_SHA256</td></tr><tr><td>[0x69]</td><td>DH-RSA-AES256-SHA256</td><td>DH/RSA</td><td>AES</td><td>256</td><td>TLS_DH_RSA_WITH_AES_256_CBC_SHA256</td></tr><tr><td>[0x6a]</td><td>DHE-DSS-AES256-SHA256</td><td>DH</td><td>AES</td><td>256</td><td>TLS_DHE_DSS_WITH_AES_256_CBC_SHA256</td></tr><tr><td>[0x6b]</td><td>DHE-RSA-AES256-SHA256</td><td>DH</td><td>AES</td><td>256</td><td>TLS_DHE_RSA_WITH_AES_256_CBC_SHA256</td></tr><tr><td>[0x6c]</td><td>ADH-AES128-SHA256</td><td>DH</td><td>AES</td><td>128</td><td>TLS_DH_anon_WITH_AES_128_CBC_SHA256</td></tr><tr><td>[0x6d]</td><td>ADH-AES256-SHA256</td><td>DH</td><td>AES</td><td>256</td><td>TLS_DH_anon_WITH_AES_256_CBC_SHA256</td></tr><tr><td>[0x80]</td><td>GOST94-GOST89-GOST89</td><td>VKO GOST 34.10-94</td><td>GOST89</td><td>256</td><td>TLS_GOSTR341094_WITH_28147_CNT_IMIT</td></tr><tr><td>[0x81]</td><td>GOST2001-GOST89-GOST89</td><td>VKO GOST 34.10-2001</td><td>GOST89</td><td>256</td><td>TLS_GOSTR341001_WITH_28147_CNT_IMIT</td></tr><tr><td>[0x82]</td><td>GOST94-NULL-GOST94</td><td>VKO GOST 34.10-94</td><td>Null</td><td>0</td><td>TLS_GOSTR341001_WITH_NULL_GOSTR3411</td></tr><tr><td>[0x83]</td><td>GOST2001-GOST89-GOST89</td><td>VKO GOST 34.10-2001</td><td>Null</td><td>0</td><td>TLS_GOSTR341094_WITH_NULL_GOSTR3411</td></tr><tr><td>[0x84]</td><td>CAMELLIA256-SHA</td><td>RSA</td><td>Camellia</td><td>256</td><td>TLS_RSA_WITH_CAMELLIA_256_CBC_SHA</td></tr><tr><td>[0x85]</td><td>DH-DSS-CAMELLIA256-SHA</td><td>DH/DSS</td><td>Camellia</td><td>256</td><td>TLS_DH_DSS_WITH_CAMELLIA_256_CBC_SHA</td></tr><tr><td>[0x86]</td><td>DH-RSA-CAMELLIA256-SHA</td><td>DH/RSA</td><td>Camellia</td><td>256</td><td>TLS_DH_RSA_WITH_CAMELLIA_256_CBC_SHA</td></tr><tr><td>[0x87]</td><td>DHE-DSS-CAMELLIA256-SHA</td><td>DH</td><td>Camellia</td><td>256</td><td>TLS_DHE_DSS_WITH_CAMELLIA_256_CBC_SHA</td></tr><tr><td>[0x88]</td><td>DHE-RSA-CAMELLIA256-SHA</td><td>DH</td><td>Camellia</td><td>256</td><td>TLS_DHE_RSA_WITH_CAMELLIA_256_CBC_SHA</td></tr><tr><td>[0x89]</td><td>ADH-CAMELLIA256-SHA</td><td>DH</td><td>Camellia</td><td>256</td><td>TLS_DH_anon_WITH_CAMELLIA_256_CBC_SHA</td></tr><tr><td>[0x8a]</td><td>PSK-RC4-SHA</td><td>PSK</td><td>RC4</td><td>128</td><td>TLS_PSK_WITH_RC4_128_SHA</td></tr><tr><td>[0x8b]</td><td>PSK-3DES-EDE-CBC-SHA</td><td>PSK</td><td>3DES</td><td>168</td><td>TLS_PSK_WITH_3DES_EDE_CBC_SHA</td></tr><tr><td>[0x8c]</td><td>PSK-AES128-CBC-SHA</td><td>PSK</td><td>AES</td><td>128</td><td>TLS_PSK_WITH_AES_128_CBC_SHA</td></tr><tr><td>[0x8d]</td><td>PSK-AES256-CBC-SHA</td><td>PSK</td><td>AES</td><td>256</td><td>TLS_PSK_WITH_AES_256_CBC_SHA</td></tr><tr><td>[0x8e]</td><td></td><td>PSK/DHE</td><td>RC4</td><td>128</td><td>TLS_DHE_PSK_WITH_RC4_128_SHA</td></tr><tr><td>[0x8f]</td><td></td><td>PSK/DHE</td><td>3DES</td><td>168</td><td>TLS_DHE_PSK_WITH_3DES_EDE_CBC_SHA</td></tr><tr><td>[0x90]</td><td></td><td>PSK/DHE</td><td>AES</td><td>128</td><td>TLS_DHE_PSK_WITH_AES_128_CBC_SHA</td></tr><tr><td>[0x91]</td><td></td><td>PSK/DHE</td><td>AES</td><td>256</td><td>TLS_DHE_PSK_WITH_AES_256_CBC_SHA</td></tr><tr><td>[0x92]</td><td></td><td>PSK/RSA</td><td>RC4</td><td>128</td><td>TLS_RSA_PSK_WITH_RC4_128_SHA</td></tr><tr><td>[0x93]</td><td></td><td>PSK/RSA</td><td>3DES</td><td>168</td><td>TLS_RSA_PSK_WITH_3DES_EDE_CBC_SHA</td></tr><tr><td>[0x94]</td><td></td><td>PSK/RSA</td><td>AES</td><td>128</td><td>TLS_RSA_PSK_WITH_AES_128_CBC_SHA</td></tr><tr><td>[0x95]</td><td></td><td>PSK/RSA</td><td>AES</td><td>256</td><td>TLS_RSA_PSK_WITH_AES_256_CBC_SHA</td></tr><tr><td>[0x96]</td><td>SEED-SHA</td><td>RSA</td><td>SEED</td><td>128</td><td>TLS_RSA_WITH_SEED_CBC_SHA</td></tr><tr><td>[0x97]</td><td>DH-DSS-SEED-SHA</td><td>DH/DSS</td><td>SEED</td><td>128</td><td>TLS_DH_DSS_WITH_SEED_CBC_SHA</td></tr><tr><td>[0x98]</td><td>DH-RSA-SEED-SHA</td><td>DH/RSA</td><td>SEED</td><td>128</td><td>TLS_DH_RSA_WITH_SEED_CBC_SHA</td></tr><tr><td>[0x99]</td><td>DHE-DSS-SEED-SHA</td><td>DH</td><td>SEED</td><td>128</td><td>TLS_DHE_DSS_WITH_SEED_CBC_SHA</td></tr><tr><td>[0x9a]</td><td>DHE-RSA-SEED-SHA</td><td>DH</td><td>SEED</td><td>128</td><td>TLS_DHE_RSA_WITH_SEED_CBC_SHA</td></tr><tr><td>[0x9b]</td><td>ADH-SEED-SHA</td><td>DH</td><td>SEED</td><td>128</td><td>TLS_DH_anon_WITH_SEED_CBC_SHA</td></tr><tr><td>[0x9c]</td><td>AES128-GCM-SHA256</td><td>RSA</td><td>AESGCM</td><td>128</td><td>TLS_RSA_WITH_AES_128_GCM_SHA256</td></tr><tr><td>[0x9d]</td><td>AES256-GCM-SHA384</td><td>RSA</td><td>AESGCM</td><td>256</td><td>TLS_RSA_WITH_AES_256_GCM_SHA384</td></tr><tr><td>[0x9e]</td><td>DHE-RSA-AES128-GCM-SHA256</td><td>DH</td><td>AESGCM</td><td>128</td><td>TLS_DHE_RSA_WITH_AES_128_GCM_SHA256</td></tr><tr><td>[0x9f]</td><td>DHE-RSA-AES256-GCM-SHA384</td><td>DH</td><td>AESGCM</td><td>256</td><td>TLS_DHE_RSA_WITH_AES_256_GCM_SHA384</td></tr><tr><td>[0xa0]</td><td>DH-RSA-AES128-GCM-SHA256</td><td>DH/RSA</td><td>AESGCM</td><td>128</td><td>TLS_DH_RSA_WITH_AES_128_GCM_SHA256</td></tr><tr><td>[0xa1]</td><td>DH-RSA-AES256-GCM-SHA384</td><td>DH/RSA</td><td>AESGCM</td><td>256</td><td>TLS_DH_RSA_WITH_AES_256_GCM_SHA384</td></tr><tr><td>[0xa2]</td><td>DHE-DSS-AES128-GCM-SHA256</td><td>DH</td><td>AESGCM</td><td>128</td><td>TLS_DHE_DSS_WITH_AES_128_GCM_SHA256</td></tr><tr><td>[0xa3]</td><td>DHE-DSS-AES256-GCM-SHA384</td><td>DH</td><td>AESGCM</td><td>256</td><td>TLS_DHE_DSS_WITH_AES_256_GCM_SHA384</td></tr><tr><td>[0xa4]</td><td>DH-DSS-AES128-GCM-SHA256</td><td>DH/DSS</td><td>AESGCM</td><td>128</td><td>TLS_DH_DSS_WITH_AES_128_GCM_SHA256</td></tr><tr><td>[0xa5]</td><td>DH-DSS-AES256-GCM-SHA384</td><td>DH/DSS</td><td>AESGCM</td><td>256</td><td>TLS_DH_DSS_WITH_AES_256_GCM_SHA384</td></tr><tr><td>[0xa6]</td><td>ADH-AES128-GCM-SHA256</td><td>DH</td><td>AESGCM</td><td>128</td><td>TLS_DH_anon_WITH_AES_128_GCM_SHA256</td></tr><tr><td>[0xa7]</td><td>ADH-AES256-GCM-SHA384</td><td>DH</td><td>AESGCM</td><td>256</td><td>TLS_DH_anon_WITH_AES_256_GCM_SHA384</td></tr><tr><td>[0xba]</td><td>CAMELLIA128-SHA256</td><td>RSA</td><td>Camellia</td><td>128</td><td>TLS_RSA_WITH_CAMELLIA_128_CBC_SHA256</td></tr><tr><td>[0xbb]</td><td>DH-DSS-CAMELLIA128-SHA256</td><td>DH/DSS</td><td>Camellia</td><td>128</td><td>TLS_DH_DSS_WITH_CAMELLIA_128_CBC_SHA256</td></tr><tr><td>[0xbc]</td><td>DH-RSA-CAMELLIA128-SHA256</td><td>DH/RSA</td><td>Camellia</td><td>128</td><td>TLS_DH_RSA_WITH_CAMELLIA_128_CBC_SHA256</td></tr><tr><td>[0xbd]</td><td>DHE-DSS-CAMELLIA128-SHA256</td><td>DH</td><td>Camellia</td><td>128</td><td>TLS_DHE_DSS_WITH_CAMELLIA_128_CBC_SHA256</td></tr><tr><td>[0xbe]</td><td>DHE-RSA-CAMELLIA128-SHA256</td><td>DH</td><td>Camellia</td><td>128</td><td>TLS_DHE_RSA_WITH_CAMELLIA_128_CBC_SHA256</td></tr><tr><td>[0xbf]</td><td>ADH-CAMELLIA128-SHA256</td><td>DH</td><td>Camellia</td><td>128</td><td>TLS_DH_anon_WITH_CAMELLIA_128_CBC_SHA256</td></tr><tr><td>[0x5600]</td><td>TLS_FALLBACK_SCSV</td><td></td><td></td><td></td><td>TLS_EMPTY_RENEGOTIATION_INFO_SCSV</td></tr><tr><td>[0x1301]</td><td>TLS_AES_128_GCM_SHA256</td><td>ECDH</td><td>AESGCM</td><td>128</td><td>TLS_AES_128_GCM_SHA256</td></tr><tr><td>[0x1302]</td><td>TLS_AES_256_GCM_SHA384</td><td>ECDH</td><td>AESGCM</td><td>256</td><td>TLS_AES_256_GCM_SHA384</td></tr><tr><td>[0x1303]</td><td>TLS_CHACHA20_POLY1305_SHA256</td><td>ECDH</td><td>ChaCha20-Poly1305</td><td>256</td><td>TLS_CHACHA20_POLY1305_SHA256</td></tr><tr><td>[0x1304]</td><td>TLS_AES_128_CCM_SHA256</td><td>ECDH</td><td>AESCCM</td><td>128</td><td>TLS_AES_128_CCM_SHA256</td></tr><tr><td>[0x1305]</td><td>TLS_AES_128_CCM_8_SHA256</td><td>ECDH</td><td>AESCCM8</td><td>128</td><td>TLS_AES_128_CCM_8_SHA256</td></tr><tr><td>[0xc001]</td><td>ECDH-ECDSA-NULL-SHA</td><td>ECDH/ECDSA</td><td>Null</td><td>0</td><td>TLS_ECDH_ECDSA_WITH_NULL_SHA</td></tr><tr><td>[0xc002]</td><td>ECDH-ECDSA-RC4-SHA</td><td>ECDH/ECDSA</td><td>RC4</td><td>128</td><td>TLS_ECDH_ECDSA_WITH_RC4_128_SHA</td></tr><tr><td>[0xc003]</td><td>ECDH-ECDSA-DES-CBC3-SHA</td><td>ECDH/ECDSA</td><td>3DES</td><td>168</td><td>TLS_ECDH_ECDSA_WITH_3DES_EDE_CBC_SHA</td></tr><tr><td>[0xc004]</td><td>ECDH-ECDSA-AES128-SHA</td><td>ECDH/ECDSA</td><td>AES</td><td>128</td><td>TLS_ECDH_ECDSA_WITH_AES_128_CBC_SHA</td></tr><tr><td>[0xc005]</td><td>ECDH-ECDSA-AES256-SHA</td><td>ECDH/ECDSA</td><td>AES</td><td>256</td><td>TLS_ECDH_ECDSA_WITH_AES_256_CBC_SHA</td></tr><tr><td>[0xc006]</td><td>ECDHE-ECDSA-NULL-SHA</td><td>ECDH</td><td>Null</td><td>0</td><td>TLS_ECDHE_ECDSA_WITH_NULL_SHA</td></tr><tr><td>[0xc007]</td><td>ECDHE-ECDSA-RC4-SHA</td><td>ECDH</td><td>RC4</td><td>128</td><td>TLS_ECDHE_ECDSA_WITH_RC4_128_SHA</td></tr><tr><td>[0xc008]</td><td>ECDHE-ECDSA-DES-CBC3-SHA</td><td>ECDH</td><td>3DES</td><td>168</td><td>TLS_ECDHE_ECDSA_WITH_3DES_EDE_CBC_SHA</td></tr><tr><td>[0xc009]</td><td>ECDHE-ECDSA-AES128-SHA</td><td>ECDH</td><td>AES</td><td>128</td><td>TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA</td></tr><tr><td>[0xc00a]</td><td>ECDHE-ECDSA-AES256-SHA</td><td>ECDH</td><td>AES</td><td>256</td><td>TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA</td></tr><tr><td>[0xc00b]</td><td>ECDH-RSA-NULL-SHA</td><td>ECDH/RSA</td><td>Null</td><td>0</td><td>TLS_ECDH_RSA_WITH_NULL_SHA</td></tr><tr><td>[0xc00c]</td><td>ECDH-RSA-RC4-SHA</td><td>ECDH/RSA</td><td>RC4</td><td>128</td><td>TLS_ECDH_RSA_WITH_RC4_128_SHA</td></tr><tr><td>[0xc00d]</td><td>ECDH-RSA-DES-CBC3-SHA</td><td>ECDH/RSA</td><td>3DES</td><td>168</td><td>TLS_ECDH_RSA_WITH_3DES_EDE_CBC_SHA</td></tr><tr><td>[0xc00e]</td><td>ECDH-RSA-AES128-SHA</td><td>ECDH/RSA</td><td>AES</td><td>128</td><td>TLS_ECDH_RSA_WITH_AES_128_CBC_SHA</td></tr><tr><td>[0xc00f]</td><td>ECDH-RSA-AES256-SHA</td><td>ECDH/RSA</td><td>AES</td><td>256</td><td>TLS_ECDH_RSA_WITH_AES_256_CBC_SHA</td></tr><tr><td>[0xc010]</td><td>ECDHE-RSA-NULL-SHA</td><td>ECDH</td><td>Null</td><td>0</td><td>TLS_ECDHE_RSA_WITH_NULL_SHA</td></tr><tr><td>[0xc011]</td><td>ECDHE-RSA-RC4-SHA</td><td>ECDH</td><td>RC4</td><td>128</td><td>TLS_ECDHE_RSA_WITH_RC4_128_SHA</td></tr><tr><td>[0xc012]</td><td>ECDHE-RSA-DES-CBC3-SHA</td><td>ECDH</td><td>3DES</td><td>168</td><td>TLS_ECDHE_RSA_WITH_3DES_EDE_CBC_SHA</td></tr><tr><td>[0xc013]</td><td>ECDHE-RSA-AES128-SHA</td><td>ECDH</td><td>AES</td><td>128</td><td>TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA</td></tr><tr><td>[0xc014]</td><td>ECDHE-RSA-AES256-SHA</td><td>ECDH</td><td>AES</td><td>256</td><td>TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA</td></tr><tr><td>[0xc015]</td><td>AECDH-NULL-SHA</td><td>ECDH</td><td>Null</td><td>0</td><td>TLS_ECDH_anon_WITH_NULL_SHA</td></tr><tr><td>[0xc016]</td><td>AECDH-RC4-SHA</td><td>ECDH</td><td>RC4</td><td>128</td><td>TLS_ECDH_anon_WITH_RC4_128_SHA</td></tr><tr><td>[0xc017]</td><td>AECDH-DES-CBC3-SHA</td><td>ECDH</td><td>3DES</td><td>168</td><td>TLS_ECDH_anon_WITH_3DES_EDE_CBC_SHA</td></tr><tr><td>[0xc018]</td><td>AECDH-AES128-SHA</td><td>ECDH</td><td>AES</td><td>128</td><td>TLS_ECDH_anon_WITH_AES_128_CBC_SHA</td></tr><tr><td>[0xc019]</td><td>AECDH-AES256-SHA</td><td>ECDH</td><td>AES</td><td>256</td><td>TLS_ECDH_anon_WITH_AES_256_CBC_SHA</td></tr><tr><td>[0xc01a]</td><td>SRP-3DES-EDE-CBC-SHA</td><td>SRP</td><td>3DES</td><td>168</td><td>TLS_SRP_SHA_WITH_3DES_EDE_CBC_SHA</td></tr><tr><td>[0xc01b]</td><td>SRP-RSA-3DES-EDE-CBC-SHA</td><td>SRP</td><td>3DES</td><td>168</td><td>TLS_SRP_SHA_RSA_WITH_3DES_EDE_CBC_SHA</td></tr><tr><td>[0xc01c]</td><td>SRP-DSS-3DES-EDE-CBC-SHA</td><td>SRP</td><td>3DES</td><td>168</td><td>TLS_SRP_SHA_DSS_WITH_3DES_EDE_CBC_SHA</td></tr><tr><td>[0xc01d]</td><td>SRP-AES-128-CBC-SHA</td><td>SRP</td><td>AES</td><td>128</td><td>TLS_SRP_SHA_WITH_AES_128_CBC_SHA</td></tr><tr><td>[0xc01e]</td><td>SRP-RSA-AES-128-CBC-SHA</td><td>SRP</td><td>AES</td><td>128</td><td>TLS_SRP_SHA_RSA_WITH_AES_128_CBC_SHA</td></tr><tr><td>[0xc01f]</td><td>SRP-DSS-AES-128-CBC-SHA</td><td>SRP</td><td>AES</td><td>128</td><td>TLS_SRP_SHA_DSS_WITH_AES_128_CBC_SHA</td></tr><tr><td>[0xc020]</td><td>SRP-AES-256-CBC-SHA</td><td>SRP</td><td>AES</td><td>256</td><td>TLS_SRP_SHA_WITH_AES_256_CBC_SHA</td></tr><tr><td>[0xc021]</td><td>SRP-RSA-AES-256-CBC-SHA</td><td>SRP</td><td>AES</td><td>256</td><td>TLS_SRP_SHA_RSA_WITH_AES_256_CBC_SHA</td></tr><tr><td>[0xc022]</td><td>SRP-DSS-AES-256-CBC-SHA</td><td>SRP</td><td>AES</td><td>256</td><td>TLS_SRP_SHA_DSS_WITH_AES_256_CBC_SHA</td></tr><tr><td>[0xc023]</td><td>ECDHE-ECDSA-AES128-SHA256</td><td>ECDH</td><td>AES</td><td>128</td><td>TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256</td></tr><tr><td>[0xc024]</td><td>ECDHE-ECDSA-AES256-SHA384</td><td>ECDH</td><td>AES</td><td>256</td><td>TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA384</td></tr><tr><td>[0xc025]</td><td>ECDH-ECDSA-AES128-SHA256</td><td>ECDH/ECDSA</td><td>AES</td><td>128</td><td>TLS_ECDH_ECDSA_WITH_AES_128_CBC_SHA256</td></tr><tr><td>[0xc026]</td><td>ECDH-ECDSA-AES256-SHA384</td><td>ECDH/ECDSA</td><td>AES</td><td>256</td><td>TLS_ECDH_ECDSA_WITH_AES_256_CBC_SHA384</td></tr><tr><td>[0xc027]</td><td>ECDHE-RSA-AES128-SHA256</td><td>ECDH</td><td>AES</td><td>128</td><td>TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256</td></tr><tr><td>[0xc028]</td><td>ECDHE-RSA-AES256-SHA384</td><td>ECDH</td><td>AES</td><td>256</td><td>TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA384</td></tr><tr><td>[0xc029]</td><td>ECDH-RSA-AES128-SHA256</td><td>ECDH/RSA</td><td>AES</td><td>128</td><td>TLS_ECDH_RSA_WITH_AES_128_CBC_SHA256</td></tr><tr><td>[0xc02a]</td><td>ECDH-RSA-AES256-SHA384</td><td>ECDH/RSA</td><td>AES</td><td>256</td><td>TLS_ECDH_RSA_WITH_AES_256_CBC_SHA384</td></tr><tr><td>[0xc02b]</td><td>ECDHE-ECDSA-AES128-GCM-SHA256</td><td>ECDH</td><td>AESGCM</td><td>128</td><td>TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256</td></tr><tr><td>[0xc02c]</td><td>ECDHE-ECDSA-AES256-GCM-SHA384</td><td>ECDH</td><td>AESGCM</td><td>256</td><td>TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384</td></tr><tr><td>[0xc02d]</td><td>ECDH-ECDSA-AES128-GCM-SHA256</td><td>ECDH/ECDSA</td><td>AESGCM</td><td>128</td><td>TLS_ECDH_ECDSA_WITH_AES_128_GCM_SHA256</td></tr><tr><td>[0xc02e]</td><td>ECDH-ECDSA-AES256-GCM-SHA384</td><td>ECDH/ECDSA</td><td>AESGCM</td><td>256</td><td>TLS_ECDH_ECDSA_WITH_AES_256_GCM_SHA384</td></tr><tr><td>[0xc02f]</td><td>ECDHE-RSA-AES128-GCM-SHA256</td><td>ECDH</td><td>AESGCM</td><td>128</td><td>TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256</td></tr><tr><td>[0xc030]</td><td>ECDHE-RSA-AES256-GCM-SHA384</td><td>ECDH</td><td>AESGCM</td><td>256</td><td>TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384</td></tr><tr><td>[0xc031]</td><td>ECDH-RSA-AES128-GCM-SHA256</td><td>ECDH/RSA</td><td>AESGCM</td><td>128</td><td>TLS_ECDH_RSA_WITH_AES_128_GCM_SHA256</td></tr><tr><td>[0xc032]</td><td>ECDH-RSA-AES256-GCM-SHA384</td><td>ECDH/RSA</td><td>AESGCM</td><td>256</td><td>TLS_ECDH_RSA_WITH_AES_256_GCM_SHA384</td></tr><tr><td>[0xc033]</td><td>ECDHE-PSK-RC4-SHA</td><td>PSK/ECDHE</td><td>RC4</td><td>128</td><td>TLS_ECDHE_PSK_WITH_RC4_128_SHA</td></tr><tr><td>[0xc034]</td><td>ECDHE-PSK-3DES-EDE-CBC-SHA</td><td>PSK/ECDHE</td><td>3DES</td><td>168</td><td>TLS_ECDHE_PSK_WITH_3DES_EDE_CBC_SHA</td></tr><tr><td>[0xc035]</td><td>ECDHE-PSK-AES128-CBC-SHA</td><td>PSK/ECDHE</td><td>AES</td><td>128</td><td>TLS_ECDHE_PSK_WITH_AES_128_CBC_SHA</td></tr><tr><td>[0xc036]</td><td>ECDHE-PSK-AES256-CBC-SHA</td><td>PSK/ECDHE</td><td>AES</td><td>256</td><td>TLS_ECDHE_PSK_WITH_AES_256_CBC_SHA</td></tr><tr><td>[0xc037]</td><td>ECDHE-PSK-AES128-CBC-SHA256</td><td>PSK/ECDHE</td><td>AES</td><td>128</td><td>TLS_ECDHE_PSK_WITH_AES_128_CBC_SHA256</td></tr><tr><td>[0xc038]</td><td>ECDHE-PSK-AES256-CBC-SHA384</td><td>PSK/ECDHE</td><td>AES</td><td>256</td><td>TLS_ECDHE_PSK_WITH_AES_256_CBC_SHA384</td></tr><tr><td>[0xc039]</td><td>ECDHE-PSK-NULL-SHA</td><td>PSK/ECDHE</td><td>Null</td><td>0</td><td>TLS_ECDHE_PSK_WITH_NULL_SHA</td></tr><tr><td>[0xc03A]</td><td>ECDHE-PSK-NULL-SHA256</td><td>PSK/ECDHE</td><td>Null</td><td>0</td><td>TLS_ECDHE_PSK_WITH_NULL_SHA256</td></tr><tr><td>[0xc03B]</td><td>ECDHE-PSK-NULL-SHA384</td><td>PSK/ECDHE</td><td>Null</td><td>0</td><td>TLS_ECDHE_PSK_WITH_NULL_SHA384</td></tr><tr><td>[0xc03C]</td><td></td><td></td><td></td><td></td><td>TLS_RSA_WITH_ARIA_128_CBC_SHA256</td></tr><tr><td>[0xc03D]</td><td></td><td></td><td></td><td></td><td>TLS_RSA_WITH_ARIA_256_CBC_SHA384</td></tr><tr><td>[0xc03E]</td><td></td><td></td><td></td><td></td><td>TLS_DH_DSS_WITH_ARIA_128_CBC_SHA256</td></tr><tr><td>[0xc03F]</td><td></td><td></td><td></td><td></td><td>TLS_DH_DSS_WITH_ARIA_256_CBC_SHA384</td></tr><tr><td>[0xc040]</td><td></td><td></td><td></td><td></td><td>TLS_DH_RSA_WITH_ARIA_128_CBC_SHA256</td></tr><tr><td>[0xc041]</td><td></td><td></td><td></td><td></td><td>TLS_DH_RSA_WITH_ARIA_256_CBC_SHA384</td></tr><tr><td>[0xc042]</td><td></td><td></td><td></td><td></td><td>TLS_DHE_DSS_WITH_ARIA_128_CBC_SHA256</td></tr><tr><td>[0xc043]</td><td></td><td></td><td></td><td></td><td>TLS_DHE_DSS_WITH_ARIA_256_CBC_SHA384</td></tr><tr><td>[0xc044]</td><td></td><td></td><td></td><td></td><td>TLS_DHE_RSA_WITH_ARIA_128_CBC_SHA256</td></tr><tr><td>[0xc045]</td><td></td><td></td><td></td><td></td><td>TLS_DHE_RSA_WITH_ARIA_256_CBC_SHA384</td></tr><tr><td>[0xc046]</td><td></td><td></td><td></td><td></td><td>TLS_DH_anon_WITH_ARIA_128_CBC_SHA256</td></tr><tr><td>[0xc047]</td><td></td><td></td><td></td><td></td><td>TLS_DH_anon_WITH_ARIA_256_CBC_SHA384</td></tr><tr><td>[0xc048]</td><td></td><td></td><td></td><td></td><td>TLS_ECDHE_ECDSA_WITH_ARIA_128_CBC_SHA256</td></tr><tr><td>[0xc049]</td><td></td><td></td><td></td><td></td><td>TLS_ECDHE_ECDSA_WITH_ARIA_256_CBC_SHA384</td></tr><tr><td>[0xc04A]</td><td></td><td></td><td></td><td></td><td>TLS_ECDH_ECDSA_WITH_ARIA_128_CBC_SHA256</td></tr><tr><td>[0xc04B]</td><td></td><td></td><td></td><td></td><td>TLS_ECDH_ECDSA_WITH_ARIA_256_CBC_SHA384</td></tr><tr><td>[0xc04C]</td><td></td><td></td><td></td><td></td><td>TLS_ECDHE_RSA_WITH_ARIA_128_CBC_SHA256</td></tr><tr><td>[0xc04D]</td><td></td><td></td><td></td><td></td><td>TLS_ECDHE_RSA_WITH_ARIA_256_CBC_SHA384</td></tr><tr><td>[0xc04E]</td><td></td><td></td><td></td><td></td><td>TLS_ECDH_RSA_WITH_ARIA_128_CBC_SHA256</td></tr><tr><td>[0xc04F]</td><td></td><td></td><td></td><td></td><td>TLS_ECDH_RSA_WITH_ARIA_256_CBC_SHA384</td></tr><tr><td>[0xc050]</td><td></td><td></td><td></td><td></td><td>TLS_RSA_WITH_ARIA_128_GCM_SHA256</td></tr><tr><td>[0xc051]</td><td></td><td></td><td></td><td></td><td>TLS_RSA_WITH_ARIA_256_GCM_SHA384</td></tr><tr><td>[0xc052]</td><td></td><td></td><td></td><td></td><td>TLS_DHE_RSA_WITH_ARIA_128_GCM_SHA256</td></tr><tr><td>[0xc053]</td><td></td><td></td><td></td><td></td><td>TLS_DHE_RSA_WITH_ARIA_256_GCM_SHA384</td></tr><tr><td>[0xc054]</td><td></td><td></td><td></td><td></td><td>TLS_DH_RSA_WITH_ARIA_128_GCM_SHA256</td></tr><tr><td>[0xc055]</td><td></td><td></td><td></td><td></td><td>TLS_DH_RSA_WITH_ARIA_256_GCM_SHA384</td></tr><tr><td>[0xc056]</td><td></td><td></td><td></td><td></td><td>TLS_DHE_DSS_WITH_ARIA_128_GCM_SHA256</td></tr><tr><td>[0xc057]</td><td></td><td></td><td></td><td></td><td>TLS_DHE_DSS_WITH_ARIA_256_GCM_SHA384</td></tr><tr><td>[0xc058]</td><td></td><td></td><td></td><td></td><td>TLS_DH_DSS_WITH_ARIA_128_GCM_SHA256</td></tr><tr><td>[0xc059]</td><td></td><td></td><td></td><td></td><td>TLS_DH_DSS_WITH_ARIA_256_GCM_SHA384</td></tr><tr><td>[0xc05A]</td><td></td><td></td><td></td><td></td><td>TLS_DH_anon_WITH_ARIA_128_GCM_SHA256</td></tr><tr><td>[0xc05B]</td><td></td><td></td><td></td><td></td><td>TLS_DH_anon_WITH_ARIA_256_GCM_SHA384</td></tr><tr><td>[0xc05C]</td><td></td><td></td><td></td><td></td><td>TLS_ECDHE_ECDSA_WITH_ARIA_128_GCM_SHA256</td></tr><tr><td>[0xc05D]</td><td></td><td></td><td></td><td></td><td>TLS_ECDHE_ECDSA_WITH_ARIA_256_GCM_SHA384</td></tr><tr><td>[0xc05E]</td><td></td><td></td><td></td><td></td><td>TLS_ECDH_ECDSA_WITH_ARIA_128_GCM_SHA256</td></tr><tr><td>[0xc05F]</td><td></td><td></td><td></td><td></td><td>TLS_ECDH_ECDSA_WITH_ARIA_256_GCM_SHA384</td></tr><tr><td>[0xc060]</td><td></td><td></td><td></td><td></td><td>TLS_ECDHE_RSA_WITH_ARIA_128_GCM_SHA256</td></tr><tr><td>[0xc061]</td><td></td><td></td><td></td><td></td><td>TLS_ECDHE_RSA_WITH_ARIA_256_GCM_SHA384</td></tr><tr><td>[0xc062]</td><td></td><td></td><td></td><td></td><td>TLS_ECDH_RSA_WITH_ARIA_128_GCM_SHA256</td></tr><tr><td>[0xc063]</td><td></td><td></td><td></td><td></td><td>TLS_ECDH_RSA_WITH_ARIA_256_GCM_SHA384</td></tr><tr><td>[0xc064]</td><td></td><td></td><td></td><td></td><td>TLS_PSK_WITH_ARIA_128_CBC_SHA256</td></tr><tr><td>[0xc065]</td><td></td><td></td><td></td><td></td><td>TLS_PSK_WITH_ARIA_256_CBC_SHA384</td></tr><tr><td>[0xc066]</td><td></td><td></td><td></td><td></td><td>TLS_DHE_PSK_WITH_ARIA_128_CBC_SHA256</td></tr><tr><td>[0xc067]</td><td></td><td></td><td></td><td></td><td>TLS_DHE_PSK_WITH_ARIA_256_CBC_SHA384</td></tr><tr><td>[0xc068]</td><td></td><td></td><td></td><td></td><td>TLS_RSA_PSK_WITH_ARIA_128_CBC_SHA256</td></tr><tr><td>[0xc069]</td><td></td><td></td><td></td><td></td><td>TLS_RSA_PSK_WITH_ARIA_256_CBC_SHA384</td></tr><tr><td>[0xc06A]</td><td></td><td></td><td></td><td></td><td>TLS_PSK_WITH_ARIA_128_GCM_SHA256</td></tr><tr><td>[0xc06B]</td><td></td><td></td><td></td><td></td><td>TLS_PSK_WITH_ARIA_256_GCM_SHA384</td></tr><tr><td>[0xc06C]</td><td></td><td></td><td></td><td></td><td>TLS_DHE_PSK_WITH_ARIA_128_GCM_SHA256</td></tr><tr><td>[0xc06D]</td><td></td><td></td><td></td><td></td><td>TLS_DHE_PSK_WITH_ARIA_256_GCM_SHA384</td></tr><tr><td>[0xc06E]</td><td></td><td></td><td></td><td></td><td>TLS_RSA_PSK_WITH_ARIA_128_GCM_SHA256</td></tr><tr><td>[0xc06F]</td><td></td><td></td><td></td><td></td><td>TLS_RSA_PSK_WITH_ARIA_256_GCM_SHA384</td></tr><tr><td>[0xc070]</td><td></td><td></td><td></td><td></td><td>TLS_ECDHE_PSK_WITH_ARIA_128_CBC_SHA256</td></tr><tr><td>[0xc071]</td><td></td><td></td><td></td><td></td><td>TLS_ECDHE_PSK_WITH_ARIA_256_CBC_SHA384</td></tr><tr><td>[0xc072]</td><td>ECDHE-ECDSA-CAMELLIA128-SHA256</td><td>ECDH</td><td>Camellia</td><td>128</td><td>TLS_ECDHE_ECDSA_WITH_CAMELLIA_128_CBC_SHA256</td></tr><tr><td>[0xc073]</td><td>ECDHE-ECDSA-CAMELLIA256-SHA38</td><td>ECDH</td><td>Camellia</td><td>256</td><td>TLS_ECDHE_ECDSA_WITH_CAMELLIA_256_CBC_SHA384</td></tr><tr><td>[0xc074]</td><td>ECDH-ECDSA-CAMELLIA128-SHA256</td><td>ECDH/ECDSA</td><td>Camellia</td><td>128</td><td>TLS_ECDH_ECDSA_WITH_CAMELLIA_128_CBC_SHA256</td></tr><tr><td>[0xc075]</td><td>ECDH-ECDSA-CAMELLIA256-SHA384</td><td>ECDH/ECDSA</td><td>Camellia</td><td>256</td><td>TLS_ECDH_ECDSA_WITH_CAMELLIA_256_CBC_SHA384</td></tr><tr><td>[0xc076]</td><td>ECDHE-RSA-CAMELLIA128-SHA256</td><td>ECDH</td><td>Camellia</td><td>128</td><td>TLS_ECDHE_RSA_WITH_CAMELLIA_128_CBC_SHA256</td></tr><tr><td>[0xc077]</td><td>ECDHE-RSA-CAMELLIA256-SHA384</td><td>ECDH</td><td>Camellia</td><td>256</td><td>TLS_ECDHE_RSA_WITH_CAMELLIA_256_CBC_SHA384</td></tr><tr><td>[0xc078]</td><td>ECDH-RSA-CAMELLIA128-SHA256</td><td>ECDH/RSA</td><td>Camellia</td><td>128</td><td>TLS_ECDH_RSA_WITH_CAMELLIA_128_CBC_SHA256</td></tr><tr><td>[0xc079]</td><td>ECDH-RSA-CAMELLIA256-SHA384</td><td>ECDH/RSA</td><td>Camellia</td><td>256</td><td>TLS_ECDH_RSA_WITH_CAMELLIA_256_CBC_SHA384</td></tr><tr><td>[0xc07A]</td><td></td><td></td><td></td><td></td><td>TLS_RSA_WITH_CAMELLIA_128_GCM_SHA256</td></tr><tr><td>[0xc07B]</td><td></td><td></td><td></td><td></td><td>TLS_RSA_WITH_CAMELLIA_256_GCM_SHA384</td></tr><tr><td>[0xc07C]</td><td></td><td></td><td></td><td></td><td>TLS_DHE_RSA_WITH_CAMELLIA_128_GCM_SHA256</td></tr><tr><td>[0xc07D]</td><td></td><td></td><td></td><td></td><td>TLS_DHE_RSA_WITH_CAMELLIA_256_GCM_SHA384</td></tr><tr><td>[0xc07E]</td><td></td><td></td><td></td><td></td><td>TLS_DH_RSA_WITH_CAMELLIA_128_GCM_SHA256</td></tr><tr><td>[0xc07F]</td><td></td><td></td><td></td><td></td><td>TLS_DH_RSA_WITH_CAMELLIA_256_GCM_SHA384</td></tr><tr><td>[0xc080]</td><td></td><td></td><td></td><td></td><td>TLS_DHE_DSS_WITH_CAMELLIA_128_GCM_SHA256</td></tr><tr><td>[0xc081]</td><td></td><td></td><td></td><td></td><td>TLS_DHE_DSS_WITH_CAMELLIA_256_GCM_SHA384</td></tr><tr><td>[0xc082]</td><td></td><td></td><td></td><td></td><td>TLS_DH_DSS_WITH_CAMELLIA_128_GCM_SHA256</td></tr><tr><td>[0xc083]</td><td></td><td></td><td></td><td></td><td>TLS_DH_DSS_WITH_CAMELLIA_256_GCM_SHA384</td></tr><tr><td>[0xc084]</td><td></td><td></td><td></td><td></td><td>TLS_DH_anon_WITH_CAMELLIA_128_GCM_SHA256</td></tr><tr><td>[0xc085]</td><td></td><td></td><td></td><td></td><td>TLS_DH_anon_WITH_CAMELLIA_256_GCM_SHA384</td></tr><tr><td>[0xc086]</td><td></td><td></td><td></td><td></td><td>TLS_ECDHE_ECDSA_WITH_CAMELLIA_128_GCM_SHA256</td></tr><tr><td>[0xc087]</td><td></td><td></td><td></td><td></td><td>TLS_ECDHE_ECDSA_WITH_CAMELLIA_256_GCM_SHA384</td></tr><tr><td>[0xc088]</td><td></td><td></td><td></td><td></td><td>TLS_ECDH_ECDSA_WITH_CAMELLIA_128_GCM_SHA256</td></tr><tr><td>[0xc089]</td><td></td><td></td><td></td><td></td><td>TLS_ECDH_ECDSA_WITH_CAMELLIA_256_GCM_SHA384</td></tr><tr><td>[0xc08A]</td><td></td><td></td><td></td><td></td><td>TLS_ECDHE_RSA_WITH_CAMELLIA_128_GCM_SHA256</td></tr><tr><td>[0xc08B]</td><td></td><td></td><td></td><td></td><td>TLS_ECDHE_RSA_WITH_CAMELLIA_256_GCM_SHA384</td></tr><tr><td>[0xc08C]</td><td></td><td></td><td></td><td></td><td>TLS_ECDH_RSA_WITH_CAMELLIA_128_GCM_SHA256</td></tr><tr><td>[0xc08D]</td><td></td><td></td><td></td><td></td><td>TLS_ECDH_RSA_WITH_CAMELLIA_256_GCM_SHA384</td></tr><tr><td>[0xc08E]</td><td></td><td></td><td></td><td></td><td>TLS_PSK_WITH_CAMELLIA_128_GCM_SHA256</td></tr><tr><td>[0xc08F]</td><td></td><td></td><td></td><td></td><td>TLS_PSK_WITH_CAMELLIA_256_GCM_SHA384</td></tr><tr><td>[0xc090]</td><td></td><td></td><td></td><td></td><td>TLS_DHE_PSK_WITH_CAMELLIA_128_GCM_SHA256</td></tr><tr><td>[0xc091]</td><td></td><td></td><td></td><td></td><td>TLS_DHE_PSK_WITH_CAMELLIA_256_GCM_SHA384</td></tr><tr><td>[0xc092]</td><td></td><td></td><td></td><td></td><td>TLS_RSA_PSK_WITH_CAMELLIA_128_GCM_SHA256</td></tr><tr><td>[0xc093]</td><td></td><td></td><td></td><td></td><td>TLS_RSA_PSK_WITH_CAMELLIA_256_GCM_SHA384</td></tr><tr><td>[0xc094]</td><td>PSK-CAMELLIA128-SHA256</td><td>PSK</td><td>CAMELLIA</td><td>128</td><td>TLS_PSK_WITH_CAMELLIA_128_CBC_SHA256</td></tr><tr><td>[0xc095]</td><td>PSK-CAMELLIA256-SHA384</td><td>PSK</td><td>CAMELLIA</td><td>256</td><td>TLS_PSK_WITH_CAMELLIA_256_CBC_SHA384</td></tr><tr><td>[0xc096]</td><td>DHE-PSK-CAMELLIA128-SHA256</td><td>PSK/DHE</td><td>CAMELLIA</td><td>128</td><td>TLS_DHE_PSK_WITH_CAMELLIA_128_CBC_SHA256</td></tr><tr><td>[0xc097]</td><td>DHE-PSK-CAMELLIA256-SHA384</td><td>PSK/DHE</td><td>CAMELLIA</td><td>256</td><td>TLS_DHE_PSK_WITH_CAMELLIA_256_CBC_SHA384</td></tr><tr><td>[0xc098]</td><td>RSA-PSK-CAMELLIA128-SHA256</td><td>PSK/RSA</td><td>CAMELLIA</td><td>128</td><td>TLS_RSA_PSK_WITH_CAMELLIA_128_CBC_SHA256</td></tr><tr><td>[0xc099]</td><td>RSA-PSK-CAMELLIA256-SHA384</td><td>PSK/RSA</td><td>CAMELLIA</td><td>256</td><td>TLS_RSA_PSK_WITH_CAMELLIA_256_CBC_SHA384</td></tr><tr><td>[0xc09A]</td><td>ECDHE-PSK-CAMELLIA128-SHA25</td><td>PSK/ECDHE</td><td>CAMELLIA</td><td>128</td><td>TLS_ECDHE_PSK_WITH_CAMELLIA_128_CBC_SHA256</td></tr><tr><td>[0xc09B]</td><td>ECDHE-PSK-CAMELLIA256-SHA38</td><td>PSK/ECDHE</td><td>CAMELLIA</td><td>256</td><td>TLS_ECDHE_PSK_WITH_CAMELLIA_256_CBC_SHA384</td></tr><tr><td>[0xc09c]</td><td>AES128-CCM</td><td>RSA</td><td>AESCCM</td><td>128</td><td>TLS_RSA_WITH_AES_128_CCM</td></tr><tr><td>[0xc09d]</td><td>AES256-CCM</td><td>RSA</td><td>AESCCM</td><td>256</td><td>TLS_RSA_WITH_AES_256_CCM</td></tr><tr><td>[0xc09e]</td><td>DHE-RSA-AES128-CCM</td><td>DH</td><td>AESCCM</td><td>128</td><td>TLS_DHE_RSA_WITH_AES_128_CCM</td></tr><tr><td>[0xc09f]</td><td>DHE-RSA-AES256-CCM</td><td>DH</td><td>AESCCM</td><td>256</td><td>TLS_DHE_RSA_WITH_AES_256_CCM</td></tr><tr><td>[0xc0a0]</td><td>AES128-CCM8</td><td>RSA</td><td>AESCCM8</td><td>128</td><td>TLS_RSA_WITH_AES_128_CCM_8</td></tr><tr><td>[0xc0a1]</td><td>AES256-CCM8</td><td>RSA</td><td>AESCCM8</td><td>256</td><td>TLS_RSA_WITH_AES_256_CCM_8</td></tr><tr><td>[0xc0a2]</td><td>DHE-RSA-AES128-CCM8</td><td>DH</td><td>AESCCM8</td><td>128</td><td>TLS_DHE_RSA_WITH_AES_128_CCM_8</td></tr><tr><td>[0xc0a3]</td><td>DHE-RSA-AES256-CCM8</td><td>DH</td><td>AESCCM8</td><td>256</td><td>TLS_DHE_RSA_WITH_AES_256_CCM_8</td></tr><tr><td>[0xc0a4]</td><td>PSK-AES128-CCM</td><td>PSK</td><td>AESCCM</td><td>128</td><td>TLS_PSK_WITH_AES_128_CCM</td></tr><tr><td>[0xc0a5]</td><td>PSK-AES256-CCM</td><td>PSK</td><td>AESCCM</td><td>256</td><td>TLS_PSK_WITH_AES_256_CCM</td></tr><tr><td>[0xc0a6]</td><td>DHE-PSK-AES128-CCM</td><td>PSK/DHE</td><td>AESCCM</td><td>128</td><td>TLS_DHE_PSK_WITH_AES_128_CCM</td></tr><tr><td>[0xc0a7]</td><td>DHE-PSK-AES256-CCM</td><td>PSK/DHE</td><td>AESCCM</td><td>256</td><td>TLS_DHE_PSK_WITH_AES_256_CCM</td></tr><tr><td>[0xc0a8]</td><td>PSK-AES128-CCM8</td><td>PSK</td><td>AESCCM</td><td>128</td><td>TLS_PSK_WITH_AES_128_CCM_8</td></tr><tr><td>[0xc0a9]</td><td>PSK-AES256-CCM8</td><td>PSK</td><td>AESCCM</td><td>256</td><td>TLS_PSK_WITH_AES_256_CCM_8</td></tr><tr><td>[0xc0aa]</td><td>DHE-PSK-AES128-CCM8</td><td>PSK/DHE</td><td>AESCCM</td><td>128</td><td>TLS_PSK_DHE_WITH_AES_128_CCM_8</td></tr><tr><td>[0xc0ab]</td><td>DHE-PSK-AES256-CCM8</td><td>PSK/DHE</td><td>AESCCM</td><td>256</td><td>TLS_PSK_DHE_WITH_AES_256_CCM_8</td></tr><tr><td>[0xc0ac]</td><td>ECDHE-ECDSA-AES128-CCM</td><td>ECDH</td><td>AESCCM</td><td>128</td><td>TLS_ECDHE_ECDSA_WITH_AES_128_CCM</td></tr><tr><td>[0xc0ad]</td><td>ECDHE-ECDSA-AES256-CCM</td><td>ECDH</td><td>AESCCM</td><td>256</td><td>TLS_ECDHE_ECDSA_WITH_AES_256_CCM</td></tr><tr><td>[0xc0ae]</td><td>ECDHE-ECDSA-AES128-CCM8</td><td>ECDH</td><td>AESCCM</td><td>128</td><td>TLS_ECDHE_ECDSA_WITH_AES_128_CCM_8</td></tr><tr><td>[0xc0af]</td><td>ECDHE-ECDSA-AES256-CCM8</td><td>ECDH</td><td>AESCCM</td><td>256</td><td>TLS_ECDHE_ECDSA_WITH_AES_256_CCM_8</td></tr><tr><td>[0xcc13]</td><td>ECDHE-RSA-CHACHA20-POLY1305-OLD</td><td>ECDH</td><td>ChaCha20-Poly1305</td><td></td><td>TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256_OLD</td></tr><tr><td>[0xcc14]</td><td>ECDHE-ECDSA-CHACHA20-POLY1305-OLD</td><td>ECDH</td><td>ChaCha20-Poly1305</td><td></td><td>TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256_OLD</td></tr><tr><td>[0xcc15]</td><td>DHE-RSA-CHACHA20-POLY1305-OLD</td><td>DH</td><td>ChaCha20-Poly1305</td><td></td><td>TLS_DHE_RSA_WITH_CHACHA20_POLY1305_SHA256_OLD</td></tr><tr><td>[0xff00]</td><td>GOST-MD5</td><td>RSA</td><td>GOST89</td><td>256</td><td>TLS_GOSTR341094_RSA_WITH_28147_CNT_MD5</td></tr><tr><td>[0xff01]</td><td>GOST-GOST94</td><td>RSA</td><td>GOST89</td><td>256</td><td>TLS_RSA_WITH_28147_CNT_GOST94</td></tr><tr><td>[0xff02]</td><td>GOST-GOST89MAC</td><td>RSA</td><td>GOST89</td><td>256</td><td></td></tr><tr><td>[0xff03]</td><td>GOST-GOST89STREAM</td><td>RSA</td><td>GOST89</td><td>256</td><td></td></tr><tr><td>[0xfefe]</td><td></td><td>RSA</td><td>DES</td><td>56</td><td>SSL_RSA_FIPS_WITH_DES_CBC_SHA</td></tr><tr><td>[0xfeff]</td><td></td><td>RSA</td><td>3DES</td><td>168</td><td>SSL_RSA_FIPS_WITH_3DES_EDE_CBC_SHA</td></tr><tr><td>[0xfee0]</td><td></td><td>RSA</td><td>3DES</td><td>168</td><td>SSL_RSA_FIPS_WITH_3DES_EDE_CBC_SHA</td></tr><tr><td>[0xfee1]</td><td></td><td>RSA</td><td>DES</td><td>56</td><td>SSL_RSA_FIPS_WITH_DES_CBC_SHA</td></tr><tr><td>[0x010080]</td><td>RC4-MD5</td><td>RSA</td><td>RC4</td><td>128</td><td>SSL_CK_RC4_128_WITH_MD5</td></tr><tr><td>[0x020080]</td><td>EXP-RC4-MD5</td><td>RSA(512)</td><td>RC4</td><td>40, export</td><td>SSL_CK_RC4_128_EXPORT40_WITH_MD5</td></tr><tr><td>[0x030080]</td><td>RC2-CBC-MD5</td><td>RSA</td><td>RC2</td><td>128</td><td>SSL_CK_RC2_128_CBC_WITH_MD5</td></tr><tr><td>[0x040080]</td><td>EXP-RC2-CBC-MD5</td><td>RSA(512)</td><td>RC2</td><td>40, export</td><td>SSL_CK_RC2_128_CBC_EXPORT40_WITH_MD5</td></tr><tr><td>[0x050080]</td><td>IDEA-CBC-MD5</td><td>RSA</td><td>IDEA</td><td>128</td><td>SSL_CK_IDEA_128_CBC_WITH_MD5</td></tr><tr><td>[0x060040]</td><td>DES-CBC-MD5</td><td>RSA</td><td>DES</td><td>56</td><td>SSL_CK_DES_64_CBC_WITH_MD5</td></tr><tr><td>[0x060140]</td><td>DES-CBC-SHA</td><td>RSA</td><td>DES</td><td>56</td><td>SSL_CK_DES_64_CBC_WITH_SHA</td></tr><tr><td>[0x0700c0]</td><td>DES-CBC3-MD5</td><td>RSA</td><td>3DES</td><td>168</td><td>SSL_CK_DES_192_EDE3_CBC_WITH_MD5</td></tr><tr><td>[0x0701c0]</td><td>DES-CBC3-SHA</td><td>RSA</td><td>3DES</td><td>168</td><td>SSL_CK_DES_192_EDE3_CBC_WITH_SHA</td></tr><tr><td>[0x080080]</td><td>RC4-64-MD5</td><td>RSA</td><td>RC4</td><td>64</td><td>SSL_CK_RC4_64_WITH_MD5</td></tr><tr><td>[0xff0800]</td><td>DES-CFB-M1</td><td>RSA</td><td>DES</td><td>64</td><td>SSL_CK_DES_64_CFB64_WITH_MD5_1</td></tr><tr><td>[0xff0810]</td><td>NULL</td><td>None</td><td>Null</td><td>0</td><td>SSL_CK_NULL</td></tr></tbody></table>]]></content>
      
      <categories>
          
          <category> linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> openssl </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>nginx通过x_forwarded_for实现黑白名单访问策略</title>
      <link href="/nginx-deny-ip/"/>
      <url>/nginx-deny-ip/</url>
      <content type="html"><![CDATA[<p>nginx通过防护墙、F5设备过来之后，remote_addr 的地址是防护墙、F5的地址， 客户端真是的IP地址是在 x_forwarded_for中的， 这样这样 nginx 默认的 deny 和 allow 就不能用了。</p><p>我们需要在每个域名中判断一个 x_forwarded_for 钟是否有我们要拒绝的IP地址，如果有就返回403，不在往后代理。</p><p>我们定义一个map 拒绝的IP地址列表。</p><a id="more"></a><p>cat x_forwarded_for_deny.conf </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">map $http_x_forwarded_for $allowed &#123;</span><br><span class="line">    default allow;</span><br><span class="line">    #~\s*192.168.0.100$ deny;   # 拒绝一个IP地址</span><br><span class="line">    #~\s*192.168.0.\d+$ deny;    #  拒绝一个网段IP地址</span><br><span class="line">    include x_forwarded_for_deny_list/*.conf;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>include x_forwarded_for_deny_list/*.conf<br>这个目录下禁止IP地址的文件<br>如：</p><p>cat x_forwarded_for_deny_list/2019-07-08.conf </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">~\s*192.168.0.100$ deny;</span><br><span class="line">~\s*8.8.8.8$ deny;</span><br></pre></td></tr></table></figure><p>nginx 配置文件需要 include  x_forwarded_for_deny.conf </p><p>vim nginx.conf   添加</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">.......</span><br><span class="line">include x_forwarded_for_deny.conf;</span><br><span class="line">.......</span><br></pre></td></tr></table></figure><p>每个域名的location中需要添加判断<br>如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">server &#123;</span><br><span class="line">    listen       80;</span><br><span class="line">    server_name  ....;</span><br><span class="line">    location / &#123;</span><br><span class="line">        if ( $allowed = &quot;deny&quot; ) &#123; return 403; &#125;</span><br><span class="line">        proxy_pass    .....;</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这样就可以拒绝你设置好的IP地址访问， nginx access日志用会有拒绝的IP得知日志，放回状态是403</p>]]></content>
      
      <categories>
          
          <category> nginx </category>
          
      </categories>
      
      
        <tags>
            
            <tag> nginx </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>mesos master和slave的配置参数说明</title>
      <link href="/mesos-configure-arg/"/>
      <url>/mesos-configure-arg/</url>
      <content type="html"><![CDATA[<h2 id="Master-和-Slave-的配置选项（转）"><a href="#Master-和-Slave-的配置选项（转）" class="headerlink" title="Master 和 Slave 的配置选项（转）"></a>Master 和 Slave 的配置选项（转）</h2><p>可以通过运行 mesos-master –help 或者 mesos-slave –help 可以查看相关的可用选项。每个选项可以通过以下两种方式设置</p><ul><li>执行命令的时候使用 –-option_name=value 来传递配置选项。value 既可以是数值，也可以指定包含参数的文件 (–opthon_name=file://文件路径)。 该路径既可以是绝对路径，也可以是相对当前工作目录的相对路径。</li><li>通过设定环境变量 MESOSOPTION_NAME (变量名都以 MESOS 开头)<br>执行时会先读取环境变量，然后才看命令行参数</li></ul><a id="more"></a><h2 id="下列选项-都被-master-和-slave-所支持："><a href="#下列选项-都被-master-和-slave-所支持：" class="headerlink" title="下列选项 都被 master 和 slave 所支持："></a>下列选项 都被 master 和 slave 所支持：</h2><table><thead><tr><th></th><th>Flag</th><th>说明</th></tr></thead><tbody><tr><td></td><td>–advertise_ip=VALUE</td><td>用来触达 mesos master/slave 的 IP 广播地址。 Mesos master/slave 不会与这个 IP 地址绑定。 但是，这个 IP 地址可以被用来访问 Mesos master/slave.</td><td></td></tr><tr><td></td><td>–advertise_port=VALUE</td><td>用来触达 mesos master/slave 的广播端口 (配合 advertise_ip). Mesos master/slave 不与这个端口绑定。 但是，这个端口 (配合 advertise_ip) 可以用于访问 Mesos master/slave.</td><td></td></tr><tr><td></td><td>–firewall_rules=VALUE</td><td>该值是终端防火墙的规则（rules），可以为JSON 类型的 rules 或包含 JSON 类型 rules 的文件。文件路径可以为 file:///path/to/file 或者 /path/to/file。<br>规则的格式请参考文件 flags.proto 中的 Firewall 信息。<br>例如:<br>{<br>  “disabled_endpoints” : {<br>    “paths” : [<br>      “/files/browse”,<br>      “/metrics/snapshot”<br>    ]<br>  }<br>}<br></td><td></td></tr><tr><td></td><td>–[no-]help</td><td>输出帮助信息 (默认值: false)</td><td></td></tr><tr><td></td><td>–ip=VALUE</td><td>监听的 IP 地址. 这个不能与–ip_discovery_command一起使用. (master默认5050，slave默认5051)</td><td></td></tr><tr><td></td><td>–ip_discovery_command=VALUE</td><td>IP 发现可选项: 如果设置 IP 地址，master/slave 将会尝试绑定这个 IP 地址。 不能与 –ip 一起使用.</td><td></td></tr><tr><td></td><td>–port=VALUE</td><td>监听端口</td><td></td></tr><tr><td></td><td>–[no-]version</td><td>显示版本并退出 (默认: false)</td><td></td></tr><tr><td></td><td>–hooks=VALUE</td><td>一个由逗号分隔的 hook 模块列表将被安装到 master/slave。</td><td></td></tr><tr><td></td><td>–hostname=VALUE</td><td>slave 节点报告或 master 节点在 ZooKeeper 里广播的 hostname. 如果不做设置，hostname 将解析为 master/slave 绑定的 IP 地址。 除非用户已经使用 –no-hostname_lookup 明确禁止了此功能, in which case the IP itself is used.</td><td></td></tr><tr><td></td><td>–[no-]hostname_lookup</td><td>当没有明确指定 hostname 时(例如 –hostname)，是否查询找出服务器的 hostname。 默认值是 true; 如果设置为 false Mesos 将会使用 IP 地址信息，除非 hostname 被明确指出了。 (默认值: true)</td><td></td></tr><tr><td></td><td>–modules=VALUE</td><td>List of modules to be loaded and be available to the internal subsystems.<br>Use –modules=filepath to specify the list of modules via a file containing a JSON-formatted string. filepath can be of the form file:///path/to/file or /path/to/file.<br>Use –modules=”{…}” to specify the list of modules inline.<br>Example:<br>{<br>  “libraries”: [<br>    {<br>      “file”: “/path/to/libfoo.so”,<br>      “modules”: [<br>        {<br>          “name”: “org_apache_mesos_bar”,<br>          “parameters”: [<br>            {<br>              “key”: “X”,<br>              “value”: “Y”<br>            }<br>          ]<br>        },<br>        {<br>          “name”: “org_apache_mesos_baz”<br>        }<br>      ]<br>    },<br>    {<br>      “name”: “qux”,<br>      “modules”: [<br>        {<br>          “name”: “org_apache_mesos_norf”<br>        }<br>      ]<br>    }<br>  ]<br>}<br></td><td></td></tr></tbody></table><p>masters 和 slaves 同时支持以下这些日志选项 更多日志信息，请访问<br><a href="http://mesos.apache.org/documentation/latest/logging/" target="_blank" rel="noopener">http://mesos.apache.org/documentation/latest/logging/</a></p><table><thead><tr><th></th><th>Flag</th><th>说明</th></tr></thead><tbody><tr><td></td><td>–[no-]quiet</td><td>禁用输出日志到 sterr （默认:false）</td><td></td></tr><tr><td></td><td>–log_dir=VALUE</td><td>输出日志文件的位置。默认方式下，不生成日志文件。这个参数不影响输出到 stderr 的日志。 如果特别指定了，就可以通过 Mesos webUI 看到这个日志文件。 注意: 第三方日志信息 (比如，ZooKeeper) 将只能写入到 stderr!</td><td></td></tr><tr><td></td><td>–logbufsecs=VALUE</td><td>缓冲日志的时长（秒数）默认：0秒</td><td></td></tr><tr><td></td><td>–logging_level=VALUE</td><td>输出日志的起始级别，包括 INFO, WARNING, ERROR。如果使用了–quiet 标记，只会影响到输出到 –log_dir 的日志的级别（默认：INFO）</td><td></td></tr><tr><td></td><td>–[no-]initialize_driver_logging</td><td>master/slave 是否为 Mesos scheduler 和 executor driver 初始化 Google logging. scheduler/executor drivers 将分别记录日志，不会写入 master/slave 的日志中。<br>如果使用的是 HTTP scheduler/executor APIs，这个选项将无效。 （默认：true）</td><td></td></tr><tr><td></td><td>–external_log_file=VALUE</td><td>定位外部管理的日志文件位置。Mesos 不会直接写入这个文件，仅会通过 WebUI 和 HTTP API 将其 暴露出来。这个仅用于混合外部日志机制来记录日志到 stderr 的情况。比如，syslog 或 journald。<br>当通过 –quiet 指定后，这个选项将无效。<br>此选项在 WebUI 的优先级高于 –log_dir . 但即使这个选项被指定了，日志任然会被 写入到 –log_dir。</td><td></td></tr></tbody></table><h3 id="Master-配置选项"><a href="#Master-配置选项" class="headerlink" title="Master 配置选项"></a>Master 配置选项</h3><p>必选参数</p><table><thead><tr><th></th><th>Flag</th><th>说明</th></tr></thead><tbody><tr><td></td><td>–quorum=VALUE</td><td>使用基于 replicated-Log 的注册表时，复制的个数。 此值需要设置为masters总数量的一半以上，也就是：quorum &gt; (number of masters)/2。 注意：单机模式下不需要设置此参数。（非HA模式）</td><td></td></tr><tr><td></td><td>–work_dir=VALUE</td><td>Registry 中持久化信息存储的位置。（如：/var/lib/mesos/master）</td><td></td></tr><tr><td></td><td>–zk=VALUE</td><td>ZooKeeper 的 URL地址 （用于在masters中做领导选举）可能是下面所列形式中的一种：<br><br>zk://host1:port1,host2:port2,…/path<br>zk://username:password@host1:port1,host2:port2,…/path<br>file:///path/to/file (where file contains one of the above)<br><br>注意: 单机模式下不需要设置此参数。（非HA模式）.</td></tr></tbody></table><p>可选参数</p><table><thead><tr><th></th><th>Flag</th><th>说明</th></tr></thead><tbody><tr><td></td><td>–acls=VALUE</td><td>此参数用于认证。一般是 JSON 格式的 ACLs 的字符串或者文件。 路径一般是这样的格式：file:///path/to/file 或 /path/to/file<br>注意：如果参数 –authorizers 的值与 local 的不相同，ACLs 的内容将被忽略。<br>在 authorizer.proto 中查看 ACLs protobuf 参考格式。<br>举例:<br>{<br>  “register_frameworks”: [<br>    {<br>      “principals”: { “type”: “ANY” },<br>      “roles”: { “values”: [“a”] }<br>    }<br>  ],<br>  “run_tasks”: [<br>    {<br>      “principals”: { “values”: [“a”, “b”] },<br>      “users”: { “values”: [“c”] }<br>    }<br>  ],<br>  “teardown_frameworks”: [<br>    {<br>      “principals”: { “values”: [“a”, “b”] },<br>      “framework_principals”: { “values”: [“c”] }<br>    }<br>  ],<br>  “set_quotas”: [<br>    {<br>      “principals”: { “values”: [“a”] },<br>      “roles”: { “values”: [“a”, “b”] }<br>    }<br>  ],<br>  “remove_quotas”: [<br>    {<br>      “principals”: { “values”: [“a”] },<br>      “quota_principals”: { “values”: [“a”] }<br>    }<br>  ]<br>}<br></td><td></td></tr><tr><td></td><td>–allocation_interval=VALUE</td><td>（批次）执行分配（allocations）的间隔时间。（如：500ms,1秒……） 默认值：1秒</td><td></td></tr><tr><td></td><td>–allocator=VALUE</td><td>分配器，用于给框架分配资源。默认使用 HierarchicalDRF 分配器，也可以通过 –modules 模块来选择其他的分配器。 （默认值：HierarchicalDRF）</td><td></td></tr><tr><td></td><td>–[no-]authenticate</td><td>如果是 true，则只有认证过的框架可以注册。 如果是 false，则未认证的框架也可以注册。（默认：false）</td><td></td></tr><tr><td></td><td>–[no-]authenticate_http</td><td>如果是 true，则只有支持认证机制的已认证的 HTTP endpoints 请求被允许访问。 如果是 false，则未认证的 HTTP endpoint 请求也会被允许访问。 （默认：false）</td><td></td></tr><tr><td></td><td>–[no-]authenticate_slaves</td><td>如果是 true，只有认证过的 slaves 才能注册。 如果是 false，未认证的 slaves 也可以注册。 （默认：false）</td><td></td></tr><tr><td></td><td>–authenticators=VALUE</td><td>框架或 slave 进行认证时使用的认证器。默认是 crammd5，也可以通过使用 –modules 更换其他认证模块。 （默认：crammd5）</td><td></td></tr><tr><td></td><td>–authorizers=VALUE</td><td>用于进行授权的 Authorizer。默认使用 local,也可以通过使用 –modules 替换成其他的 authorizer。<br>注意：如果参数 –authorizers 提供了一个与 local 不一样的值。 则通过–acls 设置的 ACLs 参数将被忽略。<br>目前并不支持多个 authorizers. （默认：local）</td><td></td></tr><tr><td></td><td>–cluster=VALUE</td><td>集群别名，会在 WebUI上显示。</td><td></td></tr><tr><td></td><td>–credentials=VALUE</td><td>一个存取凭证的路径。这个路径可以指向一个内容为凭证列表的文本文件，在这个文件中每一行包括由空格隔开的principal和secret。也可以指向一个包含凭证信息的 JSON 格式文件。 路径的格式可以是：file:///path/to/file 或 /path/to/file JSON 文件举例:<br>{<br>  “credentials”: [<br>    {<br>      “principal”: “sherman”,<br>      “secret”: “kitesurf”<br>    }<br>  ]<br>}<br>文本文件举例:<br><br>username secret<br></td><td></td></tr><tr><td></td><td>–framework_sorter=VALUE</td><td>给定 framework 之间的资源分配策略。选项与 user_allocator 相同。 （默认：drf）</td><td></td></tr><tr><td></td><td>–http_authenticators=VALUE</td><td>HTTP 认证器用于处理已验证的 endpoints 的请求。默认值是 basic，或者通过 –modules 加载一个其他的 HTTP 认证器。</td></tr><tr><td>目前不支持多种 HTTP 认证器。（默认：basic）</td><td></td></tr><tr><td></td><td>–[no-]log_auto_initialize</td><td>是否自动初始化注册使用的 <em>replicated log</em> 。如果设置为否，日志将在每次使用时手动初始化。 （默认值：true）</td><td></td></tr><tr><td></td><td>–max_completed_frameworks=VALUE</td><td>存储在内存中的完成框架的最大数量。（默认：50）</td><td></td></tr><tr><td></td><td>–max_completed_tasks_per_framework =VALUE</td><td>存储在内存的每个框架中已完成任务的最大数量。（默认：1000）</td><td></td></tr><tr><td></td><td>–max_slave_ping_timeouts=VALUE</td><td>一个 slave 对于master的 ping 响应失败的最大次数。 如果 slaves 没有在 max_slave_ping_timeouts 之内响应，就会尝试关机。 （默认：5）</td><td></td></tr><tr><td></td><td>–offer_timeout=VALUE</td><td>一个 offer 撤销的超时时间。 这可以让不同的 frameworks 提供的 offer 获得更公平的响应。 如果不设置， offers 没有超时限制。</td><td></td></tr><tr><td></td><td>–rate_limits=VALUE</td><td>该值可以为一个 JSON 格式的速率限制或一个文件路径包含了被 framework 限速 所使用的 JSON 格式的速率限制。请记住你也可以是使用 file:///path/to/file 或 /path/to/file 参数值格式来将该 JSON 写入至一个文件。<br>期望的格式请参考 mesos.proto 中的 RateLimits protobuf.<br>Example:<br>{<br>  “limits”: [<br>    {<br>      “principal”: “foo”,<br>      “qps”: 55.5<br>    },<br>    {<br>      “principal”: “bar”<br>    }<br>  ],<br>  “aggregate_default_qps”: 33.3<br>}<br></td></tr><tr><td></td><td>–recovery_slave_removal_limit=VALUE</td><td>针对故障转移，限制上的百分比的 slaves 可以从注册中移除并关机在重新注册的超时时间到了之后。 如果该限制被突破， master 将实行故障转移而不是移除 slaves. 这可被用来针对生产环境提供安全保障。生产环境可能期望在 Master 故障转移过程中， 最多一定百分比的 slaves 将永久性的挂掉 (比如, 由于 rack-level 的故障)。 设定该限制可以保证一个人需要参与进来当在该集群中一个非预期的大范围的 slave 故障发生。值: [0%-100%] (默认: 100%)</td><td></td></tr><tr><td></td><td>–registry=VALUE</td><td>注册表持久化策略。可用选项有 replicated_log,in_memory（用于测试）。 默认：replicated_log。</td><td></td></tr><tr><td></td><td>–registry_fetch_timeout=VALUE</td><td>在操作被认为是一个失败后的为了从注册中提取数据的等待的时间间隔.(默认： 1mins)</td><td></td></tr><tr><td></td><td>–registry_store_timeout=VALUE</td><td>等待的时间周期为了当操作被认为一个失败的时候将数据存储入注册机。 (默认：20secs)</td><td></td></tr><tr><td></td><td>–[no-]registry_strict</td><td>无论 Master 是否将基于注册机中存储的持久信息来采取行动。设定改值为 false 意味着注册员将永远拒绝入列，出列和一个 slave 的移除。所以， false 可以用来在一个运行的集群上来引导持久化的状态。注意： 该标志位是 <em>experimental</em> 而且还不能在应用中使用.(默认: false)</td><td></td></tr><tr><td></td><td>–roles=VALUE</td><td>其 frameworks 在这个集群中可能归属于的用逗号分离的一系列指派的角色。</td><td></td></tr><tr><td></td><td>–[no-]root_submissions</td><td>root 是否可以提交 frameworks? (默认: true)</td><td></td></tr><tr><td></td><td>–slave_ping_timeout=VALUE</td><td>在每个 slave 被期望从一个 master 回应一个 ping 值的超时时间。 Slaves 如果不是在 max_slave_ping_timeouts 回复，ping 从新尝试将被移除. (默认: 15secs)</td><td></td></tr><tr><td></td><td>–slave_removal_rate_limit=VALUE</td><td>最大的比例(e.g., 1/10mins, 2/3hrs, etc) 对于那个 slaves 将被从 master 中移除当他们遇到健康检测失败。默认的是 slave 将尽可能快的被移除当它们遇到健康监测失败。值为 (Number of slaves)/(Duration) 的模式。</td><td></td></tr><tr><td></td><td>–slave_reregister_timeout=VALUE</td><td>在所有的 slaves 被期望重新注册当一个新的 master 被选举为 leader 的超时时间。 Slaves 其不会在此超时时间内被重新注册将被从注册中移除并将被关掉如果它们尝试去与 master 通信。 注意： 该值将被设置为最少 10mins. (默认: 10mins)</td><td></td></tr><tr><td></td><td>–user_sorter=VALUE</td><td>被用来在用户中分配资源的策略。可以为以下之一：dominant_resource_fairness (drf) (default: drf)</td><td></td></tr><tr><td></td><td>–webui_dir=VALUE</td><td>管理页面的网页文件的目录，默认：/usr/local/share/mesos/webui</td><td></td></tr><tr><td></td><td>–weights=VALUE</td><td>逗号分割的角色/权重列表，成对表单 role=weight,role=weight。 weights是用来表达优先级。</td><td></td></tr><tr><td></td><td>–whitelist=VALUE</td><td>一个 文件名器包含一系列的 slaves （每行一个）来通告 offers.该文件被观测，并周期性的重读取来刷新 slave 白名单。 默认的这里没有白名单/所有机器被接收. (默认: None) 文件路径可以是这样的形式： file:///path/to/file 或 /path/to/file.</td><td></td></tr><tr><td></td><td>–zk_session_timeout=VALUE</td><td>zookeeper 的 session 超时时长。 (默认: 10secs)</td><td></td></tr></tbody></table><p>通过 –with-network-isolator 配置时可用的标记</p><table><thead><tr><th></th><th>Flag</th><th>说明</th></tr></thead><tbody><tr><td></td><td>–max_executors_per_slave=VALUE</td><td>每个 Slave 上最大允许的执行器数量。网络监控和隔离机制强行限制每个执行器使用的端口资源，所以每个 slave 上只能跑一定数量的执行器。</td><td></td></tr></tbody></table><h3 id="Slave-选项"><a href="#Slave-选项" class="headerlink" title="Slave 选项"></a>Slave 选项</h3><p>必选项</p><table><thead><tr><th></th><th>Flag</th><th>说明</th></tr></thead><tbody><tr><td></td><td>–master=VALUE</td><td>可能是其中的一种： host:port <br>zk://host1:port1,host2:port2,…/path <br>zk://username:password@host1:port1,host2:port2,…/path <br>file:///path/to/file (包含以上中的一个)</td><td></td></tr></tbody></table><p>可选项</p><table><thead><tr><th></th><th>Flag</th><th>说明</th></tr></thead><tbody><tr><td></td><td>–appc_store_dir=VALUE</td><td>appc 提供者存储镜像的目录 (默认: /tmp/mesos/store/appc)</td><td></td></tr><tr><td></td><td>–attributes=VALUE</td><td>slave 机器的属性,格式为： rack:2 或者rack:2;u:1</td></tr><tr><td>–authenticatee=VALUE</td><td>用于主节点身份验证，默认crammd5，或者用-—modules加载备用模块。（默认：crammd5）</td><td></td></tr><tr><td></td><td>–[no]-cgroups_cpu_enable_pids_and_tids_count</td><td>Cgroups 的功能标记，可以统计容器内的进程和线程的数量。（默认：false）</td><td></td></tr><tr><td></td><td>–[no]-cgroups_enable_cfs</td><td>Cgroups 的功能标记，通过限制CFS带宽来限制CPU资源. (默认: defult)</td><td></td></tr><tr><td></td><td>–cgroups_hierarchy=VALUE</td><td>cgroups的根路径位置. 默认: /sys/fs/cgroup</td><td></td></tr><tr><td></td><td>–[no]-cgroups_limit_swap</td><td>Cgroups 的功能标记，可以对内存和swap进行限制，而不仅限制内存。（默认: false）</td><td></td></tr><tr><td></td><td>–cgroups_net_cls_primary_handle    一</td><td>个非零，16位的句柄。形式类似于：<code>0xAAAA</code>. 这将作为 net_cls cgroup 的主句柄来使用。</td><td></td></tr><tr><td></td><td>–cgroups_net_cls_secondary_handles</td><td>一系列的类似 0xAAAA,0xBBBB 形式的次要句柄，将与主句柄配合使用。只有在设置了 –cgroups_net_cls_primary_handle 之后，才会生效。</td><td></td></tr><tr><td></td><td>–cgroups_root=VALUE</td><td>根cgroup的命名. 默认: mesos</td><td></td></tr><tr><td></td><td>–container_disk_watch_interval=VALUE</td><td>用于查询容器中磁盘配额的时间间隔. 被用于posix/disk的时间间隔, 默认: 15秒</td><td></td></tr><tr><td></td><td>–container_logger=VALUE</td><td>容器日志记录器的名称，日志记录器用来记录容器（如：执行器，任务）的标准输出和错误日志。 默认的日志记录器将会写入到沙盒目录中的 stdout 和 stderr。</td><td></td></tr><tr><td></td><td>–containerizer_path=VALUE</td><td>当外部隔离机制被激活时(–isolation=external), 外部容器被执行的路径</td><td></td></tr><tr><td></td><td>–containerizers=VALUE</td><td>由逗号分隔的容器化实现方式列表。可选项有 mesos, external, and docker (on Linux). 排列的顺序就是容器化过程中尝试的顺序。 （默认：mesos）</td><td></td></tr><tr><td></td><td>–credential=VALUE</td><td>一行包含principal和secret由空格隔开的文本路径. 或是包含一条凭证的JSON格式文件的路径. 路径的格式是file://path/to/file 或 /path/to/file. 例如:<br>{<br>  “principal”: “username”,<br>  “secret”: “secret”<br>}<br></td><td></td></tr><tr><td></td><td>–default_container_image=VALUE</td><td>当使用外部容器化器时，在任务没有特别指定的情况下所使用的默认容器镜像。 没有在一个 task 上指定 ，则使用默认的容器镜像。</td><td></td></tr><tr><td></td><td>–default_container_info=VALUE</td><td>JSON格式的 CONTAINERINFO 将包含到任何没有指定 ContainerInfo 的 ExecutorInfo 中。<br>See the ContainerInfo protobuf in mesos.proto for the expected format.<br>例如:<br>{<br>  “type”: “MESOS”,<br>  “volumes”: [<br>    {<br>      “host_path”: “./.private/tmp”,<br>      “container_path”: “/tmp”,<br>      “mode”: “RW”<br>    }<br>  ]<br>}<br></td><td></td></tr><tr><td></td><td>–default_role=VALUE</td><td>任何用 –resources 标志位将忽略一个 role ，以及在 –resources 标记位中出现，但被自动检测到的资源。都将使用默认的这个 role。</td><td></td></tr><tr><td></td><td>–disk_watch_interval=VALUE</td><td>周期性时间间隔(例如 10 S ,2 MIN 等)检查slave管理的硬盘使用情况。 这个会对存档信息和沙盒做垃圾回收。(默认: 1mins)</td><td></td></tr><tr><td></td><td>–docker=VALUE</td><td>docker容器化的可执行文件的绝对路径。( 默认: docker )</td><td></td></tr><tr><td></td><td>–[no-]docker_kill_orphans</td><td>允许 docker kill 掉 orphaned containers 。当你相同的 OS 中启动多个 slave，你应该考虑将此值设为 false 。 以规避 DockerContainerizer 中的一个实例移除被其他 slaves 所启用的 docker 任务。然而，你还应该确保为 slave 启用　checkpoint，这样相同 slave id 可以被重用 。否则当 slave 重启后，docker 任务不会被清除掉。( 默认为　true ) 。</td><td></td></tr><tr><td></td><td>–docker_mesos_image=VALUE</td><td>docker 镜像用于启动这个 mesos slave 实例。如果一个镜像被指定，docker containerizer 假定 slave 运行在 docker 容器中，并当 slave 重启和恢复时启动 executor 来恢复他们。</td><td></td></tr><tr><td></td><td>–docker_registry=VALUE</td><td>一个下拉 Docker 镜像的默认 url. 可以是一个 Docker registry 服务的 URL（例如：<a href="https://registry.docker.io），也可以是" target="_blank" rel="noopener">https://registry.docker.io），也可以是</a> 一个包含Docker存档的本地路径（例如：/tmp/docker/images） （默认：<a href="https://registry-1.docker.io" target="_blank" rel="noopener">https://registry-1.docker.io</a> ）</td><td></td></tr><tr><td></td><td>–docker_remove_delay=VALUE</td><td>移除 docker 前等待的时间 （ 如 3 天，2 周 等）。默认为 6 小时。</td><td></td></tr><tr><td></td><td>–docker_socket=VALUE</td><td>一个安装在 Docker executor 容器内部的 UNIX 套接字路径。用来提供通过 CLI 访问 docker daemon 的能力。 这个必须是 slave docker 镜像用的路径。（默认：/var/run/docker.sock）</td><td></td></tr><tr><td></td><td>–docker_stop_timeout=VALUE</td><td>杀死实例后，在停止它之前 docker 需要等待的间隔时间 （ 默认： 0 Secs ）。</td><td></td></tr><tr><td></td><td>–docker_store_dir=VALUE</td><td>Docker provisioner 用来存储镜像的目录。（默认：/tmp/mesos/store/docker）</td><td></td></tr><tr><td></td><td>–[no-]enforce_container_disk_quota</td><td>否为容器启用磁盘限额。这个标记位用来为 posix/disk 隔离。 （ 默认: false ）。</td><td></td></tr><tr><td></td><td>–executor_environment_variables=VALUE</td><td>使用 JSON 对象格式的环境变量。会通过 executor 来传递之后的 task。 默认情况下，executor 会继承 slave 的环境变量。 例如:<br>{<br>  “PATH”: “/bin:/usr/bin”,<br>  “LD_LIBRARY_PATH”: “/usr/local/lib”<br>}<br></td><td></td></tr><tr><td></td><td>–executor_registration_timeout=VALUE</td><td>executor 挂起或者关闭前，等待其注册 slave 的时间。（ 例如，60 S，3 mins 等 ）。默认为 1 MIN 。</td><td></td></tr><tr><td></td><td>–executor_shutdown_grace_period=VALUE</td><td>等待 executor 关闭的时间。( 例如, 60 S, 3 mins 等 )。默认为 5 S 。</td><td></td></tr><tr><td></td><td>–fetcher_cache_dir=VALUE</td><td>fetcher cache 的父目录。（每一个slave有一个子目录）。 （默认：/tmp/mesos/fetch）</td><td></td></tr><tr><td></td><td>–fetcher_cache_size=VALUE</td><td>以字节为单位的 fetcher cache 大小。( 默认: 2 GB )</td><td></td></tr><tr><td></td><td>–frameworks_home=VALUE</td><td>相对于 executor 的路径前缀的 URI 。</td><td></td></tr><tr><td></td><td>–gc_delay=VALUE</td><td>清理 executor 目录的延迟时间（ 例如，3 天 或 2 周 等）。 注意，根据实际可用磁盘的情况，这个值可能会小些（ 默认：1 周 ）。</td><td></td></tr><tr><td></td><td>–gc_disk_headroom=VALUE</td><td>Adjust disk headroom used to calculate maximum executor directory age. Age is calculated by: gc_delay * max(0.0, (1.0 - gc_disk_headroom - disk usage)) every –disk_watch_interval duration. gc_disk_headroom must be a value between 0.0 and 1.0 (default: 0.1)</td><td></td></tr><tr><td></td><td>–hadoop_home=VALUE</td><td>Hadoop 的安装路径。（用于从 HDFS 提取框架 executors ） （没有默认项，在环境中查找HADOOP_HOME，或者在PATH 查询 hadoop）</td><td></td></tr><tr><td></td><td>–image_providers=VALUE</td><td>由逗号分割的支持的镜像供应商列表。如：APPC,DOCKER.</td><td></td></tr><tr><td></td><td>–image_provisioner_backend=VALUE</td><td>从镜像中提取容器 rootfs 的策略。 如：bind, copy. (默认: copy)</td><td></td></tr><tr><td></td><td>–isolation=VALUE</td><td>所采用的隔离机制，如：posix/cpu,posix/mem 或 cgroups/cpu,cgroups/mem 或 network/port_mapping（通过 –with-network-isolator 标记来开启） 或 external 或者通过code&gt;–modules标记替换成另一个隔离模块。 注意：这个标记仅用于 Mesos 容器化器。（默认：posix/cpu,posix/mem）</td><td></td></tr><tr><td></td><td>–launcher=VALUE</td><td>Mesos 容器化器所使用的启动器。可以是 linux 或 posix。 Linux 启动器需要cgroups隔离机制。每个隔离器需要 Linux 的 namespaces 如 网络，pid,等。 如果没有特别指定，slave 将选择一个作为root运行的 Linux 启动器。</td><td></td></tr><tr><td></td><td>–launcher_dir=VALUE</td><td>Mesos 二进制目录路径。 Mesos 可以在这个目录下找到 健康检查，fetcher，容器化器，executor 的二进制文件。（ 默认： /usr/local/lib/mesos ）。</td><td></td></tr><tr><td></td><td>–oversubscribed_resources_interval=VALUE</td><td>Slave 会定期向 master 更新自己有效的，可以分配的资源。 更新的间隔时间是由这个 flag 控制的。 （ 默认：15 S ）。</td><td></td></tr><tr><td></td><td>–perf_duration=VALUE</td><td>一个 perf stat 例子的执行周期。持续时间必须比 perf_interval 少。（默认： 10 secs）</td><td></td></tr><tr><td></td><td>–perf_events=VALUE</td><td>一系列命令分离的 perf 事件当使用 perf_event 分离器时候来精简每个容器。默认为 None。运行  perf list 命令查看所有事件。当在 PerfStatistics protobuf 中被通告时候事件名称将被悲观性的消除并使用下划线代替连字符。 例如，cpu-cycles 变为 cpu_cycles。在 PerfStatistics protobuf 中可以看到所有名字。</td><td></td></tr><tr><td></td><td>–perf_interval=VALUE</td><td>Interval between the start of perf stat samples. Perf samples are obtained periodically according to perf_interval and the most recently obtained sample is returned rather than sampling on demand. For this reason, perf_interval is independent of the resource monitoring interval. (default: 60secs)</td><td></td></tr><tr><td></td><td>–qos_controller=VALUE</td><td>Qos 控制器的名称被用来超额订阅。</td><td></td></tr><tr><td></td><td>–qos_correction_interval_min=VALUE</td><td>slave 从 Qos 控制器投票和执行 QoS 的更正基于其已运行 tasks 的观察到的性能 这些校正之间的最小间隔有此标记位指定。 （ 默认： 0 secs ）。</td><td></td></tr><tr><td></td><td>–recover=VALUE</td><td>是否恢复更新状态并与老的 executors 重新连接。 recover 可用的值有： reconnect：与老的还存活的 executors 重新连接。 cleanup：杀掉所有的老的还存活的 executors 并退出。 当 slave 不兼容 或 executor 更新时，使用这个选项。 （默认：reconnect）</td><td></td></tr><tr><td></td><td>–recovery_timeout=VALUE</td><td>分配给 slave 恢复的时间。如果　slave 恢复所用的时间超过 recovery_timeout，将会被终止。( 默认：15 min )</td><td></td></tr><tr><td></td><td>–registration_backoff_factor=VALUE</td><td>Slave initially picks a random amount of time between [0, b], where b = registration_backoff_factor, to (re-)register with a new master. Subsequent retries are exponentially backed off based on this interval (e.g., 1st retry uses a random value between [0, b <em> 2^1], 2nd retry between [0, b </em> 2^2], 3rd retry between [0, b * 2^3], etc) up to a maximum of 1mins (default: 1secs)</td><td></td></tr><tr><td></td><td>–resource_estimator=VALUE</td><td>用于 过度订阅 的 资源评估者 的名称。</td><td></td></tr><tr><td></td><td>–resources=VALUE</td><td>每个 slave 总的可消耗资源。可以用 JSON 格式提供，也可以是使用分号隔开的 key:value 键值对列表，配合指定角色选项。<br>key:value 列表: name(role):value;name:value…<br>To use JSON, pass a JSON-formatted string or use –resources=filepath to specify the resources via a file containing a JSON-formatted string. ‘filepath’ can be of the form file:///path/to/file or /path/to/file.<br>Example JSON:<br>[<br>  {<br>    “name”: “cpus”,<br>    “type”: “SCALAR”,<br>    “scalar”: {<br>      “value”: 24<br>    }<br>  },<br>  {<br>    “name”: “mem”,<br>    “type”: “SCALAR”,<br>    “scalar”: {<br>      “value”: 24576<br>    }<br>  }<br>]<br></td><td></td></tr><tr><td></td><td>–[no-]revocable_cpu_low_priority</td><td>通过 revocable CPU 以相对低的优先级运行 containers 。 目前只支持 cgroups/cpu isolator 。( 默认: true )</td><td></td></tr><tr><td></td><td>–sandbox_directory=VALUE</td><td>沙盒被映射到容器中的绝对目录路径。 (默认: /mnt/mesos/sandbox)</td><td></td></tr><tr><td></td><td>–slave_subsystems=VALUE</td><td>一系列的逗号分隔的 cgroup 子系统来从二进制运行slave。例如，memory,cpuacct 。默认为 none 。此功能用于资源的监视以及 no cgroup 下限制设置，它们从 root mesos cgroup 继承而来。</td><td></td></tr><tr><td></td><td>–[no-]strict</td><td>如果 strict=true，任何以及所有错误恢复都被认为是致命的。反之，恢复期间，任何预期的错误都会被忽略。 ( 默认： true )</td><td></td></tr><tr><td></td><td>–[no-]switch_user</td><td>是否用提交它们的用户来运行 tasks 而不是使用运行 slave 的用户. ( 需要 setuid 权限)。 ( 默认: true ) If set to true, the slave will attempt to run tasks as the user who submitted them (as defined in FrameworkInfo) (this requires setuid permission and that the given user exists on the slave). If the user does not exist, an error occurs and the task will fail. If set to false, tasks will be run as the same user as the Mesos slave process. NOTE: This feature is not yet supported on Windows slave, and therefore the flag currently does not exist on that platform. (default: true)</td><td></td></tr><tr><td></td><td>–[no-]systemd_enable_support</td><td>系统支持的最高级控制。当设置为 enabled，像 executor life-time 延期这样的功能都会设置为 enabled，除非有一个明确的 flag 设置其为 disable。这个会在 agent 作为 systemd unit 发布 时设置为 enabled。 （默认：true）</td><td></td></tr><tr><td></td><td>–systemd_runtime_directory=VALUE</td><td>systemd 系统运行时目录路径。 （默认：/run/systemd/system）</td><td></td></tr><tr><td></td><td>–work_dir=VALUE</td><td>framework 工作目录的路径。( 默认: /tmp/mesos )</td><td></td></tr></tbody></table><p>当配置了 ‘ –with-network-isolator ‘, 以下标记位才会生效：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">--ephemeral_ports_per_container=VALUE   有网络隔离器分配临时端口给一个容器。此端口号必须是 2 的倍数。( 默认: 1024 )</span><br><span class="line">--eth0_name = VALUE             公网接口的名称 ( 如 eth0 )。如果没有指定，网络隔离器会尝试基于主机的默认网关来猜测它。</span><br><span class="line">--lo_name=VALUE                 网络 loopback 接口的名称( 例如, lo )。如果没有指定，网络隔离器会尝试猜测它。</span><br><span class="line">--egress_rate_limit_per_container=VALUE 每个容器的出口流量限制，单位是 字节/每秒。如果没有指定或指定为零，网络隔离器不会强制限制容器的出口流量。这个标记使用字节类型, 定义在 stout 。</span><br><span class="line">--[no-]network_enable_socket_statistics_summary 是否从每个容器收集 socket 统计摘要。这个标记位被用在  &apos;network/port_mapping&apos; 隔离器。 ( 默认: false )</span><br><span class="line">--[no-]network_enable_socket_statistics_details 是否从每个容器收集 socket 细节信息。该标记用于 &apos; network/port_mapping &apos; 隔离器。( 默认: false )</span><br></pre></td></tr></table></figure><p>参考文章：<a href="https://mesos-cn.gitbooks.io/mesos-cn/content/document/runing-Mesos/Configuration.html" target="_blank" rel="noopener">https://mesos-cn.gitbooks.io/mesos-cn/content/document/runing-Mesos/Configuration.html</a></p>]]></content>
      
      <categories>
          
          <category> mesos </category>
          
      </categories>
      
      
        <tags>
            
            <tag> mesos </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>marathon-lb上添加多证书并实现泛解析代理域名-1</title>
      <link href="/lb-https-certs-1/"/>
      <url>/lb-https-certs-1/</url>
      <content type="html"><![CDATA[<h2 id="marathon-lb上添加多证书并实现泛解析代理域名-之-nginx实现marathon-lb的vhosts泛域名代理"><a href="#marathon-lb上添加多证书并实现泛解析代理域名-之-nginx实现marathon-lb的vhosts泛域名代理" class="headerlink" title="marathon-lb上添加多证书并实现泛解析代理域名 之 nginx实现marathon-lb的vhosts泛域名代理"></a>marathon-lb上添加多证书并实现泛解析代理域名 之 nginx实现marathon-lb的vhosts泛域名代理</h2><p>marathon-lb代理https域名， 需要将证书当道lb上。nginx不需要开启443端口，nginx需要配置 vhost  才能访问。</p><p>marathon添加证书连接： <a href="https://sukbeta.github.io/lb-https-certs-2/">marathon-lb上添加多个证书</a></p><p>域名都是通过 vhost 虚拟主机方式访问。这样nginx才能拿到 x_forwarded_for 客户端的IP地址。LB才会通过HTTP方式代理，否则会走TCP代理。</p><p>nginx上回有很多个域名，我们不能添加一个域名就修改一次 vhosts ，所以我们尝试添加 泛域名。</p><a id="more"></a><p>nginx 发布的json文件：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;id&quot;: &quot;/lb-nginx/nginx-shining-test1,</span><br><span class="line">  &quot;cmd&quot;: null,</span><br><span class="line">  &quot;cpus&quot;: 0.1,</span><br><span class="line">  &quot;mem&quot;: 4096,</span><br><span class="line">  &quot;disk&quot;: 0,</span><br><span class="line">  &quot;instances&quot;: 1,</span><br><span class="line">  &quot;constraints&quot;: [</span><br><span class="line">    [</span><br><span class="line">      &quot;nginx&quot;,</span><br><span class="line">      &quot;LIKE&quot;,</span><br><span class="line">      &quot;true&quot;</span><br><span class="line">    ]</span><br><span class="line">  ],</span><br><span class="line">  &quot;container&quot;: &#123;</span><br><span class="line">    &quot;type&quot;: &quot;DOCKER&quot;,</span><br><span class="line">    &quot;volumes&quot;: [</span><br><span class="line">      &#123;</span><br><span class="line">        &quot;containerPath&quot;: &quot;/etc/nginx&quot;,</span><br><span class="line">        &quot;hostPath&quot;: &quot;/home/nginx-conf/conf&quot;,</span><br><span class="line">        &quot;mode&quot;: &quot;RW&quot;</span><br><span class="line">      &#125;</span><br><span class="line">    ],</span><br><span class="line">    &quot;docker&quot;: &#123;</span><br><span class="line">      &quot;image&quot;: &quot;nginx:1.13&quot;,</span><br><span class="line">      &quot;network&quot;: &quot;BRIDGE&quot;,</span><br><span class="line">      &quot;portMappings&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">          &quot;containerPort&quot;: 80,</span><br><span class="line">          &quot;hostPort&quot;: 0,</span><br><span class="line">          &quot;servicePort&quot;: 0,</span><br><span class="line">          &quot;protocol&quot;: &quot;tcp&quot;,</span><br><span class="line">          &quot;labels&quot;: &#123;&#125;</span><br><span class="line">        &#125;</span><br><span class="line">      ],</span><br><span class="line">        &quot;forcePullImage&quot;: false</span><br><span class="line">  &#125;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;env&quot;: &#123;</span><br><span class="line">    &quot;TZ&quot;: &quot;Asia/Shanghai&quot;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;healthChecks&quot;: [</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;gracePeriodSeconds&quot;: 60,</span><br><span class="line">      &quot;intervalSeconds&quot;: 10,</span><br><span class="line">      &quot;timeoutSeconds&quot;: 5,</span><br><span class="line">      &quot;maxConsecutiveFailures&quot;: 3,</span><br><span class="line">      &quot;portIndex&quot;: 0,</span><br><span class="line">      &quot;protocol&quot;: &quot;TCP&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  ],</span><br><span class="line">  &quot;labels&quot;: &#123;</span><br><span class="line">    &quot;HAPROXY_0_BACKEND_WEIGHT&quot;: &quot;-1&quot;,</span><br><span class="line">    &quot;HAPROXY_GROUP&quot;: &quot;lbgroupname&quot;,</span><br><span class="line">    &quot;HAPROXY_0_HTTP_FRONTEND_ACL_ONLY&quot;: &quot;  acl host_&#123;cleanedUpHostname&#125; hdr(host) -m end .&#123;hostname&#125;\n&quot;,</span><br><span class="line">    &quot;HAPROXY_0_HTTPS_FRONTEND_ACL&quot;: &quot;  use_backend &#123;backend&#125; if &#123;&#123; ssl_fc_sni -m end .&#123;hostname&#125; &#125;&#125;\n&quot;,</span><br><span class="line">    &quot;HAPROXY_0_VHOST&quot;: &quot;shiningtest1.com,shiningtest2.com&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>其中参数说明：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&quot;HAPROXY_0_HTTP_FRONTEND_ACL_ONLY&quot;: &quot;  acl host_&#123;cleanedUpHostname&#125; hdr(host) -m end .&#123;hostname&#125;\n&quot;,</span><br></pre></td></tr></table></figure><p>这个是http的默认解析。因为http会有很多二级域名，所以配置默认解析。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&quot;HAPROXY_0_HTTPS_FRONTEND_ACL&quot;: &quot;  use_backend &#123;backend&#125; if &#123;&#123; ssl_fc_sni -m end .&#123;hostname&#125; &#125;&#125;\n&quot;,</span><br></pre></td></tr></table></figure><p>这个是配置https的泛解析，会在LB的配置的vhosts域名前面加“.”点， “end .{hostname} ”  那个点。</p><h3 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h3><p>可以查看LB的配置</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"> curl 192.168.53.200:9090/_haproxy_getconfig </span><br><span class="line"></span><br><span class="line">......</span><br><span class="line">frontend marathon_http_in</span><br><span class="line">  bind *:80</span><br><span class="line">  mode http</span><br><span class="line">  acl host_shiningtest1_com_lb-nginx_nginx-shining-test1 hdr(host) -m end .shiningtest1.com</span><br><span class="line">  acl host_shiningtest1_com_lb-nginx_nginx-shining-test1 hdr(host) -m end .shiningtest2.com</span><br><span class="line">  use_backend lb-nginx_nginx-shining-test1_10111 if host_shiningtest1_com_lb-nginx_nginx-shining-test1</span><br><span class="line"></span><br><span class="line">......</span><br><span class="line"></span><br><span class="line">frontend marathon_https_in</span><br><span class="line">  bind *:443 ssl crt /mnt/mesos/sandbox/shiningtest1.com.pem crt /mnt/mesos/sandbox/shiningtest2.com.pem</span><br><span class="line">  mode http</span><br><span class="line">  use_backend lb-nginx_nginx-shining-test1_10111  if &#123; ssl_fc_sni -m end .shiningtest1.com &#125;</span><br><span class="line">  use_backend lb-nginx_nginx-shining-test1_10111 if &#123; ssl_fc_sni -m end .shiningtest2.com &#125;</span><br><span class="line">.......</span><br></pre></td></tr></table></figure><ul><li><p>可以看到 http 的 use_backend  是marathon上nginx的id</p></li><li><p>https 的end 后面的二级域名前面都添加了 “.” </p></li></ul><p>这样 shiningtest1.com 和 shiningtest2.com 所有的域名都会转发到nginx上了。</p><p>相关参考文档：<a href="https://docs.mesosphere.com/services/marathon-lb/1.13/mlb-configuration/" target="_blank" rel="noopener">https://docs.mesosphere.com/services/marathon-lb/1.13/mlb-configuration/</a></p>]]></content>
      
      <categories>
          
          <category> marathon </category>
          
      </categories>
      
      
        <tags>
            
            <tag> marathon-lb </tag>
            
            <tag> nginx </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>marathon-lb上添加多证书并实现泛解析代理域名-2</title>
      <link href="/lb-https-certs-2/"/>
      <url>/lb-https-certs-2/</url>
      <content type="html"><![CDATA[<h2 id="lb上添加多证书并实现泛解析代理域名-之-marathon-lb上添加多个证书"><a href="#lb上添加多证书并实现泛解析代理域名-之-marathon-lb上添加多个证书" class="headerlink" title="lb上添加多证书并实现泛解析代理域名 之 marathon-lb上添加多个证书"></a>lb上添加多证书并实现泛解析代理域名 之 marathon-lb上添加多个证书</h2><p>marathon-lb代理https域名， 需要将证书当道lb上。nginx不需要开启443端口，nginx需要配置 vhost  才能访问。</p><p>vhost 需要再nginx发布的时候通过标签形式发布的，但是一个nginx上可能多个域名，不是很灵活，（当你的服务全部都在mesos集群中的话，不用nginx，直接用LB+服务 方式，就可以在每个服务发布的时候声明vhosts。），之后我们研究了nginx发布的时候发布泛域名来解决这个问题。连接 ： <a href="https://sukbeta.github.io/lb-https-certs-1/">nginx实现marathon-lb的vhosts泛域名代理</a></p><p>marathon-lb 和 nginx 域名都是通过 vhost 虚拟主机方式访问。这样nginx才能拿到 x_forwarded_for 客户端的IP地址。LB才会通过HTTP方式代理，否则会走TCP代理。</p><p>marahton-lb 可以加载多个证书，–ssl-certs 用“，”逗号隔开证书路径</p><a id="more"></a><ul><li>证书需要pem格式，就是 crt 和 key 按顺序放在一起就可以了。 </li></ul><p>我没有把证书放到容器里面， 而是用的marathon uris 方式下载的。</p><p>LB的json文件：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;id&quot;: &quot;/marathon-lb/marathon-shining-001&quot;,</span><br><span class="line">  &quot;cmd&quot;: null,</span><br><span class="line">  &quot;cpus&quot;: 1,</span><br><span class="line">  &quot;mem&quot;: 1024,</span><br><span class="line">  &quot;disk&quot;: 0,</span><br><span class="line">  &quot;instances&quot;: 1,</span><br><span class="line">  &quot;constraints&quot;: [</span><br><span class="line">    [</span><br><span class="line">      &quot;lb&quot;,</span><br><span class="line">      &quot;LIKE&quot;,</span><br><span class="line">      &quot;true&quot;</span><br><span class="line">    ]</span><br><span class="line">  ],</span><br><span class="line">  &quot;container&quot;: &#123;</span><br><span class="line">    &quot;type&quot;: &quot;DOCKER&quot;,</span><br><span class="line">    &quot;volumes&quot;: [</span><br><span class="line">      &#123;</span><br><span class="line">        &quot;containerPath&quot;: &quot;/dev/log&quot;,</span><br><span class="line">        &quot;hostPath&quot;: &quot;/dev/log&quot;,</span><br><span class="line">        &quot;mode&quot;: &quot;RW&quot;</span><br><span class="line">      &#125;</span><br><span class="line">    ],</span><br><span class="line">    &quot;docker&quot;: &#123;</span><br><span class="line">      &quot;image&quot;: &quot;marathon-lb:v1.13.1&quot;,</span><br><span class="line">      &quot;network&quot;: &quot;BRIDGE&quot;,</span><br><span class="line">      &quot;portMappings&quot;: [],</span><br><span class="line">      &quot;privileged&quot;: true,</span><br><span class="line">      &quot;parameters&quot;: [</span><br><span class="line">      &#123;</span><br><span class="line">        &quot;key&quot;: &quot;network&quot;,</span><br><span class="line">        &quot;value&quot;: &quot;shining-macvlan&quot;</span><br><span class="line">      &#125;,</span><br><span class="line">      &#123;</span><br><span class="line">        &quot;key&quot;: &quot;hostname&quot;,</span><br><span class="line">        &quot;value&quot;: &quot;shining-test-lb-001&quot;</span><br><span class="line">      &#125;,</span><br><span class="line">      &#123;</span><br><span class="line">        &quot;key&quot;: &quot;ip&quot;,</span><br><span class="line">        &quot;value&quot;: &quot;192.168.53.200&quot;</span><br><span class="line">      &#125;</span><br><span class="line">        ],</span><br><span class="line">      &quot;forcePullImage&quot;: true</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;env&quot;: &#123;</span><br><span class="line">    &quot;TZ&quot;: &quot;Asia/Shanghai&quot;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;args&quot;: [</span><br><span class="line">    &quot;sse&quot;,</span><br><span class="line">    &quot;-m&quot;,</span><br><span class="line">    &quot;http://192.168.55.4:8080&quot;,</span><br><span class="line">    &quot;http://192.168.55.5:8080&quot;,</span><br><span class="line">    &quot;http://192.168.55.6:8080&quot;,</span><br><span class="line">    &quot;--auth-credentials&quot;,</span><br><span class="line">    &quot;shining-username:passwd&quot;,</span><br><span class="line">    &quot;--ssl-certs&quot;,</span><br><span class="line">    &quot;/mnt/mesos/sandbox/shiningtest1.com.pem,/mnt/mesos/sandbox/shiningtest2.com.pem&quot;,</span><br><span class="line">    &quot;--group&quot;,</span><br><span class="line">    &quot;lbgroupname&quot;</span><br><span class="line">  ],</span><br><span class="line">  &quot;uris&quot;: [</span><br><span class="line">      &quot;http://192.168.55.3/download/com-cert/shiningtest1.com.pem.tar.gz&quot;,</span><br><span class="line">      &quot;http://192.168.55.3/download/com-cert/shiningtest2.com.pem.tar.gz&quot;</span><br><span class="line">  ],</span><br><span class="line">  &quot;upgradeStrategy&quot;: &#123;</span><br><span class="line">    &quot;minimumHealthCapacity&quot;: 0,</span><br><span class="line">    &quot;maximumOverCapacity&quot;: 0</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这样LB上的443端口上默认就有了多个域名的证书，高版本的LB会自动根据域名自动匹配证书的。 </p><p>LB参数参考 <a href="https://gitlab.oye.io/oyenet/marathon-lb/blob/master/Longhelp.md" target="_blank" rel="noopener">https://gitlab.oye.io/oyenet/marathon-lb/blob/master/Longhelp.md</a></p>]]></content>
      
      <categories>
          
          <category> marathon </category>
          
      </categories>
      
      
        <tags>
            
            <tag> marathon-lb </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>marathon-lb配置多个matahon地址</title>
      <link href="/lb-confiure-many-marathon/"/>
      <url>/lb-confiure-many-marathon/</url>
      <content type="html"><![CDATA[<p>marathon 在集群中，marathon可以部署多个节点。</p><p>-m 参数是指定marathon地址的，后面跟上marathon地址就可以了， 当你有多个marathon地址的时候，用“空格”隔开就可以了。</p><p>marathon json文件中是这样写的。</p><a id="more"></a><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&quot;args&quot;: [</span><br><span class="line">  &quot;sse&quot;,</span><br><span class="line">  &quot;-m&quot;,</span><br><span class="line">  &quot;http://192.168.55.5:8080&quot;,</span><br><span class="line">  &quot;http://192.168.55.6:8080&quot;,</span><br><span class="line">  &quot;http://192.168.55.7:8080&quot;,</span><br><span class="line">  &quot;--group&quot;,</span><br><span class="line">  &quot;lb-name&quot;</span><br><span class="line">],</span><br></pre></td></tr></table></figure><p>这样配置完之后，当一个marathon有问题之后，可以在lb的日志中看在节点不能连接，但是会在其他节点上取到marathon数据的。</p>]]></content>
      
      <categories>
          
          <category> marathon </category>
          
      </categories>
      
      
        <tags>
            
            <tag> marathon </tag>
            
            <tag> marathon-lb </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>zookeeper delete yarn rmstore</title>
      <link href="/zookeeper-delete-yarn-rmstore/"/>
      <url>/zookeeper-delete-yarn-rmstore/</url>
      <content type="html"><![CDATA[<p>hadoop 版本为：apache 2.7.2<br>这几天在搭建的时候遇到yarn无法启动。报错信息：</p><a id="more"></a><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line">2019-06-18 16:34:08,362 WARN org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system already initialized!</span><br><span class="line">2019-06-18 16:34:08,362 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMAppManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.RMAppManager</span><br><span class="line">2019-06-18 16:34:08,362 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncherEventType for class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher</span><br><span class="line">2019-06-18 16:34:08,362 WARN org.apache.hadoop.metrics2.util.MBeans: Error creating MBean object name: Hadoop:service=ResourceManager,name=RMNMInfo</span><br><span class="line">org.apache.hadoop.metrics2.MetricsException: org.apache.hadoop.metrics2.MetricsException: Hadoop:service=ResourceManager,name=RMNMInfo already exists!</span><br><span class="line">        at org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.newObjectName(DefaultMetricsSystem.java:122)</span><br><span class="line">        at org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.newMBeanName(DefaultMetricsSystem.java:102)</span><br><span class="line">        at org.apache.hadoop.metrics2.util.MBeans.getMBeanName(MBeans.java:92)</span><br><span class="line">        at org.apache.hadoop.metrics2.util.MBeans.register(MBeans.java:55)</span><br><span class="line">        at org.apache.hadoop.yarn.server.resourcemanager.RMNMInfo.&lt;init&gt;(RMNMInfo.java:59)</span><br><span class="line">        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$RMActiveServices.serviceInit(ResourceManager.java:549)</span><br><span class="line">        at org.apache.hadoop.service.AbstractService.init(AbstractService.java:163)</span><br><span class="line">        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.createAndInitActiveServices(ResourceManager.java:954)</span><br><span class="line">        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.reinitialize(ResourceManager.java:984)</span><br><span class="line">        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$1.run(ResourceManager.java:1008)</span><br><span class="line">        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$1.run(ResourceManager.java:1001)</span><br><span class="line">        at java.security.AccessController.doPrivileged(Native Method)</span><br><span class="line">        at javax.security.auth.Subject.doAs(Subject.java:422)</span><br><span class="line">        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)</span><br><span class="line">        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.transitionToActive(ResourceManager.java:1001)</span><br><span class="line">        at org.apache.hadoop.yarn.server.resourcemanager.AdminService.transitionToActive(AdminService.java:303)</span><br><span class="line">        at org.apache.hadoop.yarn.server.resourcemanager.EmbeddedElectorService.becomeActive(EmbeddedElectorService.java:126)</span><br><span class="line">        at org.apache.hadoop.ha.ActiveStandbyElector.becomeActive(ActiveStandbyElector.java:813)</span><br><span class="line">        at org.apache.hadoop.ha.ActiveStandbyElector.processResult(ActiveStandbyElector.java:418)</span><br><span class="line">        at org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:599)</span><br><span class="line">        at org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:498)</span><br><span class="line">Caused by: org.apache.hadoop.metrics2.MetricsException: Hadoop:service=ResourceManager,name=RMNMInfo already exists!</span><br><span class="line">        at org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.newObjectName(DefaultMetricsSystem.java:118)</span><br><span class="line">        ... 20 more</span><br><span class="line">2019-06-18 16:34:08,363 WARN org.apache.hadoop.metrics2.util.MBeans: Failed to register MBean &quot;null&quot;</span><br><span class="line">javax.management.RuntimeOperationsException: Exception occurred trying to register the MBean</span><br><span class="line">        at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:951)</span><br><span class="line">        at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:900)</span><br><span class="line">        at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:324)</span><br><span class="line">        at com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)</span><br><span class="line">        at org.apache.hadoop.metrics2.util.MBeans.register(MBeans.java:57)</span><br><span class="line">        at org.apache.hadoop.yarn.server.resourcemanager.RMNMInfo.&lt;init&gt;(RMNMInfo.java:59)</span><br><span class="line">        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$RMActiveServices.serviceInit(ResourceManager.java:549)</span><br><span class="line">        at org.apache.hadoop.service.AbstractService.init(AbstractService.java:163)</span><br><span class="line">        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.createAndInitActiveServices(ResourceManager.java:954)</span><br><span class="line">        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.reinitialize(ResourceManager.java:984)</span><br><span class="line">        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$1.run(ResourceManager.java:1008)</span><br><span class="line">        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$1.run(ResourceManager.java:1001)</span><br><span class="line">        at java.security.AccessController.doPrivileged(Native Method)</span><br><span class="line">        at javax.security.auth.Subject.doAs(Subject.java:422)</span><br><span class="line">        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)</span><br><span class="line">        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.transitionToActive(ResourceManager.java:1001)</span><br><span class="line">        at org.apache.hadoop.yarn.server.resourcemanager.AdminService.transitionToActive(AdminService.java:303)</span><br><span class="line">        at org.apache.hadoop.yarn.server.resourcemanager.EmbeddedElectorService.becomeActive(EmbeddedElectorService.java:126)</span><br><span class="line">        at org.apache.hadoop.ha.ActiveStandbyElector.becomeActive(ActiveStandbyElector.java:813)</span><br><span class="line">        at org.apache.hadoop.ha.ActiveStandbyElector.processResult(ActiveStandbyElector.java:418)</span><br><span class="line">        at org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:599)</span><br><span class="line">        at org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:498)</span><br><span class="line">Caused by: java.lang.IllegalArgumentException: No object name specified</span><br><span class="line">        at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:949)</span><br><span class="line">        ... 21 more</span><br><span class="line">2019-06-18 16:34:08,363 INFO org.apache.hadoop.yarn.server.resourcemanager.RMNMInfo: Registered RMNMInfo MBean</span><br><span class="line">2019-06-18 16:34:08,363 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list</span><br><span class="line">2019-06-18 16:34:08,364 INFO org.apache.hadoop.service.AbstractService: Service org.apache.hadoop.yarn.server.resourcemanager.NodesListManager failed in state INITED; cause: org.apache.hadoop.metrics2.MetricsException: Metrics source ClusterMetrics already exists!</span><br><span class="line">org.apache.hadoop.metrics2.MetricsException: Metrics source ClusterMetrics already exists!</span><br><span class="line">        at org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.newSourceName(DefaultMetricsSystem.java:135)</span><br><span class="line">        at org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.sourceName(DefaultMetricsSystem.java:112)</span><br><span class="line">        at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.register(MetricsSystemImpl.java:229)</span><br><span class="line">        at org.apache.hadoop.yarn.server.resourcemanager.ClusterMetrics.registerMetrics(ClusterMetrics.java:74)</span><br></pre></td></tr></table></figure><p>或</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">2019-06-16 21:07:39,030 WARN org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=yarn OPERATION=transitionToActive TARGET=RMHAProtocolService RESULT=FAILURE DESCRIPTION=Exception transitioning to active PERMISSIONS=Users [yarn] and members of the groups [&lt;users&gt;] are allowed</span><br><span class="line">2019-06-16 21:07:39,030 WARN org.apache.hadoop.ha.ActiveStandbyElector: Exception handling the winning of election</span><br><span class="line">org.apache.hadoop.ha.ServiceFailedException: RM could not transition to Active</span><br><span class="line">  at org.apache.hadoop.yarn.server.resourcemanager.EmbeddedElectorService.becomeActive(EmbeddedElectorService.java:124)</span><br><span class="line">  at org.apache.hadoop.ha.ActiveStandbyElector.becomeActive(ActiveStandbyElector.java:812)</span><br><span class="line">  at org.apache.hadoop.ha.ActiveStandbyElector.processResult(ActiveStandbyElector.java:417)</span><br><span class="line">  at org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:599)</span><br><span class="line">  at org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:498)</span><br><span class="line">Caused by: org.apache.hadoop.ha.ServiceFailedException: Error when transitioning to Active mode</span><br><span class="line">  at org.apache.hadoop.yarn.server.resourcemanager.AdminService.transitionToActive(AdminService.java:304)</span><br><span class="line">  at org.apache.hadoop.yarn.server.resourcemanager.EmbeddedElectorService.becomeActive(EmbeddedElectorService.java:122)</span><br><span class="line">  ... 4 more</span><br><span class="line">Caused by: org.apache.hadoop.service.ServiceStateException: org.apache.hadoop.yarn.server.resourcemanager.recovery.StoreFencedException: RMStateStore has been fenced</span><br><span class="line">  at org.apache.hadoop.service.ServiceStateException.convert(ServiceStateException.java:59)</span><br><span class="line">  at org.apache.hadoop.service.AbstractService.start(AbstractService.java:204)</span><br><span class="line">  at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$RMActiveServices.serviceStart(ResourceManager.java:577)</span><br><span class="line">  at org.apache.hadoop.service.Abstr</span><br></pre></td></tr></table></figure><p>解决办法：</p><p>我们需要删除yarn在ZK上的 rmstore 信息， 之后重启yarn，就可以了。 </p><p>但是在删除zk上 rmstore 信息的时候， 遇到了问题， yarn在注册时候的时候自己添加上ACL。所以我们直接删除是不行的。</p><p>但我们可以可以重新设置一个ACL，就可以了， 如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">cd $ZOOKEEPER_HOME/bin</span><br><span class="line">./zkCli.sh   # 连接hadoop配置的zk，如果是客户端需添加 -server IP：port</span><br><span class="line">[zk: localhost:2181(CONNECTED) 0] ls /</span><br><span class="line">[zookeeper, hadoop-ha, hbase, rmstore]</span><br><span class="line">[zk: localhost:2181(CONNECTED) 1] rmr /rmstore</span><br><span class="line">Authentication is not valid : /rmstore/ZKRMStateRoot/RMVersionNode</span><br></pre></td></tr></table></figure><p>我们可以看一下这个目录的ACL</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[zk: localhost:2181(CONNECTED) 2] getAcl /rmstore/ZKRMStateRoot</span><br><span class="line">&apos;world,&apos;anyone</span><br><span class="line">: rwa</span><br><span class="line">&apos;digest,&apos;shining-namenode01.host.com:yelhKlz39YVCV9p4NTModoBq9fw=</span><br><span class="line">: cd</span><br></pre></td></tr></table></figure><p>我们重新设置ACL，并删除目录</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">[zk: localhost:2181(CONNECTED) 3] setAcl /rmstore/ZKRMStateRoot world:anyone:rwcda</span><br><span class="line">cZxid = 0x10000001b</span><br><span class="line">ctime = Mon May 27 14:58:45 CST 2019</span><br><span class="line">mZxid = 0x10000001b</span><br><span class="line">mtime = Mon May 27 14:58:45 CST 2019</span><br><span class="line">pZxid = 0x10016efd3</span><br><span class="line">cversion = 380191</span><br><span class="line">dataVersion = 0</span><br><span class="line">aclVersion = 5</span><br><span class="line">ephemeralOwner = 0x0</span><br><span class="line">dataLength = 0</span><br><span class="line">numChildren = 5</span><br><span class="line">[zk: localhost:2181(CONNECTED) 4] getAcl /rmstore/ZKRMStateRoot                   </span><br><span class="line">&apos;world,&apos;anyone</span><br><span class="line">: cdrwa</span><br><span class="line">[zk: localhost:2181(CONNECTED) 6] rmr /rmstore/ZKRMStateRoot</span><br><span class="line">[zk: localhost:2181(CONNECTED) 7] ls /</span><br><span class="line">[zookeeper, hadoop-ha, hbase, rmstore]</span><br><span class="line">[zk: localhost:2181(CONNECTED) 8] rmr /rmstore</span><br><span class="line">[zk: localhost:2181(CONNECTED) 9] ls /</span><br><span class="line">[zookeeper, hadoop-ha, hbase]</span><br></pre></td></tr></table></figure><p>之后重新启动yarn，让yarn重新在zk上注册就可以了。</p><p>相关文章链接：<br><a href="https://jxy.me/2015/05/02/hadoop-resourcemanager-recovery/" target="_blank" rel="noopener">https://jxy.me/2015/05/02/hadoop-resourcemanager-recovery/</a><br><a href="https://my.oschina.net/dabird/blog/3023781" target="_blank" rel="noopener">https://my.oschina.net/dabird/blog/3023781</a></p>]]></content>
      
      <categories>
          
          <category> hadoop </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hadoop </tag>
            
            <tag> yarn </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Elasticsearch申请免费license</title>
      <link href="/es-free-license/"/>
      <url>/es-free-license/</url>
      <content type="html"><![CDATA[<p>Elasticsearch是免费的，但是有些插件是需要license的，否则你只能试用，不能长期试用。如 marvel、x-pack、shield等插件。</p><h3 id="注册免费license"><a href="#注册免费license" class="headerlink" title="注册免费license"></a>注册免费license</h3><p>我么可以在Elasticsearch官网上注册申请免费license</p><p>申请地址：<a href="https://register.elastic.co/marvel_register" target="_blank" rel="noopener">https://register.elastic.co/marvel_register</a></p><p>安装表格填写姓名、邮箱、公司、国家</p><p>之后你的邮箱会收到来之Elastic团队反馈的license信息。</p><p>如：</p><a id="more"></a><p><img src="/images/es-license-01.jpeg" alt="es-license-01"></p><p>你可以去 download 地址上下载你的license。 免费的license有效期为一年！</p><p>邮件里还介绍了各个版本更新license的URL。</p><h3 id="更新license"><a href="#更新license" class="headerlink" title="更新license"></a>更新license</h3><p>每个版本更新api接口不一样， 可以查看官网邮件中提供的URL</p><p>2.x 版本 的命令：</p><p>导入license 命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl -XPUT &apos;http://&lt;host&gt;:&lt;port&gt;/_license&apos; -d @license.json</span><br></pre></td></tr></table></figure><p>license.json  是你下载的license</p><ul><li>如果你用了shield插件，需要集群admin权限去安装license，需要添加 -u admin</li></ul><p>如果遇到问题，你可能之前有license，没有更新成功， 可以用下面命令。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl -XPUT &apos;http://&lt;host&gt;:&lt;port&gt;/_license?acknowledge=true&apos; -d @license.json</span><br></pre></td></tr></table></figure><p>查看license信息</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">curl -XGET -u admin:password &apos;http://&lt;host&gt;:&lt;port&gt;/_license&apos;</span><br><span class="line"></span><br><span class="line">内容如：</span><br><span class="line">&#123;</span><br><span class="line">  &quot;license&quot; : &#123;</span><br><span class="line">    &quot;status&quot; : &quot;active&quot;,</span><br><span class="line">    &quot;uid&quot; : &quot;0a98411f-73f4-4c67-954c-724874ed5488&quot;,</span><br><span class="line">    &quot;type&quot; : &quot;trial&quot;,</span><br><span class="line">    &quot;issue_date&quot; : &quot;2018-10-13T18:18:20.709Z&quot;,</span><br><span class="line">    &quot;issue_date_in_millis&quot; : 1444760300709,</span><br><span class="line">    &quot;expiry_date&quot; : &quot;2019-11-12T18:18:20.709Z&quot;,</span><br><span class="line">    &quot;expiry_date_in_millis&quot; : 1447352300709,</span><br><span class="line">    &quot;max_nodes&quot; : 1000,</span><br><span class="line">    &quot;issued_to&quot; : &quot;elasticsearch&quot;,</span><br><span class="line">    &quot;issuer&quot; : &quot;elasticsearch&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      <categories>
          
          <category> elasticsearch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> elasticsearch </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>shell脚本多行注释和单行注释的方法</title>
      <link href="/shell-comment/"/>
      <url>/shell-comment/</url>
      <content type="html"><![CDATA[<p>在各种语言中都有注释的方法，单行注释、多行注释，都很方便，其实shell脚本也有多行注释，而且很灵活。</p><p>那么我们来说说shell脚本中的注释方法，</p><h3 id="单行注释"><a href="#单行注释" class="headerlink" title="单行注释"></a>单行注释</h3><p>shell 中 “#” 代表注释本行，</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">#!/bin/bash</span><br><span class="line"></span><br><span class="line">#echo &quot;1&quot;</span><br><span class="line">echo &quot;2&quot;</span><br></pre></td></tr></table></figure><h3 id="多行注释"><a href="#多行注释" class="headerlink" title="多行注释"></a>多行注释</h3><p>shell 中可以用 “:&lt;&lt; ” 后面跟上任意字符或数据， 方法注释多行</p><p>例子：</p><a id="more"></a><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">#!/bin/bash</span><br><span class="line"></span><br><span class="line">:&lt;&lt;123</span><br><span class="line">echo &quot;1&quot;</span><br><span class="line">echo &quot;1&quot;</span><br><span class="line">echo &quot;1&quot;</span><br><span class="line">echo &quot;1&quot;</span><br><span class="line">echo &quot;1&quot;</span><br><span class="line">123</span><br><span class="line"></span><br><span class="line">echo 2</span><br></pre></td></tr></table></figure><p>:&lt;&lt;123 和 123 之间为注释内容，脚本只能输出一个”2“</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">#!/bin/bash</span><br><span class="line"></span><br><span class="line">:&lt;&lt;EOF</span><br><span class="line">echo &quot;1&quot;</span><br><span class="line">echo &quot;1&quot;</span><br><span class="line">echo &quot;1&quot;</span><br><span class="line">echo &quot;1&quot;</span><br><span class="line">echo &quot;1&quot;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">echo 2</span><br></pre></td></tr></table></figure><p>:&lt;&lt;EOF 和 EOF 之间为注释内容，脚本只能输出一个”2“</p><h3 id="延伸用法"><a href="#延伸用法" class="headerlink" title="延伸用法"></a>延伸用法</h3><ul><li>“:” 代表就是什么都不做，即空命令</li></ul><p>如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">if [ -d $TEST ]; then</span><br><span class="line">    :</span><br><span class="line">else</span><br><span class="line">    echo &apos;the directory do not exit !&apos;</span><br><span class="line">fi</span><br></pre></td></tr></table></figure><ul><li>&lt;&lt; 可以用作菜单</li></ul><p>如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">#!/bin/bash</span><br><span class="line"></span><br><span class="line">cat &lt;&lt;Menu</span><br><span class="line">1. List</span><br><span class="line">2. Help</span><br><span class="line">3. Exit</span><br><span class="line">Menu</span><br></pre></td></tr></table></figure><p>脚本输出内容就是：  </p><ol><li>List</li><li>Help</li><li>Exit</li></ol>]]></content>
      
      <categories>
          
          <category> shell </category>
          
      </categories>
      
      
        <tags>
            
            <tag> shell </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>nginx日志输出json格式</title>
      <link href="/nginx-access-json/"/>
      <url>/nginx-access-json/</url>
      <content type="html"><![CDATA[<!--<center><img style="width:1400px;height:300px" src="https://w.wallhaven.cc/full/dg/wallhaven-dgkzmj.jpg" align=center /></center>--><p>nginx 默认输出acces日志格式是message格式。现在都做日志统一分析ELK了，message格式就不是很适用了。 所以输出json格式对于后期分析就很友好了。</p><p>其他就不说了，直接上配置了</p><p>修改 nginx.conf 配置文件， 注释掉之前 log_format 重新写一个 json格式的log_format</p><a id="more"></a><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">#log_format  main  &apos;$hostname $server_name $remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos;</span><br><span class="line"> #                 &apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos;</span><br><span class="line"> #                 &apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot; &quot;$upstream_addr&quot; &apos;</span><br><span class="line"> #                 &apos;&quot;$upstream_response_time&quot; &quot;$request_time&quot; &quot;$http_cookie&quot;&apos;;</span><br><span class="line"></span><br><span class="line">log_format main   &apos;&#123;&quot;@timestamp&quot;:&quot;$time_iso8601&quot;,&apos;</span><br><span class="line">                    &apos;&quot;@source&quot;:&quot;$server_addr&quot;,&apos;</span><br><span class="line">                    &apos;&quot;hostname&quot;:&quot;$hostname&quot;,&apos;</span><br><span class="line">                    &apos;&quot;remote_user&quot;:&quot;$remote_user&quot;,&apos;</span><br><span class="line">                    &apos;&quot;ip&quot;:&quot;$http_x_forwarded_for&quot;,&apos;</span><br><span class="line">                    &apos;&quot;client&quot;:&quot;$remote_addr&quot;,&apos;</span><br><span class="line">                    &apos;&quot;request_method&quot;:&quot;$request_method&quot;,&apos;</span><br><span class="line">                    &apos;&quot;scheme&quot;:&quot;$scheme&quot;,&apos;</span><br><span class="line">                    &apos;&quot;domain&quot;:&quot;$server_name&quot;,&apos;</span><br><span class="line">                    &apos;&quot;referer&quot;:&quot;$http_referer&quot;,&apos;</span><br><span class="line">                    &apos;&quot;request&quot;:&quot;$request_uri&quot;,&apos;</span><br><span class="line">                    &apos;&quot;requesturl&quot;:&quot;$request&quot;,&apos;</span><br><span class="line">                    &apos;&quot;args&quot;:&quot;$args&quot;,&apos;</span><br><span class="line">                    &apos;&quot;size&quot;:$body_bytes_sent,&apos;</span><br><span class="line">                    &apos;&quot;status&quot;: $status,&apos;</span><br><span class="line">                    &apos;&quot;responsetime&quot;:$request_time,&apos;</span><br><span class="line">                    &apos;&quot;upstreamtime&quot;:&quot;$upstream_response_time&quot;,&apos;</span><br><span class="line">                    &apos;&quot;upstreamaddr&quot;:&quot;$upstream_addr&quot;,&apos;</span><br><span class="line">                    &apos;&quot;http_user_agent&quot;:&quot;$http_user_agent&quot;,&apos;</span><br><span class="line">                    &apos;&quot;http_cookie&quot;:&quot;$http_cookie&quot;,&apos;</span><br><span class="line">                    &apos;&quot;https&quot;:&quot;$https&quot;&apos;</span><br><span class="line">                    &apos;&#125;&apos;;</span><br><span class="line"></span><br><span class="line">access_log  /var/log/nginx/access.log  main;</span><br></pre></td></tr></table></figure><p>重新加载nginx，这样日志就是json格式了</p>]]></content>
      
      <categories>
          
          <category> nginx </category>
          
      </categories>
      
      
        <tags>
            
            <tag> nginx </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>直接在nginx配置文件中配置切分日志</title>
      <link href="/nginx-access-split/"/>
      <url>/nginx-access-split/</url>
      <content type="html"><![CDATA[<p>最近我们nginx上来容器，日志实时传走，但是本地还需要留一份另作他用，这样用原来logrotate或cronolog方式切分日志就很麻烦了， 我就开始再nginx配置文件中想办法。</p><p>发现可以利用 $time_iso8601 变量来切分日志， 它就是每条日志的时间戳，取它的年、月、日、小时做变量，生成带时间戳得日志文件。就可以每小时、每天输出到不同文件里了。</p><ul><li>请注意，不可能在error_log指令中嵌入变量，因为如果无法写入文件，则无法记录任何潜在错误。  这种方法只适用于access得日志</li></ul><h4 id="time-iso8601-时间格式"><a href="#time-iso8601-时间格式" class="headerlink" title="time_iso8601 时间格式"></a>time_iso8601 时间格式</h4><p>这是一个显示 $time_iso8601格式的示例：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">2019-05-04T18:12:02+02:00</span><br></pre></td></tr></table></figure><a id="more"></a><h4 id="配置方法"><a href="#配置方法" class="headerlink" title="配置方法"></a>配置方法</h4><p>所有要做的就是使用“if”块来使用正则表达式分割所需的数据并设置时间变量。<br>要按日拆分日志，可以在服务器块中使用以下代码段：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">if ($time_iso8601 ~ &quot;^(\d&#123;4&#125;)-(\d&#123;2&#125;)-(\d&#123;2&#125;)&quot;) &#123;</span><br><span class="line">set $year $1;</span><br><span class="line">set $month $2;</span><br><span class="line">set $day $3;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">access_log /var/log/nginx/$year-$month-$day-access.log;</span><br></pre></td></tr></table></figure><p>或者，我们也可以使用Perl兼容语法进行命名正则表达式捕获：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">if ($time_iso8601 ~ &quot;^(?&lt;year&gt;\d&#123;4&#125;)-(?&lt;month&gt;\d&#123;2&#125;)-(?&lt;day&gt;\d&#123;2&#125;)&quot;) &#123;&#125;</span><br><span class="line"></span><br><span class="line">access_log /var/log/nginx/$year-$month-$day-access.log;</span><br></pre></td></tr></table></figure><p>要创建小时，分钟和秒的变量，我们可以使用以下代码段：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">if ($time_iso8601 ~ &quot;^(\d&#123;4&#125;)-(\d&#123;2&#125;)-(\d&#123;2&#125;)T(\d&#123;2&#125;):(\d&#123;2&#125;):(\d&#123;2&#125;)&quot;) &#123;</span><br><span class="line">set $year $1;</span><br><span class="line">set $month $2;</span><br><span class="line">set $day $3;</span><br><span class="line">set $hour $4;</span><br><span class="line">set $minutes $5;</span><br><span class="line">set $seconds $6;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h4><ul><li><p>当access_log文件路径包含变量时，缓冲写入不起作用，因此无法动态gzip日志。</p></li><li><p>if 模块无法再全局变量中使用，只能在 server {} 下 配置，</p></li></ul><h4 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h4><p>所以我的用法是， 每个域名都按小时单独生成自己的文件。 再外面写好配置， 每个server里include日志得配置即可。</p><p>再nginx配置目录中生成一个配置文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">vim log_format.conf</span><br><span class="line"></span><br><span class="line">if ($time_iso8601 ~ &quot;^(\d&#123;4&#125;)-(\d&#123;2&#125;)-(\d&#123;2&#125;)T(\d&#123;2&#125;):(\d&#123;2&#125;):(\d&#123;2&#125;)&quot;) &#123;</span><br><span class="line">        set $year $1;</span><br><span class="line">        set $month $2;</span><br><span class="line">        set $day $3;</span><br><span class="line">        set $hour $4;</span><br><span class="line">&#125;</span><br><span class="line">access_log /home/nginx/logs/$&#123;server_name&#125;_$&#123;year&#125;-$&#123;month&#125;-$&#123;day&#125;-$&#123;hour&#125;_access.log main;</span><br></pre></td></tr></table></figure><p>每个Server中include这个配置文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">upstream test-shining.com &#123;</span><br><span class="line">        server 192.168.1.2:9250;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">##################   server name ################</span><br><span class="line">server &#123;</span><br><span class="line">    listen       80;</span><br><span class="line">    server_name  test.shining.com;</span><br><span class="line">    include log_format.conf;</span><br><span class="line">    proxy_connect_timeout 30;  #nginx跟后端服务器连接超时时间(代理连接超时)</span><br><span class="line">    proxy_read_timeout 600;  #连接成功后，后端服务器响应时间(代理接收超时)</span><br><span class="line">    proxy_send_timeout 600;  #后端服务器数据回传时间(代理发送超时)</span><br><span class="line">    location / &#123;</span><br><span class="line">        include proxy_set_header.conf;</span><br><span class="line">        proxy_pass    http://test-shining.com.com/;</span><br><span class="line">        proxy_redirect off; </span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      <categories>
          
          <category> nginx </category>
          
      </categories>
      
      
        <tags>
            
            <tag> nginx </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>pycharm2019最新激活方式（转）</title>
      <link href="/pycharm-activation/"/>
      <url>/pycharm-activation/</url>
      <content type="html"><![CDATA[<!--<center><img style="width:900px;height:300px" src="https://w.wallhaven.cc/full/83/wallhaven-83kyz1.jpg" align=center /></center>--><p>pyCharm2019最新激活码，win, linux, mac 都可使用，亲测可用。激活步骤如下：</p><h4 id="添加-hosts-解析"><a href="#添加-hosts-解析" class="headerlink" title="添加 hosts 解析"></a>添加 hosts 解析</h4><p>添加下面一行到hosts文件，目的是屏蔽掉Pycharm对激活码的验证</p><ul><li>windwos系统hosts文件路径为：C:\Windows\System32\drivers\etc<br>如果遇到权限问题，可将hosts文件先复制出来修改后再覆盖原来的即可。</li><li>Linux和mac的hosts文件路径为：/etc/hosts , 如有权限问题。可以用 sudo vim /etc/hosts</li></ul><p>添加一条解析记录：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">0.0.0.0account.jetbrains.com</span><br></pre></td></tr></table></figure><a id="more"></a><h4 id="pycharm-激活"><a href="#pycharm-激活" class="headerlink" title="pycharm 激活"></a>pycharm 激活</h4><p>打开PyCharm，选择 Activate code（用激活码激活）</p><p>输入激活码：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">56ZS5PQ1RF-eyJsaWNlbnNlSWQiOiI1NlpTNVBRMVJGIiwibGljZW5zZWVOYW1lIjoi5q2j54mI5o6I5p2DIC4iLCJhc3NpZ25lZU5hbWUiOiIiLCJhc3NpZ25lZUVtYWlsIjoiIiwibGljZW5zZVJlc3RyaWN0aW9uIjoiRm9yIGVkdWNhdGlvbmFsIHVzZSBvbmx5IiwiY2hlY2tDb25jdXJyZW50VXNlIjpmYWxzZSwicHJvZHVjdHMiOlt7ImNvZGUiOiJJSSIsInBhaWRVcFRvIjoiMjAyMC0wMy0xMCJ9LHsiY29kZSI6IkFDIiwicGFpZFVwVG8iOiIyMDIwLTAzLTEwIn0seyJjb2RlIjoiRFBOIiwicGFpZFVwVG8iOiIyMDIwLTAzLTEwIn0seyJjb2RlIjoiUFMiLCJwYWlkVXBUbyI6IjIwMjAtMDMtMTAifSx7ImNvZGUiOiJHTyIsInBhaWRVcFRvIjoiMjAyMC0wMy0xMCJ9LHsiY29kZSI6IkRNIiwicGFpZFVwVG8iOiIyMDIwLTAzLTEwIn0seyJjb2RlIjoiQ0wiLCJwYWlkVXBUbyI6IjIwMjAtMDMtMTAifSx7ImNvZGUiOiJSUzAiLCJwYWlkVXBUbyI6IjIwMjAtMDMtMTAifSx7ImNvZGUiOiJSQyIsInBhaWRVcFRvIjoiMjAyMC0wMy0xMCJ9LHsiY29kZSI6IlJEIiwicGFpZFVwVG8iOiIyMDIwLTAzLTEwIn0seyJjb2RlIjoiUEMiLCJwYWlkVXBUbyI6IjIwMjAtMDMtMTAifSx7ImNvZGUiOiJSTSIsInBhaWRVcFRvIjoiMjAyMC0wMy0xMCJ9LHsiY29kZSI6IldTIiwicGFpZFVwVG8iOiIyMDIwLTAzLTEwIn0seyJjb2RlIjoiREIiLCJwYWlkVXBUbyI6IjIwMjAtMDMtMTAifSx7ImNvZGUiOiJEQyIsInBhaWRVcFRvIjoiMjAyMC0wMy0xMCJ9LHsiY29kZSI6IlJTVSIsInBhaWRVcFRvIjoiMjAyMC0wMy0xMCJ9XSwiaGFzaCI6IjEyMjkxNDk4LzAiLCJncmFjZVBlcmlvZERheXMiOjAsImF1dG9Qcm9sb25nYXRlZCI6ZmFsc2UsImlzQXV0b1Byb2xvbmdhdGVkIjpmYWxzZX0=-SYSsDcgL1WJmHnsiGaHUWbaZLPIe2oI3QiIneDtaIbh/SZOqu63G7RGudSjf3ssPb1zxroMti/bK9II1ugHz/nTjw31Uah7D0HqeaCO7Zc0q9BeHysiWmBZ+8bABs5vr25GgIa5pO7CJhL7RitXQbWpAajrMBAeZ2En3wCgNwT6D6hNmiMlhXsWgwkw2OKnyHZ2dl8yEL+oV5SW14t7bdjYGKQrYjSd4+2zc4FnaX88yLnGNO9B3U6G+BuM37pxS5MjHrkHqMTK8W3I66mIj6IB6dYXD5nvKKO1OZREBAr6LV0BqRYSbuJKFhZ8nd6YDG20GvW6leimv0rHVBFmA0w==-MIIElTCCAn2gAwIBAgIBCTANBgkqhkiG9w0BAQsFADAYMRYwFAYDVQQDDA1KZXRQcm9maWxlIENBMB4XDTE4MTEwMTEyMjk0NloXDTIwMTEwMjEyMjk0NlowaDELMAkGA1UEBhMCQ1oxDjAMBgNVBAgMBU51c2xlMQ8wDQYDVQQHDAZQcmFndWUxGTAXBgNVBAoMEEpldEJyYWlucyBzLnIuby4xHTAbBgNVBAMMFHByb2QzeS1mcm9tLTIwMTgxMTAxMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAxcQkq+zdxlR2mmRYBPzGbUNdMN6OaXiXzxIWtMEkrJMO/5oUfQJbLLuMSMK0QHFmaI37WShyxZcfRCidwXjot4zmNBKnlyHodDij/78TmVqFl8nOeD5+07B8VEaIu7c3E1N+e1doC6wht4I4+IEmtsPAdoaj5WCQVQbrI8KeT8M9VcBIWX7fD0fhexfg3ZRt0xqwMcXGNp3DdJHiO0rCdU+Itv7EmtnSVq9jBG1usMSFvMowR25mju2JcPFp1+I4ZI+FqgR8gyG8oiNDyNEoAbsR3lOpI7grUYSvkB/xVy/VoklPCK2h0f0GJxFjnye8NT1PAywoyl7RmiAVRE/EKwIDAQABo4GZMIGWMAkGA1UdEwQCMAAwHQYDVR0OBBYEFGEpG9oZGcfLMGNBkY7SgHiMGgTcMEgGA1UdIwRBMD+AFKOetkhnQhI2Qb1t4Lm0oFKLl/GzoRykGjAYMRYwFAYDVQQDDA1KZXRQcm9maWxlIENBggkA0myxg7KDeeEwEwYDVR0lBAwwCgYIKwYBBQUHAwEwCwYDVR0PBAQDAgWgMA0GCSqGSIb3DQEBCwUAA4ICAQAF8uc+YJOHHwOFcPzmbjcxNDuGoOUIP+2h1R75Lecswb7ru2LWWSUMtXVKQzChLNPn/72W0k+oI056tgiwuG7M49LXp4zQVlQnFmWU1wwGvVhq5R63Rpjx1zjGUhcXgayu7+9zMUW596Lbomsg8qVve6euqsrFicYkIIuUu4zYPndJwfe0YkS5nY72SHnNdbPhEnN8wcB2Kz+OIG0lih3yz5EqFhld03bGp222ZQCIghCTVL6QBNadGsiN/lWLl4JdR3lJkZzlpFdiHijoVRdWeSWqM4y0t23c92HXKrgppoSV18XMxrWVdoSM3nuMHwxGhFyde05OdDtLpCv+jlWf5REAHHA201pAU6bJSZINyHDUTB+Beo28rRXSwSh3OUIvYwKNVeoBY+KwOJ7WnuTCUq1meE6GkKc4D/cXmgpOyW/1SmBz3XjVIi/zprZ0zf3qH5mkphtg6ksjKgKjmx1cXfZAAX6wcDBNaCL+Ortep1Dh8xDUbqbBVNBL4jbiL3i3xsfNiyJgaZ5sX7i8tmStEpLbPwvHcByuf59qJhV/bZOl8KqJBETCDJcY6O2aqhTUy+9x93ThKs1GKrRPePrWPluud7ttlgtRveit/pcBrnQcXOl1rHq7ByB8CFAxNotRUYL9IF5n3wJOgkPojMy6jetQA5Ogc8Sm7RG6vg1yow==</span><br></pre></td></tr></table></figure><p>复制上面的激活码，填入激活码框，点击 OK 进行认证。目前这个激活码有效期至2020年3月11日</p>]]></content>
      
      <categories>
          
          <category> python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>marathon强制删除任务，app、deployment、task</title>
      <link href="/marathon-delete-app/"/>
      <url>/marathon-delete-app/</url>
      <content type="html"><![CDATA[<center><br><img style="width:1400px;height:200px" src="https://i.ibb.co/cCTGnWK/logo-00002.png" align="center"><br></center><p>Marathon上的任务可能会因为其他原因，卡在那，不能被删除掉， 一直在deployment。这时候我们需要强制删除掉。</p><h4 id="强制杀掉-deployment"><a href="#强制杀掉-deployment" class="headerlink" title="强制杀掉 deployment"></a>强制杀掉 deployment</h4><p>删除deployment上的任务，需要知道deployment上的id</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">marathonAddr=&quot;http://192.168.0.11:8080&quot;;</span><br><span class="line">deployment_id=&quot;14eed224-6f75-41fs-8339-ce6a758sdfr32&quot;;</span><br><span class="line">apiPath=&quot;/v2/deployments/$&#123;deployment_id&#125;&quot;</span><br><span class="line">curl -X DELETE $&#123;marathonAddr&#125;$&#123;apiPath&#125;?force=true</span><br></pre></td></tr></table></figure><p>这样就可以再命令行上删除deployment上的任务了， </p><a id="more"></a><h4 id="强制杀掉-app-task"><a href="#强制杀掉-app-task" class="headerlink" title="强制杀掉 app task"></a>强制杀掉 app task</h4><p>需要知道task的id</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">marathonAddr=&quot;http://192.168.0.11:8080&quot;&quot;;</span><br><span class="line">app_id=&quot;shining-test&quot;</span><br><span class="line">task_id=&quot;shining-test.8c873ce2-ad63-11e7-a70d-36d30528411f&quot;</span><br><span class="line">apiPath=&quot;/v2/apps/$&#123;app_id&#125;/tasks/$&#123;task_id&#125;&quot;</span><br><span class="line">curl -X DELETE $&#123;marathonAddr&#125;$&#123;apiPath&#125;?force=true</span><br></pre></td></tr></table></figure><p>例如 删除 job</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">curl -X DELETE http://192.168.0.11:8080/v2/apps/mysql-io-test -H &quot;Content-type: application/json&quot;</span><br><span class="line"></span><br><span class="line">强制删除</span><br><span class="line">curl -X DELETE http://192.168.0.11:8080/v2/apps/mysql-io-test?force=true  -H &quot;Content-type: application/json&quot;</span><br></pre></td></tr></table></figure><h4 id="页面执行删除"><a href="#页面执行删除" class="headerlink" title="页面执行删除"></a>页面执行删除</h4><p>进入marathon API 接口</p><p><img src="/images/marathon-api-1.jpeg" alt="api"></p><p>deployment delete</p><p><img src="/images/marathon-api-2.jpeg" alt="api"></p><p><img src="/images/marathon-api-3.jpeg" alt="api"></p><p>app task delete</p><p><img src="/images/marathon-api-4.jpeg" alt="api"></p><p><img src="/images/marathon-api-5.jpeg" alt="api"></p>]]></content>
      
      <categories>
          
          <category> marathon </category>
          
      </categories>
      
      
        <tags>
            
            <tag> marathon </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>rsync、wget本地拉取yum源</title>
      <link href="/rsync-wget-yum-rpm/"/>
      <url>/rsync-wget-yum-rpm/</url>
      <content type="html"><![CDATA[<h1 id="rsync、wget本地拉取yum源"><a href="#rsync、wget本地拉取yum源" class="headerlink" title="rsync、wget本地拉取yum源"></a>rsync、wget本地拉取yum源</h1><!--<center><img style="width:1400px;height:200px" src="https://w.wallhaven.cc/full/kw/wallhaven-kw1geq.jpg" align=center /></center>--><p>我们本地搭建yum源的时候，需要从官网拉取所有rrpm包到本地。再创建repo。这时候我们需要批量下载的方法。 有的镜像源提供了rsync接口，我们可以用rsync同步。没有的话我们可以用wget下载。</p><p>centos 官网提供了所有的镜像地址 list，<a href="https://www.centos.org/download/mirrors/" target="_blank" rel="noopener">https://www.centos.org/download/mirrors/</a><br>可以上着上选择可以用的镜像地址</p><p>后面有rsync的地址的镜像源，我们就可以使用rsync</p><h4 id="rsync-方法"><a href="#rsync-方法" class="headerlink" title="rsync 方法"></a>rsync 方法</h4><p>现在说一下rsync。 rsync同步还是比较简单的。 找到提供rsync接口的镜像源。之后再找到你要的系统相应的版本。</p><a id="more"></a><p><img src="/images/rsync-yum-list.jpeg" alt="rsync-list"></p><p>同步到本地命令：</p><p>只同步os下的rpm包</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rsync -zvaP  rsync://repos-jnb.psychz.net/Centos/7.5.1804/os/x86_64/Packages/  /home/7.5/os/packages</span><br></pre></td></tr></table></figure><p>同步所有的rpm（包括os、update、extras,isos等）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rsync -zvaP rsync://repos-jnb.psychz.net/Centos/7.5.1804/ /home/centos-7.5.1804/</span><br></pre></td></tr></table></figure><h4 id="wget-方法"><a href="#wget-方法" class="headerlink" title="wget 方法"></a>wget 方法</h4><p>wget 可以用户http的镜像源地址。</p><p>wget 下载命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># wget -r -p -np -k http://repos-jnb.psychz.net/centos/7.5.1804/paas/x86_64/openshift-origin13/</span><br></pre></td></tr></table></figure><h5 id="wget-参数说明"><a href="#wget-参数说明" class="headerlink" title="wget 参数说明"></a>wget 参数说明</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">-c, --continue resume getting a partially-downloaded file. 断点续传</span><br><span class="line">-nd, --no-directories don&apos;t create directories. 不创建层级目录，所有文件下载到当前目录</span><br><span class="line">-r, --recursive specify recursive download. 递归下载</span><br><span class="line">-p, --page-requisites get all images, etc. needed to display HTML page.</span><br><span class="line">下载页面所有文件，使页面能在本地打开</span><br><span class="line">-k, --convert-links make links in downloaded HTML or CSS point to local files.</span><br><span class="line">转换链接指向本地文件</span><br><span class="line">-np, --no-parent don&apos;t ascend to the parent directory. 不下载父级目录的文件</span><br><span class="line">-o, --output-file=FILE log messages to FILE. 指定日志输出文件</span><br><span class="line">-O, --output-document=FILE write documents to FILE. 指定文件下载位置</span><br><span class="line">-L, --relative follow relative links only. 只下载相对链接，如果页面嵌入其他站点不会被下载</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">wget -r -p -np -k -P . linux.csie.nctu.edu.tw</span><br><span class="line">-P 表示下载到哪个目录</span><br><span class="line">-r 表示递归下载 </span><br><span class="line">-np 表示不下载旁站连接. </span><br><span class="line">-k 表示将下载的网页里的链接修改为本地链接.</span><br><span class="line">-p 获得所有显示网页所需的元素</span><br></pre></td></tr></table></figure>]]></content>
      
      <categories>
          
          <category> linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> linux </tag>
            
            <tag> shell </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Hadoop日志按天分割和开启审计日志</title>
      <link href="/hadoop-log-segmentation/"/>
      <url>/hadoop-log-segmentation/</url>
      <content type="html"><![CDATA[<h1 id="Hadoop日志按天分割和开启审计日志"><a href="#Hadoop日志按天分割和开启审计日志" class="headerlink" title="Hadoop日志按天分割和开启审计日志"></a>Hadoop日志按天分割和开启审计日志</h1><h2 id="日志按天分割"><a href="#日志按天分割" class="headerlink" title="日志按天分割"></a>日志按天分割</h2><p>hadoop 各个组件默认日志是大小分割的，到一定大小就分割出 .1  .2  .3  .4这样的文件，这样我们在查找问题的时候不是好定位你要的那天日志在哪个文件中。要是一天一个文件，按照日志的话就很好定位了。</p><p>在这里介绍一下hadoop按天切分日志的方法。</p><h3 id="方法一-修改变量"><a href="#方法一-修改变量" class="headerlink" title="方法一 修改变量"></a>方法一 修改变量</h3><h5 id="hbase"><a href="#hbase" class="headerlink" title="hbase"></a>hbase</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hbase-env.sh</span><br><span class="line">添加：</span><br><span class="line">export HBASE_ROOT_LOGGER=INFO,DRFA</span><br></pre></td></tr></table></figure><a id="more"></a><h5 id="hdfs"><a href="#hdfs" class="headerlink" title="hdfs"></a>hdfs</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">hadoop-env.sh</span><br><span class="line">修改：</span><br><span class="line">export HADOOP_ROOT_LOGGER=INFO,DRFA</span><br><span class="line">export HADOOP_NAMENODE_OPTS=&quot;-Dhadoop.security.logger=$&#123;HADOOP_SECURITY_LOGGER:-INFO,DRFAS&#125; -Dhdfs.audit.logger=$&#123;HDFS_AUDIT_LOGGER:-INFO,DRFAAUDIT&#125; $HADOOP_NAMENODE_OPTS&quot;</span><br><span class="line">export HADOOP_DATANODE_OPTS=&quot;-Dhadoop.security.logger=INFO,DRFAS $HADOOP_DATANODE_OPTS&quot;</span><br></pre></td></tr></table></figure><h5 id="yarn"><a href="#yarn" class="headerlink" title="yarn"></a>yarn</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">yarn-env.sh</span><br><span class="line">添加：</span><br><span class="line">export YARN_ROOT_LOGGER=INFO,DRFA</span><br></pre></td></tr></table></figure><h4 id="方法二-修改启动脚本"><a href="#方法二-修改启动脚本" class="headerlink" title="方法二 修改启动脚本"></a>方法二 修改启动脚本</h4><h5 id="hdfs-1"><a href="#hdfs-1" class="headerlink" title="hdfs"></a>hdfs</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">export HADOOP_ROOT_LOGGER=$&#123;HADOOP_ROOT_LOGGER:-&quot;INFO,RFA&quot;&#125;</span><br><span class="line">export HADOOP_SECURITY_LOGGER=$&#123;HADOOP_SECURITY_LOGGER:-&quot;INFO,RFAS&quot;&#125;</span><br><span class="line">export HDFS_AUDIT_LOGGER=$&#123;HDFS_AUDIT_LOGGER:-&quot;INFO,NullAppender&quot;&#125;</span><br><span class="line">改为：</span><br><span class="line">export HADOOP_ROOT_LOGGER=$&#123;HADOOP_ROOT_LOGGER:-&quot;INFO,DRFA&quot;&#125;</span><br><span class="line">#开启hdfs审计日志</span><br><span class="line">export HADOOP_SECURITY_LOGGER=$&#123;HADOOP_SECURITY_LOGGER:-&quot;INFO,DRFAS&quot;&#125;</span><br><span class="line">export HDFS_AUDIT_LOGGER=$&#123;HDFS_AUDIT_LOGGER:-&quot;INFO,DRFAAUDIT&quot;&#125;</span><br></pre></td></tr></table></figure><h5 id="yarn-1"><a href="#yarn-1" class="headerlink" title="yarn"></a>yarn</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">修改yarn-darmon.sh下面</span><br><span class="line">export YARN_ROOT_LOGGER=$&#123;YARN_ROOT_LOGGER:-INFO,RFA&#125;</span><br><span class="line">为</span><br><span class="line">export YARN_ROOT_LOGGER=$&#123;YARN_ROOT_LOGGER:-INFO,DRFA&#125;</span><br></pre></td></tr></table></figure><h5 id="hbase-1"><a href="#hbase-1" class="headerlink" title="hbase"></a>hbase</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">export HBASE_ROOT_LOGGER=$&#123;HBASE_ROOT_LOGGER:-&quot;INFO,RFA&quot;&#125;</span><br><span class="line">export HBASE_SECURITY_LOGGER=$&#123;HBASE_SECURITY_LOGGER:-&quot;INFO,RFAS&quot;&#125;</span><br><span class="line"></span><br><span class="line">为：</span><br><span class="line">export HBASE_ROOT_LOGGER=$&#123;HBASE_ROOT_LOGGER:-&quot;INFO,DRFA&quot;&#125;</span><br><span class="line">export HBASE_SECURITY_LOGGER=$&#123;HBASE_SECURITY_LOGGER:-&quot;INFO,DRFAS&quot;&#125;(无法直接修改，log4里没有配置，需要添加day日志配置)</span><br></pre></td></tr></table></figure><h2 id="审计日志"><a href="#审计日志" class="headerlink" title="审计日志"></a>审计日志</h2><h4 id="hdfs-日审计日志"><a href="#hdfs-日审计日志" class="headerlink" title="hdfs 日审计日志"></a>hdfs 日审计日志</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">hdfs.audit.logger=INFO,console</span><br><span class="line">hdfs.audit.log.maxfilesize=256MB</span><br><span class="line">hdfs.audit.log.maxbackupindex=20</span><br><span class="line">log4j.logger.org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit=$&#123;hdfs.audit.logger&#125;</span><br><span class="line">log4j.additivity.org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit=false</span><br><span class="line">log4j.appender.DRFAAUDIT=org.apache.log4j.DailyRollingFileAppender</span><br><span class="line">log4j.appender.DRFAAUDIT.File=$&#123;hadoop.log.dir&#125;/hdfs-audit.log</span><br><span class="line">log4j.appender.DRFAAUDIT.layout=org.apache.log4j.PatternLayout</span><br><span class="line">log4j.appender.DRFAAUDIT.layout.ConversionPattern=%d&#123;ISO8601&#125; %p %c&#123;2&#125;: %m%n</span><br><span class="line">log4j.appender.DRFAAUDIT.DatePattern=.yyyy-MM-dd</span><br></pre></td></tr></table></figure><h4 id="hbase的日审计日志"><a href="#hbase的日审计日志" class="headerlink" title="hbase的日审计日志"></a>hbase的日审计日志</h4><p>log4j.properties</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">hbase.security.log.file=SecurityAuth.audit</span><br><span class="line">hbase.security.log.maxfilesize=256MB</span><br><span class="line">hbase.security.log.maxbackupindex=20</span><br><span class="line">log4j.category.SecurityLogger=$&#123;hbase.security.logger&#125;</span><br><span class="line">log4j.appender.DRFAS=org.apache.log4j.DailyRollingFileAppender</span><br><span class="line">log4j.appender.DRFAS.File=$&#123;hbase.log.dir&#125;/$&#123;hbase.security.log.file&#125;</span><br><span class="line">log4j.appender.DRFAS.layout=org.apache.log4j.PatternLayout</span><br><span class="line">log4j.appender.DRFAS.layout.ConversionPattern=%d&#123;ISO8601&#125; %p %c: %m%n</span><br><span class="line">log4j.appender.DRFAS.DatePattern=.yyyy-MM-dd</span><br><span class="line">log4j.additivity.SecurityLogger=true</span><br><span class="line">log4j.logger.SecurityLogger.org.apache.hadoop.hbase.security.access.AccessController=TRACE</span><br></pre></td></tr></table></figure><p>同时需要配置 hbase-site.xml</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;hbase.rpc.engine&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;org.apache.hadoop.hbase.ipc.SecureRpcEngine&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;hbase.coprocessor.master.classes&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;org.apache.hadoop.hbase.security.access.AccessController&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;hbase.coprocessor.region.classes&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;org.apache.hadoop.hbase.security.token.TokenProvider,org.apache.hadoop.hbase.security.access.AccessController&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line"> &lt;name&gt;hbase.superuser&lt;/name&gt;</span><br><span class="line"> &lt;value&gt;hadoop&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">      &lt;name&gt;hbase.security.authorization&lt;/name&gt;</span><br><span class="line">      &lt;value&gt;false&lt;/value&gt;  &lt;!-- 如果值为true，默认每个用户只能访问当前的表。而之前创建的member表的属主是HBase，其他用户对其没有访问权限，需要超级用户为其赋权 --&gt;</span><br><span class="line">  &lt;/property&gt;</span><br></pre></td></tr></table></figure>]]></content>
      
      <categories>
          
          <category> hadoop </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hadoop </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>hive创建一个简单外联表</title>
      <link href="/hive-external-table/"/>
      <url>/hive-external-table/</url>
      <content type="html"><![CDATA[<h1 id="hive-创建一个简单外联表"><a href="#hive-创建一个简单外联表" class="headerlink" title="hive 创建一个简单外联表"></a>hive 创建一个简单外联表</h1><h4 id="hdfs-创建目录"><a href="#hdfs-创建目录" class="headerlink" title="hdfs 创建目录"></a>hdfs 创建目录</h4><p>首先需要在hdfs上创建一个目录，用于存放hive表得数据。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs -mkdir /tmp/yarn-count-application</span><br></pre></td></tr></table></figure><h4 id="hive-创建表"><a href="#hive-创建表" class="headerlink" title="hive 创建表"></a>hive 创建表</h4><p>这时候可以再hive上创建外联表了。 </p><a id="more"></a><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">create external table op_count_yarn(</span><br><span class="line">dt string,</span><br><span class="line">num int</span><br><span class="line">)</span><br><span class="line">ROW FORMAT DELIMITED FIELDS TERMINATED BY &apos;\t&apos; location &apos;/tmp/yarn-count-application&apos;;</span><br><span class="line"></span><br><span class="line">or</span><br><span class="line"></span><br><span class="line">create external table op_yarn_job(</span><br><span class="line">jobid string,</span><br><span class="line">jobuser string,</span><br><span class="line">queue string,</span><br><span class="line">submittime string,</span><br><span class="line">starttime string,</span><br><span class="line">finishtime string,</span><br><span class="line">elapsedtime bigint,</span><br><span class="line">totalmaps bigint,</span><br><span class="line">totalreduces bigint,</span><br><span class="line">finishmaps bigint,</span><br><span class="line">finishreduces bigint,</span><br><span class="line">failedmaps bigint,</span><br><span class="line">failedreducess bigint,</span><br><span class="line">hdfsread bigint,</span><br><span class="line">hdfswrite bigint,</span><br><span class="line">vcoremaps bigint,</span><br><span class="line">vcorereduces bigint,</span><br><span class="line">cpuseconds bigint,</span><br><span class="line">physicalmem bigint,</span><br><span class="line">virtualmem bigint,</span><br><span class="line">sql_urlencode string</span><br><span class="line">)</span><br><span class="line">PARTITIONED BY (dt string)</span><br><span class="line">ROW FORMAT DELIMITED FIELDS TERMINATED BY &apos;,&apos; location &apos;/home/hadoop/yarn-job-application&apos;;</span><br></pre></td></tr></table></figure><p>location 指向 hdfs 上创建的目录就可以了</p><h4 id="产生数据"><a href="#产生数据" class="headerlink" title="产生数据"></a>产生数据</h4><p>把你需要的数据放在hdfs得目录下</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs -put hour_all_count.txt /tmp/yarn-count-application/</span><br></pre></td></tr></table></figure><h4 id="查询数据"><a href="#查询数据" class="headerlink" title="查询数据"></a>查询数据</h4><p>这时候就可以用hive还查询数据量</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; select * from op_count_yarn;</span><br><span class="line">OK</span><br><span class="line">2018-12-19-19   707</span><br><span class="line">2018-12-19-20   818</span><br><span class="line">2018-12-19-21   801</span><br><span class="line">2018-12-19-22   1027</span><br><span class="line">2018-12-19-23   806</span><br><span class="line">2018-12-20-00   859</span><br><span class="line">2018-12-20-01   629</span><br><span class="line">2018-12-20-02   1058</span><br><span class="line">2018-12-20-03   1190</span><br><span class="line">2018-12-20-04   878</span><br><span class="line">2018-12-20-05   889</span><br><span class="line">2018-12-20-06   961</span><br><span class="line">2018-12-20-07   945</span><br><span class="line">2018-12-20-08   927</span><br><span class="line">2018-12-20-09   919</span><br><span class="line">Time taken: 1.063 seconds, Fetched: 15 row(s)</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; select sum(num) from op_count_yarn where dt like &quot;2018-12-20-%&quot;;</span><br><span class="line">......</span><br><span class="line">Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1</span><br><span class="line">2018-12-20 10:42:31,362 Stage-1 map = 0%,  reduce = 0%</span><br><span class="line">2018-12-20 10:42:32,432 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 4.75 sec</span><br><span class="line">MapReduce Total cumulative CPU time: 4 seconds 750 msec</span><br><span class="line">Ended Job = job_1534758460905_2857417</span><br><span class="line">MapReduce Jobs Launched: </span><br><span class="line">Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 4.75 sec   HDFS Read: 13354 HDFS Write: 594837 SUCCESS</span><br><span class="line">Total MapReduce CPU Time Spent: 4 seconds 750 msec</span><br><span class="line">OK</span><br><span class="line">9255</span><br><span class="line">Time taken: 13.764 seconds, Fetched: 1 row(s)</span><br></pre></td></tr></table></figure><p>查看分区</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">show partitions  op_yarn_job;</span><br></pre></td></tr></table></figure><p>添加分区</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">alter table default.op_yarn_job ADD if NOT exists partition(dt=&apos;$YY-$MM-$DD&apos;);</span><br></pre></td></tr></table></figure><p>删除分区</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ALTER TABLE  table_name DROP PARTITION (day=&apos;20140722&apos;);</span><br><span class="line"></span><br><span class="line">or</span><br><span class="line"></span><br><span class="line">alter table op_yarn_job drop if exists partition(dt=&apos;2018-12-23&apos;);</span><br></pre></td></tr></table></figure><p>查看是内部表还是外部表</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">describe extended tablename;</span><br><span class="line"></span><br><span class="line">or</span><br><span class="line"></span><br><span class="line">desc formatted tablename;</span><br></pre></td></tr></table></figure>]]></content>
      
      <categories>
          
          <category> hive </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hive </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>curl方式执行shell脚本时传参数</title>
      <link href="/curl-shell-args/"/>
      <url>/curl-shell-args/</url>
      <content type="html"><![CDATA[<p>有时候shell脚本可以放在http页面上，不用download，可以直接执行。</p><p>通常我们可以用curl的方式执行http页面上的shell脚本。 一般方式是：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl http://sukbeta.github.io/web/shell.sh | bash</span><br></pre></td></tr></table></figure><p>这样脚本就可以再本地机器上执行了。 </p><p>但是需要传入参数的脚本。我们可以用下面的方式传入shell参数</p><ul><li>-s方式</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl -s http://sukbeta.github.io/web/shell.sh | bash -s arg1 arg2</span><br></pre></td></tr></table></figure><a id="more"></a><ul><li>&lt; 方式</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bash &lt;(curl -s http://sukbeta.github.io/web/shell.sh) arg1 arg2</span><br></pre></td></tr></table></figure><blockquote><p>注意 &lt;( 之间不要有空格！！！</p></blockquote><ul><li>若参数中带有”-“，则可使用长选项”–”解决</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl -s http://sukbeta.github.io/web/shell.sh | bash -s -- arg1 arg2</span><br></pre></td></tr></table></figure><ul><li>若参数为”-p arg -d arg”,则可使用以下命令执行</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl -s http://sukbeta.github.io/web/shell.sh | bash -s -- -p arg1 -d arg2</span><br></pre></td></tr></table></figure><ul><li>不止是curl的输入，其他方式的输入也满足。可以通过以下例子深入理解下</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">echo &apos;i=1; for a in $@; do echo &quot;$i = $a&quot;; i=$((i+1)); done&apos; | bash -s -- -a1 -a2 -a3 --long some_text</span><br></pre></td></tr></table></figure>]]></content>
      
      <categories>
          
          <category> shell </category>
          
      </categories>
      
      
        <tags>
            
            <tag> shell </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>hadoop修改文件副本数</title>
      <link href="/hadoop-set-replication/"/>
      <url>/hadoop-set-replication/</url>
      <content type="html"><![CDATA[<h2 id="hadoop修改文件副本数"><a href="#hadoop修改文件副本数" class="headerlink" title="hadoop修改文件副本数"></a>hadoop修改文件副本数</h2><p>Hadoop上默认一个人间的副本数是3，这个也是可以再配置文件中&lt;dfs.replication&gt;参数修改的。</p><p>这里我们说一下，上传一个文件的时候更改文件的副本数。让他不用默认的副本数。</p><h4 id="上传文件"><a href="#上传文件" class="headerlink" title="上传文件"></a>上传文件</h4><p>命令上传文件，副本数为1</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop dfs -D dfs.replication=1 -put 123.lzo /temp/123.lzo</span><br></pre></td></tr></table></figure><h4 id="查看文件的副本数"><a href="#查看文件的副本数" class="headerlink" title="查看文件的副本数"></a>查看文件的副本数</h4><p>查看整的dfs上的文件副本数</p><a id="more"></a><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">$ hadoop fsck -locations</span><br><span class="line">....Status: HEALTHY</span><br><span class="line"> Total size:    86463643890 B (Total open files size: 415 B)</span><br><span class="line"> Total dirs:    93533</span><br><span class="line"> Total files:   200704</span><br><span class="line"> Total symlinks:                0 (Files currently being written: 6)</span><br><span class="line"> Total blocks (validated):      199798 (avg. block size 432755 B) (Total open file blocks (not validated): 5)</span><br><span class="line"> Minimally replicated blocks:   199798 (100.0 %)</span><br><span class="line"> Over-replicated blocks:        0 (0.0 %)</span><br><span class="line"> Under-replicated blocks:       2512 (1.2572699 %)</span><br><span class="line"> Mis-replicated blocks:         0 (0.0 %)</span><br><span class="line"> Default replication factor:    3</span><br><span class="line"> Average block replication:     2.9998398</span><br><span class="line"> Corrupt blocks:                0</span><br><span class="line"> Missing replicas:              17584 (2.8501685 %)</span><br><span class="line"> Number of data-nodes:          3</span><br><span class="line"> Number of racks:               1</span><br><span class="line">FSCK ended at Thu Mar 28 10:27:24 CST 2019 in 6372 milliseconds</span><br></pre></td></tr></table></figure><p>检查单个文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$  hadoop fsck -locations  /temp/123.lzo</span><br><span class="line"> .......</span><br><span class="line"> Default replication factor:    3</span><br><span class="line"> Average block replication:     1.0</span><br><span class="line"> ......</span><br></pre></td></tr></table></figure><h4 id="修改已经存在的文件副本数"><a href="#修改已经存在的文件副本数" class="headerlink" title="修改已经存在的文件副本数"></a>修改已经存在的文件副本数</h4><ul><li>修改已保存文件的副本数量，为2副本</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop dfs -setrep 2 /shining/test.txt</span><br></pre></td></tr></table></figure><ul><li>对文件夹中的所有文件都修改副本</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop dfs -setrep 2 -R /shining/</span><br></pre></td></tr></table></figure><ul><li>选项是-w，表示等待副本操作结束才退出命令</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop dfs -setrep -R -w 1 /shining</span><br></pre></td></tr></table></figure>]]></content>
      
      <categories>
          
          <category> hadoop </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hadoop </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>hadoop设置目录配额-setSpaceQuota</title>
      <link href="/hadoop-set-quota/"/>
      <url>/hadoop-set-quota/</url>
      <content type="html"><![CDATA[<h2 id="hadoop设置目录配额-setSpaceQuota"><a href="#hadoop设置目录配额-setSpaceQuota" class="headerlink" title="hadoop设置目录配额-setSpaceQuota"></a>hadoop设置目录配额-setSpaceQuota</h2><p>在多人共用HDFS的环境下，配置设置非常重要。特别是在Hadoop处理大量资料的环境，如果没有配额管理，很容易把所有的空间用完造成别人无法存取。Hdfs的配额设定是针对目标而不是针对账号，所有在管理上最好让每个账号仅操作某一个目录，然后对目录设置配置。</p><p>设定方法有两种：</p><ul><li>Name Quotas：设置某一个目录下文件总数</li><li>Space Quotas：设置某一个目录下可使用空间大小</li></ul><p>Hadoop可以通过该命令可以来限定某个hdfs目录的大小：</p><h5 id="设置配额"><a href="#设置配额" class="headerlink" title="设置配额"></a>设置配额</h5><p>设置100G的目录配额，</p><a id="more"></a><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop dfsadmin -setSpaceQuota 100g /user/shining</span><br></pre></td></tr></table></figure><p>设置为3m的目录配额，默认单位是字节</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop dfsadmin -setSpaceQuota 3000000 /temp/shining</span><br></pre></td></tr></table></figure><blockquote><p> 这里统计空间的时候会将备份数也考虑在里面，因为集群设置了备份数为3，所以hadoop dfsadmin -setSpaceQuota也要讲备份数考虑进去，</p></blockquote><blockquote><p> 在core-site.xml里面设置 dfs.block.size=64MB，dfs.replication=3 ，如果一个小文件（例如，1k大小的文件）被上传到hdfs，该文件并不能占满一整个blok，但是按照hdfs配置规则也需要按照一个blok计算，即存储空间为：1 x 64MB x 3 = 192MB</p></blockquote><h5 id="查看目录配额"><a href="#查看目录配额" class="headerlink" title="查看目录配额"></a>查看目录配额</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@shining-host~]$ hadoop fs -count -q /user/shining</span><br><span class="line">        none             inf    107374182400     66658430073           97         3512         5193489830 /user/shining</span><br><span class="line">        </span><br><span class="line">依次表示为：文件数限额  可用文件数  空间限额 可用空间 目录数  文件数  总大小 文件/目录名</span><br><span class="line"></span><br><span class="line">hadoop fs -count -q -h /user/shining  显示带单位</span><br></pre></td></tr></table></figure><h5 id="清楚配额"><a href="#清楚配额" class="headerlink" title="清楚配额"></a>清楚配额</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop dfsadmin -clrSpaceQuota /user/shining</span><br></pre></td></tr></table></figure><h5 id="设置文件数"><a href="#设置文件数" class="headerlink" title="设置文件数"></a>设置文件数</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">计算公式：QUOTA – (DIR_COUNT + FILE_COUNT) = REMAINING_QUOTA</span><br><span class="line">这里的 10000 是指 DIR_COUNT + FILE_COUNT = 10000，最大值為 Long.Max_Value       </span><br><span class="line">启用设定：hadoop dfsadmin -setQuota 10000 /user/seamon</span><br><span class="line">清除設定： hadoop dfsadmin -clrQuota /user/seamon</span><br></pre></td></tr></table></figure><h5 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h5><ul><li>hdfs的配额管理是跟着目录走，如果目录被重命名，配额依然有效。</li><li>在设置完配额以后，如果超过限制，虽然文件不会写入到hdfs，但是文件名依然会存在，只是文件size为0。当加大配额设置后，还需要将之前的空文件删除才能进一步写入。</li><li>如果新设置的quota值，小于该目录现有的Name Quotas 及 Space Quotas，系统并不会给出错误提示，但是该目录的配置会变成最新设置的quota</li></ul>]]></content>
      
      <categories>
          
          <category> hadoop </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hadoop </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>查看docker容器日志</title>
      <link href="/docker-logs-explantion/"/>
      <url>/docker-logs-explantion/</url>
      <content type="html"><![CDATA[<h2 id="查看docker容器日志"><a href="#查看docker容器日志" class="headerlink" title="查看docker容器日志"></a>查看docker容器日志</h2><p>通过docker logs命令可以查看容器的日志。</p><h4 id="docker-logs-日志说明"><a href="#docker-logs-日志说明" class="headerlink" title="docker logs 日志说明"></a>docker logs 日志说明</h4><p>当我们输入docker logs的时候会转化为Docker Client向Docker Daemon发起请求,Docker Daemon 在运行容器时会去创建一个协程(goroutine)，绑定了整个容器内所有进程的标准输出文件描述符。因此容器内应用的所有只要是标准输出日志，都会被 goroutine 接收，Docker Daemon会根据容器id和日志类型读取日志内容，最终会输出到用户终端上并且通过json格式存放在/var/lib/docker/containers目录下。</p><p>docker logs是跟随容器而产生的，如果删除了某个容器，相应的日志文件也会随着被删除</p><h4 id="命令说明"><a href="#命令说明" class="headerlink" title="命令说明"></a>命令说明</h4><p>命令格式</p><a id="more"></a><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ docker logs [OPTIONS] CONTAINER</span><br><span class="line">  Options:</span><br><span class="line">        --details        显示更多的信息</span><br><span class="line">    -f, --follow         跟踪实时日志</span><br><span class="line">        --since string   显示自某个timestamp之后的日志，或相对时间，如42m（即42分钟）</span><br><span class="line">        --tail string    从日志末尾显示多少行日志， 默认是all</span><br><span class="line">    -t, --timestamps     显示时间戳</span><br><span class="line">        --until string   显示自某个timestamp之前的日志，或相对时间，如42m（即42分钟）</span><br></pre></td></tr></table></figure><p>For Example :</p><ul><li>查看实时日志，不看历史：</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker -f --tail 1 container_id</span><br></pre></td></tr></table></figure><ul><li>查看后100行的日志：</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker logs --tail 100 container_id</span><br></pre></td></tr></table></figure><ul><li>查看30分钟之内日志</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker logs  --since 30m container_id</span><br></pre></td></tr></table></figure><ul><li>查看指定日期之后的日志 (2019-03-25T13:00:00 到现在的日志)</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker logs -t --since=&quot;2019-03-25T13:00:00&quot;  container_id</span><br></pre></td></tr></table></figure><ul><li>查看指定时间后的日志，只显示最后100行：</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker logs -f -t --since=&quot;2019-03-25&quot; --tail=100 container_id</span><br></pre></td></tr></table></figure><ul><li>查看指定时间段之内的日志， (–until 需要docker API 1.35 之上才支持)</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker logs -t --since=&quot;2019-03-25T13:00:00&quot; --until=&quot;2019-03-25T14:00:00&quot; container_id</span><br></pre></td></tr></table></figure><ul><li>docker 官网说明:<br><a href="https://docs.docker.com/engine/reference/commandline/logs/" target="_blank" rel="noopener">https://docs.docker.com/engine/reference/commandline/logs/</a></li></ul>]]></content>
      
      <categories>
          
          <category> docker </category>
          
      </categories>
      
      
        <tags>
            
            <tag> docker </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>hadoop上命令行查看lzo、gz、bz文件</title>
      <link href="/hadoop-lzo-gz-bz2/"/>
      <url>/hadoop-lzo-gz-bz2/</url>
      <content type="html"><![CDATA[<h2 id="hadoop上命令行查看lzo、gz、bz文件"><a href="#hadoop上命令行查看lzo、gz、bz文件" class="headerlink" title="hadoop上命令行查看lzo、gz、bz文件"></a>hadoop上命令行查看lzo、gz、bz文件</h2><p>HDFS上的文件可能是压缩的，所以用cat不能直接查看。hadoop上默认支持lzo、gz、bz2、snappy压缩格式。</p><p>我们用命令行查看HDFS上压缩文件，也是可以的。</p><h4 id="lzo文件"><a href="#lzo文件" class="headerlink" title="lzo文件"></a>lzo文件</h4><ul><li>查看 HDFS 上 lzo 文件的命令</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -cat /Data/Logs/2018-08-22/2018-08-22_log.lzo | lzop -dc | head -1</span><br><span class="line"></span><br><span class="line">或</span><br><span class="line"></span><br><span class="line">hadoop fs -cat /Data/Logs/2018-08-22/2018-08-22_log.lzo | lzop -dc | head -1     lzop 会接受输入流然后解压输出流给head显示第一行</span><br></pre></td></tr></table></figure><h4 id="gzip-文件"><a href="#gzip-文件" class="headerlink" title="gzip 文件"></a>gzip 文件</h4><ul><li>查看 HDFS 上 gzip 文件的命令</li></ul><a id="more"></a><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -cat /shining/temp.txt.gz | gzip -d </span><br><span class="line"></span><br><span class="line">或</span><br><span class="line"></span><br><span class="line">hadoop fs -cat /shining/temp.txt.gz | zcat</span><br></pre></td></tr></table></figure><h4 id="bz2-文件"><a href="#bz2-文件" class="headerlink" title="bz2 文件"></a>bz2 文件</h4><ul><li>查看 HDFS 上 bz2 文件的命令</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -cat /temp/b.bz2 | bzip2 -d</span><br></pre></td></tr></table></figure><h4 id="text-命令"><a href="#text-命令" class="headerlink" title="text 命令"></a>text 命令</h4><p>Hadoop text 命令可以查看HDFS上的文本、压缩文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -text /temp/b.bz2</span><br><span class="line"></span><br><span class="line">hadoop fs -text /temp/test_hive.txt.gz</span><br><span class="line"></span><br><span class="line">hadoop fs -text /temp/l.lzo</span><br><span class="line"></span><br><span class="line">hadoop fs -text /tmp/out1/part-r-00000</span><br></pre></td></tr></table></figure>]]></content>
      
      <categories>
          
          <category> hadoop </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hadoop </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>web</title>
      <link href="/web/"/>
      <url>/web/</url>
      <content type="html"><![CDATA[<h5 id="本页面为个人收藏的常用web访问-持续更新-……"><a href="#本页面为个人收藏的常用web访问-持续更新-……" class="headerlink" title="本页面为个人收藏的常用web访问  持续更新 ……"></a>本页面为个人收藏的常用web访问  持续更新 ……</h5><h5 id="常用网站"><a href="#常用网站" class="headerlink" title="常用网站"></a><center>常用网站</center></h5><table><thead><tr><th style="text-align:left">web url</th><th style="text-align:center">web url</th><th style="text-align:right">web url</th></tr></thead><tbody><tr><td style="text-align:left"><a href="https://www.leso.bar/" title="去掉了百度广告" target="_blank" rel="noopener">leso乐搜</a></td><td style="text-align:center"><a href="https://www.google.com" target="_blank" rel="noopener">Google</a></td><td style="text-align:right"><a href="https://cn.bing.com" target="_blank" rel="noopener">Bing</a></td></tr><tr><td style="text-align:left"><a href="https://bwh88.net/" target="_blank" rel="noopener">搬瓦工</a></td><td style="text-align:center"><a href="https://python3-cookbook.readthedocs.io/zh_CN/latest/" target="_blank" rel="noopener">python coolbook</a></td><td style="text-align:right"><a href="https://www.hbg.com/zh-cn/" target="_blank" rel="noopener">火币网</a></td></tr><tr><td style="text-align:left"><a href="https://github.com/shadowsocks" target="_blank" rel="noopener">Shadowsocks github</a></td><td style="text-align:center"><a href="https://sourceforge.net/projects/shadowsocksgui/files/dist/" target="_blank" rel="noopener">Shadowsocks sourceforge</a></td><td style="text-align:right"><a href="https://www.coingecko.com/zh" target="_blank" rel="noopener">虚拟货币走势</a></td></tr><tr><td style="text-align:left"><a href="https://www.processon.com/" target="_blank" rel="noopener">在线画图 processon</a></td><td style="text-align:center"><a href="https://docsmall.com/" target="_blank" rel="noopener">在线压缩(图片、PDF)</a></td><td style="text-align:right"><a href="https://www.toolnb.com/" target="_blank" rel="noopener">爱资料工资(在线小工具)</a></td></tr><tr><td style="text-align:left"><a href="http://www.lsjgcx.com/" target="_blank" rel="noopener">比价网</a></td><td style="text-align:center"><a href="https://www.processon.com/" target="_blank" rel="noopener">在线画图ProcessON</a></td><td style="text-align:right"><a href="https://www.remove.bg/zh/upload" target="_blank" rel="noopener">在线扣图、图片处理</a></td></tr><tr><td style="text-align:left"><a href="https://www.polebrief.com/edit" target="_blank" rel="noopener">写简历</a></td><td style="text-align:center"><a href="https://www.library.ac.cn/" title="f代理google" target="_blank" rel="noopener">google list</a></td><td style="text-align:right"><a href="https://yandex.eu/" target="_blank" rel="noopener">yandex搜索</a></td></tr><tr><td style="text-align:left"><a href="http://www.likebookmark.com/" target="_blank" rel="noopener">喜欢书签找网站资源</a></td><td style="text-align:center"><a href="https://onlinecamscanner.com/zh-Hans/" target="_blank" rel="noopener">在线文档图片编辑转换</a></td><td style="text-align:right"><a href="http://cxysite.com/" target="_blank" rel="noopener">程序员导航</a></td></tr><tr><td style="text-align:left"><a href="https://pdf.666666.dev/" title="github地址： https://github.com/Stirling-Tools/Stirling-PDF" target="_blank" rel="noopener">PDF转换工具</a></td><td style="text-align:center"><a href="https://tool.browser.qq.com/" target="_blank" rel="noopener">腾讯-帮小忙在线工具</a></td><td style="text-align:right"><a href="https://tinywow.com/" target="_blank" rel="noopener">TinyWow在线工具</a></td></tr></tbody></table><a id="more"></a><hr><h5 id="大数据相关"><a href="#大数据相关" class="headerlink" title="大数据相关"></a><center>大数据相关</center></h5><table><thead><tr><th style="text-align:left">web url</th><th style="text-align:center">web url</th><th style="text-align:right">web url</th></tr></thead><tbody><tr><td style="text-align:left"><a href="https://hadoop.apache.org/docs/stable/hadoop-yarn/hadoop-yarn-site/ResourceManagerRest.html" target="_blank" rel="noopener">ResourceManager API</a></td><td style="text-align:center"><a href="http://hadoop.apache.org/docs/r1.0.4/webhdfs.html" target="_blank" rel="noopener">WebHDFS API</a></td><td style="text-align:right"><a href="https://hadoop.apache.org/docs/r1.0.4/cn/commands_manual.html" target="_blank" rel="noopener">Apache Hadoop 命令手册</a></td></tr><tr><td style="text-align:left"><a href="http://hadoop.apache.org/docs/current/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/HistoryServerRest.html#Overview" target="_blank" rel="noopener">History Server API</a></td><td style="text-align:center"><a href="https://mesos-cn.gitbooks.io/mesos-cn/content/" target="_blank" rel="noopener">Mesos 中文手册</a></td><td style="text-align:right"><a href="http://www.apachecn.org/classification/" target="_blank" rel="noopener">ApacheCN 社区</a></td></tr><tr><td style="text-align:left"><a href="https://central.sonatype.com/" title="查询jar包名称，可以看到pom中的用法" target="_blank" rel="noopener">mvn pom jar包配置写法</a></td><td style="text-align:center"><a href="https://mvnrepository.com/" title="查询jar包名称，可以看到jar包的版本信息，使用方法" target="_blank" rel="noopener">mvn jar包版本列表</a></td></tr></tbody></table><hr><h5 id="容器、学习、收藏"><a href="#容器、学习、收藏" class="headerlink" title="容器、学习、收藏"></a><center>容器、学习、收藏</center></h5><table><thead><tr><th style="text-align:left">web url</th><th style="text-align:center">web url</th><th style="text-align:right">web url</th></tr></thead><tbody><tr><td style="text-align:left"><a href="http://docs.ceph.org.cn/start/quick-start-preflight/" target="_blank" rel="noopener">Ceph中文官网</a></td><td style="text-align:center"><a href="https://www.widuu.com/docker/index.html" target="_blank" rel="noopener">Docker 中文指南</a></td><td style="text-align:right"><a href="https://docs.docker.com/" target="_blank" rel="noopener">Docker 官方文档</a></td></tr><tr><td style="text-align:left"><a href="https://github.com/goharbor/harbor" target="_blank" rel="noopener">Harbor镜像仓库</a></td><td style="text-align:center"><a href="https://www.runoob.com/python3/python3-basic-syntax.html" target="_blank" rel="noopener">python学习</a></td><td style="text-align:right"><a href="https://whmzsu.github.io/helm-doc-zh-cn/" target="_blank" rel="noopener">helm文档</a></td></tr><tr><td style="text-align:left"><a href="https://jimmysong.io/kubernetes-handbook/" target="_blank" rel="noopener">Kubernetes 中文指南</a></td><td style="text-align:center"><a href="http://docs.kubernetes.org.cn/" target="_blank" rel="noopener">kubernetes 中文文档</a></td><td style="text-align:right"><a href="https://ghproxy.com/" target="_blank" rel="noopener">github 代理</a></td></tr><tr><td style="text-align:left"><a href="https://studygolang.com/" target="_blank" rel="noopener">go语言中文网</a></td><td style="text-align:center"><a href="http://www.yunweipai.com/" target="_blank" rel="noopener">运维派</a></td><td style="text-align:right"><a href="http://www.ansible.com.cn/" target="_blank" rel="noopener">ansible中文网</a></td></tr><tr><td style="text-align:left"><a href="https://learnku.com/docs/the-way-to-go" target="_blank" rel="noopener">go入门指南</a></td><td style="text-align:center"><a href="https://www.runoob.com/python/python-tutorial.html" target="_blank" rel="noopener">python基础教程</a></td><td style="text-align:right"><a href="https://www.cnblogs.com/nickchen121/p/10718112.html" target="_blank" rel="noopener">python blog 文章</a></td></tr><tr><td style="text-align:left"><a href="https://www.prometheus.wang/" target="_blank" rel="noopener">prometheus中文文档</a></td><td style="text-align:center"><a href="http://openmao.panchuang.net/#/" target="_blank" rel="noopener">开放猫chartGPT</a></td><td style="text-align:right"><a href="https://github.com/cloudnativer/kube-install" target="_blank" rel="noopener">一键安装k8s</a></td></tr><tr><td style="text-align:left"><a href="https://www.yuque.com/" target="_blank" rel="noopener">语雀-在线笔记</a></td><td style="text-align:center"><a href="https://docs.python.org/zh-cn/3/index.html" target="_blank" rel="noopener">python-docs 中文</a></td><td style="text-align:right"><a href="https://docker.aityp.com/" title="可以查询镜像信息，包括docker.io上的镜像信息" target="_blank" rel="noopener">docker镜像查询地址</a></td></tr></tbody></table><hr><h5 id="GM-amp-amp-edu"><a href="#GM-amp-amp-edu" class="headerlink" title=" GM &amp;&amp; edu "></a><center> GM &amp;&amp; edu </center></h5><table><thead><tr><th style="text-align:left">web url</th><th style="text-align:center">web url</th><th style="text-align:right">web url</th></tr></thead><tbody><tr><td style="text-align:left"><a href="http://fuwu.rsj.beijing.gov.cn/bjdkhy/ggfw/" target="_blank" rel="noopener">北京社保查询</a></td><td style="text-align:center"><a href="https://ipcrs.pbccrc.org.cn/" target="_blank" rel="noopener">个人征信查询</a></td><td style="text-align:right"><a href="https://xkczb.jtw.beijing.gov.cn/" target="_blank" rel="noopener">北京小汽车摇号</a></td></tr><tr><td style="text-align:left"><a href="http://www.cdgdc.edu.cn/xwyyjsjyxx/bqxx/265705.shtml" target="_blank" rel="noopener">学位信息网</a></td><td style="text-align:center"><a href="https://www.chsi.com.cn/" target="_blank" rel="noopener">学信网</a></td><td style="text-align:right"><a href="http://gjj.beijing.gov.cn/" target="_blank" rel="noopener">北京住房公积金网</a></td></tr><tr><td style="text-align:left"><a href="https://bj.122.gov.cn/" target="_blank" rel="noopener">交通综合平台(网上违章、机动车业务)</a></td><td style="text-align:center"><a href="http://rsj.beijing.gov.cn/jflh/" target="_blank" rel="noopener">北京积分落户</a></td><td style="text-align:right"><a href="http://rsj.beijing.gov.cn/" target="_blank" rel="noopener">北京市人力资源和社会资源保障局</a></td></tr><tr><td style="text-align:left"><a href="http://www.chinagoldcoin.net/" target="_blank" rel="noopener">中国金币网</a></td><td style="text-align:center"><a href="https://www.bjrcgz.gov.cn/" target="_blank" rel="noopener">北京国际人才网</a></td><td style="text-align:right"><a href="https://fw.ybj.beijing.gov.cn/hallEnter/#/Index" target="_blank" rel="noopener">北京医保平台</a></td></tr></tbody></table><hr><h5 id="Learning-website"><a href="#Learning-website" class="headerlink" title=" Learning website "></a><center> Learning website </center></h5><table><thead><tr><th style="text-align:left">web url</th><th style="text-align:center">web url</th><th style="text-align:right">web url</th></tr></thead><tbody><tr><td style="text-align:left"><a href="https://ykt.eduyun.cn/" target="_blank" rel="noopener">国家中小学网络云平台</a></td><td style="text-align:center"><a href="http://www.xxszxw.net/" target="_blank" rel="noopener">小学生自学网</a></td><td style="text-align:right"><a href="https://1s1k.eduyun.cn/portal/html/1s1k/index/1.html" target="_blank" rel="noopener">国家教育资源公共平台</a></td></tr><tr><td style="text-align:left"><a href="http://www.dxzy163.com/" target="_blank" rel="noopener">大学资源网</a></td><td style="text-align:center"><a href="https://www.examcoo.com/index/ku" target="_blank" rel="noopener">考试酷</a></td><td style="text-align:right"><a href="https://shudu.one/sudoku/printable-sudoku-for-kids.php" target="_blank" rel="noopener">可以打印的数独</a></td></tr></tbody></table><hr><h5 id="资源搜索"><a href="#资源搜索" class="headerlink" title=" 资源搜索 "></a><center> 资源搜索 </center></h5><table><thead><tr><th style="text-align:left">web url</th><th style="text-align:center">web url</th><th style="text-align:right">web url</th></tr></thead><tbody><tr><td style="text-align:left"><a href="http://btfox0.co/" target="_blank" rel="noopener">BTfox</a></td><td style="text-align:center"><a href="https://bt113.com/" target="_blank" rel="noopener">磁力多</a></td><td style="text-align:right"><a href="http://sokankan.top/" target="_blank" rel="noopener">吃力网</a></td></tr><tr><td style="text-align:left"><a href="http://clm.la" target="_blank" rel="noopener">磁力猫</a></td><td style="text-align:center"><a href="https://gemini.epurs.com/" target="_blank" rel="noopener">gemini AI</a></td><td style="text-align:right"><a href="https://www.kedianduo.com/pc/" target="_blank" rel="noopener">小以思AI</a></td></tr><tr><td style="text-align:left"><a href="https://v2free.net/user" title="访问不了，可以在这获取新的网址：https://v2-free.github.io/" target="_blank" rel="noopener">v2free-vpn-每日签到</a></td><td style="text-align:center"><a href="https://link-ai.tech/console/account" title="每日签到" target="_blank" rel="noopener">Link.AI</a></td><td style="text-align:right"><a href="https://aigc.baidu.com/home" title="每日签到" target="_blank" rel="noopener">度加创作工具</a></td></tr><tr><td style="text-align:left"><a href="https://oxfsl.cn/" title="支持gpt4.0" target="_blank" rel="noopener">AI机器人</a></td><td style="text-align:center"><a href="https://ai-bot.cn/#term-4" target="_blank" rel="noopener">AI工具集</a></td><td style="text-align:right"><a href="https://admin.alapi.cn/dashboard/workplace" target="_blank" rel="noopener">aiapi</a></td></tr><tr><td style="text-align:left"><a href="https://pw.shengshu-ai.com/" target="_blank" rel="noopener">清华vidu</a></td><td style="text-align:center"><a href="https://www.bigbigai.com/" target="_blank" rel="noopener">大设-图片AI</a></td><td style="text-align:right"><a href="https://dreamina.jianying.com/ai-tool/home" target="_blank" rel="noopener">Dreamina-抖音</a></td></tr><tr><td style="text-align:left"><a href="https://kimi.moonshot.cn/" target="_blank" rel="noopener">kimi-AI</a></td><td style="text-align:center"><a href="https://taichu-web.ia.ac.cn/#/" target="_blank" rel="noopener">紫金太初</a></td><td style="text-align:right"><a href="https://www.opkfc.com/list" target="_blank" rel="noopener">免费共享GPT账户</a></td></tr><tr><td style="text-align:left"><a href="https://qianwen.aliyun.com/" target="_blank" rel="noopener">通义千问</a></td><td style="text-align:center"><a href="https://netbird.io/" target="_blank" rel="noopener">netbird虚拟组网</a></td><td style="text-align:right"><a href="https://cloud.fastgpt.in/" target="_blank" rel="noopener">fastgpt</a></td></tr><tr><td style="text-align:left"><a href="https://xinghuo.xfyun.cn/" target="_blank" rel="noopener">讯飞星火</a></td><td style="text-align:center"><a href="https://www.alipanx.com/" target="_blank" rel="noopener">阿里盘搜</a></td><td style="text-align:right"><a href="https://www.yunso.net/" target="_blank" rel="noopener">小云搜索</a></td></tr></tbody></table><hr><h5 id="电影-amp-amp-音频"><a href="#电影-amp-amp-音频" class="headerlink" title=" 电影 &amp;&amp; 音频 "></a><center> 电影 &amp;&amp; 音频 </center></h5><table><thead><tr><th style="text-align:left">web url</th><th style="text-align:center">web url</th><th style="text-align:right">web url</th></tr></thead><tbody><tr><td style="text-align:left"><a href="http://www.28jig.com/" target="_blank" rel="noopener">电影天堂</a></td><td style="text-align:center"><a href="http://www.hao6v.com/" target="_blank" rel="noopener">6v电影网</a></td><td style="text-align:right"><a href="https://555ryz.com/" title="手机、PC自适应" target="_blank" rel="noopener">555电影</a></td></tr><tr><td style="text-align:left"><a href="https://www.ai66.cc/" target="_blank" rel="noopener">新版6v电影</a></td><td style="text-align:center"><a href="http://www.dianliang8.com/" title="混剪视频素材" target="_blank" rel="noopener">点亮吧</a></td><td style="text-align:right"><a href="https://www.cilixiong.com/" target="_blank" rel="noopener">磁力熊</a></td></tr><tr><td style="text-align:left"><a href="https://www.vvvdj.com/" target="_blank" rel="noopener">VVDJ</a></td><td style="text-align:center"><a href="https://ddys.info/" target="_blank" rel="noopener">低端影视</a></td><td style="text-align:right"><a href="https://soupian.pro/" target="_blank" rel="noopener">搜片</a></td></tr><tr><td style="text-align:left"><a href="https://www.qncool.com/" target="_blank" rel="noopener">七味片库</a></td><td style="text-align:center"><a href="http://www.fushu520.com/" target="_blank" rel="noopener">听书网</a></td><td style="text-align:right"><a href="https://www.bugutv.org/" target="_blank" rel="noopener">布谷TV</a></td></tr></tbody></table><hr><h5 id="免费图床-amp-amp-图片"><a href="#免费图床-amp-amp-图片" class="headerlink" title=" 免费图床 &amp;&amp; 图片 "></a><center> 免费图床 &amp;&amp; 图片 </center></h5><table><thead><tr><th style="text-align:left">web url</th><th style="text-align:center">web url</th><th style="text-align:right">web url</th></tr></thead><tbody><tr><td style="text-align:left"><a href="https://imgchr.com/" title="支持免注册上传图片，永久存储，支持HTTPS加密访问和调用图片，提供多种图片链接格式" target="_blank" rel="noopener">路过图床</a></td><td style="text-align:center"><a href="https://sm.ms/" title="永久存储免注册，图片链接支持https，可以删除上传的图片，提供多种图片链接格式，但是：每个图片最大5M，每次最多上传10张" target="_blank" rel="noopener">SM</a></td><td style="text-align:right"><a href="https://pic.xiaojianjian.net/" title="每日可以上传图片20张，上传后可以获取一个简单的外链，图床用的是微博空间，速度很快，但是图片清晰度会变低" target="_blank" rel="noopener">小贱贱</a></td></tr><tr><td style="text-align:left"><a href="https://tc.xkx.me/" target="_blank" rel="noopener">多合一图床</a></td><td style="text-align:center"><a href="https://img.wang/" target="_blank" rel="noopener">img</a></td><td style="text-align:right"><a href="https://tu.aixinxi.net/" title="需要注册才可使用，永久存储，支持HTTPS加密访问和调用图片，提供两种外链格式,这不只是一个图床，同时也提供音乐、视频、压缩包、文档等文件托管" target="_blank" rel="noopener">爱信息图床(可上视频、音乐)</a></td></tr><tr><td style="text-align:left"><a href="https://www.superbed.cn/" target="_blank" rel="noopener">聚合图床</a></td><td style="text-align:center"><a href="https://www.imgtp.com/" target="_blank" rel="noopener">imgtp 再用</a></td><td style="text-align:right"><a href="https://imgbb.com/" target="_blank" rel="noopener">imgbb</a></td></tr><tr><td style="text-align:left"><a href="https://photo.ihansen.org/index.html#/today" title="无版权图片网站，图片高清、美观，本站来自 unsplash" target="_blank" rel="noopener">美图集</a></td><td style="text-align:center"><a href="https://alpha.wallhaven.cc/random" title="知名图片网站，图片高清、美观，本站图片大多来自 wallhaven、unsplash" target="_blank" rel="noopener">wallhaven</a></td><td style="text-align:right"><a href="https://moetu.org/" target="_blank" rel="noopener">moetu</a></td></tr><tr><td style="text-align:left"><a href="https://iao.su/531/" target="_blank" rel="noopener">免费在线影视网站</a></td><td style="text-align:center"></td></tr></tbody></table><hr><h5 id="开源监控"><a href="#开源监控" class="headerlink" title=" 开源监控 "></a><center> 开源监控 </center></h5><table><thead><tr><th style="text-align:left">web url</th><th style="text-align:center">web url</th><th style="text-align:right">web url</th></tr></thead><tbody><tr><td style="text-align:left"><a href="https://github.com/TalkingData/owl" target="_blank" rel="noopener">TalkingData OWL</a></td><td style="text-align:center"><a href="http://book.open-falcon.org/zh/" target="_blank" rel="noopener">小米Open-Falcon</a></td><td style="text-align:right"><a href="https://cdn.dns-detect.alicdn.com/" target="_blank" rel="noopener">阿里昆仑用户诊断工具</a></td></tr><tr><td style="text-align:left"><a href="https://starsl.cn/" title="ConsulManager 集成监控，github https://github.com/starsliao" target="_blank" rel="noopener">starsl CM监控</a></td><td style="text-align:center"><a href="https://api.github.com/meta" target="_blank" rel="noopener">获取github.com解析地址</a></td></tr></tbody></table><hr><h5 id="博客收藏"><a href="#博客收藏" class="headerlink" title=" 博客收藏 "></a><center> 博客收藏 </center></h5><table><thead><tr><th style="text-align:left">web url</th><th style="text-align:center">web url</th><th style="text-align:right">web url</th></tr></thead><tbody><tr><td style="text-align:left"><a href="http://www.linuxqq.com/" target="_blank" rel="noopener">小Q博客</a></td><td style="text-align:center"><a href="https://blog.xiaoxiaomo.com/" target="_blank" rel="noopener">小小默</a></td><td style="text-align:right"><a href="http://dongxicheng.org/" target="_blank" rel="noopener">董西成博客</a></td></tr><tr><td style="text-align:left"><a href="https://lai.yuweining.cn/tos.html" target="_blank" rel="noopener">不死鸟</a></td><td style="text-align:center"><a href="https://jimmysong.io/" target="_blank" rel="noopener">jimmysong</a></td><td style="text-align:right"><a href="https://www.cuiliangblog.cn/" target="_blank" rel="noopener">CL-blog</a></td></tr><tr><td style="text-align:left"><a href="https://www.cuiliangblog.cn/" target="_blank" rel="noopener">崔亮的博客</a></td><td style="text-align:center"><a href="https://flashcat.cloud/product/nightingale/" target="_blank" rel="noopener">夜莺监控</a></td><td style="text-align:right"><a href="https://icloudnative.io/" target="_blank" rel="noopener">云原生</a></td></tr><tr><td style="text-align:left"><a href="https://wiki.eryajf.net/" target="_blank" rel="noopener">二丫讲梵wiki</a></td><td style="text-align:center"><a href="https://tvtv.fun/" target="_blank" rel="noopener">NAS相关</a></td></tr></tbody></table><p><a href="https://www.wjzbxtyx.me/" target="_blank" rel="noopener"> . </a></p>]]></content>
      
      <categories>
          
          <category> web </category>
          
      </categories>
      
      
        <tags>
            
            <tag> web </tag>
            
            <tag> url </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>hive自定义参数</title>
      <link href="/hive-custom-variables/"/>
      <url>/hive-custom-variables/</url>
      <content type="html"><![CDATA[<center><br><img style="width:900px;height:300px" src="https://i.ibb.co/98ZJB2s/005-Yh-I8igy1fvwocy7895j318g0p0wpk.jpg" align="center"><br></center><p>有的时候我们需要执行hive的时候带一些参数，以便我们后期任务分析、排查等问题。所以这里我们说一下自定义参数的作用。</p><h3 id="hive-命令指定参数"><a href="#hive-命令指定参数" class="headerlink" title="hive 命令指定参数"></a>hive 命令指定参数</h3><p>执行hive命令的时候指定参数</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive --hiveconf hive.job.submit.username=shining -e &quot;select count(*) from temp.test_hive where pt=&apos;2019-03-21&apos;;&quot;</span><br></pre></td></tr></table></figure><p>也可以指定多个参数</p><a id="more"></a><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive --hiveconf hive.job.submit.username=shining  --hiveconf hive.job.submit.web=sukbeta.github.io  -e &quot;select count(*) from temp.test_hive where pt=&apos;2019-03-31&apos;;&quot;</span><br></pre></td></tr></table></figure><p>这时你可以在yarn中找到job的页面，在job的 Configuration 页面中可以查找到你得传的参数。</p><p>如：<br><img src="/images/hive-custom-variables-1.png" alt="hive-custom-variables-images"></p><h3 id="全局配置"><a href="#全局配置" class="headerlink" title="全局配置"></a>全局配置</h3><p>可以修改 hive 命令中的 HIVE_OPTS， 这样执行所有hive的命令都添加这个参数了。</p><p>例如：<br>编辑 hive 命令</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">vim $HIVE_HOME/bin/hive</span><br><span class="line"></span><br><span class="line">添加：</span><br><span class="line"></span><br><span class="line">HIVE_OPTS=&quot;$HIVE_OPTS --hiveconf scheduler.job.submit.username=$&#123;BUILD_USER_ID&#125; --hiveconf scheduler.job.submit.jobname=$&#123;JOB_NAME&#125;&quot;</span><br></pre></td></tr></table></figure><ul><li>BUILD_USER_ID 和 JOB_NAME 是两个参数，需要有这两个参数。否则是查不到的。</li></ul><p>我是用jenkins调用的hive，jenkins会自动传入 JOB_NAME 参数的，所有就能取到。</p><p>在jenkins上安装 Build User Vars Plugin 插件可以获取一些执行用户信息。</p><p>可以参考插件说明 ：<br><a href="https://wiki.jenkins.io/display/JENKINS/Build+User+Vars+Plugin" target="_blank" rel="noopener">https://wiki.jenkins.io/display/JENKINS/Build+User+Vars+Plugin</a></p><p>hive自定义参数这个更能用好了还是很强大的。</p>]]></content>
      
      <categories>
          
          <category> hive </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hive </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>elasticsearch导出、导入工具-elasticdump</title>
      <link href="/elasticsearch-elasticdump/"/>
      <url>/elasticsearch-elasticdump/</url>
      <content type="html"><![CDATA[<h2 id="elasticsearch导出、导入工具-elasticdump"><a href="#elasticsearch导出、导入工具-elasticdump" class="headerlink" title="elasticsearch导出、导入工具-elasticdump"></a>elasticsearch导出、导入工具-elasticdump</h2><p>elasticsearch 数据导入到本地，或本地数据导入到elasticsearch中，或集群间的数据迁移，可以用elasticsearch的工具—elasticdump</p><p>elasticdump github 地址： <a href="https://github.com/taskrabbit/elasticsearch-dump?utm_source=dbweekly&amp;utm_medium=email" target="_blank" rel="noopener">https://github.com/taskrabbit/elasticsearch-dump?utm_source=dbweekly&amp;utm_medium=email</a></p><p>elasticdump 可以用用npm安装本地运行，也可以用docker容器运行。在这里我说一下npm安装本地运行、docker运行可以参考github文章。</p><h4 id="npm-安装-elasticdump"><a href="#npm-安装-elasticdump" class="headerlink" title="npm 安装 elasticdump"></a>npm 安装 elasticdump</h4><p>先下载安装npm</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"># 以下我尽量都用绝对路径吧。 发现好多文章里的路径写的不清晰......</span><br><span class="line">cd /home/shining</span><br><span class="line">wget https://nodejs.org/dist/v8.11.2/node-v8.11.2-linux-x64.tar.xz</span><br><span class="line">tar -xf node-v8.11.2-linux-x64.tar.xz</span><br><span class="line">cd /home/shining/node-v8.11.2-linux-x64/bin</span><br><span class="line">ln -s /home/shining/node-v8.11.2-linux-x64/bin/npm /usr/local/bin/npm</span><br><span class="line">ln -s /home/shining/node-v8.11.2-linux-x64/bin/node /usr/local/bin/node</span><br><span class="line"></span><br><span class="line"># 安装 elasticdump</span><br><span class="line">./npm init -f</span><br><span class="line"></span><br><span class="line">./npm install elasticdump</span><br><span class="line"># 如果你需要全局安装的话就添加 -g 参数， 我这里没有配置全局。</span><br><span class="line"></span><br><span class="line">cd /home/shining/node-v8.11.2-linux-x64/bin/node_modules/elasticdump/bin</span><br><span class="line"></span><br><span class="line">./elasticdump --help  </span><br><span class="line"></span><br><span class="line"># 这样 elasticdump 就安装好了</span><br></pre></td></tr></table></figure><p>导出数据， 他在他的官网中已经介绍的很详细了， es导出到es，es导出到文件，导出数据直接压缩等方式。</p><p>主要记住的是， 导出的时候不仅仅的data，还需要导出mapping信息。</p><h4 id="导出数据到文件："><a href="#导出数据到文件：" class="headerlink" title="导出数据到文件："></a>导出数据到文件：</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">elasticdump \</span><br><span class="line">  --input=http://172.16.3.5:9200/shining_index \</span><br><span class="line">  --output=/data/shining_index_mapping.json \</span><br><span class="line">  --type=mapping</span><br><span class="line">elasticdump \</span><br><span class="line">  --input=http://172.16.3.5:9200/shining_index \</span><br><span class="line">  --output=/data/shining_index.json \</span><br><span class="line">  --type=data</span><br></pre></td></tr></table></figure><p>这样的话数据和mapping信息就都导出来了。</p><p>For Example：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">导出Mapping信息  </span><br><span class="line">elasticdump --ignore-errors=true  --scrollTime=120m  --bulk=true --input=http://10.10.20.164:9200/xmonitor-2015.04.29   --output=http://192.168.100.72:9200/xmonitor-prd-2015.04.29  --type=mapping  </span><br><span class="line">  </span><br><span class="line">导出数据  </span><br><span class="line">elasticdump --ignore-errors=true  --scrollTime=120m  --bulk=true --input=http://10.10.20.164:9200/xmonitor-2015.04.28   --output=/usr/local/esdump/node-v0.12.2-linux-x64/data/xmonitor-prd-2015.04.28.json --type=data  </span><br><span class="line">  </span><br><span class="line">导出数据到本地集群  </span><br><span class="line">elasticdump --ignore-errors=true  --scrollTime=120m  --bulk=true --input=http://10.10.20.164:9200/xmonitor-2015.04.29   --output=http://192.168.100.72:9200/xmonitor-prd-2015.04.29 --type=data </span><br><span class="line"></span><br><span class="line">迁移mapping</span><br><span class="line">./elasticdump  --input=http://10.214.228.44:9200/ehruserindex --output=http://10.214.226.64:9200/ehruserindex --type=mapping</span><br><span class="line">迁移数据</span><br><span class="line">./elasticdump  --input=http://10.214.228.44:9200/ehruserindex --output=http://10.214.226.64:9200/ehruserindex --limit=10000 --type=data</span><br></pre></td></tr></table></figure><h4 id="导入数据"><a href="#导入数据" class="headerlink" title="导入数据"></a>导入数据</h4><p>正常导入数据是：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">elasticdump --input /data/shining_index.json --output http://172.16.3.5:9200/shining_index</span><br></pre></td></tr></table></figure><p>如果你得ES集群配置用有配置： action.auto_create_index 参数为 false 或 为 +aaa<em>,-bbb</em>，’+’号意味着允许创建aaa开头的索引，’-‘号意味着不允许创建bbb开头的索引 有规则的话（详细可以查看这个参数的说明和配置）， 会导致导入失败。</p><p>这时候需要先创建索引和mappping之后再导入数据。</p><p>先编辑一下我们导出来的mapping.json文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">vim /data/shining_index_mapping.json</span><br><span class="line">数据类似于：</span><br><span class="line">&#123;&quot;shining_index&quot;:&#123;&quot;mappings&quot;:&#123;&quot;logs&quot;.............&#125;&#125;&#125;&#125;&#125;</span><br><span class="line"></span><br><span class="line">需要保留 mappings 之后的信息</span><br><span class="line">类似于：</span><br><span class="line">&#123;&quot;mappings&quot;:&#123;&quot;logs&quot;.............&#125;&#125;&#125;&#125;</span><br><span class="line"></span><br><span class="line">删除 &#123;&quot;shining_index&quot;: 和 最后一个 &#125;</span><br></pre></td></tr></table></figure><p>创建索引</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl -X PUT &apos;http://172.16.3.5:9200/shining_index&apos; -d@/data/shining_index_mapping.json</span><br></pre></td></tr></table></figure><p>创建成功之后再导入数据就可以了。就不会报错了。</p>]]></content>
      
      <categories>
          
          <category> elasticsearch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> elasticsearch </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>kafka查看消费组消费详情</title>
      <link href="/kafka-console-groups/"/>
      <url>/kafka-console-groups/</url>
      <content type="html"><![CDATA[<p>kafka 在 0.9 版本之后，kafka的消费者组和offset信息就不存zookeeper了。</p><h4 id="0-9-之前版本查看所有消费组："><a href="#0-9-之前版本查看所有消费组：" class="headerlink" title="0.9 之前版本查看所有消费组："></a>0.9 之前版本查看所有消费组：</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">./kafka-consumer-groups.sh --zookeeper 127.0.0.1:2181 --list</span><br><span class="line"></span><br><span class="line">erro-info-group</span><br><span class="line">console-consumer-64036</span><br><span class="line">console-consumer-98298</span><br><span class="line">logstash-new</span><br><span class="line">console-consumer-89310</span><br><span class="line">console-consumer-48800</span><br></pre></td></tr></table></figure><h4 id="新版本-0-9-版本之后查看所有消费组"><a href="#新版本-0-9-版本之后查看所有消费组" class="headerlink" title="新版本 0.9 版本之后查看所有消费组"></a>新版本 0.9 版本之后查看所有消费组</h4><a id="more"></a><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">kafka-consumer-groups.sh --new-consumer --bootstrap-server localhost:9092 --list </span><br><span class="line"></span><br><span class="line">test-info</span><br><span class="line">nginxlog</span><br></pre></td></tr></table></figure><h4 id="显示某个消费组的消费详情（仅支持offset存储在zookeeper上的）"><a href="#显示某个消费组的消费详情（仅支持offset存储在zookeeper上的）" class="headerlink" title="显示某个消费组的消费详情（仅支持offset存储在zookeeper上的）"></a>显示某个消费组的消费详情（仅支持offset存储在zookeeper上的）</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-run-class.sh kafka.tools.ConsumerOffsetChecker --zookeeper localhost:2181 --group logstash-new</span><br></pre></td></tr></table></figure><h4 id="显示某个消费组的消费详情（支持0-9版本-）"><a href="#显示某个消费组的消费详情（支持0-9版本-）" class="headerlink" title="显示某个消费组的消费详情（支持0.9版本+）"></a>显示某个消费组的消费详情（支持0.9版本+）</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-consumer-groups.sh --new-consumer --bootstrap-server localhost:9092 --describe --group nginxlog</span><br></pre></td></tr></table></figure>]]></content>
      
      <categories>
          
          <category> kafka </category>
          
      </categories>
      
      
        <tags>
            
            <tag> kafka </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>hadoop常用命令(整理笔记)</title>
      <link href="/hadoop-command/"/>
      <url>/hadoop-command/</url>
      <content type="html"><![CDATA[<!--<center><img style="width:900px;height:220px" src="https://file.moetu.org/images/2019/07/19/9bbc284bly1g4wuwpdzpkj20ds074q349a9e1fe9b7a16f79.jpg" align=center /></center>--><p>个人笔记，自己查看使用。就不一一整理了。</p><h3 id="hadoop"><a href="#hadoop" class="headerlink" title="hadoop"></a>hadoop</h3><a id="more"></a><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">hdfs zkfc -formatZK（格式化zookeeper）</span><br><span class="line">hadoop-daemon.sh start journalnode(启动journalnode)</span><br><span class="line">hdfs namenode -format（格式化namenode metadata）</span><br><span class="line">hadoop-daemon.sh start namenode</span><br><span class="line">hadoop-daemon.sh start namenode -bootstrapStandby( standy namenode)</span><br><span class="line">stop-dfs.sh</span><br><span class="line">hadoop fsck / (检测hadoop数据状态)</span><br><span class="line">start-yarn.sh (相当jobtracker)</span><br><span class="line">start-dfs.sh (启动hdfs)</span><br><span class="line">mr-jobhistory-daemon.sh start historyserver (启动historyserver 服务)</span><br><span class="line"></span><br><span class="line">hdfs haadmin -failover nn2 nn1(切换namenode)</span><br><span class="line">hdfs zkfc -formatZK（格式化zookeeper）</span><br><span class="line"> </span><br><span class="line">hadoop-daemon.sh start journalnode(启动journalnode)</span><br><span class="line">hdfs namenode -format（格式化namenode metadata）</span><br><span class="line">hadoop-daemon.sh start namenode</span><br><span class="line">hadoop-daemon.sh start namenode -bootstrapStandby( standy namenode)</span><br><span class="line">stop-dfs.sh</span><br><span class="line">hadoop fsck / (检测hadoop数据状态)</span><br><span class="line">start-yarn.sh (相当jobtracker)</span><br><span class="line">start-dfs.sh (启动hdfs)</span><br><span class="line"> </span><br><span class="line">mr-jobhistory-daemon.sh start historyserver   启动historyserver 服务 (在 mapred-site.xml 里配置的， 在哪台机器上就在哪台机器上启动)</span><br><span class="line"></span><br><span class="line">bin/hadoop dfsadmin -safemode enter   将集群置于安全模式</span><br><span class="line">-safeadmin enter | leave | get | wait：安全模式命令。安全模式是NameNode的一种状态，在这种状态下，NameNode不接受对名字空间的更改（只读）；不复制或删除块。NameNode在启动时自动进入安全模式，当配置块的最小百分数满足最小副本数的条件时，会自动离开安全模式。enter是进入，leave是离开。</span><br><span class="line"></span><br><span class="line">bin/hadoop dfsadmin -report  显示Datanode列表   </span><br><span class="line"></span><br><span class="line">bin/hadoop dfsadmin -refreshNodes：重新读取hosts和exclude文件，使新的节点或需要退出集群的节点能够被NameNode重新识别。这个命令在新增节点或注销节点时用到。</span><br><span class="line"></span><br><span class="line">bin/hadoop dfsadmin -decommission datanodename  使Datanode节点 datanodename退役   </span><br><span class="line"></span><br><span class="line">bin/hadoop dfsadmin -help 命令能列出所有当前支持的命令。比如：</span><br><span class="line">    * -report：报告HDFS的基本统计信息。有些信息也可以在NameNode Web服务首页看到。</span><br><span class="line">    * -safemode：虽然通常并不需要，但是管理员的确可以手动让NameNode进入或离开安全模式。</span><br><span class="line">    * -finalizeUpgrade：删除上一次升级时制作的集群备份。</span><br></pre></td></tr></table></figure><h3 id="HDFS"><a href="#HDFS" class="headerlink" title="HDFS"></a>HDFS</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line">hadoop-daemon.sh start zkfc</span><br><span class="line">hadoop-daemon.sh start journalnode</span><br><span class="line">hadoop-daemon.sh start namenode</span><br><span class="line"></span><br><span class="line">hdfs haadmin -getServiceState nn1   得到nn1 或 nn2 状态</span><br><span class="line">hdfs haadmin -failover nn2 nn1       (切换namenode)</span><br><span class="line"></span><br><span class="line">DFS Used hadoop文件系统所使用的空间</span><br><span class="line">Non DFS Used 非hadoop文件系统所使用的空间，比如说本身的linux系统使用的，或者存放的其它文件</span><br><span class="line">Configured Capacity = DFS Used + Non-DFSUsed+ DFS Remaining</span><br><span class="line"></span><br><span class="line">hadoop job -kill job_1441084173757_265601    停止正在执行的job</span><br><span class="line"></span><br><span class="line">hadoop checknative -a    检查hdfs lib库，支持的压缩格式等信息</span><br><span class="line"></span><br><span class="line"> 终端命令方式查看文件的块大小</span><br><span class="line">./bin/hadoop fs -stat &quot;%o&quot; TEST/jdk-7u25-linux-x64.gz</span><br><span class="line">51200      单位为B（字节）</span><br><span class="line"></span><br><span class="line">start-balancer.sh  可以执行-threshold参数。 </span><br><span class="line">-threshold参数是指定平衡的阈值。 </span><br><span class="line">-threshold的默认是10，即每个datanode节点的实际hdfs存储使用量/集群hdfs存储量 </span><br><span class="line">hdfs balancer -threshold 5 </span><br><span class="line">start-balancer.sh -threshold 1</span><br><span class="line"></span><br><span class="line">hadoop-daemon.sh start namenode -rollingUpgrade started  如果hadoop里有数据的话， 第一次启动namenode的时候用这个命令。</span><br><span class="line">hadoop-daemon.sh start namenode -rollingUpgrade</span><br><span class="line"></span><br><span class="line">export HADOOP_SLAVE_SLEEP=1</span><br><span class="line">slaves.sh jps    就可以1秒查看一个节点。 HADOOP_SLAVE_SLEEP=2 2秒 </span><br><span class="line"></span><br><span class="line">hdfs namenode -recover  </span><br><span class="line"></span><br><span class="line">统计文件的行数 ， 代表 统计 /tmp/wc/目录下所有文件的行数，并输出到 /tmp/out_wc  查看结果  hadoop fs -cat /tmp/out_wc/* 即可</span><br><span class="line">hadoop jar /home/hadoop/apache-hadoop/hadoop/share/hadoop/tools/lib/hadoop-streaming-2.7.2.jar -input /tmp/wc/ -output /tmp/out_wc -mapper /bin/cat -reducer /usr/bin/wc</span><br><span class="line"></span><br><span class="line">目录配额</span><br><span class="line">hadoop fs -count -q /user/tc   查看配置设置</span><br><span class="line">hadoop dfsadmin -setSpaceQuota 100g  /user/tc  设置配置 100g</span><br><span class="line">hadoop dfsadmin -clrSpaceQuota /user/tc  取消配额</span><br><span class="line"></span><br><span class="line">hadoop fs -setrep 3 /input/test.txt --设置hdfs的文件副本数量</span><br><span class="line">hadoop fs -setrep -R 3 &lt; hdfs path &gt;</span><br><span class="line"></span><br><span class="line">改变一个文件在hdfs中的副本个数，上述命令中数字3为所设置的副本个数，-R选项可以对一个人目录下的所有目录+文件递归执行改变副本个数的操作</span><br><span class="line"></span><br><span class="line">bin/hadoop fs -help command-name  显示关于某个命令的详细信息</span><br><span class="line"></span><br><span class="line">bin/hadoop job -history output-dir 用户可使用以下命令在指定路径下查看历史日志汇总</span><br><span class="line"></span><br><span class="line">hadoop archive -archiveName NAME *</span><br><span class="line">                        -archiveName NAME  要创建的档案的名字。</span><br><span class="line">                        src 文件系统的路径名，和通常含正则表达的一样。</span><br><span class="line">                        dest 保存档案文件的目标目录。</span><br><span class="line"></span><br><span class="line">递归地拷贝文件或目录</span><br><span class="line">  $ hadoop distcp</span><br><span class="line">                  srcurl      源Url</span><br><span class="line">                  desturl     目标Url</span><br><span class="line">                  </span><br><span class="line">运行HDFS文件系统检查工具(fsck tools)</span><br><span class="line"></span><br><span class="line">用法：hadoop fsck [GENERIC_OPTIONS]</span><br><span class="line">命令选项     描述</span><br><span class="line">-move             移动受损文件到/lost+found</span><br><span class="line">-delete     删除受损文件。</span><br><span class="line">-openforwrite     打印出写打开的文件。</span><br><span class="line">-files             打印出正被检查的文件。</span><br><span class="line">-blocks     打印出块信息报告。</span><br><span class="line">-locations     打印出每个块的位置信息。</span><br><span class="line">-racks             打印出data-node的网络拓扑结构。</span><br></pre></td></tr></table></figure><h3 id="Yarn"><a href="#Yarn" class="headerlink" title="Yarn"></a>Yarn</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line">yarn rmadmin -getServiceState rm2   得到 rm1 或 rm2 的状态</span><br><span class="line">yarn rmadmin -transitionToActive rm2 --forcemanual      切换 rm2 为主</span><br><span class="line"></span><br><span class="line">yarn node -list</span><br><span class="line">hdfs dfsadmin -refreshNodes</span><br><span class="line">yarn rmadmin -refreshNodes</span><br><span class="line">yarn rmadmin -refreshQueues  队列刷新</span><br><span class="line"></span><br><span class="line">yarn application -list</span><br><span class="line">yarn application -status application_1499826928702_868175</span><br><span class="line">yarn application -kill application_1499826928702_868175</span><br><span class="line">yarn logs  -applicationId   appid  查看日志</span><br><span class="line"></span><br><span class="line">ws/v1/cluster/apps?states=RUNNING</span><br><span class="line">http://namenode00.host-mtime.com:8088/ws/v1/cluster/apps?states=RUNNING</span><br><span class="line">curl --compressed -H &quot;Accept: application/json&quot; -X GET &quot;http://lyhadoop4.com:8088/ws/v1/cluster/apps/application_1465461051654_0001&quot; </span><br><span class="line"></span><br><span class="line">http://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-site/ResourceManagerRest.html   api 接口</span><br><span class="line"></span><br><span class="line">job 的cpu使用</span><br><span class="line">http://namenode01.host-mtime.com:19888/jobhistory/jobcounters/job_1494493840980_428367 </span><br><span class="line">查找 CPU time spent (ms)  中的 total 值</span><br><span class="line"></span><br><span class="line">job 内存</span><br><span class="line">http://namenode01.host-mtime.com:19888/jobhistory/conf/job_1494493840980_428367</span><br><span class="line">查找 （mapreduce.map.memory.mb * map数） + （mapreduce.reduce.memory.mb * reduce数）</span><br><span class="line">map 和 reduce 数 可以在  http://namenode01.host-mtime.com:19888/jobhistory/job/job_1494493840980_428367  中找到</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">job 的 io</span><br><span class="line">http://namenode01.host-mtime.com:19888/jobhistory/jobcounters/job_1494493840980_428367</span><br><span class="line">查找 FILE: Number of bytes read + FILE: Number of bytes written + HDFS: Number of bytes read + （ HDFS: Number of bytes written * 3 ）</span><br><span class="line">HDFS: Number of bytes written *3 是因为一个文件要写三份。</span><br><span class="line"></span><br><span class="line">job的sql</span><br><span class="line">http://namenode01.host-mtime.com:19888/jobhistory/conf/job_1494493840980_428367</span><br><span class="line">查找 hive.query.string  得到的是 urlencode 可以在转码网站上解码。</span><br><span class="line">正在运行的job查看sql  http://namenode01.host-mtime.com:8088/proxy/application_1499826928702_1021497/mapreduce/job/job_1499826928702_1021497</span><br><span class="line">点击 running -&gt; application ID -&gt; Tracking URL: ApplicationMaster -&gt; job ID -&gt; Configuration 页面中查找 hive.query.string</span><br><span class="line"></span><br><span class="line">shell 解码 urlencode</span><br><span class="line">echo &quot;hive.query.string urlencode 内容&quot; &gt; urlfile.txt</span><br><span class="line">for url in `cat urlfile.txt`</span><br><span class="line">do</span><br><span class="line">printf $(echo -n $url | sed &apos;s/\\/\\\\/g;s/\(%\)\([0-9a-fA-F][0-9a-fA-F]\)/\\x\2/g&apos;)&quot;\n&quot;</span><br><span class="line">done</span><br><span class="line"></span><br><span class="line">yarn 测试</span><br><span class="line">1）  hadoop jar /home/hadoop/apache-hadoop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar pi 100 10000</span><br><span class="line"></span><br><span class="line">2） hdfs dfs -put words.txt hdfs://cloud01:9000/</span><br><span class="line">       hadoop jar //home/hadoop/apache-hadoop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar wordcount  /words.txt /output</span><br><span class="line">       </span><br><span class="line"></span><br><span class="line">用于和Map Reduce作业交互和命令(jar)</span><br><span class="line"></span><br><span class="line">用法：hadoop job [GENERIC_OPTIONS] [-submit ] | [-status ] | [-counter ] | [-kill ] | [-events &lt;#-of-events&gt;] | [-history [all] ] | [-list [all]] | [-kill-task ] | [-fail-task ]</span><br><span class="line">命令选项         描述</span><br><span class="line">-submit      提交作业</span><br><span class="line">-status      打印map和reduce完成百分比和所有计数器。</span><br><span class="line">-counter     打印计数器的值。</span><br><span class="line">-kill      杀死指定作业。</span><br><span class="line">-events &lt;#-of-events&gt;    打印给定范围内jobtracker接收到的事件细节。</span><br><span class="line">-history [all]     -history      打印作业的细节、失败及被杀死原因的细节。更多的关于一个作业的细节比如   成功的任务，做过的任务尝试等信息可以通过指定[all]选项查看。</span><br><span class="line">-list [all]     -list all     显示所有作业。-list只显示将要完成的作业。</span><br><span class="line">-kill-task     杀死任务。被杀死的任务不会不利于失败尝试。</span><br><span class="line">-fail-task    使任务失败。被失败的任务会对失败尝试不利。</span><br></pre></td></tr></table></figure><h3 id="Spark"><a href="#Spark" class="headerlink" title="Spark"></a>Spark</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">spark slave 单独启动</span><br><span class="line">./start-slave.sh spark://namenode00.host-mtime.com:7077  </span><br><span class="line"></span><br><span class="line">/sbin/start-slave.sh spark://shdx006:7077,shdx007:7077</span><br><span class="line"></span><br><span class="line">http://spark.apache.org/docs/latest/monitoring.html#rest-api  api 接口</span><br></pre></td></tr></table></figure><h3 id="Hbase"><a href="#Hbase" class="headerlink" title="Hbase"></a>Hbase</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">./bin/hbase-daemon.sh start master         启动master</span><br><span class="line">./bin/hbase-daemon.sh start master --backup   启动baskup</span><br><span class="line">hbase-daemon.sh start thrift</span><br><span class="line"></span><br><span class="line">./hbase-daemon.sh stop master   停掉master </span><br><span class="line">hbase-daemon.sh start regionserver</span><br><span class="line"></span><br><span class="line">balance：</span><br><span class="line">balance_switch true   开启自动balance</span><br><span class="line">balance_switch false  关闭自动balance</span><br><span class="line">查看balance状态命令是：  balancer_enabled</span><br></pre></td></tr></table></figure>]]></content>
      
      <categories>
          
          <category> hadoop </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hadoop </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>pycharm安装package出现报错：module &#39;pip&#39; has no attribute &#39;main&#39;</title>
      <link href="/pycham-pip-no-attr/"/>
      <url>/pycham-pip-no-attr/</url>
      <content type="html"><![CDATA[<p>python 3.5<br>pip 18.1 更新之后，pycharm安装package出现报错：module ‘pip’ has no attribute ‘main’</p><p>找到安装目录下 helpers/packaging_tool.py文件。 pycham报错信息里会有显示 packaging_tool.py 文件的配置。</p><ul><li>找到下面代码： 第一部分</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">def do_install(pkgs):</span><br><span class="line">    try:</span><br><span class="line">        import pip</span><br><span class="line">    except ImportError:</span><br><span class="line">        error_no_pip()</span><br><span class="line">    return pip.main([&apos;install&apos;] + pkgs)</span><br></pre></td></tr></table></figure><p>替换为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">def do_install(pkgs):</span><br><span class="line">    try:</span><br><span class="line">        # import pip</span><br><span class="line">        try:</span><br><span class="line">            from pip._internal import main</span><br><span class="line">        except Exception:</span><br><span class="line">            from pip import main</span><br><span class="line">    except ImportError:</span><br><span class="line">        error_no_pip()</span><br><span class="line">    return main([&apos;install&apos;] + pkgs)</span><br></pre></td></tr></table></figure><ul><li>找到下面代码： 第二部分</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">def do_uninstall(pkgs):</span><br><span class="line">    try:</span><br><span class="line">        import pip</span><br><span class="line">    except ImportError:</span><br><span class="line">        error_no_pip()</span><br><span class="line">    return pip.main([&apos;uninstall&apos;, &apos;-y&apos;] + pkgs)</span><br></pre></td></tr></table></figure><p>替换为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">def do_uninstall(pkgs):</span><br><span class="line">    try:</span><br><span class="line">        # import pip</span><br><span class="line">        try:</span><br><span class="line">            from pip._internal import main</span><br><span class="line">        except Exception:</span><br><span class="line">            from pip import main</span><br><span class="line">    except ImportError:</span><br><span class="line">        error_no_pip()</span><br><span class="line">    return main([&apos;uninstall&apos;, &apos;-y&apos;] + pkgs)</span><br></pre></td></tr></table></figure><p>保存退出，之后就可以了！</p>]]></content>
      
      <categories>
          
          <category> python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>nginx url跳转、rewrite实例</title>
      <link href="/nginx-url-rewrite/"/>
      <url>/nginx-url-rewrite/</url>
      <content type="html"><![CDATA[<h2 id="nginx-url跳转、rewrite实例"><a href="#nginx-url跳转、rewrite实例" class="headerlink" title="nginx url跳转、rewrite实例"></a>nginx url跳转、rewrite实例</h2><p>nginx 的 rewrite 语法<br>语法: rewrite regex replacement flag<br>默认: none<br>作用域: server, location, if<br>此指令根据表达式来更改URI，或修改字符串。<br>指令根据配置文件中的顺序来执行。<br>﻿注意：<br>重写表达式只对相对路径有效。如果想配对主机名，应该使用if语句。<br>rewrite只是会改写路径部分的东东，不会改动用户的输入参数，因此这里的if规则里面，你无需关心用户在浏览器里输入的参数，rewrite后会自动添加的，因此，只是加上了一个？号和后面我们想要的一个小小的参数 ***https=1就可以了。<br>nginx的rewrite规则参考：</p><a id="more"></a><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">~ 为区分大小写匹配</span><br><span class="line">~* 为不区分大小写匹配</span><br><span class="line">!~和!~*分别为区分大小写不匹配及不区分大小写不匹</span><br><span class="line">-f和!-f用来判断是否存在文件</span><br><span class="line">-d和!-d用来判断是否存在目录</span><br><span class="line">-e和!-e用来判断是否存在文件或目录</span><br><span class="line">-x和!-x用来判断文件是否可执行</span><br><span class="line">last 相当于Apache里的[L]标记，表示完成rewrite，呵呵这应该是最常用的</span><br><span class="line">break 终止匹配, 不再匹配后面的规则</span><br><span class="line">redirect 返回302临时重定向 地址栏会显示跳转后的地址</span><br><span class="line">permanent 返回301永久重定向 地址栏会显示跳转后的地址</span><br><span class="line">$args</span><br><span class="line">$content_length</span><br><span class="line">$content_type</span><br><span class="line">$document_root</span><br><span class="line">$document_uri</span><br><span class="line">$host</span><br><span class="line">$http_user_agent</span><br><span class="line">$http_cookie</span><br><span class="line">$limit_rate</span><br><span class="line">$request_body_file</span><br><span class="line">$request_method</span><br><span class="line">$remote_addr</span><br><span class="line">$remote_port</span><br><span class="line">$remote_user</span><br><span class="line">$request_filename</span><br><span class="line">$request_uri</span><br><span class="line">$query_string</span><br><span class="line">$scheme</span><br><span class="line">$server_protocol</span><br><span class="line">$server_addr</span><br><span class="line">$server_name</span><br><span class="line">$server_port</span><br><span class="line">$uri</span><br></pre></td></tr></table></figure><p>多目录转成参数</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">if (!-d $request_filename) &#123;</span><br><span class="line">rewrite ^/([a-z-A-Z]+)/([a-z-A-Z]+)/?(.*)$ /index.php?namespace=user&amp;amp;controller=$1&amp;amp;action=$2&amp;amp;$3 last;</span><br><span class="line">rewrite ^/([a-z-A-Z]+)/?$ /index.php?namespace=user&amp;amp;controller=$1 last;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>目录对换</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">/123456/xxxx -&gt; /xxxx?id=123456</span><br><span class="line">rewrite ^/(\d+)/(.+)/ /$2?id=$1 last;</span><br></pre></td></tr></table></figure><p>例如下面设定nginx在用户使用ie的使用重定向到/nginx-ie目录下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">if ($http_user_agent ~ MSIE) &#123;</span><br><span class="line">rewrite ^(.*)$ /nginx-ie/$1 break;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>目录自动加“/”</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">if (-d $request_filename)&#123;</span><br><span class="line">rewrite ^/(.*)([^/])$ http://$host/$1$2/ permanent;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>禁止 ht access</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">location ~/\.ht &#123;</span><br><span class="line">deny all;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>禁止多个目录</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">location ~ ^/(cron|templates)/ &#123;</span><br><span class="line">deny all;</span><br><span class="line">break;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>禁止以/data开头的文件<br>可以禁止/data/下多级目录下.log.txt等请求;</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">location ~ ^/data &#123;</span><br><span class="line">deny all;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>禁止单个目录<br>不能禁止.log.txt能请求</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">location /searchword/cron/ &#123;</span><br><span class="line">deny all;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>禁止单个文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">location ~ /data/sql/data.sql &#123;</span><br><span class="line">deny all;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>给favicon.ico和robots.txt设置过期时间;<br>这里为favicon.ico为99天,robots.txt为7天并不记录404错误日志</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">location ~(favicon.ico) &#123;</span><br><span class="line">log_not_found off;</span><br><span class="line">expires 99d;</span><br><span class="line">break;</span><br><span class="line">&#125;</span><br><span class="line">location ~(robots.txt) &#123;</span><br><span class="line">log_not_found off;</span><br><span class="line">expires 7d;</span><br><span class="line">break;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>设定某个文件的过期时间;这里为600秒，并不记录访问日志</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">location ^~ /html/scripts/loadhead_1.js &#123;</span><br><span class="line">access_log   off;</span><br><span class="line">root /opt/lampp/htdocs/web;</span><br><span class="line">expires 600;</span><br><span class="line">break;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>文件反盗链并设置过期时间<br>这里的return 412 为自定义的http状态码，默认为403，方便找出正确的盗链的请求<br>“rewrite ^/ <a href="http://www.jbxue.com/leech.gif;”显示一张防盗链图片" target="_blank" rel="noopener">http://www.jbxue.com/leech.gif;”显示一张防盗链图片</a><br>“access_log off;”不记录访问日志，减轻压力<br>“expires 3d”所有文件3天的浏览器缓存</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">location ~* ^.+\.(jpg|jpeg|gif|png|swf|rar|zip|css|js)$ &#123;</span><br><span class="line">valid_referers none blocked *.c1gstudio.com *.c1gstudio.net localhost 208.97.167.194;</span><br><span class="line">if ($invalid_referer) &#123;</span><br><span class="line">rewrite ^/ http://www.jbxue.com/leech.gif;</span><br><span class="line">return 412;</span><br><span class="line">break;</span><br><span class="line">&#125;</span><br><span class="line">access_log   off;</span><br><span class="line">root /opt/lampp/htdocs/web;</span><br><span class="line">expires 3d;</span><br><span class="line">break;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>只充许固定ip访问网站，并加上密码</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">root  /opt/htdocs/www;</span><br><span class="line">allow   208.97.167.194;</span><br><span class="line">allow   222.33.1.2;</span><br><span class="line">allow   231.152.49.4;</span><br><span class="line">deny    all;</span><br><span class="line">auth_basic “C1G_ADMIN”;</span><br><span class="line">auth_basic_user_file htpasswd;</span><br></pre></td></tr></table></figure><p>将多级目录下的文件转成一个文件，增强seo效果</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">/job-123-456-789.html 指向/job/123/456/789.html</span><br><span class="line">rewrite ^/job-([0-9]+)-([0-9]+)-([0-9]+)\.html$ /job/$1/$2/jobshow_$3.html last;</span><br></pre></td></tr></table></figure><p>将根目录下某个文件夹指向2级目录<br>如/shanghaijob/ 指向 /area/shanghai/<br>如果你将last改成permanent，那么浏览器地址栏显是/location/shanghai/</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rewrite ^/([0-9a-z]+)job/(.*)$ /area/$1/$2 last;</span><br></pre></td></tr></table></figure><p>上面例子有个问题是访问/shanghai 时将不会匹配</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">rewrite ^/([0-9a-z]+)job$ /area/$1/ last;</span><br><span class="line">rewrite ^/([0-9a-z]+)job/(.*)$ /area/$1/$2 last;</span><br></pre></td></tr></table></figure><p>这样/shanghai 也可以访问了，但页面中的相对链接无法使用，<br>如./list_1.html真实地址是/area/shanghia/list_1.html会变成/list_1.html,导至无法访问。<br>那我加上自动跳转也是不行咯<br>(-d $request_filename)它有个条件是必需为真实目录，而我的rewrite不是的，所以没有效果</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">if (-d $request_filename)&#123;</span><br><span class="line">rewrite ^/(.*)([^/])$ http://$host/$1$2/ permanent;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>知道原因后就好办了，手动跳转：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">rewrite ^/([0-9a-z]+)job$ /$1job/ permanent;</span><br><span class="line">rewrite ^/([0-9a-z]+)job/(.*)$ /area/$1/$2 last;</span><br></pre></td></tr></table></figure><p>文件和目录不存在的时候重定向：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">if (!-e $request_filename) &#123;</span><br><span class="line">proxy_pass http://127.0.0.1;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>域名跳转</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">server</span><br><span class="line">&#123;</span><br><span class="line">listen       80;</span><br><span class="line">server_name  jump.jbxue.com;</span><br><span class="line">index index.html index.htm index.php;</span><br><span class="line">root  /opt/lampp/htdocs/www;</span><br><span class="line">rewrite ^/ http://www.jbxue.com/;</span><br><span class="line">access_log  off;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>多域名转向</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">server_name  www.jbxue.com/  www.jbxue.com/;</span><br><span class="line">index index.html index.htm index.php;</span><br><span class="line">root  /opt/lampp/htdocs;</span><br><span class="line">if ($host ~ “c1gstudio\.net”) &#123;</span><br><span class="line">rewrite ^(.*) http://www.jbxue.com$1/ permanent;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>三级域名跳转</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">if ($http_host ~* “^(.*)\.i\.c1gstudio\.com$”) &#123;</span><br><span class="line">rewrite ^(.*) http://top.jbxue.com$1/;</span><br><span class="line">break;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>域名镜向</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">server</span><br><span class="line">&#123;</span><br><span class="line">listen       80;</span><br><span class="line">server_name  mirror.c1gstudio.com;</span><br><span class="line">index index.html index.htm index.php;</span><br><span class="line">root  /opt/lampp/htdocs/www;</span><br><span class="line">rewrite ^/(.*) http://www.jbxue.com/$1 last;</span><br><span class="line">access_log  off;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>某个子目录作镜向</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">location ^~ /zhaopinhui &#123;</span><br><span class="line">rewrite ^.+ http://zph.jbxue.com/ last;</span><br><span class="line">break;</span><br><span class="line">&#125;</span><br><span class="line">discuz ucenter home (uchome) rewrite</span><br><span class="line">rewrite ^/(space|network)-(.+)\.html$ /$1.php?rewrite=$2 last;</span><br><span class="line">rewrite ^/(space|network)\.html$ /$1.php last;</span><br><span class="line">rewrite ^/([0-9]+)$ /space.php?uid=$1 last;</span><br><span class="line">discuz 7 rewrite</span><br><span class="line">rewrite ^(.*)/archiver/((fid|tid)-[\w\-]+\.html)$ $1/archiver/index.php?$2 last;</span><br><span class="line">rewrite ^(.*)/forum-([0-9]+)-([0-9]+)\.html$ $1/forumdisplay.php?fid=$2&amp;page=$3 last;</span><br><span class="line">rewrite ^(.*)/thread-([0-9]+)-([0-9]+)-([0-9]+)\.html$ $1/viewthread.php?tid=$2&amp;extra=page\%3D$4&amp;page=$3 last;</span><br><span class="line">rewrite ^(.*)/profile-(username|uid)-(.+)\.html$ $1/viewpro.php?$2=$3 last;</span><br><span class="line">rewrite ^(.*)/space-(username|uid)-(.+)\.html$ $1/space.php?$2=$3 last;</span><br><span class="line">rewrite ^(.*)/tag-(.+)\.html$ $1/tag.php?name=$2 last;</span><br></pre></td></tr></table></figure><p>给discuz某版块单独配置域名</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">server_name  bbs.c1gstudio.com news.c1gstudio.com;</span><br><span class="line">location = / &#123;</span><br><span class="line">if ($http_host ~ news\.jbxue.com$) &#123;</span><br><span class="line">rewrite ^.+ http://news.jbxue.com/forum-831-1.html last;</span><br><span class="line">break;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>discuz ucenter 头像 rewrite 优化</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">location ^~ /ucenter &#123;</span><br><span class="line">location ~ .*\.php?$</span><br><span class="line">&#123;</span><br><span class="line">#fastcgi_pass  unix:/tmp/php-cgi.sock;</span><br><span class="line">fastcgi_pass  127.0.0.1:9000;</span><br><span class="line">fastcgi_index index.php;</span><br><span class="line">include fcgi.conf;</span><br><span class="line">&#125;</span><br><span class="line">location /ucenter/data/avatar &#123;</span><br><span class="line">log_not_found off;</span><br><span class="line">access_log   off;</span><br><span class="line">location ~ /(.*)_big\.jpg$ &#123;</span><br><span class="line">error_page 404 /ucenter/images/noavatar_big.gif;</span><br><span class="line">&#125;</span><br><span class="line">location ~ /(.*)_middle\.jpg$ &#123;</span><br><span class="line">error_page 404 /ucenter/images/noavatar_middle.gif;</span><br><span class="line">&#125;</span><br><span class="line">location ~ /(.*)_small\.jpg$ &#123;</span><br><span class="line">error_page 404 /ucenter/images/noavatar_small.gif;</span><br><span class="line">&#125;</span><br><span class="line">expires 300;</span><br><span class="line">break;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">jspace rewrite</span><br><span class="line">location ~ .*\.php?$</span><br><span class="line">&#123;</span><br><span class="line">#fastcgi_pass  unix:/tmp/php-cgi.sock;</span><br><span class="line">fastcgi_pass  127.0.0.1:9000;</span><br><span class="line">fastcgi_index index.php;</span><br><span class="line">include fcgi.conf;</span><br><span class="line">&#125;</span><br><span class="line">location ~* ^/index.php/</span><br><span class="line">&#123;</span><br><span class="line">rewrite ^/index.php/(.*) /index.php?$1 break;</span><br><span class="line">fastcgi_pass  127.0.0.1:9000;</span><br><span class="line">fastcgi_index index.php;</span><br><span class="line">include fcgi.conf;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      <categories>
          
          <category> nginx </category>
          
      </categories>
      
      
        <tags>
            
            <tag> nginx </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>nginx配置nginx.conf详解</title>
      <link href="/nginx-conf-explain/"/>
      <url>/nginx-conf-explain/</url>
      <content type="html"><![CDATA[<p>nginx.conf 配置文件详解、配置案例详解</p><a id="more"></a><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br></pre></td><td class="code"><pre><span class="line">#定义Nginx运行的用户和用户组</span><br><span class="line">user www www;</span><br><span class="line"></span><br><span class="line">#nginx进程数，建议设置为等于CPU总核心数。</span><br><span class="line">worker_processes 8;</span><br><span class="line"></span><br><span class="line">#全局错误日志定义类型，[ debug | info | notice | warn | error | crit ]</span><br><span class="line">error_log /var/log/nginx/error.log info;</span><br><span class="line"></span><br><span class="line">#进程文件</span><br><span class="line">pid /var/run/nginx.pid;</span><br><span class="line"></span><br><span class="line">#一个nginx进程打开的最多文件描述符数目，理论值应该是最多打开文件数（系统的值ulimit -n）与nginx进程数相除，但是nginx分配请求并不均匀，所以建议与ulimit -n的值保持一致。</span><br><span class="line">worker_rlimit_nofile 65535;</span><br><span class="line"></span><br><span class="line">#工作模式与连接数上限</span><br><span class="line">events</span><br><span class="line">&#123;</span><br><span class="line">#参考事件模型，use [ kqueue | rtsig | epoll | /dev/poll | select | poll ]; epoll模型是Linux 2.6以上版本内核中的高性能网络I/O模型，如果跑在FreeBSD上面，就用kqueue模型。</span><br><span class="line">use epoll;</span><br><span class="line">#单个进程最大连接数（最大连接数=连接数*进程数）</span><br><span class="line">worker_connections 65535;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">#设定http服务器</span><br><span class="line">http</span><br><span class="line">&#123;</span><br><span class="line">include mime.types; #文件扩展名与文件类型映射表</span><br><span class="line">default_type application/octet-stream; #默认文件类型</span><br><span class="line">#charset utf-8; #默认编码</span><br><span class="line">server_names_hash_bucket_size 128; #服务器名字的hash表大小</span><br><span class="line">client_header_buffer_size 32k; #上传文件大小限制</span><br><span class="line">large_client_header_buffers 4 64k; #设定请求缓</span><br><span class="line">client_max_body_size 8m; #设定请求缓</span><br><span class="line">sendfile on; #开启高效文件传输模式，sendfile指令指定nginx是否调用sendfile函数来输出文件，对于普通应用设为 on，如果用来进行下载等应用磁盘IO重负载应用，可设置为off，以平衡磁盘与网络I/O处理速度，降低系统的负载。注意：如果图片显示不正常把这个改成off。</span><br><span class="line">autoindex on; #开启目录列表访问，合适下载服务器，默认关闭。</span><br><span class="line">tcp_nopush on; #防止网络阻塞</span><br><span class="line">tcp_nodelay on; #防止网络阻塞</span><br><span class="line">keepalive_timeout 120; #长连接超时时间，单位是秒</span><br><span class="line"></span><br><span class="line">#FastCGI相关参数是为了改善网站的性能：减少资源占用，提高访问速度。下面参数看字面意思都能理解。</span><br><span class="line">fastcgi_connect_timeout 300;</span><br><span class="line">fastcgi_send_timeout 300;</span><br><span class="line">fastcgi_read_timeout 300;</span><br><span class="line">fastcgi_buffer_size 64k;</span><br><span class="line">fastcgi_buffers 4 64k;</span><br><span class="line">fastcgi_busy_buffers_size 128k;</span><br><span class="line">fastcgi_temp_file_write_size 128k;</span><br><span class="line"></span><br><span class="line">#gzip模块设置</span><br><span class="line">gzip on; #开启gzip压缩输出</span><br><span class="line">gzip_min_length 1k; #最小压缩文件大小</span><br><span class="line">gzip_buffers 4 16k; #压缩缓冲区</span><br><span class="line">gzip_http_version 1.0; #压缩版本（默认1.1，前端如果是squid2.5请使用1.0）</span><br><span class="line">gzip_comp_level 2; #压缩等级</span><br><span class="line">gzip_types text/plain application/x-javascript text/css application/xml;</span><br><span class="line">#压缩类型，默认就已经包含text/html，所以下面就不用再写了，写上去也不会有问题，但是会有一个warn。</span><br><span class="line">gzip_vary on;</span><br><span class="line">#limit_zone crawler $binary_remote_addr 10m; #开启限制IP连接数的时候需要使用</span><br><span class="line"></span><br><span class="line">          #后端的Web服务器可以通过X-Forwarded-For获取用户真实IP</span><br><span class="line">          proxy_set_header Host $host;</span><br><span class="line">          proxy_set_header X-Real-IP $remote_addr;</span><br><span class="line">          proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;</span><br><span class="line">          client_max_body_size 10m;    #允许客户端请求的最大单文件字节数</span><br><span class="line">          client_body_buffer_size 128k;  #缓冲区代理缓冲用户端请求的最大字节数，</span><br><span class="line">          proxy_connect_timeout 90;  #nginx跟后端服务器连接超时时间(代理连接超时)</span><br><span class="line">          proxy_send_timeout 90;        #后端服务器数据回传时间(代理发送超时)</span><br><span class="line">          proxy_read_timeout 90;         #连接成功后，后端服务器响应时间(代理接收超时)</span><br><span class="line">          proxy_buffer_size 4k;             #设置代理服务器（nginx）保存用户头信息的缓冲区大小</span><br><span class="line">          proxy_buffers 4 32k;               #proxy_buffers缓冲区，网页平均在32k以下的话，这样设置</span><br><span class="line">          proxy_busy_buffers_size 64k;    #高负荷下缓冲大小（proxy_buffers*2）</span><br><span class="line">          proxy_temp_file_write_size 64k;  #设定缓存文件夹大小，大于这个值，将从upstream服务器传</span><br><span class="line"></span><br><span class="line">upstream blog.ha97.com &#123;</span><br><span class="line">#upstream的负载均衡，weight是权重，可以根据机器配置定义权重。weigth参数表示权值，权值越高被分配到的几率越大。</span><br><span class="line">server 192.168.80.121:80 weight=3;</span><br><span class="line">server 192.168.80.122:80 weight=2;</span><br><span class="line">server 192.168.80.123:80 weight=3;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">#虚拟主机的配置</span><br><span class="line">server</span><br><span class="line">&#123;</span><br><span class="line">#监听端口</span><br><span class="line">listen 80;</span><br><span class="line">#域名可以有多个，用空格隔开</span><br><span class="line">server_name www.ha97.com ha97.com;</span><br><span class="line">index index.html index.htm index.php;</span><br><span class="line">root /data/www/ha97;</span><br><span class="line">location ~ .*\.(php|php5)?$</span><br><span class="line">&#123;</span><br><span class="line">fastcgi_pass 127.0.0.1:9000;</span><br><span class="line">fastcgi_index index.php;</span><br><span class="line">include fastcgi.conf;</span><br><span class="line">&#125;</span><br><span class="line">#图片缓存时间设置</span><br><span class="line">location ~ .*\.(gif|jpg|jpeg|png|bmp|swf)$</span><br><span class="line">&#123;</span><br><span class="line">expires 10d;</span><br><span class="line">&#125;</span><br><span class="line">#JS和CSS缓存时间设置</span><br><span class="line">location ~ .*\.(js|css)?$</span><br><span class="line">&#123;</span><br><span class="line">expires 1h;</span><br><span class="line">&#125;</span><br><span class="line">#日志格式设定</span><br><span class="line">log_format access &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos;</span><br><span class="line">&apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos;</span><br><span class="line">&apos;&quot;$http_user_agent&quot; $http_x_forwarded_for&apos;;</span><br><span class="line">#定义本虚拟主机的访问日志</span><br><span class="line">access_log /var/log/nginx/ha97access.log access;</span><br><span class="line"></span><br><span class="line">#对 &quot;/&quot; 启用反向代理</span><br><span class="line">location / &#123;</span><br><span class="line">proxy_pass http://127.0.0.1:88;</span><br><span class="line">proxy_redirect off;</span><br><span class="line">proxy_set_header X-Real-IP $remote_addr;</span><br><span class="line">#后端的Web服务器可以通过X-Forwarded-For获取用户真实IP</span><br><span class="line">proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;</span><br><span class="line">#以下是一些反向代理的配置，可选。</span><br><span class="line">proxy_set_header Host $host;</span><br><span class="line">client_max_body_size 10m; #允许客户端请求的最大单文件字节数</span><br><span class="line">client_body_buffer_size 128k; #缓冲区代理缓冲用户端请求的最大字节数，</span><br><span class="line">proxy_connect_timeout 90; #nginx跟后端服务器连接超时时间(代理连接超时)</span><br><span class="line">proxy_send_timeout 90; #后端服务器数据回传时间(代理发送超时)</span><br><span class="line">proxy_read_timeout 90; #连接成功后，后端服务器响应时间(代理接收超时)</span><br><span class="line">proxy_buffer_size 4k; #设置代理服务器（nginx）保存用户头信息的缓冲区大小</span><br><span class="line">proxy_buffers 4 32k; #proxy_buffers缓冲区，网页平均在32k以下的设置</span><br><span class="line">proxy_busy_buffers_size 64k; #高负荷下缓冲大小（proxy_buffers*2）</span><br><span class="line">proxy_temp_file_write_size 64k;</span><br><span class="line">#设定缓存文件夹大小，大于这个值，将从upstream服务器传</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">#设定查看Nginx状态的地址</span><br><span class="line">location /NginxStatus &#123;</span><br><span class="line">stub_status on;</span><br><span class="line">access_log on;</span><br><span class="line">auth_basic &quot;NginxStatus&quot;;</span><br><span class="line">auth_basic_user_file conf/htpasswd;</span><br><span class="line">#htpasswd文件的内容可以用apache提供的htpasswd工具来产生。</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">#本地动静分离反向代理配置</span><br><span class="line">#所有jsp的页面均交由tomcat或resin处理</span><br><span class="line">location ~ .(jsp|jspx|do)?$ &#123;</span><br><span class="line">proxy_set_header Host $host;</span><br><span class="line">proxy_set_header X-Real-IP $remote_addr;</span><br><span class="line">proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;</span><br><span class="line">proxy_pass http://127.0.0.1:8080;</span><br><span class="line">&#125;</span><br><span class="line">#所有静态文件由nginx直接读取不经过tomcat或resin</span><br><span class="line">location ~ .*.(htm|html|gif|jpg|jpeg|png|bmp|swf|ioc|rar|zip|txt|flv|mid|doc|ppt|pdf|xls|mp3|wma)$</span><br><span class="line">&#123; expires 15d; &#125;</span><br><span class="line">location ~ .*.(js|css)?$</span><br><span class="line">&#123; expires 1h; &#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">更详细的模块参数请参考：http://wiki.nginx.org/Main</span><br></pre></td></tr></table></figure>]]></content>
      
      <categories>
          
          <category> nginx </category>
          
      </categories>
      
      
        <tags>
            
            <tag> nginx </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>kafka对topic leader 进行自动负载均衡</title>
      <link href="/kafka-auto-loadblance-leader/"/>
      <url>/kafka-auto-loadblance-leader/</url>
      <content type="html"><![CDATA[<p>在创建一个topic时，kafka尽量将partition均分在所有的brokers上，并且将replicas也j均分在不同的broker上。</p><p>每个partitiion的所有replicas叫做”assigned replicas”，”assigned replicas”中的第一个replicas叫”preferred replica”，刚创建的topic一般”preferred replica”是leader。leader replica负责所有的读写。</p><p>但随着时间推移，broker可能会停机，会导致leader迁移，导致机群的负载不均衡。我们期望对topic的leader进行重新负载均衡，让partition选择”preferred replica”做为leader。</p><p>查看topic详情</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">./kafka-topics.sh --zookeeper 127.0.0.1:2181 --describe  --topic logdata-es</span><br><span class="line"></span><br><span class="line">Topic:logdata-es        PartitionCount:6        ReplicationFactor:2     Configs:</span><br><span class="line">        Topic: logdata-es       Partition: 0    Leader: 2       Replicas: 3,2   Isr: 2,3</span><br><span class="line">        Topic: logdata-es       Partition: 1    Leader: 2       Replicas: 5,2   Isr: 2,5</span><br><span class="line">        Topic: logdata-es       Partition: 2    Leader: 1       Replicas: 4,1   Isr: 1,4</span><br><span class="line">        Topic: logdata-es       Partition: 3    Leader: 2       Replicas: 5,2   Isr: 2,5</span><br><span class="line">        Topic: logdata-es       Partition: 4    Leader: 1       Replicas: 1,3   Isr: 1,3</span><br><span class="line">        Topic: logdata-es       Partition: 5    Leader: 2       Replicas: 2,5   Isr: 2,5</span><br></pre></td></tr></table></figure><p>编辑相应topic的json文件  </p><p>vim logdata-es-autu.json </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line"> &quot;partitions&quot;:</span><br><span class="line">  [</span><br><span class="line">    &#123;&quot;topic&quot;: &quot;logdata-es&quot;, &quot;partition&quot;: 0&#125;,</span><br><span class="line">    &#123;&quot;topic&quot;: &quot;logdata-es&quot;, &quot;partition&quot;: 1&#125;,</span><br><span class="line">    &#123;&quot;topic&quot;: &quot;logdata-es&quot;, &quot;partition&quot;: 2&#125;,</span><br><span class="line">    &#123;&quot;topic&quot;: &quot;logdata-es&quot;, &quot;partition&quot;: 3&#125;,</span><br><span class="line">    &#123;&quot;topic&quot;: &quot;logdata-es&quot;, &quot;partition&quot;: 4&#125;,</span><br><span class="line">    &#123;&quot;topic&quot;: &quot;logdata-es&quot;, &quot;partition&quot;: 5&#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>执行</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">./kafka-preferred-replica-election.sh --zookeeper 127.0.0.1:2181 --path-to-json-file logdata-es-autu.json </span><br><span class="line"></span><br><span class="line">Successfully started preferred replica election for partitions Set([logdata-es,3], [logdata-es,2], [logdata-es,1], [logdata-es,5], [logdata-es,0], [logdata-es,4])</span><br></pre></td></tr></table></figure><p>之后在查看</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Topic:logdata-es        PartitionCount:6        ReplicationFactor:2     Configs:</span><br><span class="line">        Topic: logdata-es       Partition: 0    Leader: 3       Replicas: 3,2   Isr: 2,3</span><br><span class="line">        Topic: logdata-es       Partition: 1    Leader: 5       Replicas: 5,2   Isr: 2,5</span><br><span class="line">        Topic: logdata-es       Partition: 2    Leader: 4       Replicas: 4,1   Isr: 1,4</span><br><span class="line">        Topic: logdata-es       Partition: 3    Leader: 5       Replicas: 5,2   Isr: 2,5</span><br><span class="line">        Topic: logdata-es       Partition: 4    Leader: 1       Replicas: 1,3   Isr: 1,3</span><br><span class="line">        Topic: logdata-es       Partition: 5    Leader: 2       Replicas: 2,5   Isr: 2,5</span><br></pre></td></tr></table></figure><p>官方说明</p><p><a href="https://cwiki.apache.org/confluence/display/KAFKA/Replication%20tools" target="_blank" rel="noopener">https://cwiki.apache.org/confluence/display/KAFKA/Replication%20tools</a></p><p>如果你感觉文章还可以的话，请帮点点下面的广告。谢谢！</p>]]></content>
      
      <categories>
          
          <category> kafka </category>
          
      </categories>
      
      
        <tags>
            
            <tag> kafka </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>hive中文乱码解决办法</title>
      <link href="/hive-chinese-garbled/"/>
      <url>/hive-chinese-garbled/</url>
      <content type="html"><![CDATA[<p>环境：  hive 1.2.1</p><p>hive 中文注释为乱码，</p><h4 id="首先我们修改一下hive源数据库里的编码"><a href="#首先我们修改一下hive源数据库里的编码" class="headerlink" title="首先我们修改一下hive源数据库里的编码"></a>首先我们修改一下hive源数据库里的编码</h4><p>连接到你环境的hive源数据中。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">show create COLUMNS_V2;</span><br></pre></td></tr></table></figure><p>可以看到 </p><p><img src="/images/hive-garbled-1.jpeg" alt="hive-garbled-1"></p><p>我们将COLUMNS_V2表中的COMMENT修改为utf-8</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ALTER TABLE  `COLUMNS_V2` CHANGE  `COMMENT`  `COMMENT`  varchar(256) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL;</span><br></pre></td></tr></table></figure><p>之后在看就可以了，可以显示中文啦。 </p><p><img src="/images/hive-garbled-2.jpeg" alt="hive-garbled-2"></p>]]></content>
      
      <categories>
          
          <category> hive </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hive </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>hive计算合并小文件</title>
      <link href="/hive-merge-small-files/"/>
      <url>/hive-merge-small-files/</url>
      <content type="html"><![CDATA[<p>hive增加自动合并小文件配置以及在map阶段将多个小文件合并成一个计算。可以提高资源的利用率。</p><p>比如由于小文件原先需要启动10个map，现在只需要启动2个map。</p><p>hadoop  hive 环境： hadoop2.6+hive1.2.1    lzo压缩</p><p>hive-site.xml 配置</p><a id="more"></a><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">     &lt;name&gt;hive.merge.mapfiles&lt;/name&gt;</span><br><span class="line">     &lt;value&gt;true&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">     &lt;name&gt;hive.merge.mapredfiles&lt;/name&gt;</span><br><span class="line">     &lt;value&gt;true&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">     &lt;name&gt;hive.merge.smallfiles.avgsize&lt;/name&gt;</span><br><span class="line">     &lt;value&gt;69000000&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">     &lt;name&gt;hive.merge.size.per.task&lt;/name&gt;</span><br><span class="line">     &lt;value&gt;256000000&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">     &lt;name&gt;hive.merge.tezfiles&lt;/name&gt;</span><br><span class="line">     &lt;value&gt;true&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">     &lt;name&gt;mapreduce.input.fileinputformat.split.maxsize&lt;/name&gt;</span><br><span class="line">     &lt;value&gt;256000000&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">     &lt;name&gt;mapreduce.input.fileinputformat.split.minsize&lt;/name&gt;</span><br><span class="line">     &lt;value&gt;1&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">     &lt;name&gt;mapreduce.input.fileinputformat.split.minsize.per.node&lt;/name&gt;</span><br><span class="line">     &lt;value&gt;128000000&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">     &lt;name&gt;mapreduce.input.fileinputformat.split.minsize.per.rack&lt;/name&gt;</span><br><span class="line">     &lt;value&gt;128000000&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure><p>参数说明自己查吧！</p><p><a href="https://cwiki.apache.org/confluence/display/Hive/AdminManual+Configuration" target="_blank" rel="noopener">https://cwiki.apache.org/confluence/display/Hive/AdminManual+Configuration</a></p><h3 id="测试的步骤"><a href="#测试的步骤" class="headerlink" title="测试的步骤"></a>测试的步骤</h3><p>启动压缩</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">set hive.exec.compress.output=true;</span><br><span class="line"></span><br><span class="line">set mapreduce.output.fileoutputformat.compress=true;</span><br></pre></td></tr></table></figure><p>一.减少map数，（当有大量小文件时，启动合并）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">set hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat;</span><br><span class="line"></span><br><span class="line">set mapreduce.input.fileinputformat.split.maxsize=1073741824;</span><br><span class="line"></span><br><span class="line">set mapreduce.input.fileinputformat.split.minsize=1;</span><br><span class="line"></span><br><span class="line">set mapreduce.input.fileinputformat.split.minsize.per.node=536870912;</span><br><span class="line"></span><br><span class="line">set mapreduce.input.fileinputformat.split.minsize.per.rack=536870912;</span><br></pre></td></tr></table></figure><p>经过测试，这种设置可以在map阶段和并小文件，减少map的数量。</p><p>注意：在测试的时候，如果文件格式为Textfile，并且启用lzo压缩，不能生效。 rcfile以及orc可以生效，Textfile不启用lzo压缩也可以生效。如果是新集群的话，没有历史遗留的问题的话，建议hive都使用orc文件格式，以及启用lzo压缩。</p><p>二.MR作业结束后，判断生成文件的平均大小，如果小于阀值，就再启动一个job来合并文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">set hive.merge.mapredfiles=true;</span><br><span class="line"></span><br><span class="line">set hive.merge.mapfiles=true;</span><br><span class="line"></span><br><span class="line">set hive.merge.smallfiles.avgsize=268435456;</span><br></pre></td></tr></table></figure><p>如果你感觉文章还可以的话，请帮点点下面的广告！谢谢！</p>]]></content>
      
      <categories>
          
          <category> hive </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hive </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>marathon-lb输出代理的访问日志</title>
      <link href="/marathon-lb-access-log-debug/"/>
      <url>/marathon-lb-access-log-debug/</url>
      <content type="html"><![CDATA[<h1 id="marathon-lb输出代理的访问日志"><a href="#marathon-lb输出代理的访问日志" class="headerlink" title="marathon-lb输出代理的访问日志"></a>marathon-lb输出代理的访问日志</h1><p>之前运行marathon-lb没有打印lb的代理日志，在容器中是能看到marathon-lb获取marathon信息的日志。如果想查看访问量、代理状态、代理的具体的URL等信息的话，还是没办法的。</p><p>当然marathon-lb是有接口可以看到一些访问量、访问状态统计的信息的。 可以用：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://marathon-lb-ip:9090/haproxy?stats</span><br></pre></td></tr></table></figure><p>但是这个接口没有访问的具体信息，有问题很难排查。</p><p>还有什么接口， 你可以查看我之前写的文章</p><p><a href="https://sukbeta.github.io/marathon-lb-configure-nginx/">https://sukbeta.github.io/marathon-lb-configure-nginx/</a></p><p>所以，下面我们来说说这么收集marathon-lb的日志。</p><h4 id="marathon-lb的配置"><a href="#marathon-lb的配置" class="headerlink" title="marathon-lb的配置"></a>marathon-lb的配置</h4><p>进入容器修改配置</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker exec -it container-id /bin/bash</span><br></pre></td></tr></table></figure><p>这里没有vi 什么的，可以用sed修改 config.py</p><p>我的配置是：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">......</span><br><span class="line">global</span><br><span class="line">  daemon</span><br><span class="line">  log /dev/log local1 debug</span><br><span class="line">  spread-checks 5</span><br><span class="line">  max-spread-checks 15000</span><br><span class="line">  maxconn 500000</span><br><span class="line">  .....</span><br><span class="line">  .....</span><br><span class="line">defaults</span><br><span class="line">  load-server-state-from-file global</span><br><span class="line">  log               global</span><br><span class="line">  mode  http</span><br><span class="line">  option        httplog</span><br><span class="line">  option        dontlognull</span><br><span class="line">  retries                   3</span><br><span class="line">  backlog               10000</span><br><span class="line">  maxconn               500000</span><br><span class="line">  timeout connect          10s</span><br><span class="line">  timeout client          300s</span><br><span class="line">  timeout server          300s</span><br><span class="line">  timeout tunnel        3600s</span><br><span class="line">  timeout http-keep-alive  1s</span><br><span class="line">  timeout http-request    15s</span><br><span class="line">  timeout queue           300s</span><br><span class="line">  timeout tarpit          60s</span><br><span class="line">......</span><br></pre></td></tr></table></figure><p>重新 commit 一下容器</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker commit -m &quot;logdebug&quot; 9c1c65028b12 marathon-lb-debuglog-v1:v1.11.1</span><br></pre></td></tr></table></figure><h4 id="启动容器配置"><a href="#启动容器配置" class="headerlink" title="启动容器配置"></a>启动容器配置</h4><p>首先，marathon-lb启动容器的时候需要挂在主机的/dev/log设备。lb是把日子好打到系统上的。</p><p>marathon-lb 的json 文件：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;id&quot;: &quot;/marathon-lb/marathon-lb-mesos-slave02&quot;,</span><br><span class="line">  &quot;cmd&quot;: null,</span><br><span class="line">  &quot;cpus&quot;: 1,</span><br><span class="line">  &quot;mem&quot;: 128,</span><br><span class="line">  &quot;disk&quot;: 0,</span><br><span class="line">  &quot;instances&quot;: 0,</span><br><span class="line">  &quot;constraints&quot;: [</span><br><span class="line">    [</span><br><span class="line">      &quot;hostname&quot;,</span><br><span class="line">      &quot;CLUSTER&quot;,</span><br><span class="line">      &quot;mesos-slave02&quot;</span><br><span class="line">    ]</span><br><span class="line">  ],</span><br><span class="line">  &quot;container&quot;: &#123;</span><br><span class="line">    &quot;type&quot;: &quot;DOCKER&quot;,</span><br><span class="line">    &quot;volumes&quot;: [</span><br><span class="line">      &#123;</span><br><span class="line">        &quot;containerPath&quot;: &quot;/dev/log&quot;,</span><br><span class="line">        &quot;hostPath&quot;: &quot;/dev/log&quot;,</span><br><span class="line">        &quot;mode&quot;: &quot;RW&quot;</span><br><span class="line">      &#125;</span><br><span class="line">    ],</span><br><span class="line">    &quot;docker&quot;: &#123;</span><br><span class="line">      &quot;image&quot;: &quot;marathon-lb-debuglog-v1:v1.11.1&quot;,</span><br><span class="line">      &quot;network&quot;: &quot;HOST&quot;,</span><br><span class="line">      &quot;portMappings&quot;: [],</span><br><span class="line">      &quot;privileged&quot;: true,</span><br><span class="line">      &quot;parameters&quot;: [],</span><br><span class="line">      &quot;forcePullImage&quot;: false</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;env&quot;: &#123;</span><br><span class="line">    &quot;TZ&quot;: &quot;Asia/Shanghai&quot;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;args&quot;: [</span><br><span class="line">    &quot;sse&quot;,</span><br><span class="line">    &quot;-m&quot;,</span><br><span class="line">    &quot;http://192.168.1.10:8080&quot;,</span><br><span class="line">    &quot;--group&quot;,</span><br><span class="line">    &quot;marathon-group&quot;</span><br><span class="line">  ],</span><br><span class="line">  &quot;upgradeStrategy&quot;: &#123;</span><br><span class="line">    &quot;minimumHealthCapacity&quot;: 0,</span><br><span class="line">    &quot;maximumOverCapacity&quot;: 0</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这是就可以在系统中看到marthon的日志了</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">journalctl -f</span><br><span class="line"></span><br><span class="line">Jan 10 16:01:29 mesos-slave02.host-mtime.com haproxy[33023]: 192.168.2.2:54544 [10/Jan/2019:08:01:29.742] marathon-lb/marathon-lb-mesos-slave01_host-mtime_com_192_168_1_101_31942 0/0/0/0/0 200 225 - - ---- 1/1/0/0/0 0/0 &quot;GET / HTTP/1.1&quot;</span><br></pre></td></tr></table></figure><h4 id="系统配置"><a href="#系统配置" class="headerlink" title="系统配置"></a>系统配置</h4><p>系统需要用rsyslog服务来讲haproxy的日志打到指定的文件中</p><p>配置 rsyslog的haproxy配置文件</p><p>vim /etc/rsyslog.d/haproxy.conf </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">local1.*  /home/haproxy/haproxy.log</span><br></pre></td></tr></table></figure><ul><li>因为haproxy的log里配置的 local1 接口，所以这里接受 local1的所有日志</li></ul><p>vim /etc/rsyslog.conf </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">......</span><br><span class="line"># Provides UDP syslog reception</span><br><span class="line">$ModLoad imudp</span><br><span class="line">$UDPServerRun 514</span><br><span class="line"></span><br><span class="line"># Provides TCP syslog reception</span><br><span class="line">$ModLoad imtcp</span><br><span class="line">$InputTCPServerRun 514</span><br><span class="line">.....</span><br></pre></td></tr></table></figure><p>vim /etc/sysconfig/rsyslog </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SYSLOGD_OPTIONS=&quot;-r -m 0&quot;</span><br></pre></td></tr></table></figure><p>重启 rsyslog 服务</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl restart rsyslog</span><br></pre></td></tr></table></figure><p>如果没有日志的话，重启一下marathon-lb的容器就可以啦。</p><p>如果感觉文航还可以的话，请帮忙点点下面的广告！ 谢谢！</p>]]></content>
      
      <categories>
          
          <category> marathon </category>
          
      </categories>
      
      
        <tags>
            
            <tag> marathon </tag>
            
            <tag> marathon-lb </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>hadoop Cannot obtain block length for LocatedBlock 解决</title>
      <link href="/hadoop-Cannot-obtain-block-length-for-LocatedBlock/"/>
      <url>/hadoop-Cannot-obtain-block-length-for-LocatedBlock/</url>
      <content type="html"><![CDATA[<p>  这几天发现HDFS上的个别文件出现读取异常，使用 hdfs dfs -get 下载文件的话也会报错 “get: Cannot obtain block length for LocatedBlock” 信息。</p><p>hdfs dfs -get 报错信息：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@-client00 linshi]$ hdfs dfs -get /data/logs/dt=2018-12-24/mx.1545619356868 .</span><br><span class="line">get: Cannot obtain block length for LocatedBlock&#123;BP-2011896023-10.10.10.100-1494585324698:blk_1133914343_60174136; getBlockSize()=359; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[10.10.10.104:50010,DS-f83c59e0-b769-433e-92d3-db175fcd6717,DISK], DatanodeInfoWithStorage[10.10.10.102:50010,DS-a6654129-9355-4413-bd0c-98175a2b501c,DISK], DatanodeInfoWithStorage[10.10.10.103:50010,DS-53787b49-64bd-48d8-ac16-f6af4a233808,DISK]]&#125;</span><br></pre></td></tr></table></figure><p>  出现这样问题的文件都是Flume产生的文件， 很可能是Flume在写文件的时候没有关闭写的操作，导致hadoop上的这个文件一直为 openforwrite 状态。或data node节点突然下线的情况也会出现。</p><ul><li>Flume客户端写入hdfs文件时的网络连接被不正常的关闭了</li><li>Flume客户端写入hdfs失败了，而且其replication副本也丢失了</li><li>HDFS文件租约未释放</li></ul><p>(我们在Flume的日志中也看到了相应异常日志)</p><h4 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h4><h5 id="查找这样的文件"><a href="#查找这样的文件" class="headerlink" title="查找这样的文件"></a>查找这样的文件</h5><p>首先我们需要找出这样的文件。</p><p>出现这种情况可以用fsck检查一下hdfs的文件系统</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs fsck /</span><br></pre></td></tr></table></figure><p>这时你会发现没什么异常文件出现。  下面我在检查一遍。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hdfs fsck / –openforwrite</span><br><span class="line">或</span><br><span class="line">hdfs fsck /data/logs –openforwrite   # 检查具体目录</span><br></pre></td></tr></table></figure><p>这时就会出现有问题的文件了。</p><p>For Example:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">....................//data/logs/dt=2018-12-25/_mx_ticket_order_detail.1545895383766.tmp 578 bytes, 1 block(s), OPENFORWRITE: </span><br><span class="line">/data/logs/dt=2018-12-25/order_detail.1545895383766.tmp: MISSING 1 blocks of total size 578 B................................................................................</span><br><span class="line">....................................................................................................</span><br><span class="line">............../data/logs/dt=2018-12-26/_mx_ticket_order_detail.1545895204686.tmp 890 bytes, 1 block(s), OPENFORWRITE: </span><br><span class="line">/data/logs/dt=2018-12-26/order_detail.1545895204686.tmp: MISSING 1 blocks of total size 890 B......................................................................................</span><br><span class="line">................................................................................../data/logsdt=2018-12-27/_mx_ticket_order_detail.1545895289332.tmp 2367 bytes, 1 block(s), OPENFORWRITE: </span><br><span class="line">/data/logs/dt=2018-12-27/detail.1545895289332.tmp: MISSING 1 blocks of total size 2367 B..................</span><br><span class="line">...........................................................Status: CORRUPT</span><br></pre></td></tr></table></figure><h5 id="解决"><a href="#解决" class="headerlink" title="解决"></a>解决</h5><p>我用释放租约的方式解决的这个问题</p><p>释放租约命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs debug recoverLease -path -retries</span><br></pre></td></tr></table></figure><p>我的命令是：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs debug recoverLease /data/logs/dt=2018-12-24/mx.1545619356868</span><br></pre></td></tr></table></figure><p>之后再 get 这个文件就可以了， 问题解决！</p><p>如果你感觉文章还可以的话，请帮点点下面的广告。非常感谢！</p>]]></content>
      
      <categories>
          
          <category> hadoop </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hadoop </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>cgroup限制nodemanager、regionserver的资源</title>
      <link href="/cgroup-limit-nm-reg/"/>
      <url>/cgroup-limit-nm-reg/</url>
      <content type="html"><![CDATA[<h1 id="cgroup限制nodemanager、regionserver的资源"><a href="#cgroup限制nodemanager、regionserver的资源" class="headerlink" title="cgroup限制nodemanager、regionserver的资源"></a>cgroup限制nodemanager、regionserver的资源</h1><p>用系统自带的cgroup服务来限制nodemanager、regionserver的cpu使用率。  </p><h5 id="安装cgroup服务，"><a href="#安装cgroup服务，" class="headerlink" title="安装cgroup服务，"></a>安装cgroup服务，</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">##  centos 7.1 系统安装 cgroup</span><br><span class="line">chattr -i /etc/passwd /etc/shadow /etc/group /etc/gshadow</span><br><span class="line">yum install -y libcgroup libcgroup-tools</span><br><span class="line"></span><br><span class="line">## centos 6 系统安装 cgroup</span><br><span class="line">chattr -i /etc/passwd /etc/shadow /etc/group /etc/gshadow</span><br><span class="line">yum install -y libcgroup</span><br></pre></td></tr></table></figure><h5 id="编辑cgroup配置文件"><a href="#编辑cgroup配置文件" class="headerlink" title="编辑cgroup配置文件"></a>编辑cgroup配置文件</h5><p>cpu 32盒 最大使用 90% ，<br>yarn 32 <em> 0.9 </em> 100000 = 2880000 ，<br>hbase 600000  6盒cpu 600 * 1000</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/cgconfig.conf</span><br><span class="line">group yarn &#123;</span><br><span class="line">   perm &#123;</span><br><span class="line">    task &#123;</span><br><span class="line">        uid = hadoop;</span><br><span class="line">        gid = hadoop;</span><br><span class="line">    &#125;</span><br><span class="line">    admin &#123;</span><br><span class="line">       uid = hadoop;</span><br><span class="line">       gid = hadoop;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">   cpu &#123;</span><br><span class="line">          cpu.cfs_period_us= 100000;</span><br><span class="line">          cpu.cfs_quota_us= 2880000;</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br><span class="line">group yarn/hbase &#123;</span><br><span class="line">   perm &#123;</span><br><span class="line">    task &#123;</span><br><span class="line">        uid = hadoop;</span><br><span class="line">        gid = hadoop;</span><br><span class="line">    &#125;</span><br><span class="line">    admin &#123;</span><br><span class="line">       uid = hadoop;</span><br><span class="line">       gid = hadoop;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">   cpu &#123;</span><br><span class="line">          cpu.cfs_period_us= 100000;</span><br><span class="line">          cpu.cfs_quota_us=  600000;</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="启动cgroup服务"><a href="#启动cgroup服务" class="headerlink" title="启动cgroup服务"></a>启动cgroup服务</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">systemctl restart cgconfig.service</span><br><span class="line">systemctl enable cgconfig.service</span><br></pre></td></tr></table></figure><h5 id="重新启动-nodemanager-和-regionserver-服务"><a href="#重新启动-nodemanager-和-regionserver-服务" class="headerlink" title="重新启动 nodemanager 和 regionserver 服务"></a>重新启动 nodemanager 和 regionserver 服务</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">su - hadoop</span><br><span class="line"></span><br><span class="line">yarn-daemon.sh stop nodemanager</span><br><span class="line">cgexec -g cpu:yarn yarn-daemon.sh start nodemanager</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">hbase-daemon.sh stop regionserver</span><br><span class="line">cgexec -g cpu:yarn/hbase hbase-daemon.sh start regionserver</span><br></pre></td></tr></table></figure><h5 id="检查-服务"><a href="#检查-服务" class="headerlink" title="检查 服务"></a>检查 服务</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cd /sys/fs/cgroup/cpu/yarn</span><br><span class="line">cat tasks | grep &quot;nodemanager PID&quot;</span><br><span class="line"></span><br><span class="line">cd /sys/fs/cgroup/cpu/yarn/hbase</span><br><span class="line">cat tasks | grep &quot;regsionserver PID&quot;</span><br></pre></td></tr></table></figure>]]></content>
      
      <categories>
          
          <category> hadoop </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hadoop </tag>
            
            <tag> linux </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>hive metastore ha 配置</title>
      <link href="/hive-meta-ha/"/>
      <url>/hive-meta-ha/</url>
      <content type="html"><![CDATA[<p>hive metastore 配置多台，可以避免单节点故障导致整个集群的hive client不可用。同时hive client配置多个merastore地址，会自动选择可用节点。</p><h3 id="metastore单独配置"><a href="#metastore单独配置" class="headerlink" title="metastore单独配置"></a>metastore单独配置</h3><p>metastore 的配置单独拿出来，这样不容易让别人看到连接数据库的信息。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@cd-client00 conf]# echo $HIVE_HOME</span><br><span class="line">/home/hadoop/apache-hadoop/hive</span><br><span class="line"></span><br><span class="line">mkdir -p /home/hadoop/apache-hadoop/hive/hive-metestore/conf</span><br><span class="line">chmod 700 /home/hadoop/apache-hadoop/hive/hive-metestore/conf</span><br></pre></td></tr></table></figure><p>这个目录的权限你可以设置为 700 ，只有自己的帐号可以看到。 其他的hive client也不需要这个目录的配置。</p><p>vim /home/hadoop/apache-hadoop/hive/hive-metestore/conf/hive-site.xml</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">          &lt;property&gt;</span><br><span class="line">            &lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt;</span><br><span class="line">            &lt;value&gt;jdbc:mysql://mysql-master.inc-shining.com:8806/hive_meta?zeroDateTimeBehavior=convertToNull&amp;amp;characterEncoding=UTF-8&lt;/value&gt;</span><br><span class="line">          &lt;/property&gt;</span><br><span class="line">          </span><br><span class="line">          &lt;property&gt;</span><br><span class="line">            &lt;name&gt;javax.jdo.option.ConnectionUserName&lt;/name&gt;</span><br><span class="line">            &lt;value&gt;hive_user&lt;/value&gt;</span><br><span class="line">            &lt;description&gt;Username to use against metastore database&lt;/description&gt;</span><br><span class="line">          &lt;/property&gt;</span><br><span class="line">          </span><br><span class="line">          &lt;property&gt;</span><br><span class="line">            &lt;name&gt;javax.jdo.option.ConnectionPassword&lt;/name&gt;</span><br><span class="line">            &lt;value&gt;hive_password&lt;/value&gt;</span><br><span class="line">            &lt;description&gt;password to use against metastore database&lt;/description&gt;</span><br><span class="line">          &lt;/property&gt;</span><br><span class="line">        </span><br><span class="line">          &lt;property&gt;</span><br><span class="line">            &lt;name&gt;javax.jdo.option.ConnectionDriverName&lt;/name&gt;</span><br><span class="line">            &lt;value&gt;com.mysql.jdbc.Driver&lt;/value&gt;</span><br><span class="line">            &lt;description&gt;Driver class name for a JDBC metastore&lt;/description&gt;</span><br><span class="line">          &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure><h3 id="启动-hive-metastore"><a href="#启动-hive-metastore" class="headerlink" title="启动 hive metastore"></a>启动 hive metastore</h3><p>正常启动 metastore 的话会到 $HIVE_HOME/conf下找配置文件，我们这里已经将这个配置改目录了，所以我写了一个脚本启动。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">vim hive-meta-start.sh</span><br><span class="line"></span><br><span class="line">#!/bin/bash</span><br><span class="line">export HIVE_CONF_DIR=/home/hadoop/apache-hadoop/hive/hive-metastore/conf</span><br><span class="line">nohup  hive --service metastore &gt; /home/hadoop/apache-hadoop/hive/hive-logs/metastore.log 2&gt;&amp;1 &amp; </span><br><span class="line">echo $! &gt; /home/hadoop/apache-hadoop/hive/hive-logs/metastore.pid</span><br><span class="line">unset HIVE_CONF_DIR</span><br></pre></td></tr></table></figure><p>多台 hive metastoe 机器都是这么配置启动，即可。</p><h3 id="hive-client-配置"><a href="#hive-client-配置" class="headerlink" title="hive client 配置"></a>hive client 配置</h3><p>hive client的配置中就不需要存在连接mysql的信息配置。</p><p>vim $HIVE_HOME/conf/hive-site.xml</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">      &lt;name&gt;hive.metastore.uris&lt;/name&gt;</span><br><span class="line">      &lt;value&gt;thrift://meta-1.sukbeta.com:9083,thrift://meta-2.sukbeta.com:9083&lt;/value&gt;</span><br><span class="line">      &lt;description&gt;Thrift URI for the remote metastore. Used by metastore client to connect to remote metastore.&lt;/description&gt;</span><br><span class="line">   &lt;/property&gt;</span><br></pre></td></tr></table></figure><p>这样就配置完成了，client端就可以直接用hive了，</p><ul><li>这样启动hive的时候，本地client端就无需实例化hive的metastore，启动速度会加快。</li></ul><p>如果你感觉文章还可以的话，请帮点点下面的广告！ 谢谢！</p>]]></content>
      
      <categories>
          
          <category> hive </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hive </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>kafka设置某个topic的数据过期时间</title>
      <link href="/kafka-set-topic-retention/"/>
      <url>/kafka-set-topic-retention/</url>
      <content type="html"><![CDATA[<h1 id="kafka-单独设置某个topic的数据过期时间"><a href="#kafka-单独设置某个topic的数据过期时间" class="headerlink" title="kafka 单独设置某个topic的数据过期时间"></a>kafka 单独设置某个topic的数据过期时间</h1><p>kafka 默认存放7天的临时数据，如果遇到磁盘空间小，存放数据量大，可以设置缩短这个时间。</p><h3 id="全局设置"><a href="#全局设置" class="headerlink" title="全局设置"></a>全局设置</h3><p>修改  server.properties</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">log.retention.hours=72</span><br><span class="line">log.cleanup.policy=delete</span><br></pre></td></tr></table></figure><h3 id="单独对某一个topic设置过期时间"><a href="#单独对某一个topic设置过期时间" class="headerlink" title="单独对某一个topic设置过期时间"></a>单独对某一个topic设置过期时间</h3><p>如果你这样设置完，可以磁盘空间还是不够，或只有某一个topic数据量过大。</p><p>想单独对这个topic的过期时间设置短点，</p><h5 id="可以这样设置："><a href="#可以这样设置：" class="headerlink" title="可以这样设置："></a>可以这样设置：</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./kafka-configs.sh --zookeeper localhost:2181 --alter --entity-name wordcounttopic --entity-type topics --add-config retention.ms=86400000</span><br></pre></td></tr></table></figure><p>retention.ms=86400000  为一天，单位是毫秒。</p><h5 id="查看设置："><a href="#查看设置：" class="headerlink" title="查看设置："></a>查看设置：</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@kafka00 kafka]$   ./kafka-configs.sh --zookeeper localhost:2181 --describe --entity-name wordcounttopic --entity-type topics</span><br><span class="line"></span><br><span class="line">Configs for topics:wordcounttopic are retention.ms=86400000</span><br></pre></td></tr></table></figure><h5 id="Q-amp-A"><a href="#Q-amp-A" class="headerlink" title="Q&amp;A"></a>Q&amp;A</h5><p>如果没有立刻删除的话你可以设置下面参数。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./kafka-topics.sh --zookeeper localhost:2181 --alter --topic wordcounttopic --config cleanup.policy=delete</span><br></pre></td></tr></table></figure><p>如果你感觉文章还可以的话，请帮点点下面的广告！ 谢谢！</p>]]></content>
      
      <categories>
          
          <category> kafka </category>
          
      </categories>
      
      
        <tags>
            
            <tag> kafka </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>一个简单好用的ssh远程执行命令的脚本</title>
      <link href="/ssh-remote-exec-command/"/>
      <url>/ssh-remote-exec-command/</url>
      <content type="html"><![CDATA[<p>运维经常需要到其他机器上执行命令，copy等操作。其实也有很多工具可以实现的，如jenkins、saltstack、ansible等等。这样还需要安装工具什么的。下面的小脚本不需要任何工具。先实现copy和执行命令吧。</p><p>好了，直接看脚本吧。</p><h4 id="脚本内容"><a href="#脚本内容" class="headerlink" title="脚本内容"></a>脚本内容</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line">#!/bin/bash</span><br><span class="line">COMMAND=$1</span><br><span class="line">shift</span><br><span class="line"></span><br><span class="line">SLAVES=$1</span><br><span class="line">shift</span><br><span class="line"></span><br><span class="line">#distribute files</span><br><span class="line">if [ $COMMAND == &quot;distribute&quot; ] || [ $COMMAND == &quot;copy&quot; ];then</span><br><span class="line">  SRC=$1</span><br><span class="line">  shift </span><br><span class="line"></span><br><span class="line">  DEST=$1</span><br><span class="line">  shift</span><br><span class="line"></span><br><span class="line">  if [ -f $SLAVES ];then</span><br><span class="line">  cat $SLAVES | while read slave</span><br><span class="line">  do</span><br><span class="line">    #已#开头的注释可略过</span><br><span class="line">    echo &quot;$slave&quot; | grep -q &quot;^#&quot;</span><br><span class="line">    if [ $? -eq 0 ] ; then</span><br><span class="line">        continue;</span><br><span class="line">    fi</span><br><span class="line">  </span><br><span class="line">    echo &quot;===================$slave=================&quot;</span><br><span class="line">    scp -r  -oUserKnownHostsFile=/dev/null -oStrictHostKeyChecking=no $SRC $slave:$DEST</span><br><span class="line">  done</span><br><span class="line">  exit 0</span><br><span class="line">else</span><br><span class="line">   echo &quot;===================$SLAVES=================&quot;</span><br><span class="line">    scp -r  -oUserKnownHostsFile=/dev/null -oStrictHostKeyChecking=no $SRC $SLAVES:$DEST</span><br><span class="line">  fi</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line">#common</span><br><span class="line">if [ $COMMAND == &quot;common&quot; ] || [ $COMMAND == &quot;command&quot; ];then</span><br><span class="line">  if [ -f $SLAVES ];then</span><br><span class="line">  cat $SLAVES | while read slave</span><br><span class="line">  do</span><br><span class="line">    #已#开头的注释可略过</span><br><span class="line">    echo &quot;$slave&quot; | grep -q &quot;^#&quot;</span><br><span class="line">    if [ $? -eq 0 ] ; then</span><br><span class="line">        continue;</span><br><span class="line">    fi</span><br><span class="line"></span><br><span class="line">    ssh  -oUserKnownHostsFile=/dev/null -oStrictHostKeyChecking=no $slave &lt;&lt; EOF</span><br><span class="line">      echo &quot;==================$slave======================&quot;</span><br><span class="line">      eval $@</span><br><span class="line">      exit</span><br><span class="line">EOF</span><br><span class="line">  done</span><br><span class="line">  exit 0</span><br><span class="line">else</span><br><span class="line">    ssh  -oUserKnownHostsFile=/dev/null -oStrictHostKeyChecking=no $SLAVES &lt;&lt; EOF</span><br><span class="line">      echo &quot;==================$SLAVES======================&quot;</span><br><span class="line">      eval $@</span><br><span class="line">      exit</span><br><span class="line">EOF</span><br><span class="line">  fi</span><br><span class="line">fi</span><br></pre></td></tr></table></figure><h4 id="脚本用法"><a href="#脚本用法" class="headerlink" title="脚本用法"></a>脚本用法</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"># 复制文件到所有机器的/home/hadoop/apache-hadoop/目录下，all_node是列表</span><br><span class="line">./tools.sh copy all_node /home/hadoop/apache-hadoop/hadoop-2.8.0.tar.gz /home/hadoop/apache-hadoop/</span><br><span class="line"></span><br><span class="line"># 复制文件到shining-1.hostname机器的指定目录下</span><br><span class="line">./tools.sh copy shining-1.hostname /home/hadoop/mapred-site.xml /home/hadoop/apache-hadoop/hadoop/etc/hadoop/</span><br><span class="line"></span><br><span class="line"># 复制多个文件到所有机器的指定目录下</span><br><span class="line">./tools.sh copy all_node &quot;core-site.xml hdfs-site.xml yarn-site.xml&quot; /home/hadoop/apache-hadoop/hadoop/etc/hadoop/</span><br><span class="line"></span><br><span class="line"># 到所有机器下执行命令</span><br><span class="line">./tools.sh command all_node &apos;cd /home/hadoop/apache-hadoop/;ln -s hadoop-2.8.0 hadoop;&apos;</span><br><span class="line"></span><br><span class="line"># 到执行集群下执行命令</span><br><span class="line">./tools.sh command shining-1.hostname &quot;hostname&quot;</span><br><span class="line"></span><br><span class="line"># 执行追加命令</span><br><span class="line">./tools.sh command all_node &apos;echo &quot;export JAVA_HOME=/usr/java/jdk1.8.0_45&quot; &gt;&gt; /etc/profile ; echo &quot;export PATH=\$JAVA_HOME/bin:\$JAVA_HOME/jre/bin:\$PATH&quot; &gt;&gt; /etc/profile&apos;</span><br></pre></td></tr></table></figure><h5 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h5><ul><li>第一个参数是告诉脚本，是执行 copy 还是 command 命令</li><li>第二个参数是远程执行的主机列表， all_node 是一个文件，里面放主机列表，如果执行单台机器的，可以直接跟 shining-1.hostname 主机名。</li><li>第三个参数就是需要执行的具体命令。</li></ul><p>如果你感觉文章还可以的话，请帮点点下面的广告哦！ 谢谢</p>]]></content>
      
      <categories>
          
          <category> shell </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ssh </tag>
            
            <tag> shell </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>zookeeper清理日志</title>
      <link href="/zk-delete-log/"/>
      <url>/zk-delete-log/</url>
      <content type="html"><![CDATA[<h1 id="zookeeper-清理日志"><a href="#zookeeper-清理日志" class="headerlink" title="zookeeper 清理日志"></a>zookeeper 清理日志</h1><p>在使用zookeeper过程中，会有dataDir和dataLogDir两个目录，分别用于snapshot和事务日志的输出（默认情况下只有dataDir目录，snapshot和事务日志都保存在这个目录中，正常运行过程中，ZK会不断地把快照数据和事务日志输出到这两个目录，并且如果没有人为操作的话，ZK自己是不会清理这些文件的，需要管理员来清理。</p><h3 id="配置方法"><a href="#配置方法" class="headerlink" title="配置方法"></a>配置方法</h3><p>从3.4.0开始，zookeeper提供了自动清理snapshot和事务日志的功能，通过配置 autopurge.snapRetainCount 和 autopurge.purgeInterval 这两个参数能够实现定时清理了。这两个参数都是在zoo.cfg中配置的：</p><p>For Example： 一个zoo.cfg配置的例子</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">tickTime=2000</span><br><span class="line">initLimit=10</span><br><span class="line">syncLimit=5</span><br><span class="line">dataDir=/home/hadoop/apache-hadoop/zookeeper/var/data</span><br><span class="line">clientPort=2181</span><br><span class="line">dataLogDir=/home/hadoop/apache-hadoop/zookeeper/var/datalog</span><br><span class="line">maxClientCnxns=300</span><br><span class="line">server.1=namenode001-host.mjq-sukbeta.com:2888:3888</span><br><span class="line">server.2=namenode002-host.mjq-sukbeta.com:2888:3888</span><br><span class="line">server.3=datanode001-host.mjq-sukbeta.com:2888:3888</span><br><span class="line">server.4=datanode002-host.mjq-sukbeta.com:2888:3888</span><br><span class="line">server.5=datanode003-host.mjq-sukbeta.com:2888:3888</span><br><span class="line">autopurge.snapRetainCount=20</span><br><span class="line">autopurge.purgeInterval=48</span><br></pre></td></tr></table></figure><p>autopurge.purgeInterval  这个参数指定了清理频率，单位是小时，需要填写一个1或更大的整数，默认是0，表示不开启自己清理功能。  </p><p>autopurge.snapRetainCount 这个参数和上面的参数搭配使用，这个参数指定了需要保留的文件数目。默认是保留3个。</p><h3 id="脚本方法"><a href="#脚本方法" class="headerlink" title="脚本方法"></a>脚本方法</h3><p>写了一个脚本， 可以每天定时执行清理。</p><p>脚本内容如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">#!/bin/bash</span><br><span class="line">           </span><br><span class="line">#snapshot file dir</span><br><span class="line">dataDir=/home/hadoop/apache-hadoop/zookeeper/var/data/version-2</span><br><span class="line">#tran log dir</span><br><span class="line">dataLogDir=/home/hadoop/apache-hadoop/zookeeper/var/datalog/version-2</span><br><span class="line">#zk log dir</span><br><span class="line">#Leave 30 files</span><br><span class="line">count=30</span><br><span class="line">count=$[$count+1]</span><br><span class="line">ls -t $dataLogDir/log.* | tail -n +$count | xargs rm -f</span><br><span class="line">ls -t $dataDir/snapshot.* | tail -n +$count | xargs rm -f</span><br></pre></td></tr></table></figure><ul><li>需要根据自己的情况修改脚本中的dataDir、dataLogDir路径。</li></ul><p>如果感觉文章还可以的话，帮点点下面的广告哦！非常感谢！</p>]]></content>
      
      <categories>
          
          <category> hadoop </category>
          
      </categories>
      
      
        <tags>
            
            <tag> zookeeper </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Hue编译安装及Hadoop相关组建的配置</title>
      <link href="/hue-installed/"/>
      <url>/hue-installed/</url>
      <content type="html"><![CDATA[<h1 id="Hue安装部署"><a href="#Hue安装部署" class="headerlink" title="Hue安装部署"></a>Hue安装部署</h1><p>Hue是一个开源的Apache Hadoop UI系统，是基于Python Web框架Django实现的。Hue可以使开发者在浏览器端的Web控制台上与Hadoop集群进行交互来分析处理数据，例如操作HDFS上的数据，运行MapReduce Job等等。</p><p>本文介绍CentOS6.5安装hue3.11.0，及Hadoop相关组建的配置。</p><h4 id="安装依赖"><a href="#安装依赖" class="headerlink" title="安装依赖"></a>安装依赖</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">yum install -y ant asciidoc cyrus-sasl-devel cyrus-sasl-gssapi gcc gcc-c++ krb5-devel libtidy libxml2-devel  libxslt-devel make mysql mysql-devel openldap-devel Python-devel sqlite-devel openssl-devel gmp-devel libffi-devel unzip</span><br><span class="line">yum install -y cyrus-sasl-plain </span><br><span class="line">yum install -y libssl-devel libffi-devel</span><br><span class="line">yum install -y python-simplejson python-setuptools rsync saslwrapper-devel pycrypto libyaml-devel libsasl2-dev libsasl2-modules-gssapi-mit libkrb5-dev libssl-devel</span><br></pre></td></tr></table></figure><h4 id="编译-hue"><a href="#编译-hue" class="headerlink" title="编译 hue"></a>编译 hue</h4><p>下载hue</p><p>下载hue-3.11.0.tgz<br>解压tar -zxvf hue-3.11.0.tgz</p><p>github 下载</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git clone https://github.com/cloudera/hue.git branch-3.11.0</span><br><span class="line"></span><br><span class="line">mv branch-3.11.0 hue-3.11.0</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">编译方式一：</span><br><span class="line">cd hue-3.11.0</span><br><span class="line">make apps</span><br><span class="line">编译完成后会在当前目录下生产build等目录，hue-3.11.0即可作为安装目录</span><br><span class="line"></span><br><span class="line">编译方式二：</span><br><span class="line">make install PREFIX=/usr/local</span><br><span class="line">会在/usr/local下生产hue目录，安装的时候就用此hue</span><br></pre></td></tr></table></figure><h4 id="配置hadoop的-HttpFS服务"><a href="#配置hadoop的-HttpFS服务" class="headerlink" title="配置hadoop的  HttpFS服务"></a>配置hadoop的  HttpFS服务</h4><p>如果hdfs启用了HA，则只能使用HttpFS服务，否则也可以使用Webhdfs</p><p>HttpFS服务配置：</p><p>core-site.xml文件添加：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;hadoop.proxyuser.httpfs.hosts&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;*&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;hadoop.proxyuser.httpfs.groups&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;*&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure><p>httpfs-site.xml中加入以下内容：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;httpfs.proxyuser.$username.hosts&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;*&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;httpfs.proxyuser.$groupname.groups&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;*&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure><p>这里都是hadoop  因为所有服务都是hadoop用户安装部署。</p><p>core-site.xml添加以下内容</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">   &lt;name&gt;hadoop.proxyuser.hue.hosts&lt;/name&gt;</span><br><span class="line">   &lt;value&gt;*&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">   &lt;name&gt;hadoop.proxyuser.hue.groups&lt;/name&gt;</span><br><span class="line">   &lt;value&gt;*&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure><p>hdfs-site.xml添加这些语句</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;dfs.webhdfs.enabled&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;true&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure><h4 id="启动hdfs的HttpFS服务："><a href="#启动hdfs的HttpFS服务：" class="headerlink" title="启动hdfs的HttpFS服务："></a>启动hdfs的HttpFS服务：</h4><p>/home/hadoop/apache-hadoop/hadoop/sbin/httpfs.sh  start</p><p>测试：访问<a href="http://namenode_address:14000/webhdfs/v1" target="_blank" rel="noopener">http://namenode_address:14000/webhdfs/v1</a></p><h4 id="修改hue配置"><a href="#修改hue配置" class="headerlink" title="修改hue配置"></a>修改hue配置</h4><p>修改hue的/home/hadoop/hue-3.11.0/desktop/conf/hue.ini 配置文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br></pre></td><td class="code"><pre><span class="line"># Webserver listens on this address and port</span><br><span class="line">  http_host=192.168.110.160</span><br><span class="line">  http_port=8008</span><br><span class="line"></span><br><span class="line">  # Time zone name</span><br><span class="line">  ##time_zone=America/Los_Angeles</span><br><span class="line">  time_zone=Asia/Shanghai</span><br><span class="line">  </span><br><span class="line">  # Webserver runs as this user</span><br><span class="line">  server_user=hadoop</span><br><span class="line">  server_group=hadoop</span><br><span class="line"></span><br><span class="line">  # This should be the Hue admin and proxy user</span><br><span class="line">   default_user=hadoop</span><br><span class="line"></span><br><span class="line">  # This should be the hadoop cluster admin</span><br><span class="line">  default_hdfs_superuser=hadoop</span><br><span class="line">  </span><br><span class="line">  # Default encoding for site data</span><br><span class="line">  default_site_encoding=utf-8</span><br><span class="line"></span><br><span class="line">  </span><br><span class="line">  # Note for MariaDB use the &apos;mysql&apos; engine.</span><br><span class="line">    engine=mysql</span><br><span class="line">    host=mysql-test.shining.com</span><br><span class="line">    port=3306</span><br><span class="line">    user=hadoop</span><br><span class="line">    password=123456</span><br><span class="line">    # Execute this script to produce the database password. This will be used when &apos;password&apos; is not set.</span><br><span class="line">    password_script=/path/script</span><br><span class="line">    name=db_hue</span><br><span class="line"></span><br><span class="line">[hadoop]</span><br><span class="line"> # Enter the filesystem uri</span><br><span class="line">      fs_defaultfs=hdfs://testhadoop:8020    ##core-site.xml中的fs.defaultFS的值</span><br><span class="line">  # Use WebHdfs/HttpFs as the communication mechanism.</span><br><span class="line">      # Domain should be the NameNode or HttpFs host.</span><br><span class="line">      # Default port is 14000 for HttpFs.</span><br><span class="line">      webhdfs_url=http://192.168.110.159:14000/webhdfs/v1   ##启用HttpFS</span><br><span class="line">  # Directory of the Hadoop configuration</span><br><span class="line">      hadoop_conf_dir=$HADOOP_HOME/etc/hadoop</span><br><span class="line">[[yarn_clusters]]</span><br><span class="line"># Enter the host on which you are running the ResourceManager</span><br><span class="line">      resourcemanager_host=192.168.110.159</span><br><span class="line"></span><br><span class="line">      # The port where the ResourceManager IPC listens on</span><br><span class="line">      resourcemanager_port=8032</span><br><span class="line"># URL of the ResourceManager API</span><br><span class="line">      resourcemanager_api_url=http://192.168.53.100:8088</span><br><span class="line"># URL of the HistoryServer API</span><br><span class="line">       history_server_api_url=http://192.168.53.101:19888</span><br><span class="line">   </span><br><span class="line">   </span><br><span class="line">    # [[[ha]]]</span><br><span class="line">      # Resource Manager logical name (required for HA)</span><br><span class="line">      ## logical_name=my-rm-name</span><br><span class="line"></span><br><span class="line">      # Un-comment to enable</span><br><span class="line">      ## submit_to=True</span><br><span class="line"></span><br><span class="line">      # URL of the ResourceManager API</span><br><span class="line">      ## resourcemanager_api_url=http://localhost:8088</span><br><span class="line">  </span><br><span class="line"> [[mapred_clusters]]</span><br><span class="line"></span><br><span class="line">    [[[default]]]</span><br><span class="line">      # Enter the host on which you are running the Hadoop JobTracker</span><br><span class="line">      jobtracker_host=192.168.110.160</span><br><span class="line">[beeswax]</span><br><span class="line"></span><br><span class="line">  # Host where HiveServer2 is running.</span><br><span class="line">  # If Kerberos security is enabled, use fully-qualified domain name (FQDN).</span><br><span class="line">  hive_server_host=192.168.110.160</span><br><span class="line"></span><br><span class="line">  # Port where HiveServer2 Thrift server runs on.</span><br><span class="line">   hive_server_port=10000</span><br><span class="line"></span><br><span class="line">  # Hive configuration directory, where hive-site.xml is located</span><br><span class="line">  hive_conf_dir=/home/hadoop/apache-hadoop/hive/conf</span><br><span class="line">  </span><br><span class="line">[spark]</span><br><span class="line">  # Host address of the Livy Server.</span><br><span class="line">  ## livy_server_host=localhost</span><br><span class="line"></span><br><span class="line">  # Port of the Livy Server.</span><br><span class="line">  ## livy_server_port=8998</span><br><span class="line"></span><br><span class="line">  # Configure Livy to start in local &apos;process&apos; mode, or &apos;yarn&apos; workers.</span><br><span class="line">  ## livy_server_session_kind=yarn</span><br><span class="line"></span><br><span class="line">  # Host of the Sql Server</span><br><span class="line">  ## sql_server_host=localhost</span><br><span class="line"></span><br><span class="line">  # Port of the Sql Server</span><br><span class="line">  ## sql_server_port=10000</span><br><span class="line">[hbase]</span><br><span class="line">  # Comma-separated list of HBase Thrift servers for clusters in the format of &apos;(name|host:port)&apos;.</span><br><span class="line">  # Use full hostname with security.</span><br><span class="line">  # If using Kerberos we assume GSSAPI SASL, not PLAIN.</span><br><span class="line">  #hbase_clusters=(Cluster|192.168.53.100:9090)</span><br><span class="line"></span><br><span class="line">  # HBase configuration directory, where hbase-site.xml is located.</span><br><span class="line">  ## hbase_conf_dir=/home/hadoop/apache-hadoop/hbase/conf</span><br><span class="line"></span><br><span class="line">  # Hard limit of rows or columns per row fetched before truncating.</span><br><span class="line">  ## truncate_limit = 500</span><br><span class="line"></span><br><span class="line">  # &apos;buffered&apos; is the default of the HBase Thrift Server and supports security.</span><br><span class="line">  # &apos;framed&apos; can be used to chunk up responses,</span><br><span class="line">  # which is useful when used in conjunction with the nonblocking server in Thrift.</span><br><span class="line">  ## thrift_transport=buffered</span><br></pre></td></tr></table></figure><h5 id="建hue数据库"><a href="#建hue数据库" class="headerlink" title="建hue数据库"></a>建hue数据库</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">create database hue_123 DEFAULT CHARSET utf8 COLLATE utf8_general_ci;</span><br><span class="line">grant all PRIVILEGES on hue_123.* to &apos;hadoop&apos;@&apos;192.168.53.101&apos; IDENTIFIED BY &apos;123456&apos; with grant option ;</span><br><span class="line">grant all PRIVILEGES on hue_123.* to &apos;hadoop&apos;@&apos;%&apos; IDENTIFIED BY &apos;123456&apos; with grant option ;</span><br><span class="line">FLUSH PRIVILEGES;</span><br></pre></td></tr></table></figure><h5 id="初始化hue（顺序执行）"><a href="#初始化hue（顺序执行）" class="headerlink" title="初始化hue（顺序执行）"></a>初始化hue（顺序执行）</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">apache-hadoop/hue/build/env/bin/hue syncdb </span><br><span class="line">（有提示设置用户名和密码）</span><br><span class="line">apache-hadoop/hue/build/env/bin/hue migrate</span><br></pre></td></tr></table></figure><h5 id="启动"><a href="#启动" class="headerlink" title="启动"></a>启动</h5><p>start</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">apache-hadoop/hue/build/env/bin/supervisor &gt;/dev/null 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure><p>stop</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ps -ef |grep hue</span><br><span class="line">kill -9 pid</span><br></pre></td></tr></table></figure><h5 id="访问"><a href="#访问" class="headerlink" title="访问"></a>访问</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://192.168.110.160:8008</span><br></pre></td></tr></table></figure><p>如果您感觉文章还可以的话，请帮点点下面的广告哦！ 谢谢支持！</p>]]></content>
      
      <categories>
          
          <category> hue </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hadoop </tag>
            
            <tag> hue </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>源码编译安装 apache hadoop</title>
      <link href="/install-apache-hadoop/"/>
      <url>/install-apache-hadoop/</url>
      <content type="html"><![CDATA[<h1 id="安装-apache-hadoop-2-7-2-集群"><a href="#安装-apache-hadoop-2-7-2-集群" class="headerlink" title="安装 apache hadoop 2.7.2 集群"></a>安装 apache hadoop 2.7.2 集群</h1><p>这是我安装编译hadoop得意个笔记手册，和大家分享一下。</p><p>环境：   </p><p>  系统 Centos 7<br>  java ： 1.8<br>  apache hadoop 版本 ： 2.7.2</p><h5 id="hadoop集群hosts列表"><a href="#hadoop集群hosts列表" class="headerlink" title="hadoop集群hosts列表"></a>hadoop集群hosts列表</h5><table><thead><tr><th>IP</th><th>hostname</th><th>运行服务</th></tr></thead><tbody><tr><td>192.168.77.158</td><td>namenode00.host-shining.com</td><td>namenode、zk、journalnode、standby-resourcemanager，hbase-master、spark-master</td></tr><tr><td>192.168.77.159</td><td>namenode01.host-shining.com</td><td>namenode、zk、journalnode、resourcemanager，hbase-master、jobhistory</td></tr><tr><td>192.168.77.161</td><td>datanode00.host-shining.com</td><td>datanode、nodemanager、zk、journalnode</td></tr><tr><td>192.168.77.162</td><td>datanode01.host-shining.com</td><td>datanode、nodemanager、zk、journalnode</td></tr><tr><td>192.168.77.163</td><td>datanode02.host-shining.com</td><td>datanode、nodemanager、zk、journalnode</td></tr><tr><td>192.168.77.164</td><td>datanode03.host-shining.com</td><td>datanode、nodemanager、regionserver、spark-work</td></tr><tr><td>192.168.77.165</td><td>datanode04.host-shining.com</td><td>datanode、nodemanager、regionserver、spark-work</td></tr><tr><td>192.168.77.166</td><td>datanode05.host-shining.com</td><td>datanode、nodemanager、regionserver、spark-work</td></tr><tr><td>192.168.77.167</td><td>datanode06.host-shining.com</td><td>datanode、nodemanager、regionserver、spark-work</td></tr><tr><td>192.168.77.168</td><td>datanode07.host-shining.com</td><td>datanode、nodemanager</td></tr><tr><td>192.168.77.169</td><td>datanode08.host-shining.com</td><td>datanode、nodemanager</td></tr><tr><td>192.168.77.170</td><td>datanode09.host-shining.com</td><td>datanode、nodemanager</td></tr></tbody></table><blockquote><p>hosts文件并同步到每台机器上。  </p></blockquote><h5 id="hadoop-client-列表"><a href="#hadoop-client-列表" class="headerlink" title="hadoop client 列表"></a>hadoop client 列表</h5><table><thead><tr><th>IP</th><th>hostname</th></tr></thead><tbody><tr><td>192.168.77.160</td><td>client01.host-shining.com</td></tr></tbody></table><h5 id="安装软件包和lzop软件（每台机器都执行）"><a href="#安装软件包和lzop软件（每台机器都执行）" class="headerlink" title="安装软件包和lzop软件（每台机器都执行）"></a>安装软件包和lzop软件（每台机器都执行）</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">yum -y install  wget gcc gcc-c++ gcc-g77 autoconf automake zlib* fiex* libxml* ncurses-devel libmcrypt* libtool-ltdl-devel* make cmake bind-utils ntp ntpdate lrzsz rsync gzip unzip vim telnet openssl-devel nscd g++ sysstat ncurses-libs bzip2-devel git lsof expect  </span><br><span class="line"></span><br><span class="line">yum -y install *gcc* ncurses-devel openssl-devel cmake autoconfautomake libtool bzip2-devel g++ autoconf automake libtool cmake zlib1g-dev pkg-config  </span><br><span class="line"></span><br><span class="line">yum -y install  lzo-devel zlib-devel  gcc autoconf automakelibtool lzop subversion psmisc nc</span><br></pre></td></tr></table></figure><h5 id="安装jdk-1-8-（需要每台机器执行）"><a href="#安装jdk-1-8-（需要每台机器执行）" class="headerlink" title="安装jdk 1.8 （需要每台机器执行）"></a>安装jdk 1.8 （需要每台机器执行）</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tar -zxf jdk-8u45-linux-x64.tar.gz &amp;&amp; mkdir /usr/java/ &amp;&amp; mv  jdk1.8.0_45/ /usr/java/</span><br><span class="line">echo -e &quot;export JAVA_HOME=/usr/java/jdk1.8.0_45\nexport PATH=\$JAVA_HOME/bin:\$JAVA_HOME/jre/bin:\$PATH&quot; &gt;&gt; /etc/profile</span><br></pre></td></tr></table></figure><h5 id="创建hadoop用户并添加无密码登入（每台集群都执行）"><a href="#创建hadoop用户并添加无密码登入（每台集群都执行）" class="headerlink" title="创建hadoop用户并添加无密码登入（每台集群都执行）"></a>创建hadoop用户并添加无密码登入（每台集群都执行）</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">useradd hadoop</span><br><span class="line">su - hadoop</span><br><span class="line">echo &quot;hadoop|xiaoaojianghu&quot; | chpasswd</span><br></pre></td></tr></table></figure><p>创建添加key的脚本，每台机器添加完用户之后执行  sh key_add.sh  </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">vim key_add.sh</span><br><span class="line"></span><br><span class="line">#!/bin/bash</span><br><span class="line">source /etc/profile</span><br><span class="line"># 创建pub  key文件</span><br><span class="line">expect -c &apos;set timeout -1;</span><br><span class="line">spawn ssh-keygen -t rsa;</span><br><span class="line">expect &quot;Enter file in which to save the key&quot;;</span><br><span class="line">send &quot;\n&quot;;</span><br><span class="line">expect &quot;(empty for no passphrase):&quot;</span><br><span class="line">send &quot;\n&quot;;</span><br><span class="line">expect &quot;Enter same passphrase again:&quot;;</span><br><span class="line">send &quot;\n&quot;;</span><br><span class="line">interact&apos;</span><br><span class="line"># 在hosts文件里找到name和data的主机名</span><br><span class="line">for ip in `cat /etc/hosts | grep -v &quot;^#&quot; |grep -E &quot;name|data&quot;|awk &apos;&#123;print $2&#125;&apos;`</span><br><span class="line">do </span><br><span class="line">    echo $ip </span><br><span class="line">    # add hadoop pub key </span><br><span class="line">    expect -c &apos;set timeout -1;</span><br><span class="line">    spawn ssh-copy-id -i .ssh/id_rsa.pub &apos;$ip&apos;;</span><br><span class="line">    expect &quot;Are you sure you want to continue connecting (yes/no)?&quot;;</span><br><span class="line">    send &quot;yes\n&quot;;</span><br><span class="line">    expect &quot;password:&quot;;</span><br><span class="line">    send &quot;xiaoaojianghu\n&quot;;</span><br><span class="line">    interact&apos;</span><br><span class="line"></span><br><span class="line">done</span><br><span class="line"> </span><br><span class="line">for ip in `cat /etc/hosts | grep -E &quot;name|data&quot;|awk &apos;&#123;print $1&#125;&apos;`;do echo $ip ;ssh-copy-id -i ~/.ssh/id_rsa.pub $ip;done</span><br></pre></td></tr></table></figure><h5 id="datanode机器格式化硬盘-所有datanode节点执行"><a href="#datanode机器格式化硬盘-所有datanode节点执行" class="headerlink" title="datanode机器格式化硬盘  (所有datanode节点执行)"></a>datanode机器格式化硬盘  (所有datanode节点执行)</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">vim fdisk.sh</span><br><span class="line"></span><br><span class="line">#!/bin/bash</span><br><span class="line">source /etc/profile</span><br><span class="line">yum install -y expect parted</span><br><span class="line"></span><br><span class="line">#for letter in b c d e f g h i j k l m   #默认列表</span><br><span class="line">for letter in `fdisk -l | grep 4000 | awk &apos;&#123;print $2&#125;&apos; | cut -c 8 | sort`  # 找到4T的硬盘并格式化。</span><br><span class="line">do</span><br><span class="line">    expect -c &apos;set timeout -1;</span><br><span class="line">    spawn parted /dev/sd&apos;$letter&apos;;</span><br><span class="line">    expect &quot;(parted)&quot;;</span><br><span class="line">    send &quot;mklabel gpt\n&quot;;</span><br><span class="line">    expect &quot;(parted)&quot;;</span><br><span class="line">    send &quot;unit GB\n&quot;;</span><br><span class="line">    expect &quot;(parted)&quot;;</span><br><span class="line">    send &quot;mkpart primary 0 -1\n&quot;;</span><br><span class="line">    expect &quot;(parted)&quot;;</span><br><span class="line">    send &quot;quit\n&quot;;</span><br><span class="line">    interact&apos;</span><br><span class="line"></span><br><span class="line">    nohup mkfs.xfs /dev/sd$&#123;letter&#125;1 &gt; sd$letter.out 2&gt;&amp;1 &amp;</span><br><span class="line">done</span><br></pre></td></tr></table></figure><h5 id="mount-挂在硬盘-所有datanode节点执行"><a href="#mount-挂在硬盘-所有datanode节点执行" class="headerlink" title="mount 挂在硬盘  (所有datanode节点执行)"></a>mount 挂在硬盘  (所有datanode节点执行)</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">vim mount.sh</span><br><span class="line"></span><br><span class="line">#!/bin/bash</span><br><span class="line">source /etc/profile</span><br><span class="line"></span><br><span class="line">blkid | sort | grep -v sdm| awk -F &apos;&quot;&apos; &apos;&#123;print $2&#125;&apos; &gt; /tmp/uuid</span><br><span class="line">echo &quot;/data00</span><br><span class="line">/data01</span><br><span class="line">/data02</span><br><span class="line">/data03</span><br><span class="line">/data04</span><br><span class="line">/data05</span><br><span class="line">/data06</span><br><span class="line">/data07</span><br><span class="line">/data08</span><br><span class="line">/data09</span><br><span class="line">/data10</span><br><span class="line">/data11&quot; &gt; /tmp/dir</span><br><span class="line"></span><br><span class="line">for dir in `cat /tmp/dir`</span><br><span class="line">do</span><br><span class="line">    mkdir -p $dir</span><br><span class="line">done</span><br><span class="line"># 也可以用</span><br><span class="line"># mkdir /data&#123;00..11&#125;</span><br><span class="line"></span><br><span class="line">l=$(cat /tmp/uuid | wc -l)</span><br><span class="line">for ((i=1;i&lt;=$l;i++))</span><br><span class="line">do</span><br><span class="line">    u=$(sed -n &quot;$i&quot;p /tmp/uuid)</span><br><span class="line">    d=$(sed -n &quot;$i&quot;p /tmp/dir)</span><br><span class="line">    mount UUID=$u $d</span><br><span class="line">    cp /etc/fstab /etc/fstab_backup</span><br><span class="line">    echo -e &quot;UUID=$u\t$d\t\txfs\tdefaults,noatime,nodiratime\t0 0&quot; &gt;&gt; /etc/fstab   </span><br><span class="line">    # noatime,nodiratim   禁用文件访问时间</span><br><span class="line">done</span><br></pre></td></tr></table></figure><h5 id="下载软件包"><a href="#下载软件包" class="headerlink" title="下载软件包"></a>下载软件包</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">/home/hadoop/apache-hadoop &amp;&amp; cd /home/hadoop/apache-hadoop</span><br><span class="line">wget http://mirror.bit.edu.cn/apache/hadoop/common/hadoop-2.7.2/hadoop-2.7.2.tar.gz</span><br><span class="line">wget https://mirrors.tuna.tsinghua.edu.cn/apache/hive/stable-2/apache-hive-2.1.0-bin.tar.gz</span><br><span class="line">wget https://mirrors.tuna.tsinghua.edu.cn/apache/hive/stable-2/apache-hive-2.1.0-src.tar.gz</span><br><span class="line">wget http://apache.fayea.com/hbase/stable/hbase-1.1.5-bin.tar.gz</span><br><span class="line">wget http://apache.fayea.com/hbase/stable/hbase-1.1.5-src.tar.gz</span><br><span class="line">wget http://apache.fayea.com/mahout/0.12.2/apache-mahout-distribution-0.12.2.tar.gz</span><br><span class="line">wget http://apache.fayea.com/zookeeper/stable/zookeeper-3.4.8.tar.gz</span><br><span class="line">wget http://mirror.bit.edu.cn/apache/spark/spark-1.6.2/spark-1.6.2.tgz</span><br></pre></td></tr></table></figure><h5 id="安装zookeeper"><a href="#安装zookeeper" class="headerlink" title="安装zookeeper"></a>安装zookeeper</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf zookeeper-3.4.8.tar.gz &amp;&amp; ln -s zookeeper-3.4.8 zookeeper</span><br><span class="line">cd /home/hadoop/apache-hadoop/zookeeper &amp;&amp;  mkdir -p var/&#123;data,datalog&#125;</span><br><span class="line">cd conf</span><br><span class="line">echo &quot;JAVA_HOME=/usr/java/jdk1.8.0_45&quot; &gt; java.env</span><br><span class="line">echo &quot;export JAVA_OPTS=\&quot;-Xms1000m -Xmx1000m\&quot;&quot; &gt;&gt; java.env</span><br><span class="line">cp zoo_sample.cfg zoo.cfg</span><br><span class="line">sed -i &apos;/^dataDir=/c dataDir=/home/hadoop/apache-hadoop/zookeeper/var/data&apos; zoo.cfg</span><br><span class="line">echo &quot;dataLogDir=/home/hadoop/apache-hadoop/zookeeper/var/datalog&quot; &gt;&gt; zoo.cfg </span><br><span class="line">echo &quot;maxClientCnxns=300&quot; &gt;&gt; zoo.cfg </span><br><span class="line"></span><br><span class="line">在 zoo.cfg 里添加</span><br><span class="line">server.1=namenode00.host-shining.com:2888:3888</span><br><span class="line">server.2=namenode01.host-shining.com:2888:3888</span><br><span class="line">server.3=datanode00.host-shining.com:2888:3888</span><br><span class="line">server.4=datanode01.host-shining.com:2888:3888</span><br><span class="line">server.5=datanode02.host-shining.com:2888:3888</span><br><span class="line"></span><br><span class="line">echo 1 &gt; /home/hadoop/apache-hadoop/zookeeper/var/data/myid </span><br><span class="line">每台机器安顺序排，这个文件是不一样的。   1、2、3、4、5</span><br></pre></td></tr></table></figure><p>用supervisor守护zookeeper   (supervisor需要重启)  </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">[program:zookeeper]</span><br><span class="line">command = /home/hadoop/apache-hadoop/zookeeper/bin/zkServer.sh start-foreground</span><br><span class="line">autostart = true</span><br><span class="line">autorestart = true</span><br><span class="line">startsecs = 3</span><br><span class="line">startretries = 3</span><br><span class="line">stopwaitsecs = 5</span><br><span class="line">user = hadoop</span><br><span class="line">redirect_stderr = true</span><br><span class="line">stdout_logfile = /home/shining/logs/supervisor/zookeeper.log</span><br><span class="line">stdout_logfile_maxbytes = 500MB</span><br><span class="line">stdout_logfile_backups = 5</span><br></pre></td></tr></table></figure><h4 id="安装hdfs"><a href="#安装hdfs" class="headerlink" title="安装hdfs"></a>安装hdfs</h4><h6 id="创建目录"><a href="#创建目录" class="headerlink" title="创建目录"></a>创建目录</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">cd /home/hadoop/apache-hadoop</span><br><span class="line">tar -zxvf hadoop-2.7.2.tar.gz &amp;&amp; ln -s hadoop-2.7.2 hadoop</span><br><span class="line">mkdir -p /home/hadoop/apache-hadoop/hadoop/var/dfs/jn</span><br><span class="line">mkdir -p /home/hadoop/apache-hadoop/hadoop/var/dfs/dn</span><br><span class="line">mkdir -p /home/hadoop/apache-hadoop/hadoop/var/dfs/nn</span><br><span class="line">mkdir -p /home/hadoop/apache-hadoop/hadoop/var/run/hadoop-hdfs</span><br><span class="line">mkdir -p /home/hadoop/apache-hadoop/hadoop/var/run/hadoop-hdfs/dn_PORT</span><br><span class="line">chmod -R 755 /home/hadoop/apache-hadoop/hadoop/var/</span><br></pre></td></tr></table></figure><h5 id="开始修改配置文件"><a href="#开始修改配置文件" class="headerlink" title="开始修改配置文件"></a>开始修改配置文件</h5><h6 id="hdfs-site-xml-配置文件"><a href="#hdfs-site-xml-配置文件" class="headerlink" title="hdfs-site.xml 配置文件"></a>hdfs-site.xml 配置文件</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br></pre></td><td class="code"><pre><span class="line">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span><br><span class="line">&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;</span><br><span class="line">&lt;!--</span><br><span class="line">  Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span><br><span class="line">  you may not use this file except in compliance with the License.</span><br><span class="line">  You may obtain a copy of the License at</span><br><span class="line"></span><br><span class="line">    http://www.apache.org/licenses/LICENSE-2.0</span><br><span class="line"></span><br><span class="line">  Unless required by applicable law or agreed to in writing, software</span><br><span class="line">  distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span><br><span class="line">  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span><br><span class="line">  See the License for the specific language governing permissions and</span><br><span class="line">  limitations under the License. See accompanying LICENSE file.</span><br><span class="line">--&gt;</span><br><span class="line"></span><br><span class="line">&lt;!-- Put site-specific property overrides in this file. --&gt;</span><br><span class="line"></span><br><span class="line">&lt;configuration&gt;</span><br><span class="line"></span><br><span class="line"> &lt;property&gt;</span><br><span class="line">    &lt;name&gt;dfs.nameservices&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;shininghadoop&lt;/value&gt;</span><br><span class="line"> &lt;/property&gt;</span><br><span class="line"> &lt;property&gt;</span><br><span class="line">    &lt;name&gt;dfs.ha.namenodes.shininghadoop&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;nn1,nn2&lt;/value&gt;</span><br><span class="line"> &lt;/property&gt;</span><br><span class="line"> &lt;property&gt;</span><br><span class="line">    &lt;name&gt;dfs.namenode.rpc-address.shininghadoop.nn1&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;namenode00.host-shining.com:8020&lt;/value&gt;</span><br><span class="line"> &lt;/property&gt;</span><br><span class="line"> &lt;property&gt;</span><br><span class="line">    &lt;name&gt;dfs.namenode.rpc-address.shininghadoop.nn2&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;namenode01.host-shining.com:8020&lt;/value&gt;</span><br><span class="line"> &lt;/property&gt;</span><br><span class="line"> &lt;property&gt;</span><br><span class="line">    &lt;name&gt;dfs.namenode.http-address.shininghadoop.nn1&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;namenode00.host-shining.com:50070&lt;/value&gt;</span><br><span class="line"> &lt;/property&gt;</span><br><span class="line"> &lt;property&gt;</span><br><span class="line">    &lt;name&gt;dfs.namenode.http-address.shininghadoop.nn2&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;namenode01.host-shining.com:50070&lt;/value&gt;</span><br><span class="line"> &lt;/property&gt;</span><br><span class="line"> &lt;property&gt;</span><br><span class="line">    &lt;name&gt;dfs.namenode.shared.edits.dir&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;qjournal://namenode00.host-shining.com:8485;namenode01.host-shining.com:8485;datanode00.host-shining.com:8485;datanode01.host-shining.com:8485;datanode02.host-shining.com:8485/shininghadoop&lt;/value&gt;</span><br><span class="line"> &lt;/property&gt;</span><br><span class="line"> &lt;property&gt;</span><br><span class="line">    &lt;name&gt;dfs.journalnode.edits.dir&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;/home/hadoop/apache-hadoop/hadoop/var/dfs/jn&lt;/value&gt;</span><br><span class="line"> &lt;/property&gt;</span><br><span class="line"> &lt;property&gt;</span><br><span class="line">    &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;/data00/data,/data01/data,/data02/data,/data03/data,/data04/data,/data05/data,/data06/data,/data07/data,/data08/data,/data09/data,/data10/data,/data11/data&lt;/value&gt;</span><br><span class="line"> &lt;/property&gt;</span><br><span class="line"> &lt;property&gt;</span><br><span class="line">    &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;/home/hadoop/apache-hadoop/hadoop/var/dfs/nn&lt;/value&gt;</span><br><span class="line"> &lt;/property&gt;</span><br><span class="line"> &lt;property&gt;</span><br><span class="line">    &lt;name&gt;dfs.client.failover.proxy.provider.shininghadoop&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider&lt;/value&gt;</span><br><span class="line"> &lt;/property&gt;</span><br><span class="line"> &lt;property&gt;</span><br><span class="line">    &lt;name&gt;dfs.ha.fencing.methods&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;sshfence(hadoop)</span><br><span class="line">           shell(/bin/true)&lt;/value&gt;</span><br><span class="line"> &lt;/property&gt;</span><br><span class="line"> &lt;property&gt;</span><br><span class="line">    &lt;name&gt;dfs.ha.fencing.ssh.private-key-files&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;/home/hadoop/.ssh/id_rsa&lt;/value&gt;</span><br><span class="line"> &lt;/property&gt;</span><br><span class="line"> &lt;property&gt;</span><br><span class="line">    &lt;name&gt;dfs.ha.fencing.ssh.connect-timeout&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;60000&lt;/value&gt;</span><br><span class="line"> &lt;/property&gt;</span><br><span class="line"> &lt;property&gt;</span><br><span class="line">    &lt;name&gt;dfs.ha.automatic-failover.enabled&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;true&lt;/value&gt;</span><br><span class="line"> &lt;/property&gt;</span><br><span class="line"> &lt;property&gt;</span><br><span class="line">    &lt;name&gt;dfs.replication&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;3&lt;/value&gt;</span><br><span class="line">    &lt;description&gt;Default block replication. The actual number of replications can be specified when the file is created. The default is used if replication is not specified in create time&lt;/description&gt;</span><br><span class="line"> &lt;/property&gt;</span><br><span class="line"> &lt;property&gt;</span><br><span class="line">    &lt;name&gt;dfs.namenode.handler.count&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;60&lt;/value&gt;</span><br><span class="line"> &lt;/property&gt;</span><br><span class="line"> &lt;property&gt;</span><br><span class="line">    &lt;name&gt;dfs.datanode.balance.bandwidthPerSec&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;20971520&lt;/value&gt;</span><br><span class="line">    &lt;final&gt;true&lt;/final&gt;</span><br><span class="line"> &lt;/property&gt;</span><br><span class="line"> &lt;property&gt;</span><br><span class="line">    &lt;name&gt;dfs.block.size&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;67108864&lt;/value&gt;</span><br><span class="line">    &lt;final&gt;true&lt;/final&gt;</span><br><span class="line"> &lt;/property&gt;</span><br><span class="line"> &lt;property&gt;</span><br><span class="line">    &lt;name&gt;dfs.webhdfs.enabled&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;true&lt;/value&gt;</span><br><span class="line"> &lt;/property&gt;</span><br><span class="line"> &lt;property&gt;</span><br><span class="line">    &lt;name&gt;dfs.datanode.max.xcievers&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;8192&lt;/value&gt;</span><br><span class="line"> &lt;/property&gt;</span><br><span class="line"> &lt;property&gt;</span><br><span class="line">    &lt;name&gt;dfs.permissions.superusergroup&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;hadoop&lt;/value&gt;</span><br><span class="line"> &lt;/property&gt;</span><br><span class="line"> &lt;property&gt;</span><br><span class="line">    &lt;name&gt;dfs.support.append&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;true&lt;/value&gt;</span><br><span class="line"> &lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;dfs.client.read.shortcircuit&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;true&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;dfs.domain.socket.path&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;/home/hadoop/apache-hadoop/hadoop/var/run/hadoop-hdfs/dn_PORT&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;dfs.client.read.shortcircuit.skip.checksum&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;false&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;property&gt; </span><br><span class="line">  &lt;name&gt;dfs.ha.automatic-failover.enabled.appcluster&lt;/name&gt; </span><br><span class="line">  &lt;value&gt;true&lt;/value&gt; </span><br><span class="line">&lt;/property&gt; </span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;dfs.permissions.enabled&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;true&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;dfs.namenode.acls.enabled&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;true&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure><h6 id="core-site-xml-配置文件"><a href="#core-site-xml-配置文件" class="headerlink" title="core-site.xml 配置文件"></a>core-site.xml 配置文件</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span><br><span class="line">&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;</span><br><span class="line">&lt;!--</span><br><span class="line">  Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span><br><span class="line">  you may not use this file except in compliance with the License.</span><br><span class="line">  You may obtain a copy of the License at</span><br><span class="line"></span><br><span class="line">    http://www.apache.org/licenses/LICENSE-2.0</span><br><span class="line"></span><br><span class="line">  Unless required by applicable law or agreed to in writing, software</span><br><span class="line">  distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span><br><span class="line">  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span><br><span class="line">  See the License for the specific language governing permissions and</span><br><span class="line">  limitations under the License. See accompanying LICENSE file.</span><br><span class="line">--&gt;</span><br><span class="line"></span><br><span class="line">&lt;!-- Put site-specific property overrides in this file. --&gt;</span><br><span class="line"></span><br><span class="line">&lt;configuration&gt;</span><br><span class="line"></span><br><span class="line"> &lt;property&gt;</span><br><span class="line">   &lt;name&gt;fs.defaultFS&lt;/name&gt;</span><br><span class="line">   &lt;value&gt;hdfs://shininghadoop&lt;/value&gt;</span><br><span class="line"> &lt;/property&gt;</span><br><span class="line"> &lt;property&gt;</span><br><span class="line">   &lt;name&gt;fs.trash.interval&lt;/name&gt;</span><br><span class="line">   &lt;value&gt;10080&lt;/value&gt;</span><br><span class="line">   &lt;description&gt;Number of minutes between trash checkpoints.If zero, the trash feature is disabled.&lt;/description&gt;</span><br><span class="line"> &lt;/property&gt;</span><br><span class="line"> &lt;property&gt;</span><br><span class="line">   &lt;name&gt;ha.zookeeper.quorum&lt;/name&gt;</span><br><span class="line">   &lt;value&gt;namenode00.host-shining.com:2181,namenode01.host-shining.com:2181,datanode00.host-shining.com:2181,datanode01.host-shining.com:2181,datanode02.host-shining.com:2181&lt;/value&gt;</span><br><span class="line"> &lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;fs.trash.checkpoint.interval&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;10080&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;io.native.lib.available&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;true&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;io.compression.codecs&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;org.apache.hadoop.io.compress.GzipCodec,</span><br><span class="line">        org.apache.hadoop.io.compress.DefaultCodec,</span><br><span class="line">        com.hadoop.compression.lzo.LzoCodec,</span><br><span class="line">        com.hadoop.compression.lzo.LzopCodec,</span><br><span class="line">        org.apache.hadoop.io.compress.BZip2Codec</span><br><span class="line">  &lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;io.compression.codec.lzo.class&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;com.hadoop.compression.lzo.LzoCodec&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;io.compression.codecs&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;org.apache.hadoop.io.compress.GzipCodec,org.apache.hadoop.io.compress.DefaultCodec,com.hadoop.compression.lzo.LzoCodec,com.hadoop.compression.lzo.LzopCodec,org.apache.hadoop.io.compress.BZip2Codec&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;  </span><br><span class="line">    &lt;name&gt;hadoop.proxyuser.hadoop.hosts&lt;/name&gt;  </span><br><span class="line">    &lt;value&gt;*&lt;/value&gt;  </span><br><span class="line">&lt;/property&gt;  </span><br><span class="line">&lt;property&gt;  </span><br><span class="line">    &lt;name&gt;hadoop.proxyuser.hadoop.groups&lt;/name&gt;  </span><br><span class="line">    &lt;value&gt;*&lt;/value&gt;  </span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;fs.permissions.umask-mode&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;022&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure><h6 id="hadoop-env-sh-配置文件-（去掉了注释部分）"><a href="#hadoop-env-sh-配置文件-（去掉了注释部分）" class="headerlink" title="hadoop-env.sh 配置文件 （去掉了注释部分）"></a>hadoop-env.sh 配置文件 （去掉了注释部分）</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME=/usr/java/jdk1.8.0_45</span><br><span class="line">export HADOOP_HOME=/home/hadoop/apache-hadoop/hadoop</span><br><span class="line">export HADOOP_LOG_DIR=$&#123;HADOOP_HOME&#125;/logs</span><br><span class="line">JVM_OPTS=&quot;-server -verbose:gc</span><br><span class="line">  -XX:+PrintGCDateStamps</span><br><span class="line">  -XX:+PrintGCDetails</span><br><span class="line">  -XX:+UseGCLogFileRotation</span><br><span class="line">  -XX:NumberOfGCLogFiles=9</span><br><span class="line">  -XX:GCLogFileSize=20m&quot;</span><br><span class="line">export HADOOP_NAMENODE_OPTS=&quot;-Xmx40g -Xms10g -Xmn4g $JVM_OPTS -XX:ErrorFile=$HADOOP_LOG_DIR/nn_error_gc.log -Xloggc:$HADOOP_LOG_DIR/nn_gc.log -XX:HeapDumpPath=$HADOOP_LOG_DIR/nn_error.hprof&quot;</span><br><span class="line">export HADOOP_DATANODE_OPTS=&quot;-Xmx4g -Xms512m   $JVM_OPTS -XX:ErrorFile=$HADOOP_LOG_DIR/dn_error_gc.log -Xloggc:$HADOOP_LOG_DIR/dn_gc.log -XX:HeapDumpPath=$HADOOP_LOG_DIR/dn_error.hprof &quot;</span><br><span class="line">export HADOOP_JOB_HISTORYSERVER_OPTS=&quot;-Xmx4g -Xms2g   $JVM_OPTS -XX:ErrorFile=$HADOOP_LOG_DIR/log_error_gc.log -Xloggc:$HADOOP_LOG_DIR/log_gc.log -XX:HeapDumpPath=$HADOOP_LOG_DIR/log_error.hprof &quot;</span><br><span class="line">export HADOOP_CONF_DIR=$&#123;HADOOP_CONF_DIR:-&quot;/etc/hadoop&quot;&#125;</span><br><span class="line">for f in $HADOOP_HOME/contrib/capacity-scheduler/*.jar; do</span><br><span class="line">  if [ &quot;$HADOOP_CLASSPATH&quot; ]; then</span><br><span class="line">    export HADOOP_CLASSPATH=$HADOOP_CLASSPATH:$f</span><br><span class="line">  else</span><br><span class="line">    export HADOOP_CLASSPATH=$f</span><br><span class="line">  fi</span><br><span class="line">done</span><br><span class="line">export HADOOP_OPTS=&quot;$HADOOP_OPTS -Djava.net.preferIPv4Stack=true&quot;</span><br><span class="line">export HADOOP_NAMENODE_OPTS=&quot;-Dhadoop.security.logger=$&#123;HADOOP_SECURITY_LOGGER:-INFO,RFAS&#125; -Dhdfs.audit.logger=$&#123;HDFS_AUDIT_LOGGER:-INFO,NullAppender&#125; $HADOOP_NAMENODE_OPTS&quot;</span><br><span class="line">export HADOOP_DATANODE_OPTS=&quot;-Dhadoop.security.logger=ERROR,RFAS $HADOOP_DATANODE_OPTS&quot;</span><br><span class="line">export HADOOP_SECONDARYNAMENODE_OPTS=&quot;-Dhadoop.security.logger=$&#123;HADOOP_SECURITY_LOGGER:-INFO,RFAS&#125; -Dhdfs.audit.logger=$&#123;HDFS_AUDIT_LOGGER:-INFO,NullAppender&#125; $HADOOP_SECONDARYNAMENODE_OPTS&quot;</span><br><span class="line">export HADOOP_NFS3_OPTS=&quot;$HADOOP_NFS3_OPTS&quot;</span><br><span class="line">export HADOOP_PORTMAP_OPTS=&quot;-Xmx2048m $HADOOP_PORTMAP_OPTS&quot;</span><br><span class="line">export HADOOP_CLIENT_OPTS=&quot;-Xmx2048m $HADOOP_CLIENT_OPTS&quot;</span><br><span class="line">export HADOOP_SECURE_DN_USER=$&#123;HADOOP_SECURE_DN_USER&#125;</span><br><span class="line">export HADOOP_SECURE_DN_LOG_DIR=$&#123;HADOOP_LOG_DIR&#125;/$&#123;HADOOP_HDFS_USER&#125;</span><br><span class="line">export HADOOP_PID_DIR=$&#123;HADOOP_PID_DIR&#125;</span><br><span class="line">export HADOOP_SECURE_DN_PID_DIR=$&#123;HADOOP_PID_DIR&#125;</span><br><span class="line">export HADOOP_IDENT_STRING=$USER</span><br><span class="line">export LD_LIBRARY_PATH=$HADOOP_HOME/lib/native:/usr/lib64:/usr/local/lib/</span><br></pre></td></tr></table></figure><h6 id="mapred-site-xml-配置文件"><a href="#mapred-site-xml-配置文件" class="headerlink" title="mapred-site.xml 配置文件"></a>mapred-site.xml 配置文件</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br></pre></td><td class="code"><pre><span class="line">&lt;?xml version=&quot;1.0&quot;?&gt;</span><br><span class="line">&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;</span><br><span class="line">&lt;!--</span><br><span class="line">  Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span><br><span class="line">  you may not use this file except in compliance with the License.</span><br><span class="line">  You may obtain a copy of the License at</span><br><span class="line"></span><br><span class="line">    http://www.apache.org/licenses/LICENSE-2.0</span><br><span class="line"></span><br><span class="line">  Unless required by applicable law or agreed to in writing, software</span><br><span class="line">  distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span><br><span class="line">  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span><br><span class="line">  See the License for the specific language governing permissions and</span><br><span class="line">  limitations under the License. See accompanying LICENSE file.</span><br><span class="line">--&gt;</span><br><span class="line"></span><br><span class="line">&lt;!-- Put site-specific property overrides in this file. --&gt;</span><br><span class="line"></span><br><span class="line">&lt;configuration&gt;</span><br><span class="line"></span><br><span class="line"> &lt;property&gt;</span><br><span class="line">  &lt;name&gt;mapreduce.framework.name&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;yarn&lt;/value&gt;</span><br><span class="line"> &lt;/property&gt;</span><br><span class="line"> &lt;property&gt;</span><br><span class="line">  &lt;name&gt;yarn.app.mapreduce.am.staging-dir&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;/user&lt;/value&gt;</span><br><span class="line"> &lt;/property&gt;</span><br><span class="line"> &lt;property&gt;</span><br><span class="line">  &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;namenode01.host-shining.com:10020&lt;/value&gt;</span><br><span class="line"> &lt;/property&gt;</span><br><span class="line"> &lt;property&gt;</span><br><span class="line">  &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;namenode01.host-shining.com:19888&lt;/value&gt;</span><br><span class="line"> &lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;mapreduce.task.tmp.dir&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;/home/hadoop/apache-hadoop/hadoop/var/yarn/task&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;property&gt;  </span><br><span class="line">  &lt;name&gt;yarn.app.mapreduce.am.resource.mb&lt;/name&gt;  </span><br><span class="line">  &lt;value&gt;4096&lt;/value&gt;  </span><br><span class="line">&lt;/property&gt;  </span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;mapreduce.map.memory.mb&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;4096&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"> &lt;property&gt;</span><br><span class="line">  &lt;name&gt;mapreduce.reduce.memory.mb&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;4096&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;mapreduce.map.java.opts&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;-Xmx3400m&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;mapreduce.reduce.java.opts&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;-Xmx3400m&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;mapred.compress.map.output&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;true&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;mapred.map.output.compression.codec&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;com.hadoop.compression.lzo.LzoCodec&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;mapred.child.env&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;LD_LIBRARY_PATH=/usr/lib64&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;mapreduce.job.ubertask.enable&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;true&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;mapreduce.job.ubertask.maxmaps&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;9&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;mapreduce.job.ubertask.maxreduces&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;1&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;!-- 默认值为一个数据块的大小--&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;mapreduce.job.ubertask.maxbytes&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;67108864&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure><h6 id="yarn-site-xml-配置文件"><a href="#yarn-site-xml-配置文件" class="headerlink" title="yarn-site.xml 配置文件"></a>yarn-site.xml 配置文件</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br></pre></td><td class="code"><pre><span class="line">&lt;?xml version=&quot;1.0&quot;?&gt;</span><br><span class="line">&lt;!--</span><br><span class="line">  Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span><br><span class="line">  you may not use this file except in compliance with the License.</span><br><span class="line">  You may obtain a copy of the License at</span><br><span class="line"></span><br><span class="line">    http://www.apache.org/licenses/LICENSE-2.0</span><br><span class="line"></span><br><span class="line">  Unless required by applicable law or agreed to in writing, software</span><br><span class="line">  distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span><br><span class="line">  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span><br><span class="line">  See the License for the specific language governing permissions and</span><br><span class="line">  limitations under the License. See accompanying LICENSE file.</span><br><span class="line">--&gt;</span><br><span class="line">&lt;configuration&gt;</span><br><span class="line"></span><br><span class="line">&lt;property&gt;   </span><br><span class="line">  &lt;name&gt;yarn.resourcemanager.ha.enabled&lt;/name&gt;   </span><br><span class="line">  &lt;value&gt;true&lt;/value&gt; </span><br><span class="line">&lt;/property&gt; </span><br><span class="line">&lt;property&gt;   </span><br><span class="line">  &lt;name&gt;yarn.resourcemanager.cluster-id&lt;/name&gt;   </span><br><span class="line">  &lt;value&gt;shininghadoop-yarn&lt;/value&gt; </span><br><span class="line">&lt;/property&gt; </span><br><span class="line">&lt;property&gt;   </span><br><span class="line">  &lt;name&gt;yarn.resourcemanager.ha.rm-ids&lt;/name&gt;   </span><br><span class="line">  &lt;value&gt;rm1,rm2&lt;/value&gt; </span><br><span class="line">&lt;/property&gt; </span><br><span class="line">&lt;property&gt;   </span><br><span class="line">  &lt;name&gt;yarn.resourcemanager.hostname.rm1&lt;/name&gt;   </span><br><span class="line">  &lt;value&gt;namenode00.host-shining.com&lt;/value&gt; </span><br><span class="line">&lt;/property&gt; </span><br><span class="line">&lt;property&gt;   </span><br><span class="line">  &lt;name&gt;yarn.resourcemanager.hostname.rm2&lt;/name&gt;   </span><br><span class="line">  &lt;value&gt;namenode01.host-shining.com&lt;/value&gt; </span><br><span class="line">&lt;/property&gt; </span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;yarn.resourcemanager.webapp.address.rm1&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;namenode00.host-shining.com:8088&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;yarn.resourcemanager.webapp.address.rm2&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;namenode01.host-shining.com:8088&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;yarn.resourcemanager.recovery.enabled&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;true&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;yarn.resourcemanager.store.class&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;   </span><br><span class="line">  &lt;name&gt;yarn.resourcemanager.zk-address&lt;/name&gt;   </span><br><span class="line">  &lt;value&gt;namenode00.host-shining.com:2181,namenode01.host-shining.com:2181,datanode00.host-shining.com:2181,datanode01.host-shining.com:2181,datanode02.host-shining.com:2181&lt;/value&gt; </span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;!-- &lt;property&gt;</span><br><span class="line"> &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;</span><br><span class="line"> &lt;value&gt;namenode01.host-shining.com&lt;/value&gt;</span><br><span class="line"> &lt;/property&gt; </span><br><span class="line">&lt;property&gt; </span><br><span class="line">  &lt;name&gt;yarn.resourcemanager.resource-tracker.address&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;namenode01.host-shining.com:8031&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;yarn.resourcemanager.address&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;namenode01.host-shining.com:8032&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;yarn.resourcemanager.scheduler.address&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;namenode01.host-shining.com:8030&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;yarn.resourcemanager.admin.address&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;namenode01.host-shining.com:8033&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;yarn.resourcemanager.webapp.address&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;namenode01.host-shining.com:8088&lt;/value&gt;</span><br><span class="line">&lt;/property&gt; --&gt;</span><br><span class="line"></span><br><span class="line"> &lt;property&gt;</span><br><span class="line">   &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;</span><br><span class="line">   &lt;value&gt;mapreduce_shuffle&lt;/value&gt;</span><br><span class="line"> &lt;/property&gt;</span><br><span class="line"> &lt;property&gt;</span><br><span class="line">   &lt;name&gt;yarn.nodemanager.aux-services.mapreduce_shuffle.class&lt;/name&gt;</span><br><span class="line">   &lt;value&gt;org.apache.hadoop.mapred.ShuffleHandler&lt;/value&gt;</span><br><span class="line"> &lt;/property&gt;</span><br><span class="line"> &lt;property&gt;</span><br><span class="line">   &lt;name&gt;yarn.log-aggregation-enable&lt;/name&gt;</span><br><span class="line">   &lt;value&gt;true&lt;/value&gt;</span><br><span class="line"> &lt;/property&gt;</span><br><span class="line"> &lt;property&gt;</span><br><span class="line">   &lt;name&gt;yarn.nodemanager.local-dirs&lt;/name&gt;</span><br><span class="line">   &lt;value&gt;/home/hadoop/apache-hadoop/hadoop/var/yarn/local-dir&lt;/value&gt;</span><br><span class="line"> &lt;/property&gt;</span><br><span class="line"> &lt;property&gt;</span><br><span class="line">   &lt;name&gt;yarn.nodemanager.log-dirs&lt;/name&gt;</span><br><span class="line">   &lt;value&gt;/home/hadoop/apache-hadoop/hadoop/var/yarn/logs&lt;/value&gt;</span><br><span class="line"> &lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;yarn.nodemanager.remote-app-log-dir&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;/home/hadoop/apache-hadoop/hadoop/var/yarn/logs&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;yarn.log.aggregation-enable&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;true&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.nodemanager.resource.memory-mb&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;83968&lt;/value&gt;</span><br><span class="line">    &lt;discription&gt;每个节点可用内存,单位MB&lt;/discription&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;yarn.nodemanager.resource.cpu-vcores&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;18&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.log-aggregation-enable&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;true&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">   &lt;description&gt;Where to aggregate logs to.&lt;/description&gt;</span><br><span class="line">   &lt;name&gt;yarn.nodemanager.remote-app-log-dir&lt;/name&gt;</span><br><span class="line">   &lt;value&gt;/home/hadoop/apache-hadoop/hadoop/var/yarn/logs/apps&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;yarn.application.classpath&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;$HADOOP_CONF_DIR,</span><br><span class="line">         $HADOOP_COMMON_HOME/share/hadoop/common/*,</span><br><span class="line">         $HADOOP_COMMON_HOME/share/hadoop/common/lib/*,</span><br><span class="line">         $HADOOP_HDFS_HOME/share/hadoop/hdfs/*,</span><br><span class="line">         $HADOOP_HDFS_HOME/share/hadoop/hdfs/lib/*,</span><br><span class="line">         $YARN_HOME/share/hadoop/yarn/*,</span><br><span class="line">         $YARN_HOME/share/hadoop/yarn/lib/*,</span><br><span class="line">         $YARN_HOME/share/hadoop/mapreduce/*,</span><br><span class="line">         $YARN_HOME/share/hadoop/mapreduce/lib/*</span><br><span class="line">  &lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;yarn.resourcemanager.scheduler.class&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;yarn.scheduler.fair.allocation.file&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;/home/hadoop/apache-hadoop/hadoop/etc/hadoop/fair-scheduler.xml&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;yarn.log.server.url&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;http://namenode01.host-shining.com:19888/jobhistory/logs&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;yarn.scheduler.minimum-allocation-mb&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;1024&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;yarn.scheduler.maximum-allocation-mb&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;16384&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;yarn.scheduler.minimum-allocation-vcores&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;1&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;yarn.scheduler.maximum-allocation-vcores&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;6&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;yarn.nodemanager.vmem-pmem-ratio&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;1.8&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;yarn.scheduler.fair.preemption&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;true&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure><h6 id="yarn-env-sh-配置文件"><a href="#yarn-env-sh-配置文件" class="headerlink" title="yarn-env.sh 配置文件"></a>yarn-env.sh 配置文件</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line">export HADOOP_YARN_USER=$&#123;HADOOP_YARN_USER:-yarn&#125;</span><br><span class="line">export YARN_CONF_DIR=&quot;$&#123;YARN_CONF_DIR:-$HADOOP_YARN_HOME/conf&#125;&quot;</span><br><span class="line">export HADOOP_HOME=/home/hadoop/apache-hadoop/hadoop</span><br><span class="line">export HADOOP_LOG_DIR=$&#123;HADOOP_HOME&#125;/logs</span><br><span class="line">export YARN_LOG_DIR=$&#123;HADOOP_HOME&#125;/logs</span><br><span class="line">JVM_OPTS=&quot;-server -verbose:gc</span><br><span class="line">  -XX:+PrintGCDateStamps</span><br><span class="line">  -XX:+PrintGCDetails</span><br><span class="line">  -XX:+UseGCLogFileRotation</span><br><span class="line">  -XX:NumberOfGCLogFiles=9</span><br><span class="line">  -XX:GCLogFileSize=256m&quot;</span><br><span class="line">RESOURCEMANAGER_OPTS=&quot;-Xmx30g -Xms5g -Xmn2g $JVM_OPTS  -Xloggc:$YARN_LOG_DIR/rm_gc.log&quot;</span><br><span class="line">NODEMANAGER_OPTS=&quot;-Xmx2048m -Xms1024m -Xmn512m $JVM_OPTS  -Xloggc:$YARN_LOG_DIR/nm_gc.log&quot;</span><br><span class="line">export JAVA_HOME=/usr/java/jdk1.8.0_45</span><br><span class="line">if [ &quot;$JAVA_HOME&quot; != &quot;&quot; ]; then</span><br><span class="line">  #echo &quot;run java in $JAVA_HOME&quot;</span><br><span class="line">  JAVA_HOME=$JAVA_HOME</span><br><span class="line">fi</span><br><span class="line">  </span><br><span class="line">if [ &quot;$JAVA_HOME&quot; = &quot;&quot; ]; then</span><br><span class="line">  echo &quot;Error: JAVA_HOME is not set.&quot;</span><br><span class="line">  exit 1</span><br><span class="line">fi</span><br><span class="line">JAVA=$JAVA_HOME/bin/java</span><br><span class="line">JAVA_HEAP_MAX=-Xmx4096m </span><br><span class="line">if [ &quot;$YARN_HEAPSIZE&quot; != &quot;&quot; ]; then</span><br><span class="line">  JAVA_HEAP_MAX=&quot;-Xmx&quot;&quot;$YARN_HEAPSIZE&quot;&quot;m&quot;</span><br><span class="line">fi</span><br><span class="line">IFS=</span><br><span class="line">if [ &quot;$YARN_LOG_DIR&quot; = &quot;&quot; ]; then</span><br><span class="line">  YARN_LOG_DIR=&quot;$HADOOP_YARN_HOME/logs&quot;</span><br><span class="line">fi</span><br><span class="line">if [ &quot;$YARN_LOGFILE&quot; = &quot;&quot; ]; then</span><br><span class="line">  YARN_LOGFILE=&apos;yarn.log&apos;</span><br><span class="line">fi</span><br><span class="line">if [ &quot;$YARN_POLICYFILE&quot; = &quot;&quot; ]; then</span><br><span class="line">  YARN_POLICYFILE=&quot;hadoop-policy.xml&quot;</span><br><span class="line">fi</span><br><span class="line">unset IFS</span><br><span class="line">YARN_OPTS=&quot;$YARN_OPTS -Dhadoop.log.dir=$YARN_LOG_DIR&quot;</span><br><span class="line">YARN_OPTS=&quot;$YARN_OPTS -Dyarn.log.dir=$YARN_LOG_DIR&quot;</span><br><span class="line">YARN_OPTS=&quot;$YARN_OPTS -Dhadoop.log.file=$YARN_LOGFILE&quot;</span><br><span class="line">YARN_OPTS=&quot;$YARN_OPTS -Dyarn.log.file=$YARN_LOGFILE&quot;</span><br><span class="line">YARN_OPTS=&quot;$YARN_OPTS -Dyarn.home.dir=$YARN_COMMON_HOME&quot;</span><br><span class="line">YARN_OPTS=&quot;$YARN_OPTS -Dyarn.id.str=$YARN_IDENT_STRING&quot;</span><br><span class="line">YARN_OPTS=&quot;$YARN_OPTS -Dhadoop.root.logger=$&#123;YARN_ROOT_LOGGER:-INFO,console&#125;&quot;</span><br><span class="line">YARN_OPTS=&quot;$YARN_OPTS -Dyarn.root.logger=$&#123;YARN_ROOT_LOGGER:-INFO,console&#125;&quot;</span><br><span class="line">if [ &quot;x$JAVA_LIBRARY_PATH&quot; != &quot;x&quot; ]; then</span><br><span class="line">  YARN_OPTS=&quot;$YARN_OPTS -Djava.library.path=$JAVA_LIBRARY_PATH&quot;</span><br><span class="line">fi  </span><br><span class="line">YARN_OPTS=&quot;$YARN_OPTS -Dyarn.policy.file=$YARN_POLICYFILE&quot;</span><br></pre></td></tr></table></figure><h6 id="slave-配置文件"><a href="#slave-配置文件" class="headerlink" title="slave 配置文件"></a>slave 配置文件</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">datanode00.host-shining.com</span><br><span class="line">datanode01.host-shining.com</span><br><span class="line">datanode02.host-shining.com</span><br><span class="line">datanode03.host-shining.com</span><br><span class="line">datanode04.host-shining.com</span><br><span class="line">datanode05.host-shining.com</span><br><span class="line">datanode06.host-shining.com</span><br><span class="line">datanode07.host-shining.com</span><br><span class="line">datanode08.host-shining.com</span><br><span class="line">datanode09.host-shining.com</span><br></pre></td></tr></table></figure><h5 id="apache-maven-安装"><a href="#apache-maven-安装" class="headerlink" title="apache maven 安装"></a>apache maven 安装</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd /home/hadoop</span><br><span class="line">wget http://mirror.bit.edu.cn/apache/maven/maven-3/3.3.9/binaries/apache-maven-3.3.9-bin.tar.gz</span><br><span class="line">tar -zxvf apache-maven-3.3.9-bin.tar.gz</span><br></pre></td></tr></table></figure><h5 id="设置环境变量-（每台机器都需要配置）"><a href="#设置环境变量-（每台机器都需要配置）" class="headerlink" title="设置环境变量 （每台机器都需要配置）"></a>设置环境变量 （每台机器都需要配置）</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">export MAVEN_OPTS=&quot;-Xms1024m -Xmx1024m -Xss1m&quot;</span><br><span class="line"></span><br><span class="line">export OOZIE_HOME=/home/hadoop/apache-hadoop/oozie</span><br><span class="line">export MAVEN_HOME=/home/hadoop/apache-maven-3.3.9</span><br><span class="line">export JAVA_HOME=/usr/java/jdk1.8.0_45</span><br><span class="line">export ZK_HOME=/home/hadoop/apache-hadoop/zookeeper</span><br><span class="line">export HADOOP_HOME=/home/hadoop/apache-hadoop/hadoop</span><br><span class="line">export HBASE_HOME=/home/hadoop/apache-hadoop/hbase</span><br><span class="line">export HIVE_HOME=/home/hadoop/apache-hadoop/hive</span><br><span class="line">export HADOOP_MAPRED_HOME=$&#123;HADOOP_HOME&#125;</span><br><span class="line">export HADOOP_COMMON_HOME=$&#123;HADOOP_HOME&#125;</span><br><span class="line">export HADOOP_HDFS_HOME=$&#123;HADOOP_HOME&#125;</span><br><span class="line">export YARN_HOME=$&#123;HADOOP_HOME&#125;</span><br><span class="line">export HADOOP_YARN_HOME=$&#123;HADOOP_HOME&#125;</span><br><span class="line">export HADOOP_CONF_DIR=$&#123;HADOOP_HOME&#125;/etc/hadoop</span><br><span class="line">export HDFS_CONF_DIR=$&#123;HADOOP_HOME&#125;/etc/hadoop</span><br><span class="line">export YARN_CONF_DIR=$&#123;HADOOP_HOME&#125;/etc/hadoop</span><br><span class="line">export HADOOP_COMMON_LIB_NATIVE_DIR=$&#123;HADOOP_HOME&#125;/lib/native </span><br><span class="line">export SCALA_HOME=/home/hadoop/apache-hadoop/scala</span><br><span class="line">export MAHOUT_HOME=/home/hadoop/apache-hadoop/mahout</span><br><span class="line">export MAHOUT_CONF_DIR=$MAHOUT_HOME/conf</span><br><span class="line">export HADOOP_CONF_DIR=$&#123;HADOOP_HOME&#125;/etc/hadoop</span><br><span class="line">export SPARK_HOME=/home/hadoop/apache-hadoop/spark</span><br><span class="line"></span><br><span class="line">export PATH=$&#123;JAVA_HOME&#125;/bin:$&#123;JAVA_HOME&#125;/jre/bin:$&#123;ZK_HOME&#125;/bin:$&#123;HADOOP_HOME&#125;/bin:$&#123;HADOOP_HOME&#125;/sbin:$&#123;HBASE_HOME&#125;/bin:$MAHOUT_HOME/bin:$&#123;HIVE_HOME&#125;/bin:$&#123;SCALA_HOME&#125;/bin:$&#123;SPARK_HOME&#125;/bin:$&#123;MAVEN_HOME&#125;/bin:$&#123;OOZIE_HOME&#125;/bin:$PATH</span><br><span class="line">export classpath=$JAVA_HOME/lib/dt.jar:$HBASE_HOME/lib:$MAHOUT_HOME/lib:$PIG_HOME/lib:$HIVE_HOME/lib:$JAVA_HOME/lib/tools.jar:$HADOOP_CONF_DIR:$SPARK_HOME/lib:$HBASE_HOME/lib/native/Linux-amd64-64:/usr/local/lib:$HADOOP_HOME/lib/native</span><br><span class="line">export HBASE_LIBRARY_PATH=$&#123;HBASE_LIBRARY_PATH&#125;:$&#123;HBASE_HOME&#125;/lib/native/Linux-amd64-64:/usr/local/lib</span><br><span class="line">export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$HADOOP_HOME/lib/native/Linux-amd64-64:$HADOOP_HOME/lib/native:/usr/local/lib</span><br></pre></td></tr></table></figure><h5 id="protobuf-安装"><a href="#protobuf-安装" class="headerlink" title="protobuf 安装"></a>protobuf 安装</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf protobuf-2.5.0.tar.gz   （每台机器安装）</span><br><span class="line">cd protobuf-2.5.0</span><br><span class="line">./configure          (root用户执行)</span><br><span class="line">make                 (root用户执行)</span><br><span class="line">make install         (root用户执行)</span><br></pre></td></tr></table></figure><h5 id="编译hdfs源码，-lib库-（编译以前需要安装maven，下载之后解压，设置环境变量即可-不需要没台机器都安装）"><a href="#编译hdfs源码，-lib库-（编译以前需要安装maven，下载之后解压，设置环境变量即可-不需要没台机器都安装）" class="headerlink" title="编译hdfs源码， lib库 （编译以前需要安装maven，下载之后解压，设置环境变量即可,不需要没台机器都安装）"></a>编译hdfs源码， lib库 （编译以前需要安装maven，下载之后解压，设置环境变量即可,不需要没台机器都安装）</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">wget http://apache.fayea.com/hadoop/common/hadoop-2.7.2/hadoop-2.7.2-src.tar.gz</span><br><span class="line">tar -zxvf hadoop-2.7.2-src.tar.gz</span><br><span class="line">cd hadoop-2.7.2-src</span><br><span class="line">mvn package -Pdist,native -DskipTests -Dtar</span><br><span class="line">cp -a hadoop-dist/target/hadoop-2.7.2/lib/native/* ~/apache-hadoop/hadoop/lib/native/</span><br></pre></td></tr></table></figure><h5 id="编译lzo压缩格式"><a href="#编译lzo压缩格式" class="headerlink" title="编译lzo压缩格式"></a>编译lzo压缩格式</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">下载 lzo  https://codeload.github.com/twitter/hadoop-lzo/zip/master</span><br><span class="line">unzip hadoop-lzo-master.zip </span><br><span class="line">cd hadoop-lzo-master</span><br><span class="line">vim pom.xml     （修改hadoop版本）</span><br><span class="line">  &lt;properties&gt;</span><br><span class="line">    &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;</span><br><span class="line">    &lt;hadoop.current.version&gt;2.7.2&lt;/hadoop.current.version&gt;</span><br><span class="line">    &lt;hadoop.old.version&gt;1.0.4&lt;/hadoop.old.version&gt;</span><br><span class="line">  &lt;/properties&gt;</span><br><span class="line"></span><br><span class="line">export CFLAGS=-m64</span><br><span class="line">export CXXFLAGS=-m64</span><br><span class="line">mvn clean package -Dmaven.test.skip=true</span><br><span class="line">cp target/native/Linux-amd64-64/lib/*  ~/apache-hadoop/hadoop/lib/native/</span><br><span class="line">cp target/hadoop-lzo-0.4.20-SNAPSHOT.jar  ~/apache-hadoop/hadoop/share/hadoop/common/lib/</span><br></pre></td></tr></table></figure><h4 id="安装hbase"><a href="#安装hbase" class="headerlink" title="安装hbase"></a>安装hbase</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf  hbase-1.2.2-bin.tar.gz &amp;&amp; ln -s hbase-1.2.2 hbase</span><br><span class="line">cd hbase/conf</span><br><span class="line">cp $HADOOP_HOME/etc/hadoop/core-site.xml  $HBASE_HOME/conf/</span><br><span class="line">cp $HADOOP_HOME/etc/hadoop/hdfs-site.xml  $HBASE_HOME/conf/</span><br><span class="line">对于Hbase启用LZO</span><br><span class="line">cp -a $HADOOP_HOME/lib/native $HBASE_HOME/lib</span><br></pre></td></tr></table></figure><h5 id="修改配置文件"><a href="#修改配置文件" class="headerlink" title="修改配置文件"></a>修改配置文件</h5><h6 id="hbase-site-xml-配置文件"><a href="#hbase-site-xml-配置文件" class="headerlink" title="hbase.site.xml 配置文件"></a>hbase.site.xml 配置文件</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><span class="line">&lt;?xml version=&quot;1.0&quot;?&gt;</span><br><span class="line">&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;</span><br><span class="line">&lt;!--</span><br><span class="line">/**</span><br><span class="line"> *</span><br><span class="line"> * Licensed to the Apache Software Foundation (ASF) under one</span><br><span class="line"> * or more contributor license agreements.  See the NOTICE file</span><br><span class="line"> * distributed with this work for additional information</span><br><span class="line"> * regarding copyright ownership.  The ASF licenses this file</span><br><span class="line"> * to you under the Apache License, Version 2.0 (the</span><br><span class="line"> * &quot;License&quot;); you may not use this file except in compliance</span><br><span class="line"> * with the License.  You may obtain a copy of the License at</span><br><span class="line"> *</span><br><span class="line"> *     http://www.apache.org/licenses/LICENSE-2.0</span><br><span class="line"> *</span><br><span class="line"> * Unless required by applicable law or agreed to in writing, software</span><br><span class="line"> * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span><br><span class="line"> * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span><br><span class="line"> * See the License for the specific language governing permissions and</span><br><span class="line"> * limitations under the License.</span><br><span class="line"> */</span><br><span class="line">--&gt;</span><br><span class="line">&lt;configuration&gt;</span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;hbase.rootdir&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;hdfs://shininghadoop/hbase&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;hbase.rest.port&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;60050&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;hbase.cluster.distributed&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;true&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;hbase.tmp.dir&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;/home/hadoop/apache-hadoop/hbase/tmp&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;namenode00.host-shining.com,namenode01.host-shining.com,datanode00.host-shining.com,datanode01.host-shining.com,datanode02.host-shining.com&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;hbase.master&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;namenode00.host-shining.com,namenode01.host-shining.com&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;dfs.replication&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;3&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;hbase.zookeeper.property.dataDir&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;/home/hadoop/apache-hadoop/zookeeper&lt;/value&gt;</span><br><span class="line">  &lt;description&gt;Property from ZooKeeper&apos;sconfigzoo.cfg.The directory where the snapshot is stored.&lt;/description&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;hbase.zookeeper.property.clientPort&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;2181&lt;/value&gt;</span><br><span class="line">  &lt;description&gt;Property from ZooKeeper&apos;sconfigzoo.cfg.Theport at which the clients will connect.&lt;/description&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;io.compression.codecs&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;org.apache.hadoop.io.compress.GzipCodec,org.apache.hadoop.io.compress.DefaultCodec,com.hadoop.compression.lzo.LzoCodec,com.hadoop.compression.lzo.LzopCodec,org.apache.hadoop.io.compress.BZip2Codec&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;io.compression.codec.lzo.class&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;com.hadoop.compression.lzo.LzoCodec&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure><h6 id="hbase-env-sh-修改配置文件-（取消了注释的内容）"><a href="#hbase-env-sh-修改配置文件-（取消了注释的内容）" class="headerlink" title="hbase-env.sh 修改配置文件 （取消了注释的内容）"></a>hbase-env.sh 修改配置文件 （取消了注释的内容）</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME=/usr/java/jdk1.8.0_45</span><br><span class="line">export HADOOP_HOME=/home/hadoop/apache-hadoop/hadoop</span><br><span class="line">export HBASE_HOME=/home/hadoop/apache-hadoop/hbase</span><br><span class="line">export HBASE_HEAPSIZE=4096</span><br><span class="line">export HBASE_OPTS=&quot;-XX:+UseConcMarkSweepGC&quot;</span><br><span class="line">export HBASE_MASTER_OPTS=&quot;$HBASE_MASTER_OPTS -Xms1024m -Xmx4096m&quot;</span><br><span class="line">export HBASE_REGIONSERVER_OPTS=&quot;$HBASE_REGIONSERVER_OPTS -Xms1024m -Xmx4096m&quot;</span><br><span class="line">export HBASE_LOG_DIR=/home/hadoop/apache-hadoop/hbase/logs</span><br><span class="line">export HBASE_MANAGES_ZK=false</span><br><span class="line">export LD_LIBRARY_PATH=$HADOOP_HOME/lib/native:/usr/lib64</span><br><span class="line">export HBASE_LIBRARY_PATH=$HADOOP_HOME/lib/native:/usr/lib64</span><br><span class="line">export CLASSPATH=$CLASSPATH:$HBASE_LIBRARY_PATH</span><br></pre></td></tr></table></figure><h6 id="regionservers-配置文件修改"><a href="#regionservers-配置文件修改" class="headerlink" title="regionservers 配置文件修改"></a>regionservers 配置文件修改</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">datanode03.host-shining.com</span><br><span class="line">datanode04.host-shining.com</span><br><span class="line">datanode05.host-shining.com</span><br><span class="line">datanode06.host-shining.com</span><br></pre></td></tr></table></figure><h6 id="备注"><a href="#备注" class="headerlink" title="备注"></a>备注</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">hbase-env.sh 中   </span><br><span class="line">#export HBASE_MASTER_OPTS=&quot;$HBASE_MASTER_OPTS -XX:PermSize=128m -XX:MaxPermSize=128m&quot;</span><br><span class="line">#export HBASE_REGIONSERVER_OPTS=&quot;$HBASE_REGIONSERVER_OPTS -XX:PermSize=128m -XX:MaxPermSize=128m&quot;</span><br><span class="line">改为</span><br><span class="line">export HBASE_MASTER_OPTS=&quot;$HBASE_MASTER_OPTS -Xms1024m -Xmx1024m&quot;</span><br><span class="line">export HBASE_REGIONSERVER_OPTS=&quot;$HBASE_REGIONSERVER_OPTS -Xms1024m -Xmx1024m&quot; </span><br><span class="line"></span><br><span class="line">////  jdk 用1.8 的 PermSize MaxPermSize 参数没有，需要用 xmx</span><br></pre></td></tr></table></figure><h4 id="hive安装"><a href="#hive安装" class="headerlink" title="hive安装"></a>hive安装</h4><h6 id="数据库创建与授权"><a href="#数据库创建与授权" class="headerlink" title="数据库创建与授权"></a>数据库创建与授权</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">mysql -uroot -p</span><br><span class="line">create database shininghadoop;</span><br><span class="line"></span><br><span class="line">GRANT ALL PRIVILEGES ON shininghadoop.* TO &apos;shininghadoop&apos;@&quot;192.168.77.158&quot; IDENTIFIED BY &apos;shininghadoop&apos;WITH GRANT OPTION;</span><br><span class="line">GRANT ALL PRIVILEGES ON shininghadoop.* TO &apos;shininghadoop&apos;@&quot;namenode00.host-shining.com&quot; IDENTIFIED BY &apos;shininghadoop&apos;WITH GRANT OPTION;</span><br><span class="line">......   兜圈所有hadoop节点的IP地址</span><br><span class="line"></span><br><span class="line">FLUSH PRIVILEGES;</span><br></pre></td></tr></table></figure><h6 id="导入hive元数据库"><a href="#导入hive元数据库" class="headerlink" title="导入hive元数据库"></a>导入hive元数据库</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf apache-hive-2.1.0-bin.tar.gz &amp;&amp; ln -s apache-hive-2.1.0-bin hive</span><br><span class="line">创建源数据</span><br><span class="line">cd $HIVE_HOME/scripts/metastore/upgrade/mysql/</span><br><span class="line">mysql -h数据库地址 -ushininghadoop -p</span><br><span class="line">use shininghadoop;</span><br><span class="line">source hive-schema-2.1.0.mysql.sql;</span><br></pre></td></tr></table></figure><h6 id="替换java-jdbc-jar"><a href="#替换java-jdbc-jar" class="headerlink" title="替换java jdbc jar"></a>替换java jdbc jar</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">hive 需要 java jar</span><br><span class="line">cd $HIVE_HOME/lib</span><br><span class="line">把 mysql-connector-java-5.1.35.jar 放在这里</span><br><span class="line">ln -s mysql-connector-java-5.1.35.jar mysql-connector-java.jar</span><br></pre></td></tr></table></figure><h6 id="hive-site-xml-配置文件-根据环境配置，线上用的是default文件"><a href="#hive-site-xml-配置文件-根据环境配置，线上用的是default文件" class="headerlink" title="hive-site.xml 配置文件  (根据环境配置，线上用的是default文件)"></a>hive-site.xml 配置文件  (根据环境配置，线上用的是default文件)</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;jdbc:mysql://192.168.53.101:3306/testhadoop&lt;/value&gt;</span><br><span class="line">  &lt;description&gt;the URL of the MySQL database&lt;/description&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;javax.jdo.option.ConnectionDriverName&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;com.mysql.jdbc.Driver&lt;/value&gt;</span><br><span class="line">&lt;/property&gt; </span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;javax.jdo.option.ConnectionUserName&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;testhadoop&lt;/value&gt;</span><br><span class="line">&lt;/property&gt; </span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;javax.jdo.option.ConnectionPassword&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;testhadoop&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;datanucleus.autoCreateSchema&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;false&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;datanucleus.fixedDatastore&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;true&lt;/value&gt;</span><br><span class="line">&lt;/property&gt; </span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;datanucleus.autoStartMechanism&lt;/name&gt; </span><br><span class="line">  &lt;value&gt;SchemaTable&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;  </span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;hive.metastore.schema.verification&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;true&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;hive.security.authorization.enabled&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;false&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;hive.metastore.warehouse.dir&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;/user/hive/warehouse&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;hive.security.authorization.manager&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;org.apache.hadoop.hive.ql.security.authorization.DefaultHiveAuthorizationProvider&lt;/value&gt;</span><br><span class="line">  &lt;description&gt;The Hive client authorization manager class name.</span><br><span class="line">  The user defined authorization class should implement interface org.apache.hadoop.hive.ql.security.authorization.HiveAuthorizationProvider.</span><br><span class="line">  &lt;/description&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;hive.security.metastore.authorization.manager&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;org.apache.hadoop.hive.ql.security.authorization.DefaultHiveMetastoreAuthorizationProvider&lt;/value&gt;</span><br><span class="line">  &lt;description&gt;authorization manager class name to be used in the metastore for authorization.</span><br><span class="line">  The user defined authorization class should implement interface org.apache.hadoop.hive.ql.security.authorization.HiveMetastoreAuthorizationProvider.</span><br><span class="line">  &lt;/description&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;hive.security.authenticator.manager&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;org.apache.hadoop.hive.ql.security.HadoopDefaultAuthenticator&lt;/value&gt;</span><br><span class="line">  &lt;description&gt;hive client authenticator manager class name.</span><br><span class="line">  The user defined authenticator should implement interface org.apache.hadoop.hive.ql.security.HiveAuthenticationProvider.&lt;/description&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;hive.security.metastore.authenticator.manager&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;org.apache.hadoop.hive.ql.security.HadoopDefaultMetastoreAuthenticator&lt;/value&gt;</span><br><span class="line">  &lt;description&gt;authenticator manager class name to be used in the metastore for authentication.</span><br><span class="line">  The user defined authenticator should implement interface org.apache.hadoop.hive.ql.security.HiveAuthenticationProvider.&lt;/description&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;hive.security.authorization.createtable.group.grants&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;&lt;/value&gt;</span><br><span class="line">  &lt;description&gt;the privileges automatically granted to some groups whenever a table gets created. </span><br><span class="line">   An example like &quot;groupX,groupY:select;groupZ:create&quot; will grant select privilege to groupX and groupY, </span><br><span class="line">   and grant create privilege to groupZ whenever a new table created.&lt;/description&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;hive.security.authorization.createtable.role.grants&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;&lt;/value&gt;</span><br><span class="line">  &lt;description&gt;the privileges automatically granted to some roles whenever a table gets created. </span><br><span class="line">   An example like &quot;roleX,roleY:select;roleZ:create&quot; will grant select privilege to roleX and roleY, </span><br><span class="line">   and grant create privilege to roleZ whenever a new table created.&lt;/description&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;hive.security.authorization.createtable.owner.grants&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;ALL&lt;/value&gt;</span><br><span class="line">  &lt;description&gt;the privileges automatically granted to the owner whenever a table gets created. </span><br><span class="line">   An example like &quot;select,drop&quot; will grant select and drop privilege to the owner of the table&lt;/description&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;hive.auto.convert.join&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;false&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure><h6 id="hive-env-sh"><a href="#hive-env-sh" class="headerlink" title="hive-env.sh"></a>hive-env.sh</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">export HADOOP_HEAPSIZE=2048</span><br><span class="line">export HIVE_CONF_DIR=/home/hadoop/apache-hadoop/hive/conf</span><br><span class="line">export HIVE_AUX_JARS_PATH=/home/hadoop/apache-hadoop/hive/lib</span><br><span class="line">export HADOOP_PREFIX=/home/hadoop/apache-hadoop/hadoop</span><br><span class="line">export HADOOP_LIBEXEC_DIR=/home/hadoop/apache-hadoop/hadoop/libexec</span><br><span class="line">export HADOOP_CONF_DIR=/home/hadoop/apache-hadoop/hadoop/etc/hadoop</span><br><span class="line">export HADOOP_COMMON_HOME=/home/hadoop/apache-hadoop/hadoop</span><br><span class="line">export HADOOP_HDFS_HOME=/home/hadoop/apache-hadoop/hadoop</span><br><span class="line">export HADOOP_YARN_HOME=/home/hadoop/apache-hadoop/hadoop</span><br><span class="line">export HADOOP_MAPRED_HOME=/home/hadoop/apache-hadoop/hadoop</span><br></pre></td></tr></table></figure><h6 id="启动-hive-metastore和-server2"><a href="#启动-hive-metastore和-server2" class="headerlink" title="启动 hive metastore和 server2"></a>启动 hive metastore和 server2</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">mkdir $HIVE_HOME/hive-logs</span><br><span class="line">nohup.sh </span><br><span class="line">#!/bin/bash</span><br><span class="line"></span><br><span class="line">nohup  hive --service metastore &gt; /home/hadoop/apache-hadoop/hive/hive-logs/metastore.log 2&gt;&amp;1 &amp; </span><br><span class="line">echo $! &gt; /home/hadoop/apache-hadoop/hive/hive-logs/metastore.pid</span><br><span class="line">nohup hive  --service hiveserver2 &gt; /home/hadoop/apache-hadoop/hive/hive-logs/hiveserver2.log 2&gt;&amp;1 &amp; </span><br><span class="line">echo $! &gt; /home/hadoop/apache-hadoop/hive/hive-logs/hiveserver2.pid</span><br></pre></td></tr></table></figure><h5 id="hadoop启动"><a href="#hadoop启动" class="headerlink" title="hadoop启动"></a>hadoop启动</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">chmod 755 -R /home/hadoop/apache-hadoop</span><br><span class="line">hdfs zkfc -formatZK（格式化zookeeper）</span><br><span class="line">hadoop-daemon.sh start journalnode (启动journalnode)</span><br><span class="line">hdfs namenode -format（格式化namenode metadata）</span><br><span class="line">hadoop-daemon.sh start namenode</span><br><span class="line">hadoop-daemon.sh start namenode -bootstrapStandby( standy namenode)</span><br><span class="line">如果上面log没有问题</span><br><span class="line">stop-dfs.sh</span><br><span class="line">start-dfs.sh</span><br><span class="line">start-yarn.sh   (yarn的机器上执行)</span><br><span class="line">mr-jobhistory-daemon.sh start historyserver  (namenode01 机器上执行)</span><br><span class="line">start-hbase.sh</span><br></pre></td></tr></table></figure><h5 id="spark-安装"><a href="#spark-安装" class="headerlink" title="spark 安装"></a>spark 安装</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">wget http://downloads.lightbend.com/scala/2.11.8/scala-2.11.8.tgz    （每台机器安装）</span><br><span class="line">tar -zxvf scala-2.11.8.tgz &amp;&amp; ln -s scala-2.11.8 scala</span><br><span class="line"></span><br><span class="line">wget http://apache.fayea.com/mahout/0.12.2/apache-mahout-distribution-0.12.2.tar.gz</span><br><span class="line">tar -zxvf apache-mahout-distribution-0.12.2.tar.gz </span><br><span class="line">ln -s apache-mahout-distribution-0.12.2 mahout </span><br><span class="line">cp ~/apache-hadoop/hadoop/share/hadoop/common/lib/hadoop-lzo-0.4.20-SNAPSHOT.jar ~/apache-hadoop/mahout/lib/</span><br><span class="line"></span><br><span class="line">wget http://mirrors.hust.edu.cn/apache/spark/spark-1.6.2/spark-1.6.2.tgz</span><br><span class="line">tar -zxvf spark-1.6.2.tgz &amp;&amp; ln -s spark-1.6.2.tgz spark-1.6.2</span><br><span class="line">cd spark/conf</span><br></pre></td></tr></table></figure><h6 id="spark-default-conf-配置文件"><a href="#spark-default-conf-配置文件" class="headerlink" title="spark-default.conf  配置文件"></a>spark-default.conf  配置文件</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">spark.master                     spark://cd-namenode00.host-shining.com:7077</span><br><span class="line">spark.eventLog.enabled           true</span><br><span class="line">spark.eventLog.dir               hdfs://shininghadoop/spark</span><br><span class="line">spark.serializer                 org.apache.spark.serializer.KryoSerializer</span><br><span class="line">spark.driver.memory              5g</span><br><span class="line">spark.executor.extraJavaOptions  -XX:+PrintGCDetails -Dkey=value -Dnumbers=&quot;one two three&quot;</span><br></pre></td></tr></table></figure><h6 id="spark-env-sh-配置文件"><a href="#spark-env-sh-配置文件" class="headerlink" title="spark-env.sh 配置文件"></a>spark-env.sh 配置文件</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">export SPARK_WORKER_MEMORY=5G</span><br><span class="line">export SPARK_MEM=$&#123;SPARK_MEM:-5g&#125;</span><br><span class="line">JAVA_OPTS=&quot;$OUR_JAVA_OPTS&quot;</span><br><span class="line">JAVA_OPTS=&quot;$JAVA_OPTS-Xms$SPARK_MEM -Xmx$SPARK_MEM&quot;</span><br><span class="line">JAVA_OPTS=&quot;$JAVA_OPTS-Djava.library.path=$SPARK_LIBRARY_PATH&quot;</span><br><span class="line">export JAVA_HOME=/usr/java/jdk1.8.0_45</span><br><span class="line">export HADOOP_HOME=/home/hadoop/apache-hadoop/hadoop</span><br><span class="line">export HBASE_HOME=/home/hadoop/apache-hadoop/hbase</span><br><span class="line">export HIVE_HOME=/home/hadoop/apache-hadoop/hive</span><br><span class="line">export HADOOP_MAPRED_HOME=$&#123;HADOOP_HOME&#125;</span><br><span class="line">export HADOOP_COMMON_HOME=$&#123;HADOOP_HOME&#125;</span><br><span class="line">export HADOOP_HDFS_HOME=$&#123;HADOOP_HOME&#125;</span><br><span class="line">export YARN_HOME=$&#123;HADOOP_HOME&#125;</span><br><span class="line">export HADOOP_YARN_HOME=$&#123;HADOOP_HOME&#125;</span><br><span class="line">export HADOOP_CONF_DIR=$&#123;HADOOP_HOME&#125;/etc/hadoop</span><br><span class="line">export HDFS_CONF_DIR=$&#123;HADOOP_HOME&#125;/etc/hadoop</span><br><span class="line">export YARN_CONF_DIR=$&#123;HADOOP_HOME&#125;/etc/hadoop</span><br><span class="line">export SPARK_HOME=/home/hadoop/apache-hadoop/spark</span><br><span class="line">export SCALA_HOME=/home/hadoop/apache-hadoop/scala</span><br><span class="line">export classpath=$JAVA_HOME/lib/dt.jar:$HBASE_HOME/lib:$MAHOUT_HOME/lib:$PIG_HOME/lib:$HIVE_HOME/lib:$JAVA_HOME/lib/tools.jar:$HADOOP_CONF_DIR:$SPARK_HOME/lib:$&#123;HADOOP_HOME&#125;/lib</span><br><span class="line">export HADOOP_CLASSPATH=$JAVA_HOME/lib/dt.jar:$HBASE_HOME/lib/*:$MAHOUT_HOME/lib/*:$PIG_HOME/lib:$HIVE_HOME/lib/*:$JAVA_HOME/lib/tools.jar:$JAVA_HOME/lib/*:$HADOOP_CONF_DIR:$SPARK_HOME/lib/*:$&#123;HADOOP_HOME&#125;/lib/*:$HADOOP_CLASSPATH:</span><br><span class="line">export LD_LIBRARY_PATH=$JAVA_HOME/jre/lib/$OS_ARCH/server:$&#123;HADOOP_HOME&#125;/c++/Linux-$OS_ARCH-$OS_BIT/lib:/usr/local/lib:/usr/lib:$&#123;PBS_HOME&#125;/lib:/usr/lib64</span><br></pre></td></tr></table></figure><h6 id="slave-节点信息"><a href="#slave-节点信息" class="headerlink" title="slave 节点信息"></a>slave 节点信息</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">datanode03.host-shining.com</span><br><span class="line">datanode04.host-shining.com</span><br><span class="line">datanode05.host-shining.com</span><br><span class="line">datanode06.host-shining.com</span><br></pre></td></tr></table></figure><h6 id="spark-启动"><a href="#spark-启动" class="headerlink" title="spark 启动"></a>spark 启动</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd $SPARK_HOME/sbin</span><br><span class="line">./start-all.sh</span><br></pre></td></tr></table></figure><h5 id="查看状态"><a href="#查看状态" class="headerlink" title="查看状态"></a>查看状态</h5><p>namenode地址    <a href="http://name00.host-shining.com:50070" target="_blank" rel="noopener">http://name00.host-shining.com:50070</a><br>spark 地址        <a href="http://name00.host-shining.com:8080" target="_blank" rel="noopener">http://name00.host-shining.com:8080</a><br>hbase地址        <a href="http://name00.host-shining.com:16010" target="_blank" rel="noopener">http://name00.host-shining.com:16010</a><br>yarn 地址        <a href="http://name01.host-shining.com:8088" target="_blank" rel="noopener">http://name01.host-shining.com:8088</a><br>jobhistory 地址    <a href="http://name01.host-shining.com:19888" target="_blank" rel="noopener">http://name01.host-shining.com:19888</a>  </p><p>感觉文章还可以的话，帮忙点点下面的广告哦！ 谢谢支持！</p>]]></content>
      
      <categories>
          
          <category> hadoop </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hadoop </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>awk输出单引号或双引号</title>
      <link href="/awk-echo-SingleQuoteMark-DoubleQuotationMarks/"/>
      <url>/awk-echo-SingleQuoteMark-DoubleQuotationMarks/</url>
      <content type="html"><![CDATA[<h2 id="awk输出单引号，双引号"><a href="#awk输出单引号，双引号" class="headerlink" title="awk输出单引号，双引号"></a>awk输出单引号，双引号</h2><p>一个文件内容</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cat 1</span><br><span class="line">1       1.1.1.1</span><br><span class="line">2       2.2.2.2</span><br></pre></td></tr></table></figure><h4 id="单引号"><a href="#单引号" class="headerlink" title="单引号"></a>单引号</h4><p>需要用单引号把第二列引起来。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cat 1 | awk &apos;&#123;print &quot;&apos;\&apos;&apos;&quot;$2&quot;&apos;\&apos;&apos;&quot;&#125;&apos;</span><br><span class="line">&apos;1.1.1.1&apos;</span><br><span class="line">&apos;2.2.2.2&apos;</span><br></pre></td></tr></table></figure><p>放大分解awk ，让大家看看  （这样大家应该能看清楚了）  </p><font color="#0099ff" size="5" face="黑体">awk ‘{print “ ‘ \ ‘ ‘ “ $2 “ ‘ \ ‘ ‘ “}’</font>  <h4 id="双引号"><a href="#双引号" class="headerlink" title="双引号"></a>双引号</h4><p>用双引号把第二列引起来</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cat 1 | awk &apos;&#123;print &quot;\&quot;&quot;$2&quot;\&quot;&quot;&#125;&apos;</span><br><span class="line">&quot;1.1.1.1&quot;</span><br><span class="line">&quot;2.2.2.2&quot;</span><br></pre></td></tr></table></figure><p>放大分解awk  </p><font color="#0099ff" size="5" face="黑体">awk ‘{print “ \ “ “ $2 “ \ “ “}’</font>  <p>希望对大家有帮助！  </p><p>感觉文章还可以的话，帮忙点点下面的广告哦！ 谢谢支持！</p>]]></content>
      
      <categories>
          
          <category> shell </category>
          
      </categories>
      
      
        <tags>
            
            <tag> shell </tag>
            
            <tag> awk </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>nginx-1.10.1添加sticky模块实现基于cookie的负载均衡</title>
      <link href="/nginx-installed-sticky/"/>
      <url>/nginx-installed-sticky/</url>
      <content type="html"><![CDATA[<h1 id="nginx-1-10-1-添加sticky模块实现基于cookie的负载均衡"><a href="#nginx-1-10-1-添加sticky模块实现基于cookie的负载均衡" class="headerlink" title="nginx-1.10.1 添加sticky模块实现基于cookie的负载均衡"></a>nginx-1.10.1 添加sticky模块实现基于cookie的负载均衡</h1><p>在多台后台服务器的环境下，我们为了确保一个客户只和一台服务器通信，我们势必使用长连接。使用什么方式来实现这种连接呢，常见的有使用Nginx 自带的ip_hash来做，我想这绝对不是一个好的办法，如果前端是CDN，或者说一个局域网的客户同时访问服务器，导致出现服务器分配不均衡，以及不能 保证每次访问都粘滞在同一台服务器。如果基于cookie会是一种什么情形，想想看, 每台电脑都会有不同的cookie，在保持长连接的同时还保证了服务器的压力均衡，Nginx sticky值得推荐。  </p><p>如果浏览器不支持cookie，那么sticky不生效，毕竟整个模块是给予cookie实现的.</p><h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><p>下载 sticky 模块<br>目前共有2个版本，一个是1.0，一个是1.1，1.0已经寿终正寝了.1.1增加了权重的参数.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">下载地址：http://code.google.com/p/nginx-sticky-module/downloads/list</span><br><span class="line"></span><br><span class="line">或 直接下载</span><br><span class="line"></span><br><span class="line">wget https://storage.googleapis.com/google-code-archive-downloads/v2/code.google.com/nginx-sticky-module/nginx-sticky-module-1.1.tar.gz</span><br></pre></td></tr></table></figure><h5 id="nginx-1-6-之下版本可以直接安装，1-6之上版本可以修改配置文件"><a href="#nginx-1-6-之下版本可以直接安装，1-6之上版本可以修改配置文件" class="headerlink" title="nginx-1.6 之下版本可以直接安装，1.6之上版本可以修改配置文件"></a>nginx-1.6 之下版本可以直接安装，1.6之上版本可以修改配置文件</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">1.6之上nginx添加stickty模块会报：</span><br><span class="line"></span><br><span class="line">ngx_http_sticky_module.c: In function ‘ngx_http_get_sticky_peer’:</span><br><span class="line">/ngx_http_sticky_module.c:333: 警告：赋值时将整数赋给指针，未作类型转换</span><br><span class="line">ake[1]: *** [objs/addon/nginx-sticky-module-1.1/ngx_http_sticky_module.o] 错误 1</span><br></pre></td></tr></table></figure><p>修改如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">修改ngx_http_sticky_misc.c 的281行</span><br><span class="line">原来</span><br><span class="line">digest-&gt;len = ngx_sock_ntop(in, digest-&gt;data, len, 1);</span><br><span class="line">修改为：</span><br><span class="line">digest-&gt;len = ngx_sock_ntop(in, sizeof(struct sockaddr_in), digest-&gt;data, len, 1);</span><br></pre></td></tr></table></figure><p>修改 ngx_http_sticky_module.c文件 （主要是1.9.x或之上版本会出现这问题）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1、 第六行添加：</span><br><span class="line">    #include &lt;nginx.h&gt;</span><br></pre></td></tr></table></figure><p><img src="/images/nginx-sticky-1.jpeg" alt="image"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">2、第340行左右修改（iphp-&gt;rrp.current = iphp-&gt;selected_peer;）为：</span><br><span class="line">    #if defined(nginx_version) &amp;&amp; nginx_version &gt;= 1009000</span><br><span class="line">    iphp-&gt;rrp.current = peer;</span><br><span class="line">    #else</span><br><span class="line">    iphp-&gt;rrp.current = iphp-&gt;selected_peer;</span><br><span class="line">    #endif</span><br></pre></td></tr></table></figure><p><img src="/images/nginx-sticky-2.jpeg" alt="image">  </p><p>nginx 编译安装</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">./configure --prefix=/home/shining/nginx-1.10.1 --with-http_ssl_module --with-http_gzip_static_module --with-http_stub_status_module --with-pcre --with-http_realip_module --with-http_addition_module --with-http_dav_module --with-stream --with-stream_ssl_module --pid-path=/var/run/nginx.pid --add-module=../nginx-sticky-module-1.1/  </span><br><span class="line">make  </span><br><span class="line">make install</span><br></pre></td></tr></table></figure><p>添加cookie负载</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">在upstream中添加sticky;</span><br><span class="line">http &#123;</span><br><span class="line">    upstream myproject&#123;</span><br><span class="line">        #添加sticky模块后加入此配置</span><br><span class="line">        sticky;</span><br><span class="line">        #被代理的服务</span><br><span class="line">        server 192.168.1.100:8081;</span><br><span class="line">        server 192.168.1.101:8080;</span><br><span class="line">    &#125;</span><br><span class="line">    #  其他配置都是一样的</span><br></pre></td></tr></table></figure><h2 id="在现有nginx上添加模块"><a href="#在现有nginx上添加模块" class="headerlink" title="在现有nginx上添加模块"></a>在现有nginx上添加模块</h2><p>nginx已经安装好， 只是添加模块的话，只需要重新编译，copy nginx 命令即可。  </p><p>sticky模块修改好之后，<br>先查看原来编译的命令：<br>/home/shining/nginx-1.10.1/sbin/nginx -V  </p><p>拿到编译的命令再重新编译：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">./configure --prefix=/home/shining/nginx-1.10.1 --with-http_ssl_module --with-http_gzip_static_module --with-http_stub_status_module --with-pcre --with-http_realip_module --with-http_addition_module --with-http_dav_module --with-stream --with-stream_ssl_module --pid-path=/var/run/nginx.pid --add-module=../nginx-sticky-module-1.1/  </span><br><span class="line">make   ## 这之后就不有熬执行make install，否则会覆盖其他配置</span><br><span class="line"></span><br><span class="line"># 备份原来的nginx命令</span><br><span class="line">cp /home/shining/nginx-1.10.1/sbin/nginx /home/shining/nginx-1.10.1/sbin/nginx_backup</span><br><span class="line"># 替换新编译好的nginx命令</span><br><span class="line">cp ./objs/nginx /home/shining/nginx-1.10.1/sbin/</span><br></pre></td></tr></table></figure><p>查看编译：<br>/home/shining/nginx-1.10.1/sbin/nginx -t<br>生效<br>/home/shining/nginx-1.10.1/sbin/nginx -s stop<br>/home/shining/nginx-1.10.1/sbin/nginx  </p><h3 id="验证-sticky-模块是否生效"><a href="#验证-sticky-模块是否生效" class="headerlink" title="验证 sticky 模块是否生效"></a>验证 sticky 模块是否生效</h3><p>当配置完sticky策略之后，访问页面的时候再 Cookies 里看到 『route』信息  </p><p>如 : </p><p><img src="/images/nginx-sticky-3.jpeg" alt="images"></p><p>感觉文章还可以的话，帮忙点点下面的广告哦！ 谢谢支持！</p>]]></content>
      
      <categories>
          
          <category> nginx </category>
          
      </categories>
      
      
        <tags>
            
            <tag> nginx </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>marathon 约束 constraints 限制</title>
      <link href="/marathon-constraints-configure/"/>
      <url>/marathon-constraints-configure/</url>
      <content type="html"><![CDATA[<h2 id="marathon-约束-Constraints-限制"><a href="#marathon-约束-Constraints-限制" class="headerlink" title="marathon 约束 Constraints 限制"></a>marathon 约束 Constraints 限制</h2><p>Constraints控制在何处运行的应用程序，可以根据constraints属性，控制容器可以在哪个Agent节点上运行。</p><p>（往上看来好多文档写的都很类似，我就写一些不一样的吧。）</p><h3 id="mesos-agent-自定义-constraints-属性"><a href="#mesos-agent-自定义-constraints-属性" class="headerlink" title="mesos agent 自定义 constraints 属性"></a>mesos agent 自定义 constraints 属性</h3><p>rpm 安装的 mesos 可以在 /etc/mesos-slave/attributes 下定义这台agent。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">echo &quot;project:ppp1;IDC:BJ;oam:ops1&quot; &gt; /etc/mesos-slave/attributes</span><br></pre></td></tr></table></figure><p>重启mesos-slave服务即可，</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl start mesos-slave</span><br></pre></td></tr></table></figure><p>这样这台Agent就有利3个属性。</p><p>分别是：</p><ul><li>project:ppp1</li><li>IDC:BJ</li><li>oam:ops1</li></ul><p>另外其他的Agent机器耶可以有相同的属性，这样就可以变成一组。（容器可以固定在相同属性的Agent机器上）</p><p>源码安装，值需要加上 –attributes 参数即可，</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/home/mesos/mesos-slave/sbin/mesos-agent --master=zk://10.0.0.52:2181,10.0.0.53:2181,10.0.0.54:2181/mesos --log_dir=/var/log/mesos --containerizers=docker,mesos --executor_registration_timeout=5mins --work_dir=/home/mesos/mesos --hostname=logstash00 --attributes=project:ppp1;IDC:BJ;oam:ops1</span><br></pre></td></tr></table></figure><h3 id="marathon-使用-constraints"><a href="#marathon-使用-constraints" class="headerlink" title="marathon 使用 constraints"></a>marathon 使用 constraints</h3><p>好了， 现在说说marathon 应该怎么使用 constraints</p><h4 id="容器固定在指定的Agent机器上"><a href="#容器固定在指定的Agent机器上" class="headerlink" title="容器固定在指定的Agent机器上"></a>容器固定在指定的Agent机器上</h4><p>可以通过 hostaname 来指定容器在哪台Agent上运行。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">curl -X POST -H &quot;Content-type: application/json&quot; localhost:8080/v2/apps -d &apos;&#123;</span><br><span class="line">    &quot;id&quot;: &quot;sleep-cluster&quot;,</span><br><span class="line">    &quot;cmd&quot;: &quot;sleep 60&quot;,</span><br><span class="line">    &quot;instances&quot;: 3,</span><br><span class="line">    &quot;constraints&quot;: [[&quot;hostname&quot;, &quot;CLUSTER&quot;, &quot;host-name.test.com&quot;]]</span><br><span class="line">  &#125;&apos;</span><br></pre></td></tr></table></figure><h4 id="每个Agent上运行一个容器"><a href="#每个Agent上运行一个容器" class="headerlink" title="每个Agent上运行一个容器"></a>每个Agent上运行一个容器</h4><p>所有应用程序的任务中强制执行属性的唯一性。 确保每个主机上只运行一个应用程序任务。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&quot;constraints&quot;: [</span><br><span class="line">    [</span><br><span class="line">        &quot;hostname&quot;,</span><br><span class="line">        &quot;UNIQUE&quot;</span><br><span class="line">    ]</span><br><span class="line">],</span><br></pre></td></tr></table></figure><h4 id="利用自定义属性约束"><a href="#利用自定义属性约束" class="headerlink" title="利用自定义属性约束"></a>利用自定义属性约束</h4><p>根据自定义属性来约束在哪些Agent节点上运行容器。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&quot;constraints&quot;: [</span><br><span class="line">    [</span><br><span class="line">        &quot;IDC&quot;,</span><br><span class="line">        &quot;LIKE&quot;,</span><br><span class="line">        &quot;BJ&quot;</span><br><span class="line">    ]</span><br><span class="line">],</span><br></pre></td></tr></table></figure><p>这样就可以在有 IDC:BJ 的Agent节点上运行容器了，当然，耶可以写多个约束限制天剑的。</p><h5 id="不在哪个节点上"><a href="#不在哪个节点上" class="headerlink" title="不在哪个节点上"></a>不在哪个节点上</h5><p>指定条件，不在哪个节点运行容器</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&quot;constraints&quot;: [</span><br><span class="line">    [</span><br><span class="line">        &quot;IDC&quot;,</span><br><span class="line">        &quot;UNLIKE&quot;,</span><br><span class="line">        &quot;BJ&quot;</span><br><span class="line">    ]</span><br><span class="line">],</span><br></pre></td></tr></table></figure><h4 id="支持正则"><a href="#支持正则" class="headerlink" title="支持正则"></a>支持正则</h4><p>LIKE 接受一个正则表达式作为参数</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&quot;constraints&quot;: [</span><br><span class="line">    [</span><br><span class="line">        &quot;project&quot;,</span><br><span class="line">        &quot;LIKE&quot;,</span><br><span class="line">        &quot;ppp[1-3]&quot;</span><br><span class="line">    ]</span><br><span class="line">],</span><br></pre></td></tr></table></figure><p>mesos 可以自定义 constraints 这个就很灵活了，我们在初始化 Agent 节点的时候，就可以定义很多属性来。容器发布的时候我们就很容易约束了。</p><p>官方文档：<a href="https://mesosphere.github.io/marathon/docs/constraints.html" target="_blank" rel="noopener">https://mesosphere.github.io/marathon/docs/constraints.html</a></p><p>感觉文章还可以的话，帮忙点点下面的广告哦！ 谢谢支持！</p>]]></content>
      
      <categories>
          
          <category> marathon </category>
          
      </categories>
      
      
        <tags>
            
            <tag> marathon </tag>
            
            <tag> mesos </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>docker ulimit 配置</title>
      <link href="/docker-ulimit-configure/"/>
      <url>/docker-ulimit-configure/</url>
      <content type="html"><![CDATA[<h1 id="docker-ulimit-配置"><a href="#docker-ulimit-配置" class="headerlink" title="docker ulimit 配置"></a>docker ulimit 配置</h1><p>docker  设置 ulimit 方法</p><h3 id="一：通过docker-run-–ulimit-参数设置这个容器的-ulimit-值"><a href="#一：通过docker-run-–ulimit-参数设置这个容器的-ulimit-值" class="headerlink" title="一：通过docker run –ulimit 参数设置这个容器的 ulimit 值"></a>一：通过docker run –ulimit 参数设置这个容器的 ulimit 值</h3><p>如<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run --ulimit nofile=1024:1024 --rm debian sh -c &quot;ulimit -n&quot;</span><br></pre></td></tr></table></figure></p><p>官网说明：<br><a href="https://docs.docker.com/engine/reference/commandline/run/#set-ulimits-in-container---ulimit" target="_blank" rel="noopener">https://docs.docker.com/engine/reference/commandline/run/#set-ulimits-in-container—ulimit</a> </p><h3 id="二：-修改-docker-服务的-默认设置"><a href="#二：-修改-docker-服务的-默认设置" class="headerlink" title="二： 修改 docker 服务的 默认设置"></a>二： 修改 docker 服务的 默认设置</h3><p>vim /usr/lib/systemd/system/docker.service</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[Service]</span><br><span class="line">LimitNOFILE=1048576</span><br><span class="line">LimitNPROC=1048576</span><br><span class="line">LimitCORE=infinity</span><br></pre></td></tr></table></figure><p>systemctl daemon-reload<br>systemctl restart docker</p><p>文档： <a href="https://blog.csdn.net/signmem/article/details/51365006" target="_blank" rel="noopener">https://blog.csdn.net/signmem/article/details/51365006</a></p><ul><li>注释 设置为 infinity 时，值为 65536 ，如 LimitNOFILE=infinity，ulimit -n 值为 65536 </li></ul><h3 id="三-：-daemon-json-文件中配置"><a href="#三-：-daemon-json-文件中配置" class="headerlink" title="三 ： daemon.json 文件中配置"></a>三 ： daemon.json 文件中配置</h3><p>vim /etc/docker/daemon.json</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">        &quot;default-ulimits&quot;: &#123;</span><br><span class="line">                &quot;nofile&quot;: &#123;</span><br><span class="line">                        &quot;Name&quot;: &quot;nofile&quot;,</span><br><span class="line">                        &quot;Hard&quot;: 64000,</span><br><span class="line">                        &quot;Soft&quot;: 64000</span><br><span class="line">                &#125;</span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>systemctl restart docker</p><p>文档 <a href="https://docs.docker.com/engine/reference/commandline/dockerd/#daemon-configuration-file" target="_blank" rel="noopener">https://docs.docker.com/engine/reference/commandline/dockerd/#daemon-configuration-file</a></p><ul><li>注释： daemon.json  和 docker.service 两个都配置 ，daemon.json 中的配置生效。</li></ul><h4 id="For-Example"><a href="#For-Example" class="headerlink" title="For Example"></a>For Example</h4><ul><li>一个es memlock 的例子</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run --rm -p 9200:9200 -p 9300:9300 -e &quot;discovery.type=single-node&quot; -e &quot;bootstrap.memory_lock=true&quot; --ulimit memlock=-1:-1 docker.elastic.co/elasticsearch/elasticsearch:6.5.0</span><br></pre></td></tr></table></figure><p>感觉文章还可以的话，帮忙点点下面的广告哦！ 谢谢支持！</p>]]></content>
      
      <categories>
          
          <category> docker </category>
          
      </categories>
      
      
        <tags>
            
            <tag> docker </tag>
            
            <tag> ulimit </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Elasticsearch 解决 memory_lock 问题</title>
      <link href="/ES-Solve-memory-lock/"/>
      <url>/ES-Solve-memory-lock/</url>
      <content type="html"><![CDATA[<h1 id="Elasticsearch-解决-memory-lock-问题"><a href="#Elasticsearch-解决-memory-lock-问题" class="headerlink" title="Elasticsearch 解决 memory_lock 问题"></a>Elasticsearch 解决 memory_lock 问题</h1><p>我是docker运行的es，数据目录存放到本地磁盘上。最近做优化，想加上 memory_lock 参数，发现有问题。发现很多人有类似的问题。但都没说在docker上怎么解决。我整理一下解决办法，现在看来挺简单的。</p><h3 id="报错"><a href="#报错" class="headerlink" title="报错"></a>报错</h3><p>docker 运行 es 6.5</p><p>run docker container</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run --rm -p 9200:9200 -p 9300:9300 -e &quot;discovery.type=single-node&quot; -e &quot;bootstrap.memory_lock=true&quot; docker.elastic.co/elasticsearch/elasticsearch:6.5.0</span><br></pre></td></tr></table></figure><p>Error Message: Unable to lock JVM Memory: error=12, reason=Cannot allocate memory</p><a id="more"></a><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[2018-11-21T07:03:05,384][WARN ][o.e.b.JNANatives         ] [unknown] Unable to lock JVM Memory: error=12, reason=Cannot allocate memory</span><br><span class="line">[2018-11-21T07:03:05,385][WARN ][o.e.b.JNANatives         ] [unknown] This can result in part of the JVM being swapped out.</span><br><span class="line">[2018-11-21T07:03:05,385][WARN ][o.e.b.JNANatives         ] [unknown] Increase RLIMIT_MEMLOCK, soft limit: 65536, hard limit: 65536</span><br><span class="line">[2018-11-21T07:03:05,385][WARN ][o.e.b.JNANatives         ] [unknown] These can be adjusted by modifying /etc/security/limits.conf, for example: </span><br><span class="line">        # allow user &apos;elasticsearch&apos; mlockall</span><br><span class="line">        elasticsearch soft memlock unlimited</span><br><span class="line">        elasticsearch hard memlock unlimited</span><br><span class="line">[2018-11-21T07:03:05,385][WARN ][o.e.b.JNANatives         ] [unknown] If you are logged in interactively, you will have to re-login for the new limits to take effect.</span><br></pre></td></tr></table></figure><p>我们去系统里添加</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/secruity/limits.conf</span><br><span class="line"></span><br><span class="line">* soft  memlock  unlimited</span><br><span class="line">* hard memlock  unlimited</span><br><span class="line">elasticsearch soft memlock unlimited</span><br><span class="line">elasticsearch hard memlock unlimited</span><br></pre></td></tr></table></figure><p>之后再运行容器，问题依旧存在。<br>在网上找了好多这个问题的文章，有好多说法，我先说我解决的办法</p><h3 id="解决"><a href="#解决" class="headerlink" title="解决"></a>解决</h3><p>只需要在docker container 运行时加上ulime的设置就可以了。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run --rm -p 9200:9200 -p 9300:9300 -e &quot;discovery.type=single-node&quot; -e &quot;bootstrap.memory_lock=true&quot; --ulimit memlock=-1:-1 docker.elastic.co/elasticsearch/elasticsearch:6.5.0</span><br></pre></td></tr></table></figure><p>因为 docker 默认没有加载系统的 ulimit ，所以我们在系统上配置是没有用的，需要传进去。<br>这块可以查看 docker ulimit 的相关文档。</p><h3 id="检查"><a href="#检查" class="headerlink" title="检查"></a>检查</h3><p>检查 memory_lock 是否生效</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://172.16.124.110:9200/_nodes?filter_path=**.mlockall</span><br></pre></td></tr></table></figure><p>返回内容为 true  及生效</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;&quot;nodes&quot;:&#123;&quot;pSYaXnT1SsStth5Dbww2yA&quot;:&#123;&quot;process&quot;:&#123;&quot;mlockall&quot;:true&#125;&#125;&#125;&#125;</span><br></pre></td></tr></table></figure><h3 id="Q-amp-A"><a href="#Q-amp-A" class="headerlink" title="Q&amp;A"></a>Q&amp;A</h3><p>如果你是二进制安装或源码，可以再系统中修改，  </p><p>添加 elasticsearch 帐号。 </p><p>limits.conf中添加<br>elasticsearch soft memlock unlimited<br>elasticsearch hard memlock unlimited  </p><p>重新登入，重新启动es。  </p><p>还有人说 在 ES_JAVA_OPS 中添加  -Djna.tmpdir=/目录<br>如</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">export ES_JAVA_OPTS=&quot;$ES_JAVA_OPTS -Djava.io.tmpdir=/path/to/temp/dir&quot;</span><br><span class="line">./bin/elasticsearch</span><br></pre></td></tr></table></figure><p>二进制安装：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">systemd:  </span><br><span class="line">/usr/lib/systemd/system/elasticsearch.service set: LimitMEMLOCK=infinity  </span><br><span class="line">SysV:  </span><br><span class="line">/etc/sysconfig/elasticsearch set: MAX_LOCKED_MEMORY=unlimited  </span><br><span class="line">Upstart:  </span><br><span class="line">/etc/default/elasticsearch set: MAX_LOCKED_MEMORY=unlimited  </span><br><span class="line">Then restart Elasticsearch.</span><br></pre></td></tr></table></figure><p>二进制和源码安装方式我没有验证过。来源于网络。</p><p>感觉文章还可以的话，帮忙点点下面的广告哦！ 谢谢支持！</p>]]></content>
      
      <categories>
          
          <category> elasticsearch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> elasticsearch </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>linux 限制用户命令方法</title>
      <link href="/linux-Restrict-user-command-method/"/>
      <url>/linux-Restrict-user-command-method/</url>
      <content type="html"><![CDATA[<h2 id="linux-限制用户命令方法"><a href="#linux-限制用户命令方法" class="headerlink" title="linux 限制用户命令方法"></a>linux 限制用户命令方法</h2><p>linux 上想限制用户可以执行的命令，可以通过环境变量和安装lshell工具方式。</p><h4 id="环境变量的方式"><a href="#环境变量的方式" class="headerlink" title="环境变量的方式"></a>环境变量的方式</h4><p>脚本放在 /etc/profile.d/ 下，每个用户登入的时候都交脚在这里的环境变量。<br>脚本中判断当前用户，root 用户不受权限。  </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/profile.d/login.sh</span><br><span class="line"></span><br><span class="line">#!/bin/bash</span><br><span class="line">m=`whoami`</span><br><span class="line"></span><br><span class="line">if [[ &quot;$&#123;m&#125;&quot; != &quot;root&quot; ]];then</span><br><span class="line">    echo -e &quot;\e[01;33m* ** 你目前登录的账户是: \e[01;31m$LOGNAME\e[00m  ** \e[00m&quot;</span><br><span class="line">    echo -e &quot;\e[01;33m* ** 可以登入你申请的主机\e[00m&quot;</span><br><span class="line">    mkdir -p $HOME/bin</span><br><span class="line">    rm -f $HOME/bin/*</span><br><span class="line">    ln -s /bin/ls $HOME/bin</span><br><span class="line">    ln -s /bin/ping $HOME/bin</span><br><span class="line">    ln -s /usr/bin/ssh $HOME/bin/</span><br><span class="line">#    ln -s /usr/bin/ssh-copy-id $HOME/bin/</span><br><span class="line">    ln -s /usr/bin/ssh-keygen $HOME/bin/</span><br><span class="line">    ln -s /usr/bin/expect $HOME/bin/</span><br><span class="line">    ln -s /bin/grep $HOME/bin/</span><br><span class="line">    cat &lt;&lt; EOF &gt; $HOME/.newbash_profile</span><br><span class="line">HISTFILESIZE=500000000</span><br><span class="line">HISTSIZE=99999999</span><br><span class="line">HISTTIMEFORMAT=&quot;%Y/%m/%d_%H:%M:%S :&quot;</span><br><span class="line">PATH=$HOME/bin</span><br><span class="line">#export TMOUT=600</span><br><span class="line">export PATH</span><br><span class="line">EOF</span><br><span class="line">    chown $&#123;m&#125;:$&#123;m&#125; $HOME/.newbash_profile</span><br><span class="line">    exec bash --restricted --noprofile --rcfile $HOME/.newbash_profile</span><br><span class="line">fi</span><br></pre></td></tr></table></figure><p>将允许用户执行的命令软连到用户家目录的bin下，这样用户只能执行特定的命令。  </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">exec bash --restricted --noprofile --rcfile $HOME/.newbash_profile </span><br><span class="line"></span><br><span class="line">这句话的意思是使用restricted模式，并且不加载系统默认的profile文件，而加载我们定义的profile文件$HOME/.newbash_profile</span><br><span class="line"></span><br><span class="line">这句话也可以添加到 $HOME/.ssh/authorized_keys，在前面加上语句：</span><br><span class="line">command=&quot;bash --restricted --noprofile --rcfile $HOME/.newbash_profile&quot; ssh-rsa ......</span><br></pre></td></tr></table></figure><h4 id="lshell-工具"><a href="#lshell-工具" class="headerlink" title="lshell 工具"></a>lshell 工具</h4><p>也可以安装 lshell 工具来实现对用户命令的限制， lshell不仅可以限制用户执行的命令，还可以限制用户对目录的限制等。   </p><p>lshell 的github地址：<a href="https://github.com/ghantoos/lshell" target="_blank" rel="noopener">https://github.com/ghantoos/lshell</a></p><p>安装  </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install lshell  # 需要 epel 源</span><br></pre></td></tr></table></figure><p>lshell 使用</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ lshell --help</span><br><span class="line">Usage: lshell [OPTIONS]</span><br><span class="line"> --config &lt;file&gt; : Config file location (default /etc/lshell.conf) #指定配置文件</span><br><span class="line"> --log &lt;dir&gt; : Log files directory #指定日志目录 </span><br><span class="line"> -h, --help : Show this help message #显示帮助信息</span><br><span class="line"> --version : Show version #显示版本信息</span><br></pre></td></tr></table></figure><p>配置文件<br>配置文件分：  </p><ul><li>User configuration</li><li>Group configuration</li><li>Default configuration</li></ul><p>看一个官网的例子，很简单</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"># CONFIGURATION START</span><br><span class="line">[global]</span><br><span class="line">logpath         : /var/log/lshell/</span><br><span class="line">loglevel        : 2</span><br><span class="line"></span><br><span class="line">[default]</span><br><span class="line">allowed         : [&apos;ls&apos;,&apos;pwd&apos;]</span><br><span class="line">forbidden       : [&apos;;&apos;, &apos;&amp;&apos;, &apos;|&apos;] </span><br><span class="line">warning_counter : 2</span><br><span class="line">timer           : 0</span><br><span class="line">path            : [&apos;/etc&apos;, &apos;/usr&apos;]</span><br><span class="line">env_path        : &apos;:/sbin:/usr/foo&apos;</span><br><span class="line">scp             : 1 # or 0</span><br><span class="line">sftp            : 1 # or 0</span><br><span class="line">overssh         : [&apos;rsync&apos;,&apos;ls&apos;]</span><br><span class="line">aliases         : &#123;&apos;ls&apos;:&apos;ls --color=auto&apos;,&apos;ll&apos;:&apos;ls -l&apos;&#125;</span><br><span class="line"></span><br><span class="line">[grp:users]</span><br><span class="line">warning_counter : 5</span><br><span class="line">overssh         : - [&apos;ls&apos;]</span><br><span class="line"></span><br><span class="line">[foo]</span><br><span class="line">allowed         : &apos;all&apos; - [&apos;su&apos;]</span><br><span class="line">path            : [&apos;/var&apos;, &apos;/usr&apos;] - [&apos;/usr/local&apos;]</span><br><span class="line">home_path       : &apos;/home/users&apos;</span><br><span class="line"></span><br><span class="line">[bar]</span><br><span class="line">allowed         : + [&apos;ping&apos;] - [&apos;ls&apos;] </span><br><span class="line">path            : - [&apos;/usr/local&apos;]</span><br><span class="line">strict          : 1</span><br><span class="line">scpforce        : &apos;/home/bar/uploads/&apos;</span><br><span class="line"># CONFIGURATION END</span><br></pre></td></tr></table></figure><p>我简单使用的一个案例：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br></pre></td><td class="code"><pre><span class="line">[root@test00 ~]# cat /etc/lshell.conf </span><br><span class="line"># lshell.py configuration file</span><br><span class="line">#</span><br><span class="line"># $Id: lshell.conf,v 1.27 2010/10/18 19:05:17 ghantoos Exp $</span><br><span class="line"></span><br><span class="line">[global]</span><br><span class="line">##  log directory (default /var/log/lshell/ )</span><br><span class="line">logpath         : /var/log/lshell/</span><br><span class="line">##  set log level to 0, 1, 2, 3 or 4  (0: no logs, 1: least verbose,</span><br><span class="line">##                                                 4: log all commands)</span><br><span class="line">loglevel        : 2</span><br><span class="line">##  configure log file name (default is %u i.e. username.log)</span><br><span class="line">#logfilename     : %y%m%d-%u</span><br><span class="line">#logfilename     : syslog</span><br><span class="line"></span><br><span class="line">##  in case you are using syslog, you can choose your logname</span><br><span class="line">#syslogname      : myapp</span><br><span class="line"></span><br><span class="line">[default]</span><br><span class="line">##  a list of the allowed commands or &apos;all&apos; to allow all commands in user&apos;s PATH</span><br><span class="line">allowed         : [&apos;ls&apos;,&apos;echo&apos;,&apos;cd&apos;,&apos;ll&apos;]</span><br><span class="line"></span><br><span class="line">##  a list of forbidden character or commands</span><br><span class="line">#forbidden       : [&apos;;&apos;, &apos;&amp;&apos;, &apos;|&apos;,&apos;`&apos;,&apos;&gt;&apos;,&apos;&lt;&apos;, &apos;$(&apos;, &apos;$&#123;&apos;]</span><br><span class="line">forbidden       : [&apos;&gt;&apos;,&apos;&lt;&apos;, &apos;$(&apos;, &apos;$&#123;&apos;]</span><br><span class="line"></span><br><span class="line">##  a list of allowed command to use with sudo(8)</span><br><span class="line">#sudo_commands   : [&apos;ls&apos;, &apos;more&apos;]</span><br><span class="line"></span><br><span class="line">##  number of warnings when user enters a forbidden value before getting </span><br><span class="line">##  exited from lshell, set to -1 to disable.</span><br><span class="line">warning_counter : 2</span><br><span class="line"></span><br><span class="line">##  command aliases list (similar to bash’s alias directive)</span><br><span class="line">aliases         : &#123;&apos;ll&apos;:&apos;ls -l&apos;, &apos;vi&apos;:&apos;vim&apos;&#125;</span><br><span class="line"></span><br><span class="line">##  introduction text to print (when entering lshell)</span><br><span class="line">intro           : &quot;线上环境请谨慎执行命令\n执行help或者?\n列出可执行的命令\n执行lpath\n查看允许访问的路径&quot;</span><br><span class="line"></span><br><span class="line">##  configure your promt using %u or %h (default: username)</span><br><span class="line">prompt          : &quot;%u@%h&quot;</span><br><span class="line"></span><br><span class="line">##  a value in seconds for the session timer</span><br><span class="line">timer           : 0</span><br><span class="line"></span><br><span class="line">##  list of path to restrict the user &quot;geographicaly&quot;</span><br><span class="line">#path            : [&apos;/home/bla/&apos;,&apos;/etc&apos;]</span><br><span class="line"></span><br><span class="line">##  set the home folder of your user. If not specified the home_path is set to </span><br><span class="line">##  the $HOME environment variable</span><br><span class="line">#home_path       : &apos;/home/bla/&apos;</span><br><span class="line"></span><br><span class="line">##  update the environment variable $PATH of the user</span><br><span class="line">env_path        : &apos;:/usr/local/bin:/usr/sbin:/bin&apos;</span><br><span class="line"></span><br><span class="line">##  add environment variables</span><br><span class="line">#env_vars        : &#123;&apos;foo&apos;:1, &apos;bar&apos;:&apos;helloworld&apos;&#125;</span><br><span class="line"></span><br><span class="line">##  allow or forbid the use of scp (set to 1 or 0)</span><br><span class="line">#scp             : 1</span><br><span class="line"></span><br><span class="line">## forbid scp upload</span><br><span class="line">#scp_upload       : 0</span><br><span class="line"></span><br><span class="line">## forbid scp download</span><br><span class="line">#scp_download     : 0</span><br><span class="line"></span><br><span class="line">##  allow of forbid the use of sftp (set to 1 or 0)</span><br><span class="line">#sftp            : 1</span><br><span class="line"></span><br><span class="line">##  list of command allowed to execute over ssh (e.g. rsync, rdiff-backup, etc.)</span><br><span class="line">overssh         : [&apos;ls&apos;,&apos;sed&apos;,&apos;cp&apos;,&apos;mkdir&apos;,&apos;date&apos;,&apos;&gt;&apos;,&apos;;&apos;,&apos;&amp;&amp;&apos; ]</span><br><span class="line"></span><br><span class="line">##  logging strictness. If set to 1, any unknown command is considered as </span><br><span class="line">##  forbidden, and user&apos;s warning counter is decreased. If set to 0, command is</span><br><span class="line">##  considered as unknown, and user is only warned (i.e. *** unknown synthax)</span><br><span class="line">#strict          : 1</span><br><span class="line"></span><br><span class="line">##  force files sent through scp to a specific directory</span><br><span class="line">#scpforce        : &apos;/home/bla/uploads/&apos;</span><br><span class="line"></span><br><span class="line">##  history file maximum size </span><br><span class="line">history_size     : 9999</span><br><span class="line"></span><br><span class="line">##  set history file name (default is /home/%u/.lhistory)</span><br><span class="line">#history_file     : &quot;/home/%u/.lshell_history&quot;</span><br><span class="line"></span><br><span class="line">[rd]</span><br><span class="line">allowed : [ &apos;ls&apos;,&apos;cd&apos;,&apos;ll&apos;,&apos;ifconfig&apos;,&apos;less&apos;,&apos;echo&apos;,&apos;ip&apos;,&apos;&gt;&apos;,&apos;date&apos;,&apos;grep&apos;,&apos;cat&apos;,&apos;awk&apos;,&apos;|&apos;,&apos;telnet&apos;,&apos;ps&apos;,&apos;ping&apos;,&apos;netstat&apos;,&apos;more&apos;,&apos;jps&apos;,&apos;free&apos;,&apos;du&apos;,&apos;df&apos;,&apos;top&apos;,&apos;tail&apos;,&apos;sed&apos;,&apos;curl&apos;,&apos;date&apos;,&apos;iostat&apos;,&apos;iotop&apos;,&apos;pwd&apos;,&apos;diff&apos;,&apos;uptime&apos;,&apos;hostname&apos;,&apos;nslookup&apos; ]</span><br><span class="line">home_path : &apos;/home/rd&apos;    # 用户的家目录</span><br><span class="line">env_path : &apos;:/usr/local/bin:/usr/sbin:/sbin:/bin:/usr/local/sbin:/ust/bin&apos;</span><br><span class="line">path : [ &apos;/home/testdir&apos;,&apos;/home/rd&apos; ]  # 允许用户访问的目录</span><br><span class="line"></span><br><span class="line">#forbidden : [&apos;;&apos;, &apos;&amp;&apos;, &apos;|&apos;,&apos;`&apos;,&apos;&gt;&apos;,&apos;&lt;&apos;, &apos;$(&apos;, &apos;$&#123;&apos;]</span><br></pre></td></tr></table></figure><p>修改用户shell为lshell</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">usermod rd -s /usr/bin/lshell</span><br><span class="line">或</span><br><span class="line">chsh -s /usr/bin/lshell rd</span><br><span class="line"></span><br><span class="line">新用户</span><br><span class="line">useradd rd -d /home/rd -s /usr/bin/lshell</span><br></pre></td></tr></table></figure><p>添加组 （方便记录日志）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">usermod -aG lshell rd</span><br></pre></td></tr></table></figure><p>记录日志： (我没有使用)</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">groupadd --system lshell</span><br><span class="line">mkdir /var/log/lshell</span><br><span class="line">chown :lshell /var/log/lshell</span><br><span class="line">chmod 770 /var/log/lshell</span><br></pre></td></tr></table></figure><p>注释： lshell 没有重启， 随时修改配置文件，用户重新登入即可生效。</p><p>感觉文章还可以的话，帮忙点点下面的广告哦！ 谢谢支持！</p>]]></content>
      
      <categories>
          
          <category> linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> linux </tag>
            
            <tag> command </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>parted 分区方法</title>
      <link href="/parted-partition/"/>
      <url>/parted-partition/</url>
      <content type="html"><![CDATA[<h2 id="使用说明"><a href="#使用说明" class="headerlink" title="使用说明"></a>使用说明</h2><p>parted 支持2TB以上的磁盘分区，并且允许调整分区的大小。</p><h2 id="分区表"><a href="#分区表" class="headerlink" title="分区表"></a>分区表</h2><h4 id="MBR分区表：（MBR含义：主引导记录）"><a href="#MBR分区表：（MBR含义：主引导记录）" class="headerlink" title="MBR分区表：（MBR含义：主引导记录）"></a>MBR分区表：（MBR含义：主引导记录）</h4><ul><li>所支持的最大卷：2T （T; terabytes,1TB=1024GB）</li><li>对分区的设限：最多4个主分区或3个主分区加一个扩展分区。</li></ul><h4 id="GPT分区表：（GPT含义：GUID分区表）"><a href="#GPT分区表：（GPT含义：GUID分区表）" class="headerlink" title="GPT分区表：（GPT含义：GUID分区表）"></a>GPT分区表：（GPT含义：GUID分区表）</h4><ul><li>支持最大卷：18EB，（E：exabytes,1EB=1024TB）  </li><li>每个磁盘最多支持128个分区</li></ul><h2 id="使用案例"><a href="#使用案例" class="headerlink" title="使用案例"></a>使用案例</h2><h4 id="大于2T的整个磁盘分一个分区"><a href="#大于2T的整个磁盘分一个分区" class="headerlink" title="大于2T的整个磁盘分一个分区"></a>大于2T的整个磁盘分一个分区</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">parted /dev/sdb</span><br><span class="line">可以输入p打印磁盘信息，查看分区的情况，找到起始和结束位置。</span><br><span class="line"></span><br><span class="line">mklabel gpt</span><br><span class="line">　　设置分区类型为gpt</span><br><span class="line"></span><br><span class="line">mkpart primary 0% 100%</span><br><span class="line">　　primary指分区类型为主分区，0是分区开始位置，100%是分区结束位置。相同的命令为：mkpart primary 0 -1 或者是：mkpart  primary 0  XXX 结束的空间</span><br><span class="line"></span><br><span class="line">print</span><br><span class="line">　　打印当前分区,查看分区设置是否正确</span><br><span class="line">　　</span><br><span class="line">quit</span><br><span class="line">　　退出</span><br><span class="line">　　</span><br><span class="line">mkfs.xfs /dev/sdb1</span><br><span class="line">格式化</span><br></pre></td></tr></table></figure><h4 id="设置lvm分区"><a href="#设置lvm分区" class="headerlink" title="设置lvm分区"></a>设置lvm分区</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">parted /dev/sdb</span><br><span class="line">mklabel gpt</span><br><span class="line">mkpart primary xfs 0G 300G      # 300G的磁盘</span><br><span class="line">mkpart primary xfs 300G 500G    # 200G的磁盘</span><br><span class="line">mkpart primary xfs 500G -0G   # 500G到剩余所有空间的分区</span><br><span class="line">print</span><br><span class="line">set 1 lvm on   # 设置 第一个分区为 lvm 文件系统</span><br><span class="line">print</span><br><span class="line">rm 2       # 删除 2 分区  </span><br><span class="line">quit</span><br><span class="line"></span><br><span class="line">mkfs.xfs /dev/sdb2</span><br><span class="line">mkfs.xfs /dev/sdb3</span><br></pre></td></tr></table></figure><h4 id="批量分区"><a href="#批量分区" class="headerlink" title="批量分区"></a>批量分区</h4><p>自己用的一个批量分区脚本</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">source /etc/profile</span><br><span class="line">yum install -y expect parted</span><br><span class="line"></span><br><span class="line">#for letter in b c d e f g h i j k l m</span><br><span class="line">for letter in `fdisk -l | grep 4000 | awk &apos;&#123;print $2&#125;&apos; | cut -c 8 | sort`</span><br><span class="line">do</span><br><span class="line">expect -c &apos;set timeout -1;</span><br><span class="line">spawn parted /dev/sd&apos;$letter&apos;;</span><br><span class="line">expect &quot;(parted)&quot;;</span><br><span class="line">send &quot;mklabel gpt\n&quot;;</span><br><span class="line">expect &quot;(parted)&quot;;</span><br><span class="line">send &quot;unit GB\n&quot;;</span><br><span class="line">expect &quot;(parted)&quot;;</span><br><span class="line">send &quot;mkpart primary 0 -1\n&quot;;</span><br><span class="line">expect &quot;(parted)&quot;;</span><br><span class="line">send &quot;quit\n&quot;;</span><br><span class="line">interact&apos;</span><br><span class="line"></span><br><span class="line">nohup mkfs.xfs /dev/sd$&#123;letter&#125;1 &gt; sd$letter.out 2&gt;&amp;1 &amp;</span><br><span class="line"></span><br><span class="line">done</span><br></pre></td></tr></table></figure><h4 id="非交互式模式"><a href="#非交互式模式" class="headerlink" title="非交互式模式"></a>非交互式模式</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># parted /dev/sdb mklabel gpt </span><br><span class="line"># parted /dev/sdb mkpart primary 0 300G</span><br><span class="line"># parted /dev/sdb mkpart primary 300G 1000G </span><br><span class="line"># parted /dev/sdb mkpart logical 1000G -0G</span><br><span class="line"># parted /dev/sdb p</span><br></pre></td></tr></table></figure>]]></content>
      
      <categories>
          
          <category> linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> linux </tag>
            
            <tag> parted </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>源码安装mesos</title>
      <link href="/source-install-mesos/"/>
      <url>/source-install-mesos/</url>
      <content type="html"><![CDATA[<h1 id="源码安装mesos"><a href="#源码安装mesos" class="headerlink" title="源码安装mesos"></a>源码安装mesos</h1><p>源码安装mesos</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">wget http://archive.apache.org/dist/mesos/1.3.0/mesos-1.3.0.tar.gz</span><br><span class="line"></span><br><span class="line">需要 mvn 环境 export MAVEN_HOME</span><br><span class="line">yum groupinstall -y &quot;Development Tools&quot;</span><br><span class="line">yum install apr* patch libcurl libcurl-devel path python-devel java-1.7.0-openjdk-devel zlib-devel libcurl-devel openssl-devel cyrus-sasl-devel cyrus-sasl-md5 apr-devel subversion-devel apr-util-devel subversion subversion-devel systemtap systemtap-client zlib-devel</span><br><span class="line"></span><br><span class="line">tar -zxvf mesos-1.3.0.tar.gz</span><br><span class="line">cd mesos-1.3.0</span><br><span class="line">./configure --prefix=/home/mesos/mesos-slave</span><br><span class="line">make</span><br><span class="line">make install</span><br></pre></td></tr></table></figure><p>官网安装说明 ：   <a href="http://mesos.apache.org/documentation/latest/building/" target="_blank" rel="noopener">http://mesos.apache.org/documentation/latest/building/</a></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"># Install a few utility tools</span><br><span class="line">$ sudo yum install -y tar wget git</span><br><span class="line"></span><br><span class="line"># Fetch the Apache Maven repo file.</span><br><span class="line">$ sudo wget http://repos.fedorapeople.org/repos/dchen/apache-maven/epel-apache-maven.repo -O /etc/yum.repos.d/epel-apache-maven.repo</span><br><span class="line"></span><br><span class="line"># Install the EPEL repo so that we can pull in &apos;libserf-1&apos; as part of our</span><br><span class="line"># subversion install below.</span><br><span class="line">$ sudo yum install -y epel-release</span><br><span class="line"></span><br><span class="line"># &apos;Mesos &gt; 0.21.0&apos; requires &apos;subversion &gt; 1.8&apos; devel package,</span><br><span class="line"># which is not available in the default repositories.</span><br><span class="line"># Create a WANdisco SVN repo file to install the correct version:</span><br><span class="line">$ sudo bash -c &apos;cat &gt; /etc/yum.repos.d/wandisco-svn.repo &lt;&lt;EOF</span><br><span class="line">[WANdiscoSVN]</span><br><span class="line">name=WANdisco SVN Repo 1.9</span><br><span class="line">enabled=1</span><br><span class="line">baseurl=http://opensource.wandisco.com/centos/7/svn-1.9/RPMS/\$basearch/</span><br><span class="line">gpgcheck=1</span><br><span class="line">gpgkey=http://opensource.wandisco.com/RPM-GPG-KEY-WANdisco</span><br><span class="line">EOF&apos;</span><br><span class="line"></span><br><span class="line"># Parts of Mesos require systemd in order to operate. However, Mesos</span><br><span class="line"># only supports versions of systemd that contain the &apos;Delegate&apos; flag.</span><br><span class="line"># This flag was first introduced in &apos;systemd version 218&apos;, which is</span><br><span class="line"># lower than the default version installed by centos. Luckily, centos</span><br><span class="line"># 7.1 has a patched &apos;systemd &lt; 218&apos; that contains the &apos;Delegate&apos; flag.</span><br><span class="line"># Explicity update systemd to this patched version.</span><br><span class="line">$ sudo yum update systemd</span><br><span class="line"></span><br><span class="line"># Install essential development tools.</span><br><span class="line">$ sudo yum groupinstall -y &quot;Development Tools&quot;</span><br><span class="line"></span><br><span class="line"># Install other Mesos dependencies.</span><br><span class="line">$ sudo yum install -y apache-maven python-devel python-six python-virtualenv java-1.8.0-openjdk-devel zlib-devel libcurl-devel openssl-devel cyrus-sasl-devel cyrus-sasl-md5 apr-devel subversion-devel apr-util-devel</span><br><span class="line"></span><br><span class="line"># Change working directory.</span><br><span class="line">$ cd mesos</span><br><span class="line"></span><br><span class="line"># Bootstrap (Only required if building from git repository).</span><br><span class="line">$ ./bootstrap</span><br><span class="line"></span><br><span class="line"># Configure and build.</span><br><span class="line">$ mkdir build</span><br><span class="line">$ cd build</span><br><span class="line">$ ../configure</span><br><span class="line">$ make</span><br><span class="line"></span><br><span class="line"># Run test suite.</span><br><span class="line">$ make check</span><br><span class="line"></span><br><span class="line"># Install (Optional).</span><br><span class="line">$ make install</span><br></pre></td></tr></table></figure><p>用super启动mesos-agent</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[root@logstash00 conf]# cat mesos-agent.ini </span><br><span class="line">[program:mesos-agent]</span><br><span class="line">command = /home/mesos/mesos-slave/sbin/mesos-agent --master=zk://10.0.0.52:2181,10.0.0.53:2181,10.0.0.54:2181/mesos --log_dir=/var/log/mesos --containerizers=docker,mesos --executor_registration_timeout=5mins --work_dir=/home/mesos/mesos --hostname=logstash00 --attributes=nginx:ok;service:nginx;test:ok;app:nginx;db:ok;server:nginx</span><br><span class="line">autostart = true</span><br><span class="line">autorestart = true</span><br><span class="line">startsecs = 3</span><br><span class="line">startretries = 3</span><br><span class="line">stopwaitsecs = 5</span><br><span class="line">user = root</span><br><span class="line">redirect_stderr = true</span><br><span class="line">stdout_logfile = /home/mesos/logs/supervisor/mesos-agent.log</span><br><span class="line">stdout_logfile_maxbytes = 500MB</span><br><span class="line">stdout_logfile_backups = 3</span><br></pre></td></tr></table></figure><p>感觉文章还可以的话，帮忙点点下面的广告哦！ 谢谢支持！</p>]]></content>
      
      <categories>
          
          <category> mesos </category>
          
      </categories>
      
      
        <tags>
            
            <tag> mesos </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>logstash 配置文件写法</title>
      <link href="/logstash-configure-file/"/>
      <url>/logstash-configure-file/</url>
      <content type="html"><![CDATA[<h1 id="logstash-配置文件"><a href="#logstash-配置文件" class="headerlink" title="logstash 配置文件"></a>logstash 配置文件</h1><h5 id="开启http接口，并把收集到的日志放入ES中。"><a href="#开启http接口，并把收集到的日志放入ES中。" class="headerlink" title="开启http接口，并把收集到的日志放入ES中。"></a>开启http接口，并把收集到的日志放入ES中。</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line">input &#123;</span><br><span class="line">    http &#123;</span><br><span class="line">         host =&gt; &quot;0.0.0.0&quot;</span><br><span class="line">         port =&gt; 7881   # 开启端口</span><br><span class="line">         codec =&gt; json  # 格式化 json</span><br><span class="line">          add_field =&gt; &#123;   # 添加字段，在接受到的每条日志中添加 marathon：base-marathon 一个字段</span><br><span class="line">            &quot;marathon&quot; =&gt; &quot;base-marathon&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">##  判断日志中包含 oam_type 的key 放到相应的ES索引中。192.168.5</span><br><span class="line">output &#123;</span><br><span class="line">     if [oam_type] == &quot;hadoop&quot; &#123;</span><br><span class="line">         elasticsearch &#123;</span><br><span class="line">              hosts =&gt; [&quot;192.168.5.27:9250&quot;,&quot;192.168.5.28:9250&quot;,&quot;192.168.5.29:9250&quot;]</span><br><span class="line">              index =&gt; &quot;logstash-cd-hadoop-%&#123;+YYYY.MM.dd&#125;&quot;</span><br><span class="line">              flush_size =&gt; 10000</span><br><span class="line">              idle_flush_time =&gt; 60</span><br><span class="line">              template_overwrite =&gt; true</span><br><span class="line">          &#125;</span><br><span class="line">     &#125; else if [oam_type] == &quot;kafka&quot; &#123;</span><br><span class="line">         elasticsearch &#123;</span><br><span class="line">              hosts =&gt; [&quot;192.168.5.27:9250&quot;,&quot;192.168.5.28:9250&quot;,&quot;192.168.5.29:9250&quot;]</span><br><span class="line">              index =&gt; &quot;logstash-cd-kafka-%&#123;+YYYY.MM.dd&#125;&quot;</span><br><span class="line">              flush_size =&gt; 10000</span><br><span class="line">              idle_flush_time =&gt; 60</span><br><span class="line">              template_overwrite =&gt; true</span><br><span class="line">          &#125;</span><br><span class="line">     &#125; else if [oam_type] == &quot;es&quot; &#123;</span><br><span class="line">         elasticsearch &#123;</span><br><span class="line">              hosts =&gt; [&quot;192.168.5.27:9250&quot;,&quot;192.168.5.28:9250&quot;,&quot;192.168.5.29:9250&quot;]</span><br><span class="line">              index =&gt; &quot;logstash-cd-es-%&#123;+YYYY.MM.dd&#125;&quot;</span><br><span class="line">              flush_size =&gt; 10000</span><br><span class="line">              idle_flush_time =&gt; 60</span><br><span class="line">              template_overwrite =&gt; true</span><br><span class="line">          &#125;</span><br><span class="line">     &#125; else &#123;</span><br><span class="line">         elasticsearch &#123;</span><br><span class="line">              hosts =&gt; [&quot;192.168.5.27:9250&quot;,&quot;192.168.5.28:9250&quot;,&quot;192.168.5.29:9250&quot;]</span><br><span class="line">              index =&gt; &quot;logstash-cd-marathon-%&#123;+YYYY.MM.dd&#125;&quot;</span><br><span class="line">              flush_size =&gt; 10000</span><br><span class="line">              idle_flush_time =&gt; 60</span><br><span class="line">              template_overwrite =&gt; true</span><br><span class="line">          &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="从kafka中取出nginx日志，放入到HDFS上"><a href="#从kafka中取出nginx日志，放入到HDFS上" class="headerlink" title="从kafka中取出nginx日志，放入到HDFS上"></a>从kafka中取出nginx日志，放入到HDFS上</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br></pre></td><td class="code"><pre><span class="line">input &#123;</span><br><span class="line">    kafka &#123;</span><br><span class="line">        zk_connect =&gt; &quot;10.10.110.122:2181,10.10.110.123:2181,10.10.110.124:2181/kafka&quot;</span><br><span class="line">        group_id =&gt; &quot;logstash-kafka-hdfs&quot;</span><br><span class="line">        topic_id =&gt; &quot;prd_nginx_access&quot;</span><br><span class="line">        codec =&gt; plain</span><br><span class="line">        reset_beginning =&gt; false # boolean (optional)， default: false</span><br><span class="line">        consumer_threads =&gt; 1  # number (optional)， default: 1</span><br><span class="line">        decorate_events =&gt; false # boolean (optional)， default: false</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"># 格式化，将十二个月转换成数字。</span><br><span class="line">filter &#123;</span><br><span class="line">        grok &#123;</span><br><span class="line">                match =&gt; &#123;</span><br><span class="line">                        &quot;message&quot; =&gt;&quot;^(?&lt;hostname&gt;.+?)\s(?&lt;modulname&gt;.+?)\s(?&lt;remote_addr&gt;.+?)\s\-\s(?&lt;remote_user&gt;.+?)\s\[(?&lt;Day&gt;.+?)/(?&lt;Month&gt;.+?)/(?&lt;Year&gt;.+?):(?&lt;Hour&gt;.+?):&quot;</span><br><span class="line">                &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        if [Month] == &quot;Jan&quot; &#123;</span><br><span class="line">                        mutate &#123;</span><br><span class="line">                                update =&gt; [&quot;Month&quot;,&quot;01&quot;]</span><br><span class="line">                        &#125; </span><br><span class="line">        &#125; else if [Month] == &quot;Feb&quot; &#123;</span><br><span class="line">                        mutate &#123;</span><br><span class="line">                                update =&gt; [&quot;Month&quot;,&quot;02&quot;]</span><br><span class="line">                        &#125;</span><br><span class="line">        &#125; else if [Month] == &quot;Mar&quot; &#123;</span><br><span class="line">                        mutate &#123;</span><br><span class="line">                                update =&gt; [&quot;Month&quot;,&quot;03&quot;]</span><br><span class="line">                        &#125;</span><br><span class="line">        &#125; else if [Month] == &quot;Apr&quot; &#123;</span><br><span class="line">                        mutate &#123;</span><br><span class="line">                                update =&gt; [&quot;Month&quot;,&quot;04&quot;]</span><br><span class="line">                        &#125;</span><br><span class="line">        &#125; else if [Month] == &quot;May&quot; &#123;</span><br><span class="line">                        mutate &#123;</span><br><span class="line">                                update =&gt; [&quot;Month&quot;,&quot;05&quot;]</span><br><span class="line">                        &#125;</span><br><span class="line">        &#125; else if [Month] == &quot;Jun&quot; &#123;</span><br><span class="line">                        mutate &#123;</span><br><span class="line">                                update =&gt; [&quot;Month&quot;,&quot;06&quot;]</span><br><span class="line">                        &#125;</span><br><span class="line">        &#125; else if [Month] == &quot;Jul&quot; &#123;</span><br><span class="line">                        mutate &#123;</span><br><span class="line">                                update =&gt; [&quot;Month&quot;,&quot;07&quot;]</span><br><span class="line">                        &#125;</span><br><span class="line">        &#125; else if [Month] == &quot;Aug&quot; &#123;</span><br><span class="line">                        mutate &#123;</span><br><span class="line">                                update =&gt; [&quot;Month&quot;,&quot;08&quot;]</span><br><span class="line">                        &#125;</span><br><span class="line">        &#125; else if [Month] == &quot;Sep&quot; &#123;</span><br><span class="line">                        mutate &#123;</span><br><span class="line">                                update =&gt; [&quot;Month&quot;,&quot;09&quot;]</span><br><span class="line">                        &#125;</span><br><span class="line">        &#125; else if [Month] == &quot;Oct&quot; &#123;</span><br><span class="line">                        mutate &#123;</span><br><span class="line">                                update =&gt; [&quot;Month&quot;,&quot;10&quot;]</span><br><span class="line">                        &#125;</span><br><span class="line">        &#125; else if [Month] == &quot;Nov&quot; &#123;</span><br><span class="line">                        mutate &#123;</span><br><span class="line">                                update =&gt; [&quot;Month&quot;,&quot;11&quot;]</span><br><span class="line">                        &#125;</span><br><span class="line">        &#125; else if [Month] == &quot;Dec&quot; &#123;</span><br><span class="line">                        mutate &#123;</span><br><span class="line">                                update =&gt; [&quot;Month&quot;,&quot;12&quot;]</span><br><span class="line">                        &#125;</span><br><span class="line">        &#125; </span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">output &#123;</span><br><span class="line">        if [modulname] &#123;</span><br><span class="line">           webhdfs &#123;</span><br><span class="line">                workers =&gt; 1</span><br><span class="line">                host =&gt; &quot;namenode-master.host.com&quot;</span><br><span class="line">                port =&gt; 14000</span><br><span class="line">                user =&gt; &quot;hadoop&quot;</span><br><span class="line">                path =&gt; &quot;/Data/Logs/domain=%&#123;modulname&#125;/dt=%&#123;Year&#125;%&#123;Month&#125;%&#123;Day&#125;/hour=%&#123;Hour&#125;/%&#123;modulname&#125;_%&#123;Year&#125;%&#123;Month&#125;%&#123;Day&#125;%&#123;Hour&#125;.log&quot;</span><br><span class="line">                flush_size =&gt; 5000</span><br><span class="line">                compression =&gt; &quot;gzip&quot;</span><br><span class="line">                idle_flush_time =&gt; 6</span><br><span class="line">                retry_interval =&gt; 3</span><br><span class="line">                retry_times =&gt; 3</span><br><span class="line">                codec =&gt; line &#123;</span><br><span class="line">                        format =&gt; &quot;%&#123;message&#125;&quot;</span><br><span class="line">                &#125;</span><br><span class="line">           &#125;</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">           file &#123;</span><br><span class="line">                path =&gt; &quot;/home/logs/supervisor/logstash_prd_kafka_hdfs_error.log&quot;</span><br><span class="line">                codec =&gt;  line &#123; format =&gt; &quot;custom format: %&#123;message&#125;&quot; &#125;</span><br><span class="line">           &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        stdout&#123;codec =&gt; rubydebug&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="收集nginx日志放到kafka中"><a href="#收集nginx日志放到kafka中" class="headerlink" title="收集nginx日志放到kafka中"></a>收集nginx日志放到kafka中</h5><p> 日志格式为文本, logstash 放到kafka中会变成一个大的json串</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">input &#123;</span><br><span class="line">    file &#123;</span><br><span class="line">        path =&gt; [&quot;/home/nginx/logs/accesslog/**/*.log&quot;]</span><br><span class="line">        exclude =&gt; [&quot;/home/nginx/logs/accesslog/11.test.com/*.log&quot;,&quot;/home/nginx/logs/accesslog/2.test.com/*.log&quot;,&quot;/home/nginx/logs/accesslog/3.test.com/*.log&quot;]</span><br><span class="line">        sincedb_path =&gt; &quot;/home/optools/logstash/sincedb&quot;</span><br><span class="line">        start_position =&gt; &quot;beginning&quot;</span><br><span class="line">        discover_interval =&gt; 10</span><br><span class="line">        close_older =&gt; 3600</span><br><span class="line">        ignore_older =&gt; 86400</span><br><span class="line">        sincedb_write_interval =&gt; 5</span><br><span class="line">        stat_interval =&gt; 1</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">output &#123;</span><br><span class="line">    kafka &#123;</span><br><span class="line">        bootstrap_servers =&gt; &quot;kafka00:9092,kafka01:9092,kafka02:9092&quot;</span><br><span class="line">        topic_id =&gt; &quot;prd_nginx_access&quot;</span><br><span class="line">        compression_type =&gt; &quot;gzip&quot;</span><br><span class="line">        codec =&gt; plain &#123;</span><br><span class="line">                        format =&gt; &quot;%&#123;message&#125;&quot;</span><br><span class="line">                &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="处理json日志"><a href="#处理json日志" class="headerlink" title="处理json日志"></a>处理json日志</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">input &#123;</span><br><span class="line">    file &#123;</span><br><span class="line">        path =&gt; [&quot;/home/logs/v4-weblog/*.log&quot;]</span><br><span class="line">        sincedb_path =&gt; &quot;/home/logstash/conf/sincedb&quot;</span><br><span class="line">        start_position =&gt; &quot;beginning&quot;</span><br><span class="line">        codec =&gt; &quot;json&quot;  # 往后端传是json，如果后端要文本，codec =&gt; &quot;plain&quot;</span><br><span class="line">        discover_interval =&gt; 10</span><br><span class="line">        close_older =&gt; 3600</span><br><span class="line">        ignore_older =&gt; 86400</span><br><span class="line">        sincedb_write_interval =&gt; 5</span><br><span class="line">        stat_interval =&gt; 1</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">output &#123;</span><br><span class="line">        kafka &#123;</span><br><span class="line">        topic_id =&gt; &quot;weblogv4_mx_wandafilm&quot;</span><br><span class="line">        bootstrap_servers =&gt; &quot;192.168.5.30:9092,192.168.5.38:9092,192.168.5.48:9092&quot;</span><br><span class="line">        codec =&gt; plain &#123;</span><br><span class="line">                        format =&gt; &quot;%&#123;message&#125;&quot;</span><br><span class="line">                &#125;</span><br><span class="line">     &#125;</span><br><span class="line">    </span><br><span class="line">    #stdout&#123;</span><br><span class="line">    #    codec =&gt; rubydebug</span><br><span class="line">    #&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="filter"><a href="#filter" class="headerlink" title="filter"></a>filter</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">input &#123;</span><br><span class="line">    kafka &#123;</span><br><span class="line">        zk_connect =&gt; &quot;192.168.5.18:2181,192.168.5.28:2181,192.168.5.30:2181,192.168.5.38:2181,192.168.5.48:2181&quot;</span><br><span class="line">        group_id =&gt; &quot;huawei_hard_monitor&quot;</span><br><span class="line">        topic_id =&gt; &quot;huawei_hard_monitor&quot;</span><br><span class="line">        codec =&gt; json</span><br><span class="line">        reset_beginning =&gt; false # boolean (optional)， default: false</span><br><span class="line">        consumer_threads =&gt; 1  # number (optional)， default: 1</span><br><span class="line">        decorate_events =&gt; false # boolean (optional)， default: false</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">filter &#123;</span><br><span class="line">        grok &#123;</span><br><span class="line">                match =&gt; &#123;</span><br><span class="line">                        &quot;SNMPv2-SMI::enterprises.2011.23.2.1&quot; =&gt; &quot;^Location:(?&lt;Location&gt;.*?); Time:(?&lt;Time&gt;.*?); Sensor:(?&lt;Sensor&gt;.*?); Severity:(?&lt;Severity&gt;.*?); Code:(?&lt;Code&gt;.*?); Description:(?&lt;Description&gt;.*?)$&quot;</span><br><span class="line">                &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        mutate &#123;</span><br><span class="line">                rename =&gt; [&quot;SNMPv2-MIB::sysUpTime.0&quot;, &quot;SNMPv2-MIB--sysUpTime-0&quot;]</span><br><span class="line">                rename =&gt; [&quot;SNMPv2-MIB::snmpTrapOID.0&quot;, &quot;SNMPv2-MIB--snmpTrapOID-0&quot;]</span><br><span class="line">                rename =&gt; [&quot;SNMPv2-SMI::enterprises.2011.23.2.1&quot;, &quot;SNMPv2-SMI--enterprises_2011_23_2_1&quot;]</span><br><span class="line">         &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">output &#123;</span><br><span class="line">           elasticsearch &#123;</span><br><span class="line">                workers =&gt; 4</span><br><span class="line">                hosts =&gt; [&quot;192.168.5.27:9250&quot;,&quot;192.168.5.28:9250&quot;,&quot;192.168.5.29:9250&quot;]</span><br><span class="line">                index =&gt; &quot;logstash-huawei_hard_monitor-%&#123;+YYYY.MM.dd&#125;&quot;</span><br><span class="line">                flush_size =&gt; 50000</span><br><span class="line">                idle_flush_time =&gt; 30</span><br><span class="line">                template_overwrite =&gt; true</span><br><span class="line">            &#125;</span><br><span class="line">#        stdout&#123;codec =&gt; rubydebug&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="nginx-日志收集"><a href="#nginx-日志收集" class="headerlink" title="nginx 日志收集"></a>nginx 日志收集</h5><p>中文转码，\x 转为Xx \\x 转为 XXx<br>添加字段，nginx access 和 error 日志放在不同索引中。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line">input &#123;</span><br><span class="line">    kafka &#123;</span><br><span class="line">        zk_connect =&gt; &quot;192.168.5.30:2181,192.168.5.38:2181,192.168.5.48:2181,192.168.5.18:2181,192.168.5.28:2181&quot;</span><br><span class="line">        group_id =&gt; &quot;logstash-docker-nginx&quot;</span><br><span class="line">        topic_id =&gt; &quot;test_for_docker&quot;</span><br><span class="line">        codec =&gt; json</span><br><span class="line">        reset_beginning =&gt; false # boolean (optional)， default: false</span><br><span class="line">        consumer_threads =&gt; 4  # number (optional)， default: 1</span><br><span class="line">        decorate_events =&gt; false # boolean (optional)， default: false</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">filter &#123;</span><br><span class="line">        ruby &#123;</span><br><span class="line">                code =&gt; &quot;</span><br><span class="line">                  event[&apos;log&apos;] = event[&apos;log&apos;].gsub(&apos;\x&apos;,&apos;Xx&apos;)</span><br><span class="line">                  event[&apos;log&apos;] = event[&apos;log&apos;].gsub(&apos;\\x&apos;,&apos;XXx&apos;)</span><br><span class="line">                  &quot;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">        if &quot;http_cookie&quot; in [log] &#123;</span><br><span class="line">                mutate &#123; add_tag =&gt; &quot;nginx-access&quot; &#125;</span><br><span class="line">                json &#123;</span><br><span class="line">                         source =&gt; &quot;log&quot;</span><br><span class="line">                &#125;</span><br><span class="line">                mutate &#123;</span><br><span class="line">                        convert =&gt; [</span><br><span class="line">                        &quot;status&quot;, &quot;integer&quot;,</span><br><span class="line">                        &quot;body_bytes_sent&quot; , &quot;integer&quot;,</span><br><span class="line">                        &quot;upstream_response_time&quot;, &quot;float&quot;,</span><br><span class="line">                        &quot;request_time&quot;, &quot;float&quot;</span><br><span class="line">                        ]</span><br><span class="line">                        remove_field =&gt; &quot;log&quot;</span><br><span class="line">                &#125;</span><br><span class="line">                geoip &#123;</span><br><span class="line">                        source =&gt; &quot;ip&quot;</span><br><span class="line">                &#125;</span><br><span class="line">                date &#123;</span><br><span class="line">                        match =&gt; [&quot;time_local&quot;, &quot;ISO8601&quot;]</span><br><span class="line">                        locale =&gt;&quot;en&quot;</span><br><span class="line">                &#125;</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">                 mutate &#123; add_tag =&gt; &quot;nginx-error&quot; &#125;</span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">output &#123;</span><br><span class="line">        if &quot;nginx-access&quot;  in [tags] &#123;</span><br><span class="line">           elasticsearch &#123;</span><br><span class="line">                workers =&gt; 4</span><br><span class="line">                hosts =&gt; [&quot;192.168.5.27:9250&quot;,&quot;192.168.5.28:9250&quot;,&quot;192.168.5.29:9250&quot;]</span><br><span class="line">                index =&gt; &quot;logstash-nginxaccess-%&#123;+YYYY.MM.dd&#125;&quot;</span><br><span class="line">                flush_size =&gt; 10240</span><br><span class="line">                idle_flush_time =&gt; 30</span><br><span class="line">                template_overwrite =&gt; true</span><br><span class="line">                &#125;</span><br><span class="line">         &#125; else if &quot;nginx-error&quot; in [tags] &#123;</span><br><span class="line">             elasticsearch &#123;</span><br><span class="line">                workers =&gt; 4</span><br><span class="line">                hosts =&gt; [&quot;192.168.5.27:9250&quot;,&quot;192.168.5.28:9250&quot;,&quot;192.168.5.29:9250&quot;]</span><br><span class="line">                index =&gt; &quot;logstash-nginxerror-%&#123;+YYYY.MM.dd&#125;&quot;</span><br><span class="line">                flush_size =&gt; 100</span><br><span class="line">                idle_flush_time =&gt; 5</span><br><span class="line">                template_overwrite =&gt; true</span><br><span class="line">                &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">#               stdout&#123;codec =&gt; rubydebug&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="转换时间"><a href="#转换时间" class="headerlink" title="转换时间"></a>转换时间</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">input &#123;</span><br><span class="line">    kafka &#123;</span><br><span class="line">        zk_connect =&gt; &quot;192.168.5.18:2181,192.168.5.28:2181,192.168.5.30:2181,192.168.5.38:2181,192.168.5.48:2181&quot;</span><br><span class="line">        group_id =&gt; &quot;es-hdfs&quot;</span><br><span class="line">        topic_id =&gt; &quot;logdata-es&quot;</span><br><span class="line">        codec =&gt; json</span><br><span class="line">        reset_beginning =&gt; false # boolean (optional)， default: false</span><br><span class="line">        consumer_threads =&gt; 1  # number (optional)， default: 1</span><br><span class="line">        decorate_events =&gt; false # boolean (optional)， default: false</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">filter &#123;</span><br><span class="line">        date &#123;</span><br><span class="line">                match =&gt; [ &quot;time&quot; , &quot;yyyy-MM-dd HH:mm:ss&quot; ]</span><br><span class="line">                locale =&gt; &quot;zh&quot;</span><br><span class="line">                timezone =&gt; &quot;-00:00:00&quot;</span><br><span class="line">                target =&gt; &quot;@timestamp&quot;</span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">output &#123;</span><br><span class="line">     elasticsearch &#123;</span><br><span class="line">        hosts =&gt; [&quot;192.168.5.27:9250&quot;,&quot;192.168.5.28:9250&quot;,&quot;192.168.5.29:9250&quot;]</span><br><span class="line">        index =&gt; &quot;logstash-%&#123;app&#125;-%&#123;+YYYY.MM.dd&#125;&quot;</span><br><span class="line">        #document_type =&gt; &quot;%&#123;type&#125;&quot;</span><br><span class="line">        flush_size =&gt; 3840</span><br><span class="line">        idle_flush_time =&gt; 10</span><br><span class="line">        template_overwrite =&gt; true</span><br><span class="line">    &#125;</span><br><span class="line">#  stdout &#123; codec =&gt; rubydebug &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="一个nginx-json-日志收集的例子"><a href="#一个nginx-json-日志收集的例子" class="headerlink" title="一个nginx json 日志收集的例子"></a>一个nginx json 日志收集的例子</h4><p>nginx 配置日志格式</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">log_format main   &apos;&#123;&quot;@timestamp&quot;:&quot;$time_iso8601&quot;,&apos;</span><br><span class="line">                    &apos;&quot;@source&quot;:&quot;$server_addr&quot;,&apos;</span><br><span class="line">                    &apos;&quot;hostname&quot;:&quot;$hostname&quot;,&apos;</span><br><span class="line">                    &apos;&quot;remote_user&quot;:&quot;$remote_user&quot;,&apos;</span><br><span class="line">                    &apos;&quot;ip&quot;:&quot;$http_x_forwarded_for&quot;,&apos;</span><br><span class="line">                    &apos;&quot;client&quot;:&quot;$remote_addr&quot;,&apos;</span><br><span class="line">                    &apos;&quot;request_method&quot;:&quot;$request_method&quot;,&apos;</span><br><span class="line">                    &apos;&quot;scheme&quot;:&quot;$scheme&quot;,&apos;</span><br><span class="line">                    &apos;&quot;domain&quot;:&quot;$server_name&quot;,&apos;</span><br><span class="line">                    &apos;&quot;referer&quot;:&quot;$http_referer&quot;,&apos;</span><br><span class="line">                    &apos;&quot;request&quot;:&quot;$request_uri&quot;,&apos;</span><br><span class="line">                    &apos;&quot;requesturl&quot;:&quot;$request&quot;,&apos;</span><br><span class="line">                    &apos;&quot;args&quot;:&quot;$args&quot;,&apos;</span><br><span class="line">                    &apos;&quot;size&quot;:$body_bytes_sent,&apos;</span><br><span class="line">                    &apos;&quot;status&quot;: $status,&apos;</span><br><span class="line">                    &apos;&quot;responsetime&quot;:$request_time,&apos;</span><br><span class="line">                    &apos;&quot;upstreamtime&quot;:&quot;$upstream_response_time&quot;,&apos;</span><br><span class="line">                    &apos;&quot;upstreamaddr&quot;:&quot;$upstream_addr&quot;,&apos;</span><br><span class="line">                    &apos;&quot;http_user_agent&quot;:&quot;$http_user_agent&quot;,&apos;</span><br><span class="line">                    &apos;&quot;http_cookie&quot;:&quot;$http_cookie&quot;,&apos;</span><br><span class="line">                    &apos;&quot;https&quot;:&quot;$https&quot;,&apos;</span><br><span class="line">                    &apos;&quot;request_body&quot;:&quot;$request_body&quot;,&apos;</span><br><span class="line">                    &apos;&quot;http_x_clientid&quot;:&quot;$http_x_clientid&quot;&apos;</span><br><span class="line">                    &apos;&#125;&apos;;</span><br></pre></td></tr></table></figure><p>logstash 手机nginx日志，并处理转码问题。（需要2.4版本之上，才能支持这个正则）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line">input &#123;</span><br><span class="line">    file &#123;</span><br><span class="line">        path =&gt; [&quot;/home/nginx/logs/accesslog/**/*.log&quot;]</span><br><span class="line">        codec =&gt; json</span><br><span class="line">        sincedb_path =&gt; &quot;/home/logstash/sincedb&quot;</span><br><span class="line">        start_position =&gt; &quot;beginning&quot;</span><br><span class="line">        discover_interval =&gt; 30</span><br><span class="line">        close_older =&gt; 3600</span><br><span class="line">        ignore_older =&gt; 86400</span><br><span class="line">        sincedb_write_interval =&gt; 10</span><br><span class="line">        stat_interval =&gt; 1</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">filter &#123;</span><br><span class="line">ruby &#123;</span><br><span class="line">                code =&gt; &quot;if event.get(&apos;message&apos;).include?(&apos;\x&apos;) then</span><br><span class="line">    event.set(&apos;message&apos;, event.get(&apos;message&apos;).gsub(/\\x([0-9A-F]&#123;2&#125;)/) &#123;</span><br><span class="line">        case $1</span><br><span class="line">            when &apos;22&apos;</span><br><span class="line">                &apos;\\&quot;&apos;</span><br><span class="line">            when &apos;0D&apos;</span><br><span class="line">                &apos;\\r&apos;</span><br><span class="line">            when &apos;0A&apos;</span><br><span class="line">                &apos;\\n&apos;</span><br><span class="line">            when &apos;27&apos;</span><br><span class="line">                &apos;\\\&apos;&apos;</span><br><span class="line">            when &apos;5C&apos;</span><br><span class="line">                &apos;\\\\&apos;</span><br><span class="line">            else</span><br><span class="line">                $1.hex.chr</span><br><span class="line">        end</span><br><span class="line">    &#125;)</span><br><span class="line">end&quot;</span><br><span class="line">        &#125;</span><br><span class="line">        json &#123;</span><br><span class="line">                source =&gt; &quot;message&quot;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">mutate &#123;</span><br><span class="line">        remove_field =&gt;[&quot;message&quot;]</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">output &#123;</span><br><span class="line">    kafka &#123;</span><br><span class="line">        bootstrap_servers =&gt; &quot;192.168.0.2:9092,192.168.0.3:9092,192.168.0.4:9092&quot;</span><br><span class="line">        topic_id =&gt; &quot;mtopic_name&quot;</span><br><span class="line">        compression_type =&gt; &quot;gzip&quot;</span><br><span class="line">    &#125;</span><br><span class="line">#stdout &#123; codec =&gt; rubydebug &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>感觉文章还可以的话，帮忙点点下面的广告哦！ 谢谢支持！</p>]]></content>
      
      <categories>
          
          <category> logstash </category>
          
      </categories>
      
      
        <tags>
            
            <tag> logstash </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>marathon事件日志收集</title>
      <link href="/marathon-EventLog-to-ES/"/>
      <url>/marathon-EventLog-to-ES/</url>
      <content type="html"><![CDATA[<h2 id="marathon-事件日志收集到ES中"><a href="#marathon-事件日志收集到ES中" class="headerlink" title="marathon 事件日志收集到ES中"></a>marathon 事件日志收集到ES中</h2><p>  marathon 有配置可以主动把 marathon 的事件日志发送到 http 接口上。这里的事件包括，发布容器的json内容，docker容器死掉、启动，运行、kill，健康检查等日志。也可以说 marathon 所有的动作日志这上都会有。所有我要把这个日志收集起来，并可以做监控，历史查询等等。<br>  先说一下我的方案：<br>  启动一个logstash实例，并配置http接口，把收集到的日志存到ES索引中。<br>  marathon 配置 logstash 的 http 接口地址，把日志发送到这里即可。<br>  后期可以在ES中查询你想要的事件日志，并报警，或用kibana出图等。  </p><h3 id="logstash-配置"><a href="#logstash-配置" class="headerlink" title="logstash 配置"></a>logstash 配置</h3><p>#####logstash 配置文件<br>vim /etc/logstash.conf  </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">input &#123;</span><br><span class="line">    http &#123;</span><br><span class="line">         host =&gt; &quot;0.0.0.0&quot;</span><br><span class="line">         port =&gt; 7882</span><br><span class="line">         codec =&gt; json</span><br><span class="line">          add_field =&gt; &#123;</span><br><span class="line">            &quot;marathon&quot; =&gt; &quot;base-marathon&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">output &#123;</span><br><span class="line">     elasticsearch &#123;</span><br><span class="line">          hosts =&gt; [&quot;10.214.193.27:9250&quot;,&quot;10.214.193.28:9250&quot;,&quot;10.214.193.29:9250&quot;]</span><br><span class="line">          index =&gt; &quot;logstash-marathon-%&#123;+YYYY.MM.dd&#125;&quot;</span><br><span class="line">          flush_size =&gt; 10000</span><br><span class="line">          idle_flush_time =&gt; 60</span><br><span class="line">          template_overwrite =&gt; true</span><br><span class="line">      &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>其中 add_field 添加一个字段  “marathon”:”base-marathon”<br>这样 ES的一个索引所可以放多个marathon的日志，但是需要启动多个logstash，每个配置不同，因为marathon的日志是一样的，区别不出来是哪个集群的日志。  </p><h5 id="启动"><a href="#启动" class="headerlink" title="启动"></a>启动</h5><p>可以用supervisor或docker方式启动。就不在这里说了。</p><h3 id="marathon-配置"><a href="#marathon-配置" class="headerlink" title="marathon 配置"></a>marathon 配置</h3><p>我用的是 yum 安装的marathon，版本是 1.4.9 , 配置是:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /etc/marathon/conf/</span><br><span class="line"></span><br><span class="line">echo &quot;http_callback&quot; &gt; /etc/marathon/conf/event_subscriber</span><br><span class="line">echo &quot;http://logstashIP:7882&quot; &gt; /etc/marathon/conf/http_endpoints</span><br></pre></td></tr></table></figure><p>二进制配置的参数是一样的。  </p><p>重启服务加载配置  </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl restart marathon</span><br></pre></td></tr></table></figure><h4 id="ES-上查询日志"><a href="#ES-上查询日志" class="headerlink" title="ES 上查询日志"></a>ES 上查询日志</h4><p>这样配置完成之后，等marathon有动作的话，ES上就会有数据了，   </p><p>如：<br><img src="/images/marathon-es-data.jpeg" alt="marathon-es-data"></p><p>这只是一个事件，还还有好多时间呢！</p><p>感觉文章还可以的话，帮忙点点下面的广告哦！ 谢谢支持！</p>]]></content>
      
      <categories>
          
          <category> marathon </category>
          
      </categories>
      
      
        <tags>
            
            <tag> marathon </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Unix / Linux ssh-add Command Examples to Add SSH Key to Agent (转)</title>
      <link href="/Unix-Linux-ssh-add-Command-Examples-to-Add-SSH-Key-to-Agent/"/>
      <url>/Unix-Linux-ssh-add-Command-Examples-to-Add-SSH-Key-to-Agent/</url>
      <content type="html"><![CDATA[<h3 id="Unix-Linux-ssh-add-Command-Examples-to-Add-SSH-Key-to-Agent"><a href="#Unix-Linux-ssh-add-Command-Examples-to-Add-SSH-Key-to-Agent" class="headerlink" title="Unix / Linux ssh-add Command Examples to Add SSH Key to Agent"></a>Unix / Linux ssh-add Command Examples to Add SSH Key to Agent</h3><p>ssh-add is a helper program for ssh-agent.<br>ssh-add adds RSA or DSA identity files to the ssh agent. For ssh-add to work properly, the agent should be running, and have the SSH_AUTH_SOCK environment variable set.  </p><ol><li>Fix “Could not Open” Error (and Add Default RSA/DSA identities)<br>By default, when you try to execute the ssh-add command, you might get “Could not open a connection to your authentication agent.” error message as shown below.  </li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ ssh-add</span><br><span class="line">Could not open a connection to your authentication agent.</span><br><span class="line">The reason is ssh-agent is not running.  </span><br><span class="line">But, if you start the ssh-agent as shown below, you’ll still get the same error.  </span><br><span class="line"></span><br><span class="line">$ ssh-agent</span><br><span class="line">SSH_AUTH_SOCK=/tmp/ssh-cYYsc14689/agent.14689; export SSH_AUTH_SOCK;</span><br><span class="line">SSH_AGENT_PID=14690; export SSH_AGENT_PID;</span><br><span class="line">echo Agent pid 14690;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">$ ssh-add</span><br><span class="line">Could not open a connection to your authentication agent.</span><br><span class="line">In order to fix the issue, you should start the ssh-agent as shown below.  </span><br><span class="line"></span><br><span class="line">$ exec ssh-agent bash</span><br><span class="line">Now, when you execute the ssh-add, it will add the ~/.ssh/id_rsa, ~/.ssh/id_dsa and ~/.ssh/identity files to ssh-agent, and will not throw any error message.</span><br><span class="line"></span><br><span class="line">$ ssh-add</span><br><span class="line">Identity added: /home/ramesh/.ssh/id_rsa (/home/ramesh/.ssh/id_rsa)</span><br><span class="line">Identity added: /home/ramesh/.ssh/id_dsa (/home/ramesh/.ssh/id_dsa)</span><br></pre></td></tr></table></figure><ol start="2"><li>Display the entries loaded in ssh-agent<br>Use either -l or -L as shown below to display all the RSA and DSA entries that are currently loaded into the ssh-agent.<br>The following examples shows that there are two entries currently loaded to the ssh-agent.  </li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">$ ssh-add -l</span><br><span class="line">2048 34:36:63:c2:7d:a5:13:e4 /home/ramesh/.ssh/id_rsa (RSA)</span><br><span class="line">1024 ee:60:11:bf:1b:31:3b:fb /home/ramesh/.ssh/id_dsa (DSA)</span><br><span class="line"></span><br><span class="line">$ ssh-add -L</span><br><span class="line">ssh-rsa A2EAAAABIwAAAQEAtVRcaEnxOef0n5WLr9DV1JsLpx4E+P2Zf/N9JBLBbVKDD1BZf</span><br><span class="line">eRmLK8hZZKf0iva8+q1VNyxQB5oTfKGr79ll7KDRwfIgErw== /home/ramesh/.ssh/id_rsa</span><br><span class="line"></span><br><span class="line">ssh-dsa 8WDTpyJiLUNlIXSfCRe7nOjeMlgyn8vM3cWsosO0x4eMDYEMvefzhev0RAtbhyBvs</span><br><span class="line">WLLCwkaVzCZdZvsDa2cl7zKRd+3zLSfBQRa1wpMjJaeJbCg== /home/ramesh/.ssh/id_dsa</span><br></pre></td></tr></table></figure><ol start="3"><li>Delete all entries from ssh-agent<br>Use option -D as shown below to remove all the ssh entries from the ssh-agent.  </li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ ssh-add -D</span><br><span class="line">All identities removed.</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ ssh-add -l</span><br><span class="line">The agent has no identities.</span><br></pre></td></tr></table></figure><ol start="4"><li>Delete specific entries from ssh-agent<br>Using -d option, you can specify exactly what entries you like to delete.<br>The following example will remove only the default RSA entry from the ssh-agent.  </li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ ssh-add -l</span><br><span class="line">2048 34:36:63:c2:7d:a5:13:e4 /home/ramesh/.ssh/id_rsa (RSA)</span><br><span class="line">1024 ee:60:11:bf:1b:31:3b:fb /home/ramesh/.ssh/id_dsa (DSA)</span><br><span class="line"></span><br><span class="line">$ ssh-add -d /home/ramesh/.ssh/id_rsa</span><br><span class="line">Identity removed: /home/ramesh/.ssh/id_rsa (/home/ramesh/.ssh/id_rsa.pub)</span><br><span class="line"></span><br><span class="line">$ ssh-add -l</span><br><span class="line">1024 ee:60:11:bf:1b:31:3b:fb /home/ramesh/.ssh/id_dsa (DSA)</span><br></pre></td></tr></table></figure><ol start="5"><li>Lock (or) Unlock the SSH Agent<br>You can lock the ssh agent as shown below using -x option. Once you lock the agent, you cannot add, delete, or list entries in the ssh agent without a password.  </li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ ssh-add -x</span><br><span class="line">Enter lock password:</span><br><span class="line">Again:</span><br><span class="line">Agent locked.</span><br><span class="line">After locking, if you try to add, you’ll se SSH_AGENT_FAILURE message as shown below.</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ ssh-add</span><br><span class="line">SSH_AGENT_FAILURE</span><br><span class="line">SSH_AGENT_FAILURE</span><br><span class="line">Could not add identity: /home/ramesh/.ssh/id_rsa</span><br><span class="line">To unlock an agent, use -X option as shown below. Make sure you enter the same password that you gave while locking the agent. If you give a wrong password, you’ll set “Failed to unlock agent.” message.</span><br><span class="line"></span><br><span class="line">$ ssh-add -X</span><br><span class="line">Enter lock password:</span><br><span class="line">Agent unlocked.</span><br></pre></td></tr></table></figure>]]></content>
      
      <categories>
          
          <category> linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ssh </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>cgroup 服务限制进程资源</title>
      <link href="/cgroup-limit-process-resources/"/>
      <url>/cgroup-limit-process-resources/</url>
      <content type="html"><![CDATA[<h3 id="CGroup-功能及组成"><a href="#CGroup-功能及组成" class="headerlink" title="CGroup 功能及组成"></a>CGroup 功能及组成</h3><p>  CGroup 是将任意进程进行分组化管理的 Linux 内核功能。CGroup 本身是提供将进程进行分组化管理的功能和接口的基础结构，I/O 或内存的分配控制等具体的资源管理功能是通过这个功能来实现的。这些具体的资源管理功能称为 CGroup 子系统或控制器。CGroup 子系统有控制内存的 Memory 控制器、控制进程调度的 CPU 控制器等。运行中的内核可以使用的 Cgroup 子系统由/proc/cgroup 来确认。  </p><p>  CGroup 提供了一个 CGroup 虚拟文件系统，作为进行分组管理和各子系统设置的用户接口。要使用 CGroup，必须挂载 CGroup 文件系统。这时通过挂载选项指定使用哪个子系统。</p><h4 id="安装cgroup服务"><a href="#安装cgroup服务" class="headerlink" title="安装cgroup服务"></a>安装cgroup服务</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">centos 6</span><br><span class="line">yum install -y libcgroup</span><br><span class="line"></span><br><span class="line">centos 7 </span><br><span class="line">yum install -y libcgroup libcgroup-tools</span><br></pre></td></tr></table></figure><h4 id="配置cgroup配置"><a href="#配置cgroup配置" class="headerlink" title="配置cgroup配置"></a>配置cgroup配置</h4><p>  这里需要是限制cpu<br>  先创建一个组，把需要限制的进程，启动的时候放到这组下。  </p><p>vim /etc/cgconfig.conf</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">mount &#123;</span><br><span class="line">#       cpuset  = /cgroup/cpuset;</span><br><span class="line">        cpu     = /cgroup/cpu;</span><br><span class="line">#       cpuacct = /cgroup/cpuacct;</span><br><span class="line">#       memory  = /cgroup/memory;</span><br><span class="line">#       devices = /cgroup/devices;</span><br><span class="line">#       freezer = /cgroup/freezer;</span><br><span class="line">#       net_cls = /cgroup/net_cls;</span><br><span class="line">#       blkio   = /cgroup/blkio;</span><br><span class="line">&#125;</span><br><span class="line">group yarn &#123;       # yarn 为组名</span><br><span class="line">   perm &#123;</span><br><span class="line">    task &#123;</span><br><span class="line">        uid = hadoop;     # 权限设置，为hadoop</span><br><span class="line">        gid = hadoop;</span><br><span class="line">    &#125;</span><br><span class="line">    admin &#123;</span><br><span class="line">       uid = hadoop;</span><br><span class="line">       gid = hadoop;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">   cpu &#123;   # 可以用 cpu.cfs_period_us 和 cpu.cfs_quota_us 来限制该组中的所有进程在单位时间里可以使用的 cpu 时间。</span><br><span class="line">          cpu.cfs_period_us= 100000;  # 就是时间周期，默认为 100000，即百毫秒  值的范围： 1000-100000 </span><br><span class="line">          cpu.cfs_quota_us= 2160000;  # cpu.cfs_quota_us 就是在这期间内可使用的 cpu 时间，默认 -1，即无限制</span><br><span class="line">   &#125;   # 现在这个设置代表，这个组可以用的cpu为21.6盒，2160000/100000 </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>强制上限的可调参数</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">cpu.cfs_period_us  </span><br><span class="line">此参数可以设定重新分配 cgroup 可用 CPU 资源的时间间隔，单位为微秒（µs，这里以 “us” 表示）。如果一个 cgroup 中的任务在每 1 秒钟内有 0.2 秒的时间可存取一个单独的 CPU，则请将 cpu.rt_runtime_us 设定为 2000000，并将 cpu.rt_period_us 设定为 1000000。cpu.cfs_quota_us 参数的上限为 1 秒，下限为 1000 微秒。</span><br><span class="line"></span><br><span class="line">cpu.cfs_quota_us</span><br><span class="line">此参数可以设定在某一阶段（由 cpu.cfs_period_us 规定）某个 cgroup 中所有任务可运行的时间总量，单位为微秒（µs，这里以 &quot;us&quot; 代表）。一旦 cgroup 中任务用完按配额分得的时间，它们就会被在此阶段的时间提醒限制流量，并在进入下阶段前禁止运行。如果 cgroup 中任务在每 1 秒内有 0.2 秒，可对单独 CPU 进行存取，请将 cpu.cfs_quota_us 设定为 200000，cpu.cfs_period_us 设定为 1000000。请注意，配额和时间段参数都根据 CPU 来操作。例如，如要让一个进程完全利用两个 CPU，请将 cpu.cfs_quota_us 设定为 200000，cpu.cfs_period_us 设定为 100000。</span><br><span class="line"></span><br><span class="line">如将 cpu.cfs_quota_us 的值设定为 -1，这表示 cgroup 不需要遵循任何 CPU 时间限制。这也是每个 cgroup 的默认值（root cgroup 除外）。</span><br></pre></td></tr></table></figure><h4 id="启动cgroup服务"><a href="#启动cgroup服务" class="headerlink" title="启动cgroup服务"></a>启动cgroup服务</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">service cgroup restart</span><br><span class="line">chkconfig cgroup on</span><br></pre></td></tr></table></figure><h4 id="启动-yarn-服务"><a href="#启动-yarn-服务" class="headerlink" title="启动 yarn 服务"></a>启动 yarn 服务</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">su - hadoop</span><br><span class="line">yarn-daemon.sh stop nodemanager</span><br><span class="line">cgexec -g cpu:yarn yarn-daemon.sh start nodemanager</span><br></pre></td></tr></table></figure><p>注释： 用cgexe启动的服务，他的子进程也会在这个cgroup组下。总体cpu加和不会超过组的设置。</p><p>查看进程在哪个组下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@db-datanode09 ~]$ ps -eo pid,cgroup,cmd</span><br><span class="line">153514 cpu:/                               /sbin/udevd -d</span><br><span class="line">153515 cpu:/                               /sbin/udevd -d</span><br><span class="line">154089 cpu:/yarn                           /usr/java/jdk1.8.0_45/bin/java -Dproc_nodemanager -Xmx4096m -Dhadoop.log.dir=/home/hadoop/apache-hadoop/hadoop/logs</span><br><span class="line"></span><br><span class="line"># 注释： cpu:/  代表在cgroup根配置下，cpu:/yarn 代表在根的yarn的配置下</span><br></pre></td></tr></table></figure><p>检查服务  </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd /sys/fs/cgroup/cpu/yarn</span><br><span class="line">cat tasks | grep &quot;nodemanager PID&quot;</span><br></pre></td></tr></table></figure><p>这是在 /cgroup/cpu/ 目录下就会出现 yarn 目录， 权限是hadoop用户</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[root@db-datanode09 cpu]# cd /cgroup/cpu/yarn</span><br><span class="line">[root@db-datanode09 yarn]# ls -l</span><br><span class="line">total 0</span><br><span class="line">--w--w---- 1 hadoop hadoop 0 Aug  1 14:19 cgroup.event_control</span><br><span class="line">-rw-rw-r-- 1 hadoop hadoop 0 Aug  1 14:19 cgroup.procs</span><br><span class="line">-rw-rw-r-- 1 hadoop hadoop 0 Aug  1 14:19 cpu.cfs_period_us</span><br><span class="line">-rw-rw-r-- 1 hadoop hadoop 0 Aug  1 14:19 cpu.cfs_quota_us</span><br><span class="line">-rw-rw-r-- 1 hadoop hadoop 0 Aug  1 14:19 cpu.rt_period_us</span><br><span class="line">-rw-rw-r-- 1 hadoop hadoop 0 Aug  1 14:19 cpu.rt_runtime_us</span><br><span class="line">-rw-rw-r-- 1 hadoop hadoop 0 Aug  1 14:19 cpu.shares</span><br><span class="line">-r--r--r-- 1 hadoop hadoop 0 Aug  1 14:19 cpu.stat</span><br><span class="line">-rw-rw-r-- 1 hadoop hadoop 0 Aug  1 14:19 notify_on_release</span><br><span class="line">-rw-rw-r-- 1 hadoop hadoop 0 Aug  1 14:22 tasks</span><br></pre></td></tr></table></figure><hr><h2 id="cgroup服务几种模式介绍"><a href="#cgroup服务几种模式介绍" class="headerlink" title="cgroup服务几种模式介绍"></a>cgroup服务几种模式介绍</h2><h4 id="cgroup-配置文件说明"><a href="#cgroup-配置文件说明" class="headerlink" title="cgroup 配置文件说明"></a>cgroup 配置文件说明</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">mount &#123;</span><br><span class="line">       cpuset  = /cgroup/cpuset;为cgroup中的任务分配独立的cpu</span><br><span class="line">       cpu     = /cgroup/cpu;使用调度程序对cpu的使用控制</span><br><span class="line">       cpuacct = /cgroup/cpuacct;自动生成cgroup中的cpu使用的报告</span><br><span class="line">       memory  = /cgroup/memory;管理任务的内存</span><br><span class="line">       devices = /cgroup/devices;允许或拒绝cgroup中的任务访问设备</span><br><span class="line">       freezer = /cgroup/freezer;挂起或者恢复任务</span><br><span class="line">       net_cls = /cgroup/net_cls;控制网络流量</span><br><span class="line">       blkio   = /cgroup/blkio;为块设备输入输出设置，比如物理设备(磁盘，usb等)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="cpu限制"><a href="#cpu限制" class="headerlink" title="cpu限制"></a>cpu限制</h4><p>cgroup中对cpu资源控制的方式大约有三种：  </p><p>1.通过cpu子系统中的cpu quote方式</p><p>2.通过cpu子系统中的cpu share方式</p><p>3.通过cpuset子系统中的cpuset 将任务绑定到相应的cpu核上</p><p>cpuset的方式是限定任务可以在哪些cpu上运行；cpu share的方式，是在控制群组中设置权重，通过权重和任务等来分配能够使用cpu的资源；</p><h6 id="通过cpu-quote方式来限制"><a href="#通过cpu-quote方式来限制" class="headerlink" title="通过cpu quote方式来限制"></a>通过cpu quote方式来限制</h6><p>启动cgroup服务后，可以在/cgroup/cpu目录下看到如下文件：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">total 0</span><br><span class="line">--w--w--w- 1 root   root   0 Jul 26 11:44 cgroup.event_control</span><br><span class="line">-rw-r--r-- 1 root   root   0 Jul 26 11:44 cgroup.procs</span><br><span class="line">-rw-r--r-- 1 root   root   0 Jul 26 11:44 cpu.cfs_period_us</span><br><span class="line">-rw-r--r-- 1 root   root   0 Jul 26 11:44 cpu.cfs_quota_us</span><br><span class="line">-rw-r--r-- 1 root   root   0 Jul 26 11:44 cpu.rt_period_us</span><br><span class="line">-rw-r--r-- 1 root   root   0 Jul 26 11:44 cpu.rt_runtime_us</span><br><span class="line">-rw-r--r-- 1 root   root   0 Jul 26 11:44 cpu.shares</span><br><span class="line">-r--r--r-- 1 root   root   0 Jul 26 11:44 cpu.stat</span><br><span class="line">-rw-r--r-- 1 root   root   0 Jul 26 11:44 notify_on_release</span><br><span class="line">-rw-r--r-- 1 root   root   0 Jul 26 11:44 release_agent</span><br><span class="line">-rw-r--r-- 1 root   root   0 Jul 26 11:44 tasks</span><br></pre></td></tr></table></figure><p>这里做一下说明：</p><p>cpu.cfs_period_us： 单位是微秒，最大值是1s，最小值是1毫秒(ms),取值范围为1000-1000000</p><p>cpu.cfs_quota_us 单位是微秒，意思是在 cpu.cfs_period_us的时间内，用户可以占用的时间。对于单核来说，最大等于 cpu.cfs_period_us的值，对于多核来说，可以理解为最多可使用的cpu核数</p><p>cpu.stat:</p><p>nr_periods 时间间隔， 指经过了多少个cpu.cfs_period_us的时间间隔 nr_throttled 被限制运行的次数 throttled_time 总共被限制的时间，微秒</p><p>在多核的系统中， cpu.cfs_quota_us/cpu.cfs_period_us 的值就是可以使用的最大的cpu的核数</p><p>tasks 将需要控制的任务的id写入到tasks文件中，就可以控制资源了</p><h6 id="分组"><a href="#分组" class="headerlink" title="分组"></a>分组</h6><p>cpu限制也有分组、分层的概念，<br>如： /cgroup/cpu  这是cpu的根级，默认不限制cpu使用量，<br>  /cgroup/cpu/yarn 这是cpu下的一层，也是一个组，他的cpu使用量不能大于上一层设置。<br>  还可以在/cgroup/cpu/yarn 下创建其他层。</p><h6 id="进程添加到控制组"><a href="#进程添加到控制组" class="headerlink" title="进程添加到控制组"></a>进程添加到控制组</h6><ol><li>单一pid添加到某个控制组<br> echo pid &gt; /cgroup/cpu/yarn/tasks</li><li>cgrule服务<br>用法：  </li></ol><p>user hierarchies control_group<br>user:command hierarchies control_group<br>当在user 使用前缀时代表是一个组群而不是单独用户例如@admins 是admins组群中的所有用户<br>cgrule配置文件在/etc/cgrule.conf,配置好启动服务后就可以根据规则自动将任务附加到控制群组了。</p><p>如：<br>vim /etc/cgrule.conf</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"># Example:</span><br><span class="line">#&lt;user&gt;         &lt;controllers&gt;   &lt;destination&gt;</span><br><span class="line">#@student       cpu,memory      usergroup/student/</span><br><span class="line">#peter          cpu             test1/</span><br><span class="line">#%              memory          test2/</span><br><span class="line">rd           cpu             yarn     # rd 用户所有进程的cpu限制都在yarn这个组里</span><br><span class="line">@hadoopcpuyarn  # hadoop 组里所有用户的进程cpu限制都在yarn这个组里</span><br><span class="line">mtime:scpcpuyarn  # mtime的scp命令的cpu限制在yarn这个组里</span><br></pre></td></tr></table></figure><p>启动服务：  </p><p>/etc/init.d/cgred restart  </p><ol start="3"><li>cgexec 命令启动服务<br>用法：<br>cgexec -g subsystems:path_to_cgroup command arguments<br>如：<br>cgexec -g cpu:yarn yarn-daemon.sh start nodemanager</li></ol><h3 id="redhat-cgroup"><a href="#redhat-cgroup" class="headerlink" title="redhat cgroup"></a>redhat cgroup</h3><p>关于其他资源 如 memory、network等限制，可以参考 radhat cgroup的介绍<br>地址：<br>centos 6<br> <a href="https://access.redhat.com/documentation/zh-CN/Red_Hat_Enterprise_Linux/6/html-single/Resource_Management_Guide/index.html#chap-Introduction_to_Control_Groups" target="_blank" rel="noopener">https://access.redhat.com/documentation/zh-CN/Red_Hat_Enterprise_Linux/6/html-single/Resource_Management_Guide/index.html#chap-Introduction_to_Control_Groups</a></p><p>centos 7<br><a href="https://access.redhat.com/documentation/zh-CN/Red_Hat_Enterprise_Linux/7/html-single/Resource_Management_Guide/index.html#chap-Introduction_to_Control_Groups" target="_blank" rel="noopener">https://access.redhat.com/documentation/zh-CN/Red_Hat_Enterprise_Linux/7/html-single/Resource_Management_Guide/index.html#chap-Introduction_to_Control_Groups</a></p><p>感觉文章还可以的话，帮忙点点下面的广告哦！ 谢谢支持！</p>]]></content>
      
      <categories>
          
          <category> linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> cgroup </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>kafka修改分区、副本数、副本迁移</title>
      <link href="/kafka-Modify-Partitions-and-ReplicationFactor/"/>
      <url>/kafka-Modify-Partitions-and-ReplicationFactor/</url>
      <content type="html"><![CDATA[<h2 id="kafka修改分区和副本数"><a href="#kafka修改分区和副本数" class="headerlink" title="kafka修改分区和副本数"></a>kafka修改分区和副本数</h2><h3 id="查看现在副本分配情况"><a href="#查看现在副本分配情况" class="headerlink" title="查看现在副本分配情况"></a>查看现在副本分配情况</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">../bin/kafka-topics.sh --zookeeper 127.0.0.1:2181 --describe  --topic test1</span><br><span class="line"></span><br><span class="line">Topic:test1       PartitionCount:3        ReplicationFactor:2     Configs:</span><br><span class="line">        Topic: test1      Partition: 0    Leader: 2       Replicas: 2,4   Isr: 2,4</span><br><span class="line">        Topic: test1      Partition: 1    Leader: 3       Replicas: 3,5   Isr: 3,5</span><br><span class="line">        Topic: test1      Partition: 2    Leader: 4       Replicas: 4,1   Isr: 4,1</span><br></pre></td></tr></table></figure><h3 id="topic-分区扩容"><a href="#topic-分区扩容" class="headerlink" title="topic 分区扩容"></a>topic 分区扩容</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./kafka-topics.sh --zookeeper 127.0.0.1:2181 -alter --partitions 4 --topic test1</span><br></pre></td></tr></table></figure><h3 id="修改副本数量、副本迁移"><a href="#修改副本数量、副本迁移" class="headerlink" title="修改副本数量、副本迁移"></a>修改副本数量、副本迁移</h3><h4 id="这个文件自己创建-格式按照下面的格式就可以了"><a href="#这个文件自己创建-格式按照下面的格式就可以了" class="headerlink" title="这个文件自己创建 格式按照下面的格式就可以了"></a>这个文件自己创建 格式按照下面的格式就可以了</h4><p>根据topic的分区情况自行修改 partitions-topic.json 文件配置  </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">        &quot;partitions&quot;:</span><br><span class="line">                [</span><br><span class="line">                &#123;</span><br><span class="line">                        &quot;topic&quot;: &quot;test1&quot;,</span><br><span class="line">                        &quot;partition&quot;: 0,</span><br><span class="line">                        &quot;replicas&quot;: [1,2]</span><br><span class="line">                &#125;,</span><br><span class="line">                &#123;</span><br><span class="line">                        &quot;topic&quot;: &quot;test1&quot;,</span><br><span class="line">                        &quot;partition&quot;: 1,</span><br><span class="line">                        &quot;replicas&quot;: [0,3]</span><br><span class="line">                &#125;,</span><br><span class="line">                &#123;</span><br><span class="line">                        &quot;topic&quot;: &quot;test1&quot;,</span><br><span class="line">                        &quot;partition&quot;: 2,</span><br><span class="line">                        &quot;replicas&quot;: [4,5]</span><br><span class="line">                &#125;</span><br><span class="line">                ],</span><br><span class="line">        &quot;version&quot;:1</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="执行副本搬迁"><a href="#执行副本搬迁" class="headerlink" title="执行副本搬迁"></a>执行副本搬迁</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">../bin/kafka-reassign-partitions.sh --zookeeper 127.0.0.1:2181 --reassignment-json-file partitions-topic.json --execute</span><br></pre></td></tr></table></figure><h4 id="查看迁移情况："><a href="#查看迁移情况：" class="headerlink" title="查看迁移情况："></a>查看迁移情况：</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">../bin/kafka-reassign-partitions.sh --zookeeper 127.0.0.1:2181 --reassignment-json-file partitions-topic.json --verify</span><br><span class="line"></span><br><span class="line">Status of partition reassignment:</span><br><span class="line">Reassignment of partition [mx_prd_nginx_access,0] is still in progress</span><br><span class="line">Reassignment of partition [mx_prd_nginx_access,1] completed successfully</span><br><span class="line">Reassignment of partition [mx_prd_nginx_access,2] is still in progress</span><br></pre></td></tr></table></figure><h4 id="注释"><a href="#注释" class="headerlink" title="注释"></a>注释</h4><p>kafka-reassign-partitions.sh工具来重新分布分区。该工具有三种使用模式：  </p><ol><li>generate模式，给定需要重新分配的Topic，自动生成reassign plan（并不执行）</li><li>execute模式，根据指定的reassign plan重新分配Partition</li><li>verify模式，验证重新分配Partition是否成功</li></ol><p>感觉文章还可以的话，帮忙点点下面的广告哦！ 谢谢支持！</p>]]></content>
      
      <categories>
          
          <category> kafka </category>
          
      </categories>
      
      
        <tags>
            
            <tag> kafka </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>docker搭建macvlan网络</title>
      <link href="/docker-build-MacVlanNetwork/"/>
      <url>/docker-build-MacVlanNetwork/</url>
      <content type="html"><![CDATA[<h2 id="docker-搭建macvlan-网络"><a href="#docker-搭建macvlan-网络" class="headerlink" title="docker 搭建macvlan 网络"></a>docker 搭建macvlan 网络</h2><p>  简单说，macvlan就是在宿主的网卡设置多个vlan信息，根据走的网卡不同，并带有不行的vlan标记。  </p><h3 id="交换机需要支持"><a href="#交换机需要支持" class="headerlink" title="交换机需要支持"></a>交换机需要支持</h3><p>macvlan需要交换机上有几个设置：  </p><ul><li>连接宿主的交换机接口需要改为 Trunk 模式。（这样才能多vlan通过这个口通讯）</li><li>交换机上添加macvlan设置的相应vlan信息。</li><li>三层交换机上设置各个vlan的网关地址。并实现vlan间互联。</li></ul><h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><p>环境介绍<br><a id="more"></a><br>宿主机IP|宿主机vlan|macvlan IP| vlan 号<br>—|—|—|—<br>192.168.53.11|233|172.20.30.x|30<br>192.168.53.12|233|172.20.19.x|19</p><h4 id="实时生效安装"><a href="#实时生效安装" class="headerlink" title="实时生效安装"></a>实时生效安装</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">yum install -y epel-release</span><br><span class="line">yum install -y vconfig</span><br><span class="line">加载模块哦</span><br><span class="line">modprobe 8021q</span><br><span class="line">lsmod |grep -i 8021q</span><br><span class="line">网卡开启混合模式</span><br><span class="line">ip link set em1 promisc on</span><br><span class="line">使用vconfig命令配置vlan </span><br><span class="line">vconfig add em1 233 </span><br><span class="line">vconfig add em1 30   # 另外一台设置  vconfig add em1 19</span><br><span class="line">在em1接口上配置两个VLAN </span><br><span class="line">vconfig set_flag em1.233 1 1 </span><br><span class="line">vconfig set_flag em1.30 1 1   # 另外一台 vconfig set_flag em1.19 1 1</span><br><span class="line"></span><br><span class="line">ifconfig em1 0.0.0.0 </span><br><span class="line">ifconfig em1.233 192.168.53.11 netmask 255.255.255.0 up </span><br><span class="line">ifconfig em1.30 172.20.30.2 netmask 255.255.255.0 up</span><br></pre></td></tr></table></figure><p>这样一个临时配置就可以了， 配置docker的网络就可以，docker配置网络的命令后面一起发吧，  </p><p>上面属于临时配置，机器重启配置就没有了，不适合生产。</p><h4 id="永久配置"><a href="#永久配置" class="headerlink" title="永久配置"></a>永久配置</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">um install -y epel-release</span><br><span class="line">yum install -y vconfig</span><br></pre></td></tr></table></figure><p>添加模块<br>vim /etc/rc.d/rc.local 添加  </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/sbin/modprobe 8021q</span><br></pre></td></tr></table></figure><p>网卡开启混合模式</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">echo &quot;PROMISC=yes&quot; &gt;&gt; /etc/sysconfig/network-scripts/ifcfg-em1</span><br></pre></td></tr></table></figure><p>修改王凯配置文件<br>vim /etc/sysconfig/network-scripts/ifcfg-em1</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">DEVICE=em1</span><br><span class="line">NAME=em1</span><br><span class="line">TYPE=Ethernet</span><br><span class="line">BONDING_MASTER=yes</span><br><span class="line">ONBOOT=yes</span><br><span class="line">BOOTPROTO=none</span><br><span class="line">PEERDNS=yes</span><br><span class="line">PROMISC=yes</span><br></pre></td></tr></table></figure><p>生成 macvlan 网卡</p><p>vim /etc/sysconfig/network-scripts/ifcfg-em1.233</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">DEVICE=em1.233</span><br><span class="line">NAME=em1.233</span><br><span class="line">ONBOOT=yes</span><br><span class="line">IPADDR=192.168.53.11</span><br><span class="line">NETMASK=255.255.255.0</span><br><span class="line">GATEWAY=192.168.53.1</span><br><span class="line">BOOTPROTO=static</span><br><span class="line">VLAN=yes</span><br><span class="line">NM_CONTROLLED=no</span><br></pre></td></tr></table></figure><p>vim /etc/sysconfig/network-scripts/ifcfg-em1.30</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">DEVICE=em1.30</span><br><span class="line">NAME=em1.30</span><br><span class="line">ONBOOT=yes</span><br><span class="line">BOOTPROTO=static</span><br><span class="line">VLAN=yes</span><br><span class="line">NM_CONTROLLED=no</span><br></pre></td></tr></table></figure><p>另外一台 其他配置都一样， ifcfg-em1.30 网卡信息修改为 ifcfg-em1.19 即可。  </p><p>之后重启网卡，如果配置没有问题，网络是可以连接的。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/etc/init.d/network restart</span><br></pre></td></tr></table></figure><p>以后新添加vlan的时候，也可以先做好配置文件。直接ifup即可。<br>ifup /etc/sysconfig/network-scripts/ifcfg-em1.19</p><p>网络信息</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">[root@wd-slave01 ~]# ifconfig</span><br><span class="line">em1: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500</span><br><span class="line">        inet6 fe80::d6be:d9ff:feae:80cf  prefixlen 64  scopeid 0x20&lt;link&gt;</span><br><span class="line">        ether d4:be:d9:ae:80:cf  txqueuelen 1000  (Ethernet)</span><br><span class="line">        RX packets 108408  bytes 17234693 (16.4 MiB)</span><br><span class="line">        RX errors 0  dropped 11508  overruns 0  frame 0</span><br><span class="line">        TX packets 24225  bytes 4849942 (4.6 MiB)</span><br><span class="line">        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0</span><br><span class="line">        </span><br><span class="line">docker0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500</span><br><span class="line">        inet 172.17.0.1  netmask 255.255.0.0  broadcast 0.0.0.0</span><br><span class="line">        inet6 fe80::42:87ff:fecd:c222  prefixlen 64  scopeid 0x20&lt;link&gt;</span><br><span class="line">        ether 02:42:87:cd:c2:22  txqueuelen 0  (Ethernet)</span><br><span class="line">        RX packets 458940  bytes 71009715 (67.7 MiB)</span><br><span class="line">        RX errors 0  dropped 0  overruns 0  frame 0</span><br><span class="line">        TX packets 198525  bytes 55224280 (52.6 MiB)</span><br><span class="line">        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0</span><br><span class="line"></span><br><span class="line">em1.233: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500</span><br><span class="line">        inet 192.168.53.12  netmask 255.255.255.0  broadcast 192.168.53.255</span><br><span class="line">        inet6 fe80::d6be:d9ff:feae:80cf  prefixlen 64  scopeid 0x20&lt;link&gt;</span><br><span class="line">        ether d4:be:d9:ae:80:cf  txqueuelen 1000  (Ethernet)</span><br><span class="line">        RX packets 108408  bytes 17234693 (16.4 MiB)</span><br><span class="line">        RX errors 0  dropped 11508  overruns 0  frame 0</span><br><span class="line">        TX packets 24225  bytes 4849942 (4.6 MiB)</span><br><span class="line">        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0</span><br><span class="line"></span><br><span class="line">em1.30: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500</span><br><span class="line">        inet6 fe80::d6be:d9ff:feae:80cf  prefixlen 64  scopeid 0x20&lt;link&gt;</span><br><span class="line">        ether d4:be:d9:ae:80:cf  txqueuelen 1000  (Ethernet)</span><br><span class="line">        RX packets 2133458  bytes 245138875 (233.7 MiB)</span><br><span class="line">        RX errors 0  dropped 0  overruns 0  frame 0</span><br><span class="line">        TX packets 1343034  bytes 151915911 (144.8 MiB)</span><br><span class="line">        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0</span><br></pre></td></tr></table></figure><h4 id="docker-配置网络"><a href="#docker-配置网络" class="headerlink" title="docker 配置网络"></a>docker 配置网络</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker network create -d macvlan --subnet=172.20.30.0 --gateway=172.20.30.1 -o parent=em1.30 mac_net1</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">docker network ls   查看网络情况    </span><br><span class="line">docker network inspect 074ebc238447  查看网络详细信息及ip地址分配清凉</span><br></pre></td></tr></table></figure><p>启动容器   指定IP 指定网络  </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">docker run -d --name test1 --ip=172.55.55.10 --network mac_net1 nginx-nettools:1.13  </span><br><span class="line">或动态分配</span><br><span class="line">docker run -d --name test2  --network mac_net1 nginx-nettools:1.13</span><br></pre></td></tr></table></figure><p>限制分配ip地址池</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">docker network create -d macvlan --subnet=172.20.30.0/24 --gateway=172.20.30.1 --ip-range=172.20.30.48/30 -o parent=em1.20 mac_net30</span><br><span class="line">这样只能分配4个ip地址</span><br><span class="line">172.20.30.128/25 也就是 128-255 可得 128个ip地址</span><br></pre></td></tr></table></figure><p>感觉文章还可以的话，帮忙点点下面的广告哦！ 谢谢支持！</p>]]></content>
      
      <categories>
          
          <category> docker </category>
          
      </categories>
      
      
        <tags>
            
            <tag> docker </tag>
            
            <tag> macvlan </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>linux 删除乱码文件</title>
      <link href="/linux-Delete-garbled-files/"/>
      <url>/linux-Delete-garbled-files/</url>
      <content type="html"><![CDATA[<h2 id="linux-利用-inum-删除乱码文件"><a href="#linux-利用-inum-删除乱码文件" class="headerlink" title="linux 利用 inum 删除乱码文件"></a>linux 利用 inum 删除乱码文件</h2><p>  当系统中产生一些乱码文件的时候，rm直接是删除不掉的。如 “-，&amp;”等一些特殊字符。<br>  这时候我们可以利用linux 的inum 号来找到这个文件，并删除。</p><p>  例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@test00 ~]# ll -i</span><br><span class="line">总用量 4</span><br><span class="line">   213388 -rw-r--r--. 1 root root    0 6月   4 07:40 -c</span><br><span class="line">134938544 drwxr-xr-x. 2 root root   23 12月 18 05:12 123</span><br><span class="line">   213391 -rw-r--r--. 1 root root    0 6月   4 07:40 --poolmetadata</span><br><span class="line">   213390 -rw-r--r--. 1 root root    0 6月   4 07:40 --thinpool</span><br><span class="line">   213387 -rw-r--r--. 1 root root    0 6月   4 07:40 --zero</span><br></pre></td></tr></table></figure><p>利用inum 号删除文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">删除文件或文件夹</span><br><span class="line">find ./ -inum 213388 -print -exec rm &#123;&#125; -rf \;</span><br><span class="line">删除文件</span><br><span class="line">find ./ -inum 213388 -delete;</span><br></pre></td></tr></table></figure><p>也可以重命名乱码文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">find ./ -inum 213388 -exec mv &#123;&#125; newfile \;</span><br></pre></td></tr></table></figure><p>文件名字就改为了 newfile</p>]]></content>
      
      <categories>
          
          <category> linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> linux </tag>
            
            <tag> rm </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>logstash out file to HDFS</title>
      <link href="/logstash-out-file-to-HDFS/"/>
      <url>/logstash-out-file-to-HDFS/</url>
      <content type="html"><![CDATA[<h2 id="logstash-out-file-to-HDFS"><a href="#logstash-out-file-to-HDFS" class="headerlink" title="logstash out file to HDFS"></a>logstash out file to HDFS</h2><p>  logstash 直接把文件内容写入 hdfs 中， 并支持 hdfs 压缩格式。<br>  logstash 需要安装第三方插件，webhdfs插件，通过hdfs的web接口写入。<br>  即 <a href="http://namenode00:50070/webhdfs/v1/" target="_blank" rel="noopener">http://namenode00:50070/webhdfs/v1/</a>  接口  </p><h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><p>  可以在官网找到相应的版本， 我们用的是2.3.1，下载地址：  </p><pre><code>https://www.elastic.co/downloads/past-releases  </code></pre><p>  webhdfs插件地址  </p><pre><code>github地址：  git clone  https://github.com/heqin5136/logstash-output-webhdfs-discontinued.git官网地址及使用说明：  https://www.elastic.co/guide/en/logstash/current/plugins-outputs-webhdfs.html</code></pre><a id="more"></a><p>插件安装方式：</p><pre><code>logstash 安装在 /home/mtime/logstash-2.3.1git clone  https://github.com/heqin5136/logstash-output-webhdfs-discontinued.gitcd logstash-output-webhdfs-discontinued/home/mtime/logstash-2.3.1/bin/plugin install logstash-output-webhdfs-discontinued</code></pre><p>检查hdfs的webhds接口</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">   curl -i  &quot;http://namenode:50070/webhdfs/v1/?user.name=hadoop&amp;op=LISTSTATUS&quot;   </span><br><span class="line">   </span><br><span class="line">HTTP/1.1 200 OK</span><br><span class="line">Cache-Control: no-cache</span><br><span class="line">Expires: Thu, 13 Jul 2017 04:53:39 GMT</span><br><span class="line">Date: Thu, 13 Jul 2017 04:53:39 GMT</span><br><span class="line">Pragma: no-cache</span><br><span class="line">Expires: Thu, 13 Jul 2017 04:53:39 GMT</span><br><span class="line">Date: Thu, 13 Jul 2017 04:53:39 GMT</span><br><span class="line">Pragma: no-cache</span><br><span class="line">Content-Type: application/json</span><br><span class="line">Set-Cookie: hadoop.auth=&quot;u=hadoop&amp;p=hadoop&amp;t=simple&amp;e=1499957619679&amp;s=KSxdSAtjXAllhn73vh1MAurG9Bk=&quot;; Path=/; Expires=Thu, 13-Jul-2017 14:53:39 GMT; HttpOnly</span><br><span class="line">Transfer-Encoding: chunked</span><br><span class="line">Server: Jetty(6.1.26)</span><br></pre></td></tr></table></figure><p>注释： active namenode 返回是200 ，standby namenode 返回是403.</p><h3 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h3><p>添加 logstash 一个配置文件</p><p>vim /home/mtime/logstash-2.3.1/conf/hdfs.conf</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">input &#123;</span><br><span class="line">  kafka &#123;</span><br><span class="line">    zk_connect =&gt; &quot;192.168.51.191:2181,192.168.51.192:2181,192.168.51.193:2181&quot;   ## kafka zk 地址 </span><br><span class="line">    group_id =&gt; &apos;hdfs&apos;   # 消费者组</span><br><span class="line">    topic_id =&gt; &apos;tracks&apos;  # topic 名字</span><br><span class="line">    consumer_threads =&gt; 1  </span><br><span class="line">    codec =&gt; &apos;json&apos;  </span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">filter &#123;   ##  为解决 插入hdfs时间相差8小时， </span><br><span class="line">        date &#123;  </span><br><span class="line">                match =&gt; [ &quot;time&quot; , &quot;yyyy-MM-dd HH:mm:ss&quot; ]</span><br><span class="line">                locale =&gt; &quot;zh&quot;</span><br><span class="line">                timezone =&gt; &quot;-00:00:00&quot;</span><br><span class="line">                target =&gt; &quot;@timestamp&quot;</span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">output &#123;</span><br><span class="line">    webhdfs &#123;</span><br><span class="line">           workers =&gt; 1</span><br><span class="line">           host =&gt; &quot;namenode&quot;</span><br><span class="line">           standby_host =&gt; &quot;standbynamenode&quot;</span><br><span class="line">           port =&gt; 14000</span><br><span class="line">           user =&gt; &quot;loguser&quot;</span><br><span class="line">           path =&gt; &quot;/Service-Data/%&#123;+YYYY&#125;-%&#123;+MM&#125;-%&#123;+dd&#125;/%&#123;app&#125;/logstash-%&#123;+HH&#125;.log&quot;</span><br><span class="line">           flush_size =&gt; 10000</span><br><span class="line">           idle_flush_time =&gt; 10</span><br><span class="line">           compression =&gt; &quot;gzip&quot;</span><br><span class="line">           retry_interval =&gt; 3</span><br><span class="line">           codec =&gt; &apos;json&apos;   # 解决 写入hdfs文件是json格式，否则内容为 %&#123;message&#125;</span><br><span class="line">       &#125;</span><br><span class="line">  # stdout &#123; codec =&gt; rubydebug &#125; # 打开日志</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>关于hdfs部分配置，可以在 <a href="https://www.elastic.co/guide/en/logstash/current/plugins-outputs-webhdfs.html" target="_blank" rel="noopener">plugins-outputs-webhdfs</a>  官网找到。</p><h3 id="启动-logstart"><a href="#启动-logstart" class="headerlink" title="启动 logstart"></a>启动 logstart</h3><pre><code>cd /home/mtime/logstash-2.3.1/bin/./logstash -f ../conf/hdfs.conf    # 为前台启动 </code></pre><h2 id="问题总结"><a href="#问题总结" class="headerlink" title="问题总结"></a>问题总结</h2><ul><li>新版logstash已经支持webhdfs插件，可以直接安装啦。</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./logstash-plugin install logstash-output-webhdfs</span><br></pre></td></tr></table></figure><ul><li>报错处理</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[WARN ][logstash.outputs.webhdfs ] Failed to flush outgoing items &#123;:outgoing_count=&gt;160, :exception=&gt;&quot;WebHDFS::IOError&quot;,</span><br></pre></td></tr></table></figure><p>我将hdfs端口 由原来的50070 改为 14000 端口，就在不报错了。<br>官方提供的例子中用的就是50070端口，一直没有尝试14000端口。</p><p>还有：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">because this file lease is currently owned by DFSClient</span><br></pre></td></tr></table></figure><p>hadoop 租约问题，后期正常就没有了。<br> 执行recoverLease来释放文件的锁</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hdfs debug recoverLease -path /logstash/2017/02/10/go-03.log</span><br></pre></td></tr></table></figure><p>还有：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">:message=&gt;&quot;webhdfs write caused an exception: &#123;\&quot;RemoteException\&quot;:&#123;\&quot;message\&quot;:\&quot;Failed to APPEND_FILE</span><br></pre></td></tr></table></figure><p>当一个进程在读写这个文件的时候，另一个进程应该是不能同时写入的。<br>我们由原来3个logstash同时消费，改为了1个logstash消费，不在报错了。<br>这个应该也可以通过有话写入hdfs参数来解决。</p><p>还有：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Max write retries reached. Exception: initialize: name or service not known &#123;:level=&gt;:error&#125;</span><br></pre></td></tr></table></figure><p>losgstash 需要能解析所有 hadoop 集群所有节点的主机名。</p><p>感觉文章还可以的话，帮忙点点下面的广告哦！ 谢谢支持！</p>]]></content>
      
      <categories>
          
          <category> logstash </category>
          
      </categories>
      
      
        <tags>
            
            <tag> logstash </tag>
            
            <tag> hdfs </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>mesos容器映射端口限制</title>
      <link href="/mesos-container-port-limit/"/>
      <url>/mesos-container-port-limit/</url>
      <content type="html"><![CDATA[<h2 id="mesos-容器映射端口限制"><a href="#mesos-容器映射端口限制" class="headerlink" title="mesos 容器映射端口限制"></a>mesos 容器映射端口限制</h2><h3 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h3><p>  mesos 在启动容器的时候，理念是容器内的端都映射到宿主的随机端口。<br>  在容器的时代，其实这样的理念是很好，当容器多的时候，固定端口肯定是有一定的局限性的。可以通过注册中心、mesos-dns、marathon-lb等服务来找到你要的服务地址和端口。<br>  但是有时候有一些服务需要一些固定端口。比如cadvisor、还有我们自己写的容器，可能会映射一些其他端口。  </p><h3 id="默认端口限制"><a href="#默认端口限制" class="headerlink" title="默认端口限制"></a>默认端口限制</h3><p>  默认mesos的端口也是可以指定的，只是范围比较小。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">31000 - 32000</span><br></pre></td></tr></table></figure><p>  marahotn 的json 文件中，你可以写。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&quot;portMappings&quot;: [</span><br><span class="line">  &#123;</span><br><span class="line">    &quot;containerPort&quot;: 80,</span><br><span class="line">    &quot;hostPort&quot;: 31000,  # 一般设置 0 为随机端口，</span><br><span class="line">    &quot;servicePort&quot;: 0,</span><br><span class="line">    &quot;protocol&quot;: &quot;tcp&quot;</span><br><span class="line">  &#125;</span><br><span class="line">]</span><br></pre></td></tr></table></figure><p>docker 启动时候就是</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@test00 ~]# docker ps</span><br><span class="line">CONTAINER ID        IMAGE                 COMMAND                  CREATED             STATUS              PORTS                            NAMES</span><br><span class="line">70314cd31714        nginx-nettools:1.13   &quot;nginx -g &apos;daemon ...&quot;   24 minutes ago      Up 24 minutes       443/tcp, 0.0.0.0:31000-&gt;80/tcp   mesos-07a768f1-f635-4517-9b60-4e86bfef658e</span><br></pre></td></tr></table></figure><h3 id="配置mesos"><a href="#配置mesos" class="headerlink" title="配置mesos"></a>配置mesos</h3><p>yum 安装的meoss 添加配置</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">echo &quot;ports(*):[1024-65534]&quot; &gt; /etc/mesos-slave/resources</span><br></pre></td></tr></table></figure><p>重启 mesos-slave 服务</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl restart mesos-slave</span><br></pre></td></tr></table></figure><p>二进制安装的mesos 在启动命令中添加</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">--resources=ports(*):[1024-65534]</span><br></pre></td></tr></table></figure><p>这样你的端口就是在 1024 - 65524 中间随意指定了。</p><h3 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h3><p>marathon json文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&quot;portMappings&quot;: [</span><br><span class="line">  &#123;</span><br><span class="line">    &quot;containerPort&quot;: 80,</span><br><span class="line">    &quot;hostPort&quot;: 8080,</span><br><span class="line">    &quot;servicePort&quot;: 0,</span><br><span class="line">    &quot;protocol&quot;: &quot;tcp&quot;</span><br><span class="line">  &#125;</span><br><span class="line">]</span><br></pre></td></tr></table></figure><p>docker 启动时候是</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@test00 ~]# docker ps</span><br><span class="line">CONTAINER ID        IMAGE                 COMMAND                  CREATED             STATUS              PORTS                           NAMES</span><br><span class="line">1235513ee658        nginx-nettools:1.13   &quot;nginx -g &apos;daemon ...&quot;   6 minutes ago       Up 6 minutes        443/tcp, 0.0.0.0:8080-&gt;80/tcp   mesos-655d4923-0d1f-4130-8d61-aab824df3f25-S13.9e0c2cfb-3d07-467f-ac47-08e492703263</span><br></pre></td></tr></table></figure><h3 id="Q-amp-A"><a href="#Q-amp-A" class="headerlink" title="Q&amp;A"></a>Q&amp;A</h3><p>如果mesos上运行过容器，在你修改配置文件之后重启会有问题。  </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">你可以通过</span><br><span class="line">journalctl -xe</span><br><span class="line">或</span><br><span class="line">查看mesos的log日志 找到问题</span><br></pre></td></tr></table></figure><p>解决方法： 日志中会有提示</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">To remedy this do as follows:</span><br><span class="line">Step 1: rm -f /home/mtime/mesos/meta/slaves/latest</span><br><span class="line">        This ensures agent doesn&apos;t recover old live executors.</span><br><span class="line">  ep 2: Restart the agent.</span><br></pre></td></tr></table></figure><p>rm -f /home/mtime/mesos/meta/slaves/latest<br>删除之后在重启即可。</p>]]></content>
      
      <categories>
          
          <category> mesos </category>
          
      </categories>
      
      
        <tags>
            
            <tag> mesos </tag>
            
            <tag> port </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>marathon私有仓库用户名和密码方式</title>
      <link href="/marathon-DockerRegistry-user/"/>
      <url>/marathon-DockerRegistry-user/</url>
      <content type="html"><![CDATA[<h1 id="marathon-使用仓库用户名和密码方式"><a href="#marathon-使用仓库用户名和密码方式" class="headerlink" title="marathon 使用仓库用户名和密码方式"></a>marathon 使用仓库用户名和密码方式</h1><h2 id="首先需要本地手动登入镜像仓库。"><a href="#首先需要本地手动登入镜像仓库。" class="headerlink" title="首先需要本地手动登入镜像仓库。"></a>首先需要本地手动登入镜像仓库。</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># docker login registry.inc-test.com</span><br><span class="line">   Username: admin </span><br><span class="line">   Password: Default@123</span><br></pre></td></tr></table></figure><p>登入成功之后会在当前用户的家目录创建一个隐藏目录 ~/.docker ，打包这么目录，放在一个目录下， 并让marathon启动容器的时候引用这个文件即可。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># cd ~</span><br><span class="line"># tar czf docker.tar.gz .docker</span><br><span class="line"></span><br><span class="line"># cp docker.tar.gz /etc/</span><br></pre></td></tr></table></figure><h2 id="marathon-json-启动容器引用验证文件"><a href="#marathon-json-启动容器引用验证文件" class="headerlink" title="marathon json 启动容器引用验证文件"></a>marathon json 启动容器引用验证文件</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&quot;uris&quot;: [</span><br><span class="line">   &quot;file:///etc/docker.tar.gz&quot;</span><br><span class="line">]</span><br></pre></td></tr></table></figure><p>注释：  </p><ul><li>这样需要每台mesos slave机器都需要放置这个文件，实际操作很不灵活，</li><li>而且用户切换也不好做，每台机器需要放不不用户的验证文件。</li><li>如果用户密码修改，还需要批量修改每台slave机器上的验证文件。</li></ul><h2 id="结论："><a href="#结论：" class="headerlink" title="结论："></a>结论：</h2><ul><li>把这个文件放在http页面上，只要网络通就可以访问，不需要每台机器都配置验证文件，修改也比较访问。</li></ul><p>把docker.tar.gz文件放在http页面中</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">scp /etc/docker.tar.gz 10.10.130.201:/var/www/html/download/docker_img/harbor-admin.tar.gz</span><br><span class="line"></span><br><span class="line"># 一个用户手动生成一个文件，如需要切换用户的时候指定不同文件即可。</span><br></pre></td></tr></table></figure><h2 id="例如："><a href="#例如：" class="headerlink" title="例如："></a>例如：</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;id&quot;: &quot;nginx&quot;,</span><br><span class="line">    &quot;cpus&quot;: 0.2,</span><br><span class="line">    &quot;mem&quot;: 128,</span><br><span class="line">    &quot;instances&quot;: 1,</span><br><span class="line">    &quot;constraints&quot;: [</span><br><span class="line">        [</span><br><span class="line">            &quot;hostname&quot;,</span><br><span class="line">            &quot;CLUSTER&quot;,</span><br><span class="line">            &quot;es02.host-test.com&quot;</span><br><span class="line">        ]</span><br><span class="line">    ],</span><br><span class="line">    &quot;uris&quot;: [</span><br><span class="line">        &quot;http://10.10.130.201/download/docker_img/harbor-admin.tar.gz&quot;</span><br><span class="line">    ],</span><br><span class="line">    &quot;container&quot;: &#123;</span><br><span class="line">        &quot;type&quot;: &quot;DOCKER&quot;,</span><br><span class="line">        &quot;docker&quot;: &#123;</span><br><span class="line">            &quot;image&quot;: &quot;registry.inc-test.com/web-lb/nginx:1.13&quot;,</span><br><span class="line">            &quot;network&quot;: &quot;BRIDGE&quot;,</span><br><span class="line">            &quot;portMappings&quot;: [</span><br><span class="line">                &#123;</span><br><span class="line">                    &quot;containerPort&quot;: 80,</span><br><span class="line">                    &quot;hostPort&quot;: 31009,</span><br><span class="line">                    &quot;servicePort&quot;: 0,</span><br><span class="line">                    &quot;protocol&quot;: &quot;tcp&quot;</span><br><span class="line">                &#125;</span><br><span class="line">            ]</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>marathon 官网说明 <a href="https://mesosphere.github.io/marathon/docs/native-docker-private-registry.html" target="_blank" rel="noopener">https://mesosphere.github.io/marathon/docs/native-docker-private-registry.html</a></p>]]></content>
      
      <categories>
          
          <category> marathon </category>
          
      </categories>
      
      
        <tags>
            
            <tag> marathon </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>mesos解决sandbox日志切分问题</title>
      <link href="/mesos-sandbox-split/"/>
      <url>/mesos-sandbox-split/</url>
      <content type="html"><![CDATA[<h1 id="mesos-解决sandbox日志切分问题"><a href="#mesos-解决sandbox日志切分问题" class="headerlink" title="mesos 解决sandbox日志切分问题"></a>mesos 解决sandbox日志切分问题</h1><p>mesos运行的docker容器，容器打印到前台console的日志会记录到mesos的work目录中容器沙箱中stdout和stderr文件中，容器不重启，日志会一直变大，这样会到只宿主空间变大。  </p><p>另外这份日志还会日志到系统的/var/log/messages 文件中。  </p><p>首先关于 mesos-slave 的 work-dir 中设置的目录，里面存放的docker容器的沙箱目录，会有 stderr\stdout等文件，其中这两个文件是记录容器console的日志，会一直保留，直到容器销毁，这样日志文件会持续增大。</p><p>为解决这个问题问题。mesos 没有明确的配置。 <a href="http://mesos.apache.org/documentation/latest/logging/" target="_blank" rel="noopener">http://mesos.apache.org/documentation/latest/logging/</a> 文章中有提到沙箱大小的设置，但是没有测试成功。</p><p>我的解决办法：利用系统的 logrotate 模块做日志的切分和删除。</p><p>如：添加配置文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; /etc/logrotate.d/mesos  &lt;&lt; EOF</span><br><span class="line">/home/mtime/mesos/slaves/*/frameworks/*/executors/*/runs/latest/stderr</span><br><span class="line">/home/mtime/mesos/slaves/*/frameworks/*/executors/*/runs/latest/stdout </span><br><span class="line">&#123;</span><br><span class="line">        daily</span><br><span class="line">        missingok</span><br><span class="line">        copytruncate</span><br><span class="line">        notifempty</span><br><span class="line">        size 102400</span><br><span class="line">        dateext</span><br><span class="line">        rotate 7</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>这样每天都会切分 大于 100Mb的日志了， 并保留7天。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">/usr/sbin/logrotate -d -v -f /etc/logrotate.conf</span><br><span class="line"></span><br><span class="line">-d  测试配置文件，不是真正执行。</span><br></pre></td></tr></table></figure><p>crontab  中 已经添加，logrotate 会每天执行的。/etc/cron.daily/logrotate </p>]]></content>
      
      <categories>
          
          <category> mesos </category>
          
      </categories>
      
      
        <tags>
            
            <tag> mesos </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>marathon-lb配置及nginx负载</title>
      <link href="/marathon-lb-configure-nginx/"/>
      <url>/marathon-lb-configure-nginx/</url>
      <content type="html"><![CDATA[<h1 id="marathon-lb配置"><a href="#marathon-lb配置" class="headerlink" title="marathon-lb配置"></a>marathon-lb配置</h1><h2 id="marathon-lb-get-images"><a href="#marathon-lb-get-images" class="headerlink" title="marathon-lb get images"></a>marathon-lb get images</h2><p>Marathon-lb既是一个服务发现工具，也是负载均衡工具，它集成了haproxy，自动获取各个app的信息，为每一组app生成haproxy配置，通过servicePort或者web虚拟主机提供服务。</p><p>要使用marathonn-lb，每组app必须设置HAPROXY_GROUP标签。</p><p>Marathon-lb运行时绑定在各组app定义的服务端口（servicePort，如果app不定义servicePort，marathon会随机分配端口号）上，可以通过marathon-lb所在节点的相关服务端口访问各组app。</p><p>例如：marathon-lb部署在slave5，test-app 部署在slave1，test-app 的servicePort是10004，那么可以在slave5的 10004端口访问到test-app提供的服务。</p><p>由于servicePort 非80、443端口（80、443端口已被marathon-lb中的 haproxy独占），对于web服务来说不太方便，可以使用 haproxy虚拟主机解决这个问题：</p><p>在提供web服务的app配置里增加HAPROXY_{n}_VHOST（WEB虚拟主机）标签，marathon-lb会自动把这组app的WEB集群服务发布在marathon-lb所在节点的80和443端口上，用户设置DNS后通过虚拟主机名来访问。</p><a id="more"></a><h3 id="官方下载镜像"><a href="#官方下载镜像" class="headerlink" title="官方下载镜像"></a>官方下载镜像</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">images url :</span><br><span class="line">https://store.docker.com/community/images/mesosphere/marathon-lb</span><br><span class="line"></span><br><span class="line">docker pull mesosphere/marathon-lb</span><br><span class="line"></span><br><span class="line">github url:</span><br><span class="line">https://github.com/mesosphere/marathon-lb</span><br></pre></td></tr></table></figure><h3 id="运行"><a href="#运行" class="headerlink" title="运行"></a>运行</h3><p>docker</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -d --privileged -e PORTS=9090 --net=host docker.io/mesosphere/marathon-lb sse -m http://marathon1_ip:8080 -m http://marathon2_ip:8080 -m http://master3_ip:8080  --group external</span><br></pre></td></tr></table></figure><p>marathon</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">vim marathon-lb.json</span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line">    &quot;id&quot;: &quot;marathon-lb-testv1&quot;,</span><br><span class="line">    &quot;instances&quot;: 1,</span><br><span class="line">    &quot;constraints&quot;: [</span><br><span class="line">        [</span><br><span class="line">            &quot;hostname&quot;,</span><br><span class="line">            &quot;CLUSTER&quot;,</span><br><span class="line">            &quot;host-hostname.com&quot;</span><br><span class="line">        ]</span><br><span class="line">    ],</span><br><span class="line">    &quot;container&quot;: &#123;</span><br><span class="line">        &quot;type&quot;: &quot;DOCKER&quot;,</span><br><span class="line">        &quot;docker&quot;: &#123;</span><br><span class="line">            &quot;image&quot;: &quot;docker.io/mesosphere/marathon-lb:latest&quot;,</span><br><span class="line">            &quot;privileged&quot;: true,</span><br><span class="line">            &quot;network&quot;: &quot;HOST&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;args&quot;: [</span><br><span class="line">        &quot;sse&quot;,</span><br><span class="line">        &quot;-m&quot;,</span><br><span class="line">        &quot;http://10.10.131.78:8080&quot;,</span><br><span class="line">        &quot;--auth-credentials&quot;,</span><br><span class="line">        &quot;admin:adminpassword&quot;,</span><br><span class="line">        &quot;--group&quot;,</span><br><span class="line">        &quot;external&quot;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">curl -X POST http://10.10.131.78:8080/v2/apps -d @marathon-lb.json -H &quot;Content-type: application/json&quot;</span><br></pre></td></tr></table></figure><h2 id="marathon-lb-API"><a href="#marathon-lb-API" class="headerlink" title="marathon-lb API"></a>marathon-lb API</h2><table><thead><tr><th>Endpoint</th><th>Description</th></tr></thead><tbody><tr><td>:9090/haproxy?stats</td><td>HAProxy stats endpoint. This produces an HTML page which can be viewed in your browser, providing various statistics about the current HAProxy instance.</td></tr><tr><td>:9090/haproxy?stats;csv</td><td>This is a CSV version of the stats above, which can be consumed by other tools. For example, it’s used in the zdd.py script.</td></tr><tr><td>:9090/_haproxy_health_check</td><td>HAProxy health check endpoint. Returns 200 OK if HAProxy is healthy.</td></tr><tr><td>:9090/_haproxy_getconfig</td><td>Returns the HAProxy config file as it was when HAProxy was started. Implemented in getconfig.lua.</td></tr><tr><td>:9090/_haproxy_getvhostmap</td><td>Returns the HAProxy vhost to backend map. This endpoint returns HAProxy map file only when the –haproxy-map flag is enabled, it returns an empty string otherwise. Implemented in getmaps.lua.</td></tr><tr><td>:9090/_haproxy_getappmap</td><td>Returns the HAProxy app ID to backend map. Like _haproxy_getvhostmap, this requires the –haproxy-map flag to be enabled and returns an empty string otherwise. Also implemented in getmaps.lua.</td></tr><tr><td>:9090/_haproxy_getpids</td><td>Returns the PIDs for all HAProxy instances within the current process namespace. This literally returns $(pidof haproxy). Implemented in getpids.lua. This is also used by the zdd.py script to determine if connections have finished draining during a deploy.</td></tr><tr><td>:9090/_mlb_signal/hup*</td><td>Sends a SIGHUP signal to the marathon-lb process, causing it to fetch the running apps from Marathon and reload the HAProxy config as though an event was received from Marathon.</td></tr><tr><td>:9090/_mlb_signal/usr1*</td><td>Sends a SIGUSR1 signal to the marathon-lb process, causing it to restart HAProxy with the existing config, without checking Marathon for changes.</td></tr></tbody></table><ul><li>API from marathon-lb <a href="https://github.com/mesosphere/marathon-lb" target="_blank" rel="noopener">!github</a></li><li>marathon-lb 文档详解 <a href="https://github.com/mesosphere/marathon-lb/blob/master/Longhelp.md#templates" target="_blank" rel="noopener">!https://github.com/mesosphere/marathon-lb/blob/master/Longhelp.md#templates</a></li></ul><p>如常用： <a href="http://marathon-lb-ip:9090/haproxy?stats" target="_blank" rel="noopener">http://marathon-lb-ip:9090/haproxy?stats</a></p><h2 id="nginx-start"><a href="#nginx-start" class="headerlink" title="nginx start"></a>nginx start</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"># vim nginx.json</span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line">    &quot;id&quot;: &quot;nginx-test&quot;,</span><br><span class="line">    &quot;cpus&quot;: 0.2,</span><br><span class="line">    &quot;mem&quot;: 128,</span><br><span class="line">    &quot;instances&quot;: 1,</span><br><span class="line">  &quot;labels&quot;: &#123;</span><br><span class="line">     &quot;HAPROXY_GROUP&quot;:&quot;external&quot;</span><br><span class="line">     &quot;HAPROXY_0_VHOST&quot;:&quot;nginx.test.com&quot;</span><br><span class="line">  &#125;,</span><br><span class="line">    &quot;uris&quot;: [</span><br><span class="line">        &quot;http://10.10.130.201/download/docker_img/db-harbor-admin.tar.gz&quot;</span><br><span class="line">    ],</span><br><span class="line">    &quot;healthChecks&quot;: [&#123; &quot;path&quot;: &quot;/&quot; &#125;],</span><br><span class="line">    &quot;container&quot;: &#123;</span><br><span class="line">        &quot;type&quot;: &quot;DOCKER&quot;,</span><br><span class="line">        &quot;docker&quot;: &#123;</span><br><span class="line">            &quot;image&quot;: &quot;nginx:1.13&quot;,</span><br><span class="line">            &quot;network&quot;: &quot;BRIDGE&quot;,</span><br><span class="line">            &quot;portMappings&quot;: [</span><br><span class="line">                &#123;</span><br><span class="line">                    &quot;containerPort&quot;: 80,</span><br><span class="line">                    &quot;hostPort&quot;: 0,</span><br><span class="line">                    &quot;servicePort&quot;: 10000,</span><br><span class="line">                    &quot;protocol&quot;: &quot;tcp&quot;</span><br><span class="line">                &#125;</span><br><span class="line">            ]</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"># curl -X POST http://10.10.131.78:8080/v2/apps -d @nginx.json -H &quot;Content-type: application/json&quot;</span><br></pre></td></tr></table></figure><h2 id="说明："><a href="#说明：" class="headerlink" title="说明："></a>说明：</h2><ol><li>一定要加上HAPROXY_GROUP标签，它填写的是marathon-lb创建时定义的组名 </li><li>HAPROXY_0_VHOST是标签名，对于web服务可以加上VHOST标签，让marathon-lb设置WEB虚拟主机；</li><li>containerPort为80,是指容器内的端口。</li><li>hostPort是当前主机映射到contenterPort的端口，如果hostPort为0的话,则说明是随机的。</li><li>serverPort是marathon-lb需要配置的haproxy代理暴露的端口,这里设置为10000，说明访问marathon-lb机器的10000端口就可为访问这个应用容器的80端口。</li></ol><h2 id="访问marathon-lb"><a href="#访问marathon-lb" class="headerlink" title="访问marathon-lb"></a>访问marathon-lb</h2><p>ip 访问</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl http://marathon-lb_ip:10000/</span><br></pre></td></tr></table></figure><ul><li>访问marathon-lb部署的宿主机ip地址和serverPort的端口。</li></ul><p>域名访问</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">需要添加dns解析，根据 &quot;HAPROXY_0_VHOST&quot;:&quot;nginx.test.com&quot; 设置的配置。</span><br><span class="line">如：</span><br><span class="line">vim /etc/hosts  添加</span><br><span class="line">10.10.131.151nginx.test.com</span><br><span class="line"></span><br><span class="line">这里 10.10.131.151 是 marathon-lb 的ip地址</span><br><span class="line"></span><br><span class="line">curl nginx.test.com  即可</span><br></pre></td></tr></table></figure><h2 id="marathon-lb-代理80端口"><a href="#marathon-lb-代理80端口" class="headerlink" title="marathon-lb 代理80端口"></a>marathon-lb 代理80端口</h2><p>默认marathon-lb 80和443端口是被占用的，所以nginx在发布的时候“serverPort”是不能设置为80和443端口的。  </p><p>为了解决这个问题，需要更改源码，重新生成镜像。  </p><p>首先现在 marathon-lb源码：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"># git clone https://github.com/mesosphere/marathon-lb.git</span><br><span class="line"># cd marathon-lb</span><br><span class="line"></span><br><span class="line">在这个目录下找到所有80、443端口信息。改为其他端口</span><br><span class="line"></span><br><span class="line"># grep 80 . -R</span><br><span class="line">找到相应文件，80 替换为7080</span><br><span class="line">:%s/80/7080/g</span><br><span class="line"></span><br><span class="line">找到相应文件，443 替换为7443</span><br><span class="line">:%s/443/7443/g</span><br></pre></td></tr></table></figure><p>重新生成镜像</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">docker build -t marathon-lb-7080 .</span><br><span class="line"></span><br><span class="line">成功之后 docker images 就会多出 marathon-lb-7080 镜像</span><br></pre></td></tr></table></figure><p>感觉文章还可以的话，帮忙点点下面的广告哦！ 谢谢支持！</p>]]></content>
      
      <categories>
          
          <category> marathon </category>
          
      </categories>
      
      
        <tags>
            
            <tag> marathon </tag>
            
            <tag> marathon-lb </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>mesos-dns搭建</title>
      <link href="/mesos-dns-installed/"/>
      <url>/mesos-dns-installed/</url>
      <content type="html"><![CDATA[<h2 id="mesos-dns-搭建"><a href="#mesos-dns-搭建" class="headerlink" title="mesos-dns 搭建"></a>mesos-dns 搭建</h2><p>  Mesos-DNS用来支持Mesos集群上的服务发现，使运行在Mesos上的应用和服务可以通过域名服务器来发现彼此。你只要知道一个Mesos数据中心上运行的应用的名字，就可以通过Mesos-DNS查询到该应用的IP和端口号。  </p><h4 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h4><p>  官方下载mesos-dns镜像没有提供mesos-dns的HTTP接口出来，所以先用二进制搭建，在自己build镜像。  </p><p>  mesos-dns文件下载：<a href="https://github.com/mesosphere/mesos-dns/releases" target="_blank" rel="noopener">!https://github.com/mesosphere/mesos-dns/releases</a></p><p>  下载 mesos-dns-v0.6.0-linux-amd64 一个二进制文件。</p><p>  准备配置文件：config.json</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;zk&quot;: &quot;zk://10.0.0.52:2181,10.0.0.53:2181,10.0.0.54:2181/mesos&quot;,</span><br><span class="line">  &quot;masters&quot;: [&quot;10.0.0.52:5050&quot;, &quot;10.0.0.53:5050&quot;, &quot;10.0.0.54:5050&quot;],</span><br><span class="line">  &quot;refreshSeconds&quot;: 10,</span><br><span class="line">  &quot;ttl&quot;: 0,</span><br><span class="line">  &quot;domain&quot;: &quot;mesos&quot;,</span><br><span class="line">  &quot;port&quot;: 53,</span><br><span class="line">  &quot;resolvers&quot;: [&quot;10.10.130.5&quot;],</span><br><span class="line">  &quot;timeout&quot;: 5, </span><br><span class="line">  &quot;httpon&quot;: true,</span><br><span class="line">  &quot;dnson&quot;: true,</span><br><span class="line">  &quot;httpport&quot;: 8123,</span><br><span class="line">  &quot;externalon&quot;: true,</span><br><span class="line">  &quot;listener&quot;: &quot;0.0.0.0&quot;,</span><br><span class="line">  &quot;SOAMname&quot;: &quot;docker-test.com&quot;,</span><br><span class="line">  &quot;SOARname&quot;: &quot;root.docker-test.com&quot;,</span><br><span class="line">  &quot;SOARefresh&quot;: 10,</span><br><span class="line">  &quot;SOARetry&quot;:   3,</span><br><span class="line">  &quot;SOAExpire&quot;:  86400,</span><br><span class="line">  &quot;SOAMinttl&quot;: 10,</span><br><span class="line">  &quot;IPSources&quot;: [&quot;netinfo&quot;, &quot;mesos&quot;, &quot;host&quot;]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>启动 mesos-dns</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mv mesos-dns-v0.6.0-linux-amd64 mesos-dns</span><br><span class="line">chmod +x mesos-dns</span><br><span class="line">./mesos-dns -config=config.json -v=2</span><br></pre></td></tr></table></figure><p>mesos-dns 会启动 53 和 8123 两个端口， 53 为dns端口，8123 为http api端口。  </p><h5 id="HTTP-API-接口"><a href="#HTTP-API-接口" class="headerlink" title="HTTP API 接口"></a>HTTP API 接口</h5><table><thead><tr><th>URL</th><th>说明 </th></tr></thead><tbody><tr><td> <a href="http://10.0.0.49:8123/v1/version" target="_blank" rel="noopener">http://10.0.0.49:8123/v1/version</a></td><td>mesos-dns版本信息</td></tr><tr><td> <a href="http://10.0.0.49:8123/v1/config" target="_blank" rel="noopener">http://10.0.0.49:8123/v1/config</a></td><td>mesos-dns配置信息</td></tr><tr><td> <a href="http://10.0.0.49:8123/v1/hosts/{host}" target="_blank" rel="noopener">http://10.0.0.49:8123/v1/hosts/{host}</a></td><td>该host的IP地址信息</td></tr><tr><td> <a href="http://10.0.0.49:8123/v1/services/{service}" target="_blank" rel="noopener">http://10.0.0.49:8123/v1/services/{service}</a></td><td>该service的host、IP、端口信息</td></tr></tbody></table><p> 例子：</p><pre><code>http://10.0.0.49:8123/v1/hosts/nginxqq-nginx.marathon.slave.mesos</code></pre><p>  分析：marathon.slave.mesos 是固定的，mesos是condig.json中domain定义的，在往前是从节点，marathon是框架，nginx是组，nginxqq是appid </p><pre><code>http://10.0.0.49:8123/v1/services/_nginxqq-nginx._tcp.marathon.slave.mesos  </code></pre><p>  分析： _nginxqq-nginx._tcp.marathon.slave.mesos ， nginxqq容器的ID名，nginx为组名，_tcp.marathon.slave.mesos 为固定的。</p><h5 id="dig-获取mesos-dns信息"><a href="#dig-获取mesos-dns信息" class="headerlink" title="dig 获取mesos-dns信息"></a>dig 获取mesos-dns信息</h5><p>查找app所在节点的IP</p><pre><code>dig nginxqq-nginx.marathon.slave.mesos +short</code></pre><p>查找app服务端口号</p><pre><code>dig SRV _nginxqq-nginx._tcp.marathon.slave.mesos +short </code></pre><ul><li>其中 过得到的主机名 mesos-dns 是可以解析的，就是app所在的物理机。</li></ul><h4 id="docker-images"><a href="#docker-images" class="headerlink" title="docker images"></a>docker images</h4><p>创建 docker file 目录，放入所用的文件</p><pre><code>mkdir dockerfile-mesos-dnscd dockerfile-mesos-dnscp ~/mesos-dns .cp ~/config.json .</code></pre><p>编辑 Dockerfile 文件  </p><p>vim Dockerfile</p><pre><code>FROM centos:6WORKDIR /root/ADD mesos-dns /root/ADD config.json /root/EXPOSE 53 8123CMD [&quot;/root/mesos-dns&quot;, &quot;-config=/root/config.json&quot;, &quot;-v=2&quot;]</code></pre><p>生成镜像</p><pre><code>docker build -t stg-mesos-dns:0.6.0 .</code></pre><p>运行镜像</p><pre><code>docker run  -d --name=stg-mesos-dns --net=host stg-mesos-dns:0.6.0</code></pre><p>感觉文章还可以的话，帮忙点点下面的广告哦！ 谢谢支持！</p>]]></content>
      
      <categories>
          
          <category> mesos </category>
          
      </categories>
      
      
        <tags>
            
            <tag> mesos </tag>
            
        </tags>
      
    </entry>
    
  
  
</search>
